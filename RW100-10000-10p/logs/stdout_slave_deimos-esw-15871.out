/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-15871 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-15871
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0788670 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@14320874
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5704, using socket ServerSocket[addr=/0.0.0.0,localport=5704], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5704
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 59794 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 36455 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 59968 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5704 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5704 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5704 this
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
	Member [127.0.0.1]:5713
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 51046 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 58068 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 51176 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:53356
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 54948 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 34017 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 33697 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5713, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:53356
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 38261 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 52745 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34825
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 39492 accepted socket connection from /127.0.0.1:5713
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:34825
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34741
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:34741
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:50945
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:50945
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:40302
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:40302
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 1
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Creating cache with the following configuration: hzl3-repl-sync.xml
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5714, using socket ServerSocket[addr=/0.0.0.0,localport=5714], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5714 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5714
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5714 [dev] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5714 [dev] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5714 [dev] Address[127.0.0.1]:5714 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5714 [dev] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5714 [dev] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5714 [dev] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 55411 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 52782 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 56290 accepted socket connection from /127.0.0.1:5701
[GC 259695K->11177K(2944064K), 0.0407730 secs]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5714 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
 WARN  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5714 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5714 [dev] 

Members [12] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5714 this
	Member [127.0.0.1]:5715
	Member [127.0.0.1]:5716
	Member [127.0.0.1]:5717
	Member [127.0.0.1]:5718
	Member [127.0.0.1]:5719
	Member [127.0.0.1]:5720
	Member [127.0.0.1]:5721
	Member [127.0.0.1]:5722
	Member [127.0.0.1]:5723
	Member [127.0.0.1]:5724
}

 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5715, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:49509
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 41265 accepted socket connection from /127.0.0.1:5715
 INFO  [hz._hzInstance_2_dev.cached.thread-13] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5716, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5718, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5719, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:49509
 INFO  [hz._hzInstance_2_dev.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5717, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-14] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5723, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:34339
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 42571 accepted socket connection from /127.0.0.1:5719
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 55281 accepted socket connection from /127.0.0.1:5718
 INFO  [hz._hzInstance_2_dev.cached.thread-16] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5722, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 44787 accepted socket connection from /127.0.0.1:5716
 INFO  [hz._hzInstance_2_dev.cached.thread-16] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 58430 accepted socket connection from /127.0.0.1:5722
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5720, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5721, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5714 [dev] Connecting to /127.0.0.1:5724, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 43619 accepted socket connection from /127.0.0.1:5720
 INFO  [hz._hzInstance_2_dev.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 56677 accepted socket connection from /127.0.0.1:5723
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:34339
 INFO  [hz._hzInstance_2_dev.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 44280 accepted socket connection from /127.0.0.1:5717
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 58887 accepted socket connection from /127.0.0.1:5724
 INFO  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 51756 accepted socket connection from /127.0.0.1:5721
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:42327
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:42327
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:36702
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:36702
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:42594
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:42594
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:45533
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:45533
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:48373
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:48373
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:50926
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:50926
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:36613
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:36613
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5714 [dev] Accepting socket connection from /127.0.0.1:36122
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5714 [dev] 5714 accepted socket connection from /127.0.0.1:36122
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5714 [dev] Config seed port is 5701 and cluster size is 12. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5714 [dev] Address[127.0.0.1]:5714 is STARTED
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 1, serverOidBase: 1000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@1d9eaef2
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 WARN  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> 8a68affd-584c-48ab-b9a8-5be45832bf7a
 WARN  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> 2e87b37a-36fc-4ba3-a42b-36991299ad5c
 WARN  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> fb565a18-5900-4922-b0e0-eec50e36c5da
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 WARN  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> 8edef975-64b2-4e06-9cd3-5a78cc64310e
 WARN  [hz._hzInstance_2_dev.cached.thread-15] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> 7c169ca2-bfcf-44b8-86f7-be20a692d988
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5714 [dev] No tx backup log is found, tx -> d954cdb6-b917-4f8d-9c93-224c0ee80039
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=10000, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@1d9eaef2, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
 INFO  [hz._hzInstance_2_dev.scheduled] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5714 [dev] Re-sending sync replica request for partition: 0, replica: 1
[GC 267241K->13306K(2944064K), 0.0371840 secs]
[GC 269370K->17639K(2944064K), 0.0376180 secs]
[GC 273703K->24302K(2944064K), 0.0399540 secs]
[GC 280366K->29659K(2944064K), 0.0392090 secs]
[GC 285723K->38145K(2944064K), 0.0397750 secs]
 INFO  [Stressor-0] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=26539 <= mostRecentNum=26541.
[GC 294209K->53265K(2944064K), 0.0433130 secs]
[GC 309329K->56187K(2944064K), 0.0452720 secs]
[GC 312251K->56819K(2944064K), 0.0443200 secs]
[GC 312883K->64879K(2944064K), 0.0472330 secs]
[GC 320943K->84747K(2944064K), 0.0553990 secs]
[GC 340811K->100550K(2944064K), 0.0531870 secs]
[GC 356614K->102739K(2944064K), 0.0763690 secs]
[GC 358803K->114748K(2944064K), 0.0723860 secs]
[GC 370812K->117937K(2944064K), 0.0625720 secs]
[GC 374001K->110339K(2944064K), 0.0640630 secs]
 INFO  [Stressor-3] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=86094 <= mostRecentNum=86095.
[GC 366403K->129872K(2944064K), 0.0652830 secs]
[GC 385936K->139398K(2944064K), 0.0644810 secs]
[GC 395462K->145304K(2944064K), 0.0792900 secs]
[GC 401368K->152512K(2944064K), 0.0539380 secs]
 INFO  [Stressor-3] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=101159 <= mostRecentNum=101161.
[GC 408576K->153478K(2944064K), 0.0680600 secs]
[GC 409542K->160503K(2944064K), 0.0523130 secs]
[GC 416567K->163935K(2944064K), 0.0559490 secs]
[GC 419999K->161874K(2944064K), 0.0718540 secs]
[GC 417938K->164999K(2944064K), 0.0619600 secs]
[GC 421063K->175128K(2944064K), 0.0679800 secs]
[GC 431192K->187522K(2944064K), 0.0703360 secs]
[GC 443586K->192479K(2944064K), 0.0568260 secs]
[GC 448543K->211185K(2944064K), 0.0595880 secs]
[GC 467249K->199435K(2944064K), 0.0670250 secs]
[GC 455499K->209952K(2944064K), 0.0572250 secs]
[GC 466016K->236295K(2944064K), 0.0640280 secs]
[GC 492359K->210240K(2944064K), 0.0657310 secs]
[GC 466304K->254379K(2944064K), 0.0634170 secs]
[GC 510443K->219612K(2944064K), 0.0664810 secs]
[GC 475676K->265983K(2944064K), 0.0671980 secs]
[GC 522047K->231111K(2944064K), 0.0657890 secs]
[GC 487175K->278064K(2944064K), 0.0640020 secs]
[GC 534128K->242938K(2944064K), 0.0664200 secs]
[GC 499002K->290075K(2944064K), 0.0654860 secs]
[GC 546139K->254567K(2944064K), 0.0667930 secs]
[GC 510631K->285938K(2944064K), 0.0680930 secs]
[GC 542002K->300810K(2944064K), 0.0665700 secs]
[GC 556874K->274397K(2944064K), 0.0705810 secs]
[GC 530461K->319498K(2944064K), 0.0777630 secs]
[GC 575562K->302592K(2944064K), 0.0870920 secs]
[GC 558656K->312454K(2944064K), 0.0730700 secs]
[GC 568518K->329942K(2944064K), 0.0665340 secs]
[GC 586006K->334403K(2944064K), 0.0676960 secs]
[GC 590467K->340251K(2944064K), 0.0680370 secs]
[GC 596315K->346266K(2944064K), 0.0705880 secs]
 INFO  [Stressor-1] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=287894 <= mostRecentNum=287897.
[GC 602330K->322956K(2944064K), 0.0770740 secs]
[GC 579020K->334227K(2944064K), 0.0770790 secs]
[GC 590291K->356818K(2944064K), 0.0604530 secs]
[GC 612882K->376470K(2944064K), 0.0646230 secs]
[GC 632534K->384286K(2944064K), 0.0793890 secs]
[GC 640350K->416692K(2944064K), 0.0768400 secs]
[GC 672756K->394990K(2944064K), 0.0817640 secs]
[GC 651054K->429679K(2944064K), 0.0694140 secs]
[GC 685743K->394850K(2944064K), 0.0705800 secs]
[GC 650914K->440188K(2944064K), 0.0702420 secs]
[GC 696252K->406670K(2944064K), 0.0685960 secs]
[GC 662734K->452252K(2944064K), 0.0672540 secs]
[GC 708316K->425043K(2944064K), 0.0711410 secs]
[GC 681107K->456216K(2944064K), 0.0646950 secs]
[GC 712280K->486687K(2944064K), 0.0838550 secs]
[GC 742751K->463676K(2944064K), 0.0779050 secs]
[GC 719740K->501200K(2944064K), 0.0685540 secs]
[GC 757264K->465984K(2944064K), 0.0699240 secs]
[GC 722048K->511016K(2944064K), 0.0702210 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 767080K->487368K(2944064K), 0.0714970 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 50000. Elapsed time: 20.751 secs. Remaining: 39.249 secs. Total: 1 mins 0 secs
[GC 743432K->503429K(2944064K), 0.0808420 secs]
[GC 759493K->515395K(2944064K), 0.0732170 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 160000. Elapsed time: 45.001 secs. Remaining: 14.999 secs. Total: 1 mins 0 secs
[GC 771459K->556587K(2944064K), 0.0571020 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 180000. Elapsed time: 1 mins 8 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 812651K->520109K(2944064K), 0.0659930 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 50 mins 10 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 3010 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 776173K->561400K(2944064K), 0.0695190 secs]
[GC 817464K->582759K(2944064K), 0.0986650 secs]
[GC 838823K->606737K(2944064K), 0.1049370 secs]
[GC 862801K->636676K(2944064K), 0.1232750 secs]
[GC 892740K->657142K(2944064K), 0.1007790 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5713] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5713] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5704 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 76 ms.
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5721] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5720] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5720] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5721] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5719] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5723] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5723] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5718] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5724] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5724] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5717] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5722] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5722] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5717] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5718] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5714 [dev] Connection [Address[127.0.0.1]:5719] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5714 [dev] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5714 [dev] Hazelcast Shutdown is completed in 306 ms.
