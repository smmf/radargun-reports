/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-2405 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-2405
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0604440 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@500ae176
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36071
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36071
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 54615 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:52711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42603
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:42603
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:49100
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:49100
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41014
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:41014
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34553
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:34553
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38487
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:38487
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:46723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:46723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:46932
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:46932
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:51551
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:51551
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 1
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 2
[GC 259695K->13657K(2944064K), 0.0576040 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|1] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-27097, physical addresses are [127.0.0.1:52002]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|2] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|3] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404]
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|4] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|5] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830]
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|6] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120]
 INFO  [Incoming-4,deimos-esw-27097] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|7] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120, deimos-esw-29201]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 1, serverOidBase: 1000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@6a5f8639
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 2
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6a5f8639, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269721K->22287K(2944064K), 0.0590070 secs]
[GC 278351K->30534K(2944064K), 0.0470670 secs]
[GC 286598K->46371K(2944064K), 0.0518350 secs]
[GC 302435K->66298K(2944064K), 0.0549110 secs]
[GC 322362K->71467K(2944064K), 0.0580020 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 327528K->113974K(2944064K), 0.0646680 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6700. Elapsed time: 20.294 secs. Remaining: 39.706 secs. Total: 1 mins 0 secs
[GC 370038K->116756K(2944064K), 0.1227620 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15900. Elapsed time: 40.327 secs. Remaining: 19.673 secs. Total: 1 mins 0 secs
[GC 372820K->112389K(2944064K), 0.0895240 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 51 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 171 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 368453K->137559K(2944064K), 0.0700370 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,573,982 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 370081K->132496K(2944064K), 0.6745840 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,810,794 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6a5f8639, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 388624K->198652K(2944192K), 0.0371630 secs]
[GC 454780K->155148K(2944192K), 0.0380190 secs]
[GC 411276K->166204K(2944192K), 0.0453660 secs]
[GC 422332K->177643K(2944192K), 0.0623620 secs]
[GC 433771K->191924K(2944192K), 0.0777660 secs]
[GC 448052K->207455K(2944192K), 0.0909060 secs]
[GC 463583K->222734K(2944192K), 0.1068500 secs]
[GC 478862K->237947K(2944192K), 0.1383030 secs]
[GC 494075K->238663K(2944192K), 0.1503080 secs]
[GC 494791K->269843K(2944192K), 0.1755960 secs]
[GC 525971K->286955K(2944192K), 0.1384660 secs]
[GC 543030K->301729K(2944192K), 0.1093310 secs]
[GC 557676K->287825K(2944192K), 0.1036250 secs]
[GC 543953K->297321K(2944192K), 0.0774400 secs]
[GC 553449K->348581K(2944192K), 0.0831560 secs]
[GC 604709K->334586K(2944192K), 0.0769330 secs]
[GC 590714K->369715K(2944192K), 0.0562630 secs]
[GC 625843K->376028K(2944192K), 0.0578710 secs]
[GC 632156K->358292K(2944192K), 0.0981340 secs]
[GC 614420K->379315K(2944192K), 0.0923830 secs]
[GC 635429K->376800K(2944192K), 0.1167860 secs]
[GC 632928K->424776K(2944192K), 0.0765670 secs]
[GC 680892K->447149K(2944192K), 0.0752660 secs]
[GC 703277K->461745K(2944192K), 0.1372730 secs]
[GC 717873K->467220K(2944192K), 0.1090180 secs]
[GC 723348K->455566K(2944192K), 0.0779290 secs]
[GC 711694K->488695K(2944192K), 0.0771740 secs]
[GC 744823K->489792K(2944192K), 0.0800720 secs]
[GC 745920K->533964K(2944192K), 0.0555440 secs]
[GC 790092K->496183K(2944192K), 0.0594690 secs]
[GC 752311K->505375K(2944192K), 0.0835990 secs]
[GC 761503K->539279K(2944192K), 0.0614690 secs]
[GC 795407K->560284K(2944192K), 0.0621670 secs]
[GC 816412K->534822K(2944192K), 0.0812160 secs]
[GC 790950K->564989K(2944192K), 0.0945770 secs]
[GC 821117K->580096K(2944192K), 0.1039310 secs]
[GC 836224K->552925K(2944192K), 0.1188980 secs]
[GC 809053K->587193K(2944192K), 0.0713800 secs]
[GC 843321K->602137K(2944192K), 0.1301090 secs]
[GC 858265K->596773K(2944192K), 0.0760000 secs]
[GC 852901K->587738K(2944192K), 0.0764960 secs]
[GC 843866K->629742K(2944192K), 0.1567770 secs]
[GC 885870K->603507K(2944192K), 0.0754470 secs]
[GC 859635K->634428K(2944192K), 0.1213740 secs]
[GC 890556K->626062K(2944192K), 0.1823420 secs]
[GC 882190K->653067K(2944192K), 0.0682740 secs]
[GC 909195K->659291K(2944192K), 0.0860330 secs]
[GC 915419K->661269K(2944192K), 0.0768390 secs]
[GC 917397K->666546K(2944192K), 0.1263110 secs]
[GC 922674K->680986K(2944192K), 0.0673920 secs]
[GC 937114K->672548K(2944192K), 0.0852760 secs]
[GC 928676K->698691K(2944192K), 0.0678710 secs]
[GC 954819K->696619K(2944192K), 0.0776150 secs]
[GC 952747K->705038K(2944192K), 0.0813090 secs]
[GC 961166K->712619K(2944192K), 0.0967330 secs]
[GC 968747K->719637K(2944192K), 0.0820780 secs]
[GC 975765K->727901K(2944192K), 0.0734230 secs]
[GC 984029K->734486K(2944192K), 0.1413040 secs]
[GC 990614K->740839K(2944192K), 0.0735510 secs]
[GC 996967K->749319K(2944192K), 0.0806130 secs]
[GC 1005447K->772847K(2944192K), 0.1322820 secs]
[GC 1028975K->746707K(2944192K), 0.0724430 secs]
[GC 1002835K->777404K(2944192K), 0.0780870 secs]
[GC 1033532K->791449K(2944192K), 0.1228220 secs]
[GC 1047577K->767444K(2944192K), 0.0724350 secs]
[GC 1023572K->798417K(2944192K), 0.0757760 secs]
[GC 1054545K->797276K(2944192K), 0.0756190 secs]
[GC 1053404K->807196K(2944192K), 0.1178850 secs]
[GC 1063324K->832346K(2944192K), 0.1331560 secs]
[GC 1088474K->804664K(2944192K), 0.0741900 secs]
[GC 1060792K->835299K(2944192K), 0.0841630 secs]
[GC 1091427K->850509K(2944192K), 0.0763430 secs]
[GC 1106637K->825225K(2944192K), 0.0930900 secs]
[GC 1081353K->873385K(2944192K), 0.1050680 secs]
[GC 1129513K->858404K(2944192K), 0.1269940 secs]
[GC 1114532K->905417K(2944192K), 0.1085490 secs]
[GC 1161529K->919182K(2944192K), 0.1227450 secs]
[GC 1175257K->912146K(2944192K), 0.0945910 secs]
[GC 1168274K->947834K(2944192K), 0.0932940 secs]
[GC 1203962K->924732K(2944192K), 0.0947020 secs]
[GC 1180860K->939123K(2944192K), 0.0893760 secs]
[GC 1195251K->980363K(2944192K), 0.0739820 secs]
[GC 1236491K->954464K(2944192K), 0.0994310 secs]
[GC 1210592K->992325K(2944192K), 0.0702020 secs]
[GC 1248453K->970174K(2944192K), 0.0859550 secs]
[GC 1226302K->1003085K(2944192K), 0.0651630 secs]
[GC 1259213K->1007314K(2944192K), 0.0692790 secs]
[GC 1263442K->1016624K(2944192K), 0.0804320 secs]
[GC 1272752K->1027617K(2944192K), 0.0697980 secs]
[GC 1283745K->1042208K(2944192K), 0.0803570 secs]
[GC 1298336K->1017830K(2944192K), 0.1329970 secs]
[GC 1273958K->1074797K(2944192K), 0.0982800 secs]
[GC 1330888K->1095772K(2944192K), 0.1024030 secs]
[GC 1351882K->1077031K(2944192K), 0.0950030 secs]
[GC 1333159K->1129948K(2944192K), 0.0999430 secs]
[GC 1386076K->1113581K(2944192K), 0.0842030 secs]
[GC 1369709K->1108522K(2944192K), 0.0836150 secs]
[GC 1364650K->1149466K(2944192K), 0.0694900 secs]
[GC 1405594K->1141559K(2944192K), 0.0946650 secs]
[GC 1397687K->1161724K(2944192K), 0.0753020 secs]
[GC 1417852K->1142348K(2944192K), 0.0955990 secs]
[GC 1398476K->1187192K(2944192K), 0.0731700 secs]
[GC 1443320K->1215919K(2944192K), 0.0934390 secs]
[GC 1472047K->1230952K(2944192K), 0.0974430 secs]
[GC 1487080K->1244948K(2944192K), 0.1261770 secs]
[GC 1501076K->1268028K(2944192K), 0.0995620 secs]
[GC 1524156K->1258449K(2944192K), 0.0977750 secs]
[GC 1514577K->1305195K(2944192K), 0.1025240 secs]
[GC 1561323K->1298129K(2944192K), 0.0988830 secs]
[GC 1554257K->1319342K(2944192K), 0.1001590 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1575470K->1330388K(2944192K), 0.0934620 secs]
[GC 1586516K->1347533K(2944192K), 0.0953170 secs]
[GC 1603661K->1358681K(2944192K), 0.0873970 secs]
[GC 1614809K->1346607K(2944192K), 0.0654210 secs]
[GC 1602735K->1373134K(2944192K), 0.0770890 secs]
[GC 1373238K(2944192K), 0.0227710 secs]
[GC 1629262K->1372242K(2944192K), 0.0602840 secs]
[GC 1503899K(2944192K), 0.1142580 secs]
[GC 1420079K->1145869K(2944192K), 0.0566840 secs]
[GC 1401526K->1162738K(2944192K), 0.0608720 secs]
[GC 1418866K->1167329K(2944192K), 0.0699490 secs]
[GC 1423457K->1162456K(2944192K), 0.0647620 secs]
[GC 1418584K->1176805K(2944192K), 0.0717280 secs]
[GC 1432933K->1191169K(2944192K), 0.0731580 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7999938. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 1447297K->1195888K(2944192K), 0.0601880 secs]
[GC 1452016K->1207121K(2944192K), 0.0648980 secs]
[GC 1463249K->1206834K(2944192K), 0.0739170 secs]
[GC 1462962K->1193841K(2944192K), 0.0587020 secs]
[GC 1449969K->1228243K(2944192K), 0.0840300 secs]
[GC 1484371K->1224332K(2944192K), 0.0590270 secs]
[GC 1480444K->1222885K(2944192K), 0.0609330 secs]
[GC 1479013K->1242661K(2944192K), 0.0701260 secs]
[GC 1498789K->1237732K(2944192K), 0.0621440 secs]
[GC 1493860K->1222775K(2944192K), 0.0538440 secs]
[GC 1478903K->1232624K(2944192K), 0.0615730 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 17370000. Elapsed time: 40.014 secs. Remaining: 19.986 secs. Total: 1 mins 0 secs
[GC 1488752K->1253346K(2944192K), 0.0642240 secs]
[GC 1509474K->1244241K(2944192K), 0.0557980 secs]
[GC 1500369K->1245145K(2944192K), 0.0573120 secs]
[GC 1501273K->1255997K(2944192K), 0.0617390 secs]
[GC 1512125K->1254960K(2944192K), 0.0638800 secs]
[GC 1511088K->1249742K(2944192K), 0.0536350 secs]
[GC 1505870K->1253416K(2944192K), 0.0638330 secs]
[GC 1509544K->1283063K(2944192K), 0.0592710 secs]
[GC 1539191K->1264179K(2944192K), 0.0533680 secs]
[GC 1520307K->1270164K(2944192K), 0.0562170 secs]
[GC 1526292K->1282174K(2944192K), 0.0608550 secs]
[GC 1538162K->1285921K(2944192K), 0.0641120 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 25550000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 44 mins 26 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1542049K->1271908K(2944192K), 0.0552030 secs]
[GC 1528036K->1254780K(2944192K), 0.0597560 secs]
[GC 1510908K->1297800K(2944192K), 0.0757970 secs]
[GC 1553928K->1341633K(2944192K), 0.0950570 secs]
[GC 1597548K->1346788K(2944192K), 0.1239150 secs]
[GC 1602898K->1384179K(2944192K), 0.1045590 secs]
[GC 1640307K->1418078K(2944192K), 0.1090610 secs]
[GC 1674205K->1442656K(2944192K), 0.1120760 secs]
[GC 1698784K->1469365K(2944192K), 0.1127070 secs]
[GC 1725493K->1493958K(2944192K), 0.1128040 secs]
[GC 1749999K->1516392K(2944192K), 0.1100370 secs]
[GC 1772520K->1541322K(2944192K), 0.1123460 secs]
[GC 1797450K->1565218K(2944192K), 0.1128230 secs]
[GC 1821346K->1546865K(2944192K), 0.1066720 secs]
[GC 1802993K->1618088K(2944192K), 0.1138940 secs]
[GC 1874073K->1642426K(2944192K), 0.1078350 secs]
[GC 1898438K->1667171K(2944192K), 0.1094270 secs]
[GC 1923122K->1691930K(2944192K), 0.1038880 secs]
[GC 1948058K->1717986K(2944192K), 0.1088650 secs]
[GC 1974114K->1743576K(2944192K), 0.1057470 secs]
[GC 1999704K->1751278K(2944192K), 0.1069340 secs]
[GC 2007406K->1777169K(2944192K), 0.1048160 secs]
[GC 2033232K->1803494K(2944192K), 0.1043680 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 58 ms.
