/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-15448 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-15448
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0693710 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 9. Sleeping for 9500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 9
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@50246923
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5710, using socket ServerSocket[addr=/0.0.0.0,localport=5710], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5710
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5710 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 46797 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 55369 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 46723 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5710 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710 this
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59669
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:59669
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 36120 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45573
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:45573
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 38846 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 52999 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 59841 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 42332 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36265
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:36265
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 44869 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 38318 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41631
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:41631
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:46350
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:46350
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 8
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 9
[GC 259695K->13191K(2944064K), 0.0419270 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|5] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-35830, physical addresses are [127.0.0.1:52008]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-35830] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|6] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-35830] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|7] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120, deimos-esw-29201]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 8, serverOidBase: 8000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 9: org.radargun.cachewrappers.FFWrapper@3a6b2ec8
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@3a6b2ec8, nodeIndex=9, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269255K->22985K(2944064K), 0.0561010 secs]
[GC 279049K->31427K(2944064K), 0.0491700 secs]
[GC 287491K->52681K(2944064K), 0.0522000 secs]
[GC 308745K->67671K(2944064K), 0.0563690 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 323735K->84045K(2944064K), 0.0611620 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 13150. Elapsed time: 20.198 secs. Remaining: 39.802 secs. Total: 1 mins 0 secs
[GC 340109K->105236K(2944064K), 0.0697600 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 29600. Elapsed time: 40.299 secs. Remaining: 19.701 secs. Total: 1 mins 0 secs
[GC 361300K->115110K(2944064K), 0.1588820 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 45650. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 33 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 153 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 371174K->154097K(2944064K), 0.0687860 secs]
[GC 410161K->127631K(2944064K), 0.0888820 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,618,097 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 325966K->133867K(2944064K), 0.7504330 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,809,507 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@3a6b2ec8, nodeIndex=9, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 389995K->202602K(2944192K), 0.0348600 secs]
[GC 458730K->157335K(2944192K), 0.0417020 secs]
[GC 413463K->167869K(2944192K), 0.0418300 secs]
[GC 423997K->179134K(2944192K), 0.0495620 secs]
[GC 435262K->193423K(2944192K), 0.0519200 secs]
[GC 449551K->208758K(2944192K), 0.0582830 secs]
[GC 464886K->223924K(2944192K), 0.0610320 secs]
[GC 480052K->226747K(2944192K), 0.0644050 secs]
[GC 482875K->255241K(2944192K), 0.0707290 secs]
[GC 511362K->270383K(2944192K), 0.0929160 secs]
[GC 526511K->287317K(2944192K), 0.0956330 secs]
[GC 543409K->302415K(2944192K), 0.0907930 secs]
[GC 558543K->287958K(2944192K), 0.1086040 secs]
[GC 544055K->316046K(2944192K), 0.0876290 secs]
[GC 572174K->367066K(2944192K), 0.0892570 secs]
[GC 623194K->352828K(2944192K), 0.0952560 secs]
[GC 608956K->373286K(2944192K), 0.0641730 secs]
[GC 629414K->351076K(2944192K), 0.0849090 secs]
[GC 607204K->395788K(2944192K), 0.0620400 secs]
[GC 651916K->368373K(2944192K), 0.0693460 secs]
[GC 624501K->386410K(2944192K), 0.0920890 secs]
[GC 642538K->421471K(2944192K), 0.0973140 secs]
[GC 677599K->435085K(2944192K), 0.1089920 secs]
[GC 691213K->463504K(2944192K), 0.1202990 secs]
[GC 719596K->445290K(2944192K), 0.1428160 secs]
[GC 701385K->454354K(2944192K), 0.0812380 secs]
[GC 710482K->487557K(2944192K), 0.0842740 secs]
[GC 743685K->490671K(2944192K), 0.0943230 secs]
[GC 746799K->524853K(2944192K), 0.0642590 secs]
[GC 780981K->516722K(2944192K), 0.0682560 secs]
[GC 772850K->530456K(2944192K), 0.0897790 secs]
[GC 786584K->549285K(2944192K), 0.0665070 secs]
[GC 805413K->530877K(2944192K), 0.0694420 secs]
[GC 787005K->531500K(2944192K), 0.0896730 secs]
[GC 787628K->580130K(2944192K), 0.0688870 secs]
[GC 836258K->543955K(2944192K), 0.0719330 secs]
[GC 800083K->581234K(2944192K), 0.0829150 secs]
[GC 837362K->584202K(2944192K), 0.0964680 secs]
[GC 840330K->575357K(2944192K), 0.1205090 secs]
[GC 831485K->600359K(2944192K), 0.0901400 secs]
[GC 856487K->607829K(2944192K), 0.1609360 secs]
[GC 863957K->614414K(2944192K), 0.0815060 secs]
[GC 870542K->614285K(2944192K), 0.0978330 secs]
[GC 870413K->640115K(2944192K), 0.0726290 secs]
[GC 896243K->628558K(2944192K), 0.0922090 secs]
[GC 884686K->630251K(2944192K), 0.0788330 secs]
[GC 886379K->675482K(2944192K), 0.1441470 secs]
[GC 931610K->648642K(2944192K), 0.1686520 secs]
[GC 904770K->679374K(2944192K), 0.0747060 secs]
[GC 935502K->671235K(2944192K), 0.0857180 secs]
[GC 927363K->683953K(2944192K), 0.1537900 secs]
[GC 940081K->690727K(2944192K), 0.0853960 secs]
[GC 946855K->682047K(2944192K), 0.0849830 secs]
[GC 938175K->688570K(2944192K), 0.1738870 secs]
[GC 944698K->729099K(2944192K), 0.1572220 secs]
[GC 985227K->702582K(2944192K), 0.0835270 secs]
[GC 958710K->732016K(2944192K), 0.0976160 secs]
[GC 988144K->750788K(2944192K), 0.0852730 secs]
[GC 1006916K->724238K(2944192K), 0.0810920 secs]
[GC 980366K->753197K(2944192K), 0.0845840 secs]
[GC 1009325K->753622K(2944192K), 0.0816670 secs]
[GC 1009750K->778713K(2944192K), 0.0855940 secs]
[GC 1034841K->753005K(2944192K), 0.0805330 secs]
[GC 1009133K->783459K(2944192K), 0.0921230 secs]
[GC 1039587K->781606K(2944192K), 0.1498900 secs]
[GC 1037734K->774713K(2944192K), 0.1244380 secs]
[GC 1030841K->815238K(2944192K), 0.1122290 secs]
[GC 1071366K->789359K(2944192K), 0.0831250 secs]
[GC 1045487K->803589K(2944192K), 0.0828740 secs]
[GC 1059717K->833592K(2944192K), 0.0844610 secs]
[GC 1089720K->827877K(2944192K), 0.1681960 secs]
[GC 1084005K->834659K(2944192K), 0.1134560 secs]
[GC 1090787K->860253K(2944192K), 0.0794110 secs]
[GC 1116381K->832247K(2944192K), 0.0824340 secs]
[GC 1088375K->859943K(2944192K), 0.1227800 secs]
[GC 1116071K->860718K(2944192K), 0.1206590 secs]
[GC 1116846K->869518K(2944192K), 0.0874450 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 1125646K->878813K(2944192K), 0.1178890 secs]
[GC 1134941K->869250K(2944192K), 0.1070480 secs]
[GC 1125329K->874738K(2944192K), 0.0799500 secs]
[GC 1130866K->892328K(2944192K), 0.0894230 secs]
[GC 1148456K->893350K(2944192K), 0.0782490 secs]
[GC 1149478K->918243K(2944192K), 0.0757950 secs]
[GC 1174371K->912908K(2944192K), 0.0703170 secs]
[GC 1169036K->915467K(2944192K), 0.0747540 secs]
[GC 1171595K->930081K(2944192K), 0.0815470 secs]
[GC 1186209K->938513K(2944192K), 0.0772990 secs]
[GC 1194641K->929604K(2944192K), 0.0660430 secs]
[GC 1185732K->928648K(2944192K), 0.0581540 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8294720. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 1184776K->932785K(2944192K), 0.0615440 secs]
[GC 1188913K->948597K(2944192K), 0.0659010 secs]
[GC 1204725K->942106K(2944192K), 0.0623720 secs]
[GC 1198234K->937800K(2944192K), 0.0584620 secs]
[GC 1193926K->939796K(2944192K), 0.0560370 secs]
[GC 1195816K->953673K(2944192K), 0.0702430 secs]
[GC 1209801K->929027K(2944192K), 0.0533620 secs]
[GC 1185155K->956870K(2944192K), 0.0604030 secs]
[GC 1212998K->959007K(2944192K), 0.0635880 secs]
[GC 1215135K->971506K(2944192K), 0.0728390 secs]
[GC 1227634K->961115K(2944192K), 0.0549100 secs]
[GC 1217243K->973443K(2944192K), 0.0573490 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16419440. Elapsed time: 40.001 secs. Remaining: 19.999 secs. Total: 1 mins 0 secs
[GC 1229571K->969191K(2944192K), 0.0594170 secs]
[GC 1225319K->965457K(2944192K), 0.0568180 secs]
[GC 1221585K->967663K(2944192K), 0.0581090 secs]
[GC 1223791K->985283K(2944192K), 0.0609050 secs]
[GC 1241411K->991774K(2944192K), 0.0719890 secs]
[GC 1247902K->972173K(2944192K), 0.0559540 secs]
[GC 1228301K->979066K(2944192K), 0.0538460 secs]
[GC 1235194K->1006911K(2944192K), 0.0598180 secs]
[GC 1263039K->997507K(2944192K), 0.0641890 secs]
[GC 1253635K->996061K(2944192K), 0.0582030 secs]
[GC 1252189K->1010215K(2944192K), 0.0667100 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 24545139. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 32 mins 54 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:9, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1266343K->1011876K(2944192K), 0.0644340 secs]
[GC 1268004K->986984K(2944192K), 0.0541660 secs]
[GC 1243112K->1000983K(2944192K), 0.0644480 secs]
[GC 1257111K->1017408K(2944192K), 0.0728630 secs]
[GC 1273536K->1041391K(2944192K), 0.0837610 secs]
[GC 1297519K->1045233K(2944192K), 0.1090700 secs]
[GC 1301361K->1071151K(2944192K), 0.1144250 secs]
[GC 1327279K->1101732K(2944192K), 0.1022420 secs]
[GC 1357728K->1127082K(2944192K), 0.1169060 secs]
[GC 1383210K->1131330K(2944192K), 0.1171370 secs]
[GC 1387458K->1146833K(2944192K), 0.0998930 secs]
[GC 1402961K->1146560K(2944192K), 0.1059480 secs]
[GC 1402688K->1186092K(2944192K), 0.0769110 secs]
[GC 1442220K->1209041K(2944192K), 0.1121180 secs]
[GC 1465169K->1248785K(2944192K), 0.1285140 secs]
[GC 1504761K->1261814K(2944192K), 0.1098000 secs]
[GC 1517942K->1293875K(2944192K), 0.1334450 secs]
[GC 1550003K->1291969K(2944192K), 0.1100400 secs]
[GC 1548009K->1343359K(2944192K), 0.1204600 secs]
[GC 1599487K->1345274K(2944192K), 0.1199380 secs]
[GC 1601232K->1385535K(2944192K), 0.1153140 secs]
[GC 1641660K->1418573K(2944192K), 0.1100620 secs]
[GC 1419403K(2944192K), 0.0484510 secs]
[GC 1596512K(2944192K), 0.1422170 secs]
[GC 1455058K->1223237K(2944192K), 0.1120290 secs]
[GC 1479365K->1246646K(2944192K), 0.1094530 secs]
[GC 1502755K->1270869K(2944192K), 0.1069100 secs]
[GC 1526997K->1251700K(2944192K), 0.1020180 secs]
[GC 1507746K->1305590K(2944192K), 0.1027100 secs]
[GC 1561718K->1346623K(2944192K), 0.1041900 secs]
[GC 1602698K->1328666K(2944192K), 0.1023990 secs]
[GC 1584794K->1375688K(2944192K), 0.1014810 secs]
[GC 1631809K->1410235K(2944192K), 0.1029140 secs]
[GC 1666308K->1433408K(2944192K), 0.1000710 secs]
[GC 1689536K->1458720K(2944192K), 0.1082750 secs]
[GC 1714848K->1486054K(2944192K), 0.1107310 secs]
[GC 1742147K->1508791K(2944192K), 0.1081960 secs]
[GC 1764919K->1531490K(2944192K), 0.1107030 secs]
[GC 1787532K->1555680K(2944192K), 0.1036420 secs]
[GC 1811808K->1538449K(2944192K), 0.1044980 secs]
[GC 1794577K->1582502K(2944192K), 0.1049730 secs]
[GC 1838630K->1633202K(2944192K), 0.1048100 secs]
[GC 1889330K->1658111K(2944192K), 0.1163510 secs]
[GC 1914127K->1682436K(2944192K), 0.1101930 secs]
[GC 1938352K->1708033K(2944192K), 0.1102140 secs]
[GC 1964157K->1733718K(2944192K), 0.1028790 secs]
[GC 1989697K->1759640K(2944192K), 0.1103640 secs]
[GC 2015768K->1767571K(2944192K), 0.1056270 secs]
[GC 2023587K->1793802K(2944192K), 0.1035510 secs]
[GC 2049855K->1819447K(2944192K), 0.1019410 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5710 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 56 ms.
