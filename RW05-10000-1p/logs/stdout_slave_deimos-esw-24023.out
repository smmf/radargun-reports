/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-24023 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-24023
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0631130 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 4. Sleeping for 7000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 4
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@5381062e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5705, using socket ServerSocket[addr=/0.0.0.0,localport=5705], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5705
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 48580 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 42603 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 49547 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5705 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705 this
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:46878
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:46878
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:55864
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:55864
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:47416
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:47416
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 38714 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38846
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:38846
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:51078
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:51078
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:44665
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:44665
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34910
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 35710 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:34910
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36126
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:36126
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 34341 accepted socket connection from /127.0.0.1:5712
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 3
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 4
[GC 259695K->13332K(2944064K), 0.0389590 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|2] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-15831, physical addresses are [127.0.0.1:52003]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-15831] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|3] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-15831] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|4] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685]
 INFO  [Incoming-4,deimos-esw-15831] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|5] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-15831] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|6] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120]
 INFO  [Incoming-4,deimos-esw-15831] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|7] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120, deimos-esw-29201]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 3, serverOidBase: 3000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 4: org.radargun.cachewrappers.FFWrapper@78bcf8b5
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 1
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@78bcf8b5, nodeIndex=4, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269396K->22104K(2944064K), 0.0554570 secs]
[GC 278168K->32857K(2944064K), 0.0607220 secs]
[GC 288921K->47088K(2944064K), 0.0517640 secs]
[GC 303152K->75427K(2944064K), 0.0588020 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 331491K->84100K(2944064K), 0.0618170 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9050. Elapsed time: 20.123 secs. Remaining: 39.877 secs. Total: 1 mins 0 secs
[GC 340164K->116768K(2944064K), 0.0688590 secs]
[GC 372832K->114554K(2944064K), 0.1534000 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15700. Elapsed time: 40.938 secs. Remaining: 19.062 secs. Total: 1 mins 0 secs
[GC 370618K->138231K(2944064K), 0.0744810 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 43 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 163 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 394295K->152194K(2944064K), 0.0759420 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,620,149 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 323914K->133158K(2944064K), 0.6395770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,809,622 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@78bcf8b5, nodeIndex=4, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 389286K->200725K(2944192K), 0.0331810 secs]
[GC 456853K->156288K(2944192K), 0.0387320 secs]
[GC 412416K->167443K(2944192K), 0.0461320 secs]
[GC 423571K->179017K(2944192K), 0.0483390 secs]
[GC 435145K->193455K(2944192K), 0.0548390 secs]
[GC 449583K->199142K(2944192K), 0.0552630 secs]
[GC 455270K->213214K(2944192K), 0.0585490 secs]
[GC 469342K->226665K(2944192K), 0.0596470 secs]
[GC 482793K->255534K(2944192K), 0.0694680 secs]
[GC 511662K->272499K(2944192K), 0.0873970 secs]
[GC 528595K->292267K(2944192K), 0.1001300 secs]
[GC 548356K->273744K(2944192K), 0.0864200 secs]
[GC 529872K->298748K(2944192K), 0.0997590 secs]
[GC 554809K->315119K(2944192K), 0.0812850 secs]
[GC 571247K->333985K(2944192K), 0.0829200 secs]
[GC 590113K->337065K(2944192K), 0.0859270 secs]
[GC 593193K->370666K(2944192K), 0.0552570 secs]
[GC 626794K->393002K(2944192K), 0.0638240 secs]
[GC 649130K->375724K(2944192K), 0.0936700 secs]
[GC 631852K->397888K(2944192K), 0.0571530 secs]
[GC 654016K->376540K(2944192K), 0.0902400 secs]
[GC 632668K->427303K(2944192K), 0.0714480 secs]
[GC 683431K->443784K(2944192K), 0.0971040 secs]
[GC 699912K->468491K(2944192K), 0.0937840 secs]
[GC 724619K->449233K(2944192K), 0.1033280 secs]
[GC 705361K->494371K(2944192K), 0.0898250 secs]
[GC 750499K->492887K(2944192K), 0.0847000 secs]
[GC 749015K->520603K(2944192K), 0.0599260 secs]
[GC 776731K->498394K(2944192K), 0.0793510 secs]
[GC 754522K->520033K(2944192K), 0.0892520 secs]
[GC 776161K->515473K(2944192K), 0.1043330 secs]
[GC 771601K->544513K(2944192K), 0.0540260 secs]
[GC 800641K->548944K(2944192K), 0.0627150 secs]
[GC 805072K->558330K(2944192K), 0.0658750 secs]
[GC 814458K->555761K(2944192K), 0.0804990 secs]
[GC 811889K->562372K(2944192K), 0.0679990 secs]
[GC 818500K->574792K(2944192K), 0.0784950 secs]
[GC 830920K->584517K(2944192K), 0.0785970 secs]
[GC 840645K->610256K(2944192K), 0.1762750 secs]
[GC 866384K->585164K(2944192K), 0.1491140 secs]
[GC 841292K->617363K(2944192K), 0.0795070 secs]
[GC 873491K->616055K(2944192K), 0.0808580 secs]
[GC 872183K->617756K(2944192K), 0.0907190 secs]
[GC 873884K->635671K(2944192K), 0.1418060 secs]
[GC 891799K->648844K(2944192K), 0.0846890 secs]
[GC 904972K->639131K(2944192K), 0.1366580 secs]
[GC 895259K->657607K(2944192K), 0.1029790 secs]
[GC 913735K->670728K(2944192K), 0.1341080 secs]
[GC 926856K->661512K(2944192K), 0.1585030 secs]
[GC 917640K->687881K(2944192K), 0.0734750 secs]
[GC 944009K->687544K(2944192K), 0.0864260 secs]
[GC 943672K->696178K(2944192K), 0.1587580 secs]
[GC 952306K->720362K(2944192K), 0.1134860 secs]
[GC 976490K->704112K(2944192K), 0.0791920 secs]
[GC 960240K->707925K(2944192K), 0.0825170 secs]
[GC 964053K->738683K(2944192K), 0.1585500 secs]
[GC 994811K->714067K(2944192K), 0.1626900 secs]
[GC 970195K->759873K(2944192K), 0.1702390 secs]
[GC 1016001K->725309K(2944192K), 0.0766170 secs]
[GC 981437K->759806K(2944192K), 0.0758380 secs]
[GC 1015934K->757980K(2944192K), 0.1676130 secs]
[GC 1014108K->766693K(2944192K), 0.1136760 secs]
[GC 1022821K->758861K(2944192K), 0.0774620 secs]
[GC 1014989K->783227K(2944192K), 0.1630200 secs]
[GC 1039355K->806754K(2944192K), 0.0825220 secs]
[GC 1062882K->780649K(2944192K), 0.1179500 secs]
[GC 1036777K->795833K(2944192K), 0.1553420 secs]
[GC 1051961K->811597K(2944192K), 0.1335480 secs]
[GC 1067725K->802952K(2944192K), 0.1606350 secs]
[GC 1059080K->827406K(2944192K), 0.1584790 secs]
 INFO  [Stressor-2] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=330352 <= mostRecentNum=330353.
[GC 1083534K->835278K(2944192K), 0.1488790 secs]
[GC 1091406K->842601K(2944192K), 0.0771150 secs]
[GC 1098729K->849542K(2944192K), 0.1209770 secs]
[GC 1105662K->875882K(2944192K), 0.1130490 secs]
[GC 1132010K->856782K(2944192K), 0.0976270 secs]
[GC 1112910K->910197K(2944192K), 0.1270170 secs]
[GC 1166325K->900762K(2944192K), 0.1643190 secs]
[GC 1156816K->936148K(2944192K), 0.0958670 secs]
[GC 1192276K->955093K(2944192K), 0.0944060 secs]
[GC 1211221K->933004K(2944192K), 0.0852190 secs]
[GC 1189132K->945756K(2944192K), 0.0832350 secs]
[GC 1201884K->968763K(2944192K), 0.0697290 secs]
[GC 1224891K->959468K(2944192K), 0.0889410 secs]
[GC 1215596K->1011546K(2944192K), 0.1004970 secs]
[GC 1267674K->979617K(2944192K), 0.1214030 secs]
[GC 1235745K->978921K(2944192K), 0.1451920 secs]
[GC 1235049K->1033494K(2944192K), 0.0677930 secs]
[GC 1289622K->1012077K(2944192K), 0.0790550 secs]
[GC 1268205K->1027085K(2944192K), 0.0907850 secs]
[GC 1283038K->1058317K(2944192K), 0.1298270 secs]
[GC 1314215K->1032659K(2944192K), 0.1406020 secs]
[GC 1288787K->1089494K(2944192K), 0.0910790 secs]
[GC 1345622K->1076174K(2944192K), 0.1272270 secs]
[GC 1332218K->1125230K(2944192K), 0.1074810 secs]
[GC 1381358K->1110504K(2944192K), 0.0943420 secs]
[GC 1366632K->1107837K(2944192K), 0.0805710 secs]
[GC 1363965K->1119835K(2944192K), 0.0806030 secs]
[GC 1375963K->1170270K(2944192K), 0.0634520 secs]
[GC 1426398K->1149701K(2944192K), 0.0885770 secs]
[GC 1405829K->1168651K(2944192K), 0.0842860 secs]
[GC 1424779K->1187047K(2944192K), 0.1183680 secs]
[GC 1443175K->1207984K(2944192K), 0.1345740 secs]
[GC 1464112K->1228766K(2944192K), 0.0944200 secs]
[GC 1484864K->1247264K(2944192K), 0.1035290 secs]
[GC 1503392K->1265737K(2944192K), 0.1218680 secs]
[GC 1521865K->1236774K(2944192K), 0.0951740 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1492902K->1273693K(2944192K), 0.0861950 secs]
[GC 1529821K->1284709K(2944192K), 0.0826580 secs]
[GC 1540837K->1286487K(2944192K), 0.0711930 secs]
[GC 1542615K->1300738K(2944192K), 0.0816390 secs]
[GC 1556866K->1306342K(2944192K), 0.0640210 secs]
[GC 1562470K->1318331K(2944192K), 0.0694350 secs]
[GC 1574459K->1303299K(2944192K), 0.0565740 secs]
[GC 1559427K->1323608K(2944192K), 0.0624880 secs]
[GC 1579736K->1335929K(2944192K), 0.0665270 secs]
[GC 1592057K->1328612K(2944192K), 0.0619740 secs]
[GC 1584740K->1327983K(2944192K), 0.0617650 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7809473. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 1584111K->1334813K(2944192K), 0.0874880 secs]
[GC 1590941K->1343694K(2944192K), 0.0663780 secs]
[GC 1599822K->1334803K(2944192K), 0.0538340 secs]
[GC 1590931K->1343919K(2944192K), 0.0570190 secs]
[GC 1600047K->1361386K(2944192K), 0.0675840 secs]
[GC 1617514K->1345354K(2944192K), 0.0518710 secs]
[GC 1601482K->1350178K(2944192K), 0.0886370 secs]
[GC 1606306K->1359175K(2944192K), 0.0551970 secs]
[GC 1615303K->1362365K(2944192K), 0.0633840 secs]
[GC 1618475K->1366939K(2944192K), 0.0609440 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 14864673. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 1623033K->1345654K(2944192K), 0.0586720 secs]
[GC 1601782K->1356121K(2944192K), 0.0637500 secs]
[GC 1612249K->1353662K(2944192K), 0.0595650 secs]
[GC 1609790K->1372202K(2944192K), 0.0707530 secs]
[GC 1628330K->1378865K(2944192K), 0.0793200 secs]
[GC 1380941K(2944192K), 0.0379120 secs]
[GC 1634950K->1370654K(2944192K), 0.0683900 secs]
[GC 1533713K(2944192K), 0.1336880 secs]
[GC 1403590K->1169346K(2944192K), 0.0743150 secs]
[GC 1425474K->1161404K(2944192K), 0.0702180 secs]
[GC 1417532K->1181650K(2944192K), 0.0747600 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 20335502. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 43 mins 48 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:4, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1437778K->1199560K(2944192K), 0.0734110 secs]
[GC 1455688K->1235012K(2944192K), 0.0870610 secs]
[GC 1491140K->1210007K(2944192K), 0.1008100 secs]
[GC 1466135K->1225399K(2944192K), 0.1128720 secs]
[GC 1481527K->1282421K(2944192K), 0.1063060 secs]
[GC 1538549K->1324271K(2944192K), 0.1112250 secs]
[GC 1580399K->1307855K(2944192K), 0.1037770 secs]
[GC 1563972K->1353784K(2944192K), 0.1082930 secs]
[GC 1609912K->1388886K(2944192K), 0.1079010 secs]
[GC 1645014K->1412050K(2944192K), 0.1095900 secs]
[GC 1668178K->1428957K(2944192K), 0.1064730 secs]
[GC 1685085K->1456695K(2944192K), 0.1159310 secs]
[GC 1712789K->1487470K(2944192K), 0.1157170 secs]
[GC 1743598K->1510245K(2944192K), 0.1053810 secs]
[GC 1766373K->1533769K(2944192K), 0.1105310 secs]
[GC 1789897K->1558384K(2944192K), 0.1090850 secs]
[GC 1814496K->1581307K(2944192K), 0.1027770 secs]
[GC 1837370K->1611858K(2944192K), 0.1039790 secs]
[GC 1867743K->1636855K(2944192K), 0.1064750 secs]
[GC 1892983K->1661301K(2944192K), 0.1053930 secs]
[GC 1917429K->1686611K(2944192K), 0.1058260 secs]
[GC 1942739K->1693939K(2944192K), 0.1039820 secs]
[GC 1949981K->1720139K(2944192K), 0.1084500 secs]
[GC 1976267K->1764417K(2944192K), 0.1042230 secs]
[GC 2020421K->1790252K(2944192K), 0.1161220 secs]
[GC 2046226K->1816235K(2944192K), 0.1028390 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5705 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 52 ms.
