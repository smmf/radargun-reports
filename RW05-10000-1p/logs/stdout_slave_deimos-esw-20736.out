/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-20736 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-20736
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0773050 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 11. Sleeping for 10500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 11
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@640fa784
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=11, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5712, using socket ServerSocket[addr=/0.0.0.0,localport=5712], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5712 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5712
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5712 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5712 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5712 [FenixFrameworkGroup] Address[127.0.0.1]:5712 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 56340 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 57899 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 51551 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5712 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:55797
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:55797
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52805
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:52805
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 59368 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52520
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 36126 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 54785 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:52520
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 50506 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 40046 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5712 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38318
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 59115 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:38318
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45663
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:45663
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 46350 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:48325
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:48325
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5712 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34341
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5712 [FenixFrameworkGroup] 5712 accepted socket connection from /127.0.0.1:34341
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5712 [FenixFrameworkGroup] Address[127.0.0.1]:5712 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 11
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=11, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 11
[GC 259695K->13062K(2944064K), 0.0425410 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-38052|7] [deimos-esw-38052, deimos-esw-51174, deimos-esw-27097, deimos-esw-15831, deimos-esw-4404, deimos-esw-39163, deimos-esw-30685, deimos-esw-28161, deimos-esw-35830, deimos-esw-2996, deimos-esw-20120, deimos-esw-29201]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-29201, physical addresses are [127.0.0.1:52011]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 11, serverOidBase: b000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 11: org.radargun.cachewrappers.FFWrapper@607f3c5b
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 10
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@607f3c5b, nodeIndex=11, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269126K->23117K(2944064K), 0.0571760 secs]
[GC 279181K->34294K(2944064K), 0.0556290 secs]
[GC 290358K->53777K(2944064K), 0.0502710 secs]
[GC 309841K->77309K(2944064K), 0.0599750 secs]
[GC 333373K->85756K(2944064K), 0.0583660 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 341820K->117244K(2944064K), 0.0665310 secs]
[GC 373308K->118787K(2944064K), 0.1323720 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3000. Elapsed time: 20.167 secs. Remaining: 39.833 secs. Total: 1 mins 0 secs
[GC 374851K->134490K(2944064K), 0.0937310 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 14232. Elapsed time: 40.167 secs. Remaining: 19.833 secs. Total: 1 mins 0 secs
[GC 390554K->159618K(2944064K), 0.0693580 secs]
[GC 415682K->164729K(2944064K), 0.0746090 secs]
[GC 420793K->200674K(2944064K), 0.0833540 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 3 mins 9 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 189 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,701,787 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 242276K->165377K(2944064K), 0.5987470 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,776,978 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@607f3c5b, nodeIndex=11, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 421505K->230068K(2944192K), 0.0317070 secs]
[GC 486196K->187591K(2944192K), 0.0388790 secs]
[GC 443719K->198652K(2944192K), 0.0456560 secs]
[GC 454780K->210574K(2944192K), 0.0484390 secs]
[GC 466702K->217901K(2944192K), 0.0506410 secs]
[GC 474029K->231275K(2944192K), 0.0549460 secs]
[GC 487403K->244937K(2944192K), 0.0614170 secs]
[GC 501065K->258847K(2944192K), 0.0627660 secs]
[GC 514917K->272577K(2944192K), 0.0711170 secs]
[GC 528705K->304043K(2944192K), 0.0891200 secs]
[GC 560171K->309439K(2944192K), 0.0993030 secs]
[GC 565567K->326425K(2944192K), 0.0890990 secs]
[GC 582553K->321363K(2944192K), 0.1086110 secs]
[GC 577438K->350867K(2944192K), 0.0903730 secs]
[GC 606995K->367657K(2944192K), 0.0879960 secs]
[GC 623785K->369685K(2944192K), 0.0866510 secs]
[GC 625813K->416724K(2944192K), 0.0765060 secs]
[GC 672852K->386544K(2944192K), 0.0933170 secs]
[GC 642672K->401880K(2944192K), 0.1252150 secs]
[GC 658008K->438887K(2944192K), 0.0963320 secs]
[GC 694835K->410320K(2944192K), 0.0820530 secs]
[GC 666448K->474650K(2944192K), 0.0948240 secs]
[GC 730605K->445668K(2944192K), 0.0888720 secs]
[GC 701796K->493505K(2944192K), 0.0980050 secs]
[GC 749633K->482737K(2944192K), 0.1052370 secs]
[GC 738865K->510533K(2944192K), 0.0833530 secs]
[GC 766661K->510369K(2944192K), 0.0887560 secs]
[GC 766497K->566864K(2944192K), 0.0634730 secs]
[GC 822992K->545386K(2944192K), 0.0814780 secs]
[GC 801514K->565500K(2944192K), 0.0677120 secs]
[GC 821628K->543804K(2944192K), 0.0686850 secs]
[GC 799932K->546942K(2944192K), 0.0879230 secs]
[GC 803070K->581602K(2944192K), 0.0645630 secs]
[GC 837730K->587957K(2944192K), 0.0695900 secs]
[GC 844085K->581451K(2944192K), 0.0846650 secs]
[GC 837579K->606892K(2944192K), 0.0809540 secs]
[GC 863020K->605584K(2944192K), 0.1169090 secs]
[GC 861712K->632233K(2944192K), 0.0800460 secs]
[GC 888361K->607708K(2944192K), 0.0795390 secs]
[GC 863836K->639533K(2944192K), 0.0801240 secs]
[GC 895661K->656900K(2944192K), 0.0834420 secs]
[GC 913028K->631602K(2944192K), 0.0856470 secs]
[GC 887730K->679896K(2944192K), 0.1791250 secs]
[GC 936024K->654405K(2944192K), 0.0928770 secs]
[GC 910533K->685359K(2944192K), 0.1319430 secs]
[GC 941487K->694715K(2944192K), 0.1610510 secs]
[GC 950843K->679896K(2944192K), 0.1399710 secs]
[GC 936024K->705924K(2944192K), 0.1322820 secs]
[GC 962052K->703424K(2944192K), 0.1112360 secs]
[GC 959552K->721297K(2944192K), 0.0899290 secs]
[GC 977425K->697393K(2944192K), 0.0706200 secs]
[GC 953521K->732330K(2944192K), 0.0829830 secs]
[GC 988458K->749459K(2944192K), 0.0817050 secs]
[GC 1005587K->724679K(2944192K), 0.0843920 secs]
[GC 980807K->770107K(2944192K), 0.1546460 secs]
[GC 1026235K->735554K(2944192K), 0.0799850 secs]
[GC 991682K->769095K(2944192K), 0.0807780 secs]
[GC 1025203K->768781K(2944192K), 0.1444930 secs]
[GC 1024909K->761028K(2944192K), 0.0867760 secs]
[GC 1017156K->786918K(2944192K), 0.1349310 secs]
[GC 1043046K->794363K(2944192K), 0.1138180 secs]
[GC 1050491K->801512K(2944192K), 0.1300370 secs]
[GC 1057640K->810033K(2944192K), 0.1323340 secs]
[GC 1066161K->799673K(2944192K), 0.0776130 secs]
[GC 1055801K->823710K(2944192K), 0.0770620 secs]
[GC 1079838K->831760K(2944192K), 0.0811670 secs]
[GC 1087888K->839630K(2944192K), 0.0786980 secs]
[GC 1095758K->846564K(2944192K), 0.0839880 secs]
[GC 1102692K->871403K(2944192K), 0.0774240 secs]
[GC 1127531K->844030K(2944192K), 0.1154180 secs]
[GC 1100158K->873617K(2944192K), 0.0786740 secs]
[GC 1129745K->891323K(2944192K), 0.0826390 secs]
[GC 1147366K->888643K(2944192K), 0.1508330 secs]
[GC 1144771K->930318K(2944192K), 0.1178960 secs]
[GC 1186446K->951039K(2944192K), 0.1236350 secs]
[GC 1207167K->955547K(2944192K), 0.1119820 secs]
[GC 1211649K->954796K(2944192K), 0.1073260 secs]
[GC 1210924K->953012K(2944192K), 0.0855630 secs]
[GC 1209140K->965467K(2944192K), 0.0853770 secs]
[GC 1221595K->1019935K(2944192K), 0.0646820 secs]
[GC 1276063K->994968K(2944192K), 0.0946330 secs]
[GC 1251096K->1016942K(2944192K), 0.0839970 secs]
[GC 1273070K->994569K(2944192K), 0.0871950 secs]
[GC 1250697K->995950K(2944192K), 0.1144810 secs]
[GC 1252078K->1048131K(2944192K), 0.0926590 secs]
[GC 1304259K->1009534K(2944192K), 0.1007480 secs]
[GC 1265662K->1067475K(2944192K), 0.1210060 secs]
[GC 1323603K->1044269K(2944192K), 0.0853540 secs]
[GC 1300397K->1093037K(2944192K), 0.0947080 secs]
[GC 1349165K->1103616K(2944192K), 0.1404250 secs]
[GC 1359744K->1129529K(2944192K), 0.0947630 secs]
[GC 1385657K->1141282K(2944192K), 0.1202740 secs]
[GC 1397410K->1136890K(2944192K), 0.1073160 secs]
[GC 1393018K->1130023K(2944192K), 0.0920930 secs]
[GC 1386151K->1154213K(2944192K), 0.0775310 secs]
[GC 1410341K->1144838K(2944192K), 0.0989770 secs]
[GC 1400966K->1182540K(2944192K), 0.0744290 secs]
[GC 1438639K->1163370K(2944192K), 0.0940150 secs]
[GC 1419498K->1214270K(2944192K), 0.0786310 secs]
[GC 1470311K->1236873K(2944192K), 0.1019130 secs]
[GC 1493001K->1251803K(2944192K), 0.1119120 secs]
[GC 1507931K->1275991K(2944192K), 0.1098260 secs]
[GC 1532119K->1266762K(2944192K), 0.1163900 secs]
[GC 1522890K->1312613K(2944192K), 0.0862980 secs]
[GC 1568741K->1322573K(2944192K), 0.1104120 secs]
[GC 1578701K->1349012K(2944192K), 0.1163390 secs]
[GC 1605140K->1365163K(2944192K), 0.1075240 secs]
[GC 1621291K->1363161K(2944192K), 0.1259470 secs]
[GC 1363766K(2944192K), 0.0341430 secs]
[GC 1574766K(2944192K), 0.1927760 secs]
[GC 1374373K->1162515K(2944192K), 0.0896640 secs]
[GC 1418643K->1165470K(2944192K), 0.0878340 secs]
[GC 1421598K->1168242K(2944192K), 0.0879460 secs]
[GC 1424246K->1186700K(2944192K), 0.0829530 secs]
[GC 1442828K->1245577K(2944192K), 0.0672500 secs]
[GC 1501705K->1211330K(2944192K), 0.0823230 secs]
[GC 1467458K->1242745K(2944192K), 0.0813340 secs]
[GC 1498670K->1284941K(2944192K), 0.0704180 secs]
[GC 1541069K->1305691K(2944192K), 0.0928570 secs]
[GC 1561784K->1313993K(2944192K), 0.0888140 secs]
[GC 1570121K->1313122K(2944192K), 0.0949730 secs]
[GC 1569206K->1348294K(2944192K), 0.0847860 secs]
[GC 1604422K->1375575K(2944192K), 0.0862660 secs]
[GC 1631703K->1365622K(2944192K), 0.1018510 secs]
[GC 1621750K->1374229K(2944192K), 0.0817950 secs]
[GC 1630357K->1429470K(2944192K), 0.0675580 secs]
[GC 1685573K->1454235K(2944192K), 0.0927450 secs]
[GC 1710363K->1438959K(2944192K), 0.1019410 secs]
[GC 1695015K->1452276K(2944192K), 0.0865950 secs]
[GC 1708404K->1470288K(2944192K), 0.0824810 secs]
[GC 1726416K->1489657K(2944192K), 0.0811220 secs]
[GC 1745733K->1545560K(2944192K), 0.0666120 secs]
[GC 1801682K->1551653K(2944192K), 0.0870490 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1807781K->1531459K(2944192K), 0.0780130 secs]
[GC 1787587K->1563659K(2944192K), 0.0778320 secs]
[GC 1819787K->1590683K(2944192K), 0.0629800 secs]
[GC 1846811K->1585167K(2944192K), 0.0772290 secs]
[GC 1841287K->1577636K(2944192K), 0.0637090 secs]
[GC 1833764K->1604257K(2944192K), 0.0510870 secs]
[GC 1860385K->1609509K(2944192K), 0.0656490 secs]
[GC 1865637K->1606694K(2944192K), 0.0665550 secs]
[GC 1862822K->1611609K(2944192K), 0.0522290 secs]
[GC 1867737K->1616420K(2944192K), 0.0622090 secs]
[GC 1872548K->1610644K(2944192K), 0.0478770 secs]
[GC 1866772K->1633771K(2944192K), 0.0511080 secs]
[GC 1889899K->1657913K(2944192K), 0.0662840 secs]
[GC 1914041K->1642810K(2944192K), 0.0617900 secs]
[GC 1898900K->1646583K(2944192K), 0.0511030 secs]
[GC 1902711K->1652332K(2944192K), 0.0609600 secs]
[GC 1908460K->1677017K(2944192K), 0.0524490 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 10359689. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 1932855K->1654227K(2944192K), 0.0562950 secs]
[GC 1910342K->1689342K(2944192K), 0.0557890 secs]
[GC 1945470K->1669585K(2944192K), 0.0690520 secs]
[GC 1925713K->1666770K(2944192K), 0.0517680 secs]
[GC 1922898K->1683381K(2944192K), 0.0559950 secs]
[GC 1939509K->1692460K(2944192K), 0.0507260 secs]
[GC 1948588K->1687325K(2944192K), 0.0569270 secs]
[GC 1943453K->1719168K(2944192K), 0.0563520 secs]
[GC 1975296K->1681794K(2944192K), 0.0589930 secs]
[GC 1937922K->1713480K(2944192K), 0.0511010 secs]
[GC 1969608K->1702762K(2944192K), 0.0628620 secs]
[GC 1958890K->1723380K(2944192K), 0.0568370 secs]
[GC 1979508K->1736264K(2944192K), 0.0602100 secs]
[GC 1992392K->1732380K(2944192K), 0.0638250 secs]
[GC 1988469K->1750785K(2944192K), 0.0585890 secs]
[GC 2006913K->1736650K(2944192K), 0.0550770 secs]
[GC 1992778K->1748644K(2944192K), 0.0612220 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 21098243. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 2004772K->1754545K(2944192K), 0.0646090 secs]
[GC 2010673K->1766397K(2944192K), 0.0601410 secs]
[GC 2022525K->1765730K(2944192K), 0.0612170 secs]
[GC 2021858K->1777895K(2944192K), 0.0546720 secs]
[GC 2034023K->1787101K(2944192K), 0.0681310 secs]
[GC 2043229K->1772807K(2944192K), 0.0601250 secs]
[GC 2028935K->1787543K(2944192K), 0.0636520 secs]
[GC 2043514K->1783928K(2944192K), 0.0611980 secs]
[GC 2040056K->1804279K(2944192K), 0.0683330 secs]
[GC 2060407K->1794574K(2944192K), 0.0571150 secs]
[GC 2050702K->1805475K(2944192K), 0.0659140 secs]
[GC 2061603K->1822813K(2944192K), 0.0654670 secs]
[GC 2078941K->1812846K(2944192K), 0.0588490 secs]
[GC 2068974K->1829154K(2944192K), 0.0631410 secs]
[GC 2085282K->1831383K(2944192K), 0.0568190 secs]
[GC 2087407K->1838075K(2944192K), 0.0521010 secs]
[GC 2094203K->1852799K(2944192K), 0.0660160 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 31813758. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 48 mins 52 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:11, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5712 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5712 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5712 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 53 ms.
