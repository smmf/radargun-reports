/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-14196 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-14196
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0799750 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@6b4f7392
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5708, using socket ServerSocket[addr=/0.0.0.0,localport=5708], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5708
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 47541 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 59996 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 41903 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5708 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708 this
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:55653
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:55653
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34339
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:34339
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52010
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:52010
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:54752
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:54752
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:55637
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:55637
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:54866
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:54866
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 7
[GC 259695K->12508K(2944064K), 0.0396230 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-46324|5] [deimos-esw-46324, deimos-esw-51111, deimos-esw-54422, deimos-esw-2377, deimos-esw-62566, deimos-esw-36778, deimos-esw-47871, deimos-esw-63624, deimos-esw-8969]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-63624, physical addresses are [127.0.0.1:52007]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-63624] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-46324|6] [deimos-esw-46324, deimos-esw-51111, deimos-esw-54422, deimos-esw-2377, deimos-esw-62566, deimos-esw-36778, deimos-esw-47871, deimos-esw-63624, deimos-esw-8969, deimos-esw-28098]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@4ebca121
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 5
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@4ebca121, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268572K->22908K(2944064K), 0.0586470 secs]
[GC 278972K->30491K(2944064K), 0.0489910 secs]
[GC 286555K->52072K(2944064K), 0.0485360 secs]
[GC 308136K->67572K(2944064K), 0.0571470 secs]
[GC 323613K->84674K(2944064K), 0.0583140 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 340738K->104620K(2944064K), 0.0687640 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6350. Elapsed time: 20.318 secs. Remaining: 39.682 secs. Total: 1 mins 0 secs
[GC 360684K->116000K(2944064K), 0.1612860 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16500. Elapsed time: 40.738 secs. Remaining: 19.262 secs. Total: 1 mins 0 secs
[GC 372064K->142886K(2944064K), 0.0774400 secs]
[GC 398950K->159004K(2944064K), 0.0777490 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 46 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 166 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,716,496 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 227567K->128733K(2944064K), 0.5456340 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,316 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@4ebca121, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 384861K->198913K(2944192K), 0.0315060 secs]
[GC 455041K->147917K(2944192K), 0.0340100 secs]
[GC 404045K->159426K(2944192K), 0.0375780 secs]
[GC 415554K->169242K(2944192K), 0.0466770 secs]
[GC 425370K->182851K(2944192K), 0.0515830 secs]
[GC 438979K->196484K(2944192K), 0.0540270 secs]
[GC 452612K->210644K(2944192K), 0.0581300 secs]
[GC 466772K->224877K(2944192K), 0.0598310 secs]
[GC 480949K->246733K(2944192K), 0.0774310 secs]
[GC 502691K->244139K(2944192K), 0.0779020 secs]
[GC 500247K->284043K(2944192K), 0.0922550 secs]
[GC 540171K->290636K(2944192K), 0.1199160 secs]
[GC 546764K->287147K(2944192K), 0.1101670 secs]
[GC 543275K->313253K(2944192K), 0.1193750 secs]
[GC 569381K->348004K(2944192K), 0.0836490 secs]
[GC 604132K->333168K(2944192K), 0.0890620 secs]
[GC 589296K->373530K(2944192K), 0.0622210 secs]
[GC 629658K->353096K(2944192K), 0.0863480 secs]
[GC 609224K->387343K(2944192K), 0.0621090 secs]
[GC 643471K->409832K(2944192K), 0.0654420 secs]
[GC 665960K->418168K(2944192K), 0.0973470 secs]
[GC 674296K->443280K(2944192K), 0.1182610 secs]
[GC 699408K->463231K(2944192K), 0.0906560 secs]
[GC 719359K->440401K(2944192K), 0.0939560 secs]
[GC 696529K->486400K(2944192K), 0.0783820 secs]
[GC 742528K->502099K(2944192K), 0.0807380 secs]
[GC 758227K->487614K(2944192K), 0.0757790 secs]
[GC 743742K->533950K(2944192K), 0.0591590 secs]
[GC 790078K->495757K(2944192K), 0.0609030 secs]
[GC 751885K->504153K(2944192K), 0.0769660 secs]
[GC 760281K->541489K(2944192K), 0.0624290 secs]
[GC 797617K->563729K(2944192K), 0.0663450 secs]
[GC 819857K->548889K(2944192K), 0.0791640 secs]
[GC 805017K->568861K(2944192K), 0.1083870 secs]
[GC 824989K->584927K(2944192K), 0.1177770 secs]
[GC 841055K->555381K(2944192K), 0.1530720 secs]
[GC 811509K->590804K(2944192K), 0.0783120 secs]
[GC 846932K->608399K(2944192K), 0.0719820 secs]
[GC 864527K->591242K(2944192K), 0.0833370 secs]
[GC 847370K->600668K(2944192K), 0.1409930 secs]
[GC 856796K->630392K(2944192K), 0.0791170 secs]
[GC 886520K->617614K(2944192K), 0.0766630 secs]
[GC 873742K->640725K(2944192K), 0.0807490 secs]
[GC 896853K->657196K(2944192K), 0.0815700 secs]
[GC 913324K->633409K(2944192K), 0.1519810 secs]
[GC 889537K->664667K(2944192K), 0.1266150 secs]
[GC 920795K->664616K(2944192K), 0.0836900 secs]
[GC 920744K->690407K(2944192K), 0.0790440 secs]
[GC 946535K->665996K(2944192K), 0.0801310 secs]
[GC 922124K->696912K(2944192K), 0.0792850 secs]
[GC 953040K->711995K(2944192K), 0.1642940 secs]
[GC 968123K->688825K(2944192K), 0.1455540 secs]
[GC 944953K->733396K(2944192K), 0.1636820 secs]
[GC 989524K->711379K(2944192K), 0.1509220 secs]
[GC 967507K->734368K(2944192K), 0.1665830 secs]
[GC 990496K->734342K(2944192K), 0.0763880 secs]
[GC 990470K->751236K(2944192K), 0.0676030 secs]
[GC 1007364K->769520K(2944192K), 0.0772240 secs]
[GC 1025648K->743635K(2944192K), 0.1658300 secs]
[GC 999763K->752214K(2944192K), 0.1783440 secs]
[GC 1008342K->783105K(2944192K), 0.1332210 secs]
[GC 1039233K->782642K(2944192K), 0.1469170 secs]
[GC 1038770K->791463K(2944192K), 0.0731370 secs]
[GC 1047591K->817257K(2944192K), 0.1620570 secs]
[GC 1073385K->837039K(2944192K), 0.1043010 secs]
[GC 1093078K->831643K(2944192K), 0.1314060 secs]
[GC 1087771K->852130K(2944192K), 0.1006300 secs]
[GC 1108082K->894556K(2944192K), 0.1034620 secs]
[GC 1150684K->861132K(2944192K), 0.1032600 secs]
[GC 1117260K->876684K(2944192K), 0.1074170 secs]
[GC 1132812K->888352K(2944192K), 0.1080310 secs]
[GC 1144480K->934145K(2944192K), 0.0747760 secs]
[GC 1190273K->895456K(2944192K), 0.0851680 secs]
[GC 1151584K->918363K(2944192K), 0.0991060 secs]
[GC 1174491K->956966K(2944192K), 0.1329750 secs]
[GC 1213094K->984842K(2944192K), 0.1602470 secs]
[GC 1240970K->974174K(2944192K), 0.1591520 secs]
[GC 1230302K->1006520K(2944192K), 0.1064880 secs]
[GC 1262648K->1037494K(2944192K), 0.1048110 secs]
[GC 1293622K->1024943K(2944192K), 0.0955840 secs]
[GC 1281071K->1020278K(2944192K), 0.0859780 secs]
[GC 1276406K->1032549K(2944192K), 0.0884760 secs]
[GC 1288677K->1080625K(2944192K), 0.0699970 secs]
[GC 1336753K->1065168K(2944192K), 0.0874910 secs]
[GC 1321296K->1116221K(2944192K), 0.0911180 secs]
[GC 1372349K->1108634K(2944192K), 0.0908420 secs]
[GC 1364762K->1153603K(2944192K), 0.1028180 secs]
[GC 1409731K->1170738K(2944192K), 0.0964950 secs]
[GC 1426866K->1158286K(2944192K), 0.0939240 secs]
[GC 1414414K->1153853K(2944192K), 0.0926900 secs]
[GC 1409981K->1165553K(2944192K), 0.1111890 secs]
[GC 1421681K->1223422K(2944192K), 0.0814810 secs]
[GC 1479550K->1247737K(2944192K), 0.1139370 secs]
[GC 1503865K->1238045K(2944192K), 0.1270330 secs]
[GC 1494173K->1303648K(2944192K), 0.1090180 secs]
[GC 1559776K->1327526K(2944192K), 0.1148870 secs]
[GC 1583654K->1346272K(2944192K), 0.1146440 secs]
[GC 1602347K->1372200K(2944192K), 0.1091430 secs]
[GC 1628328K->1376753K(2944192K), 0.1089770 secs]
[GC 1632881K->1400953K(2944192K), 0.1032240 secs]
[GC 1401476K(2944192K), 0.0473300 secs]
[GC 1657069K->1403565K(2944192K), 0.1003000 secs]
[GC 1415154K(2944192K), 0.0258780 secs]
[GC 1391226K->1158080K(2944192K), 0.1064250 secs]
[GC 1414208K->1177881K(2944192K), 0.1011360 secs]
[GC 1434009K->1195956K(2944192K), 0.0934400 secs]
[GC 1452084K->1228568K(2944192K), 0.0724230 secs]
[GC 1484696K->1252287K(2944192K), 0.0772310 secs]
[GC 1508365K->1222578K(2944192K), 0.0882780 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1478706K->1273455K(2944192K), 0.0706460 secs]
[GC 1529102K->1241288K(2944192K), 0.0829160 secs]
[GC 1497416K->1278396K(2944192K), 0.0663040 secs]
[GC 1534524K->1255954K(2944192K), 0.0782650 secs]
[GC 1512082K->1275499K(2944192K), 0.0799480 secs]
[GC 1531627K->1268256K(2944192K), 0.0608000 secs]
[GC 1524384K->1283104K(2944192K), 0.0749660 secs]
[GC 1539232K->1280346K(2944192K), 0.0627520 secs]
[GC 1536474K->1294952K(2944192K), 0.0676820 secs]
[GC 1551080K->1297088K(2944192K), 0.0736280 secs]
[GC 1553216K->1291882K(2944192K), 0.0671300 secs]
[GC 1548010K->1317177K(2944192K), 0.0824000 secs]
[GC 1573305K->1317605K(2944192K), 0.0678940 secs]
[GC 1573733K->1322566K(2944192K), 0.0662060 secs]
[GC 1578694K->1320819K(2944192K), 0.0698770 secs]
[GC 1576947K->1317219K(2944192K), 0.0647490 secs]
[GC 1573347K->1336493K(2944192K), 0.0722570 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 12266601. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 1592621K->1337960K(2944192K), 0.0696180 secs]
[GC 1594088K->1353710K(2944192K), 0.0699460 secs]
[GC 1609714K->1343930K(2944192K), 0.0629900 secs]
[GC 1600058K->1355868K(2944192K), 0.0691520 secs]
[GC 1611996K->1352468K(2944192K), 0.0606660 secs]
[GC 1608567K->1359546K(2944192K), 0.0676610 secs]
[GC 1615674K->1381736K(2944192K), 0.0742690 secs]
[GC 1637864K->1382289K(2944192K), 0.0659830 secs]
[GC 1638417K->1378073K(2944192K), 0.0629020 secs]
[GC 1634201K->1383735K(2944192K), 0.0660030 secs]
[GC 1639863K->1391522K(2944192K), 0.0629830 secs]
[GC 1647650K->1388688K(2944192K), 0.0633390 secs]
[GC 1644816K->1406820K(2944192K), 0.0693610 secs]
[GC 1662948K->1406472K(2944192K), 0.0676950 secs]
[GC 1662600K->1400401K(2944192K), 0.0616620 secs]
[GC 1656529K->1418534K(2944192K), 0.0735320 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 23477031. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 1674662K->1413427K(2944192K), 0.0636430 secs]
[GC 1669555K->1433676K(2944192K), 0.0748440 secs]
[GC 1689804K->1433609K(2944192K), 0.0675290 secs]
[GC 1689726K->1430338K(2944192K), 0.1436470 secs]
[GC 1686386K->1455294K(2944192K), 0.0697210 secs]
[GC 1711422K->1442008K(2944192K), 0.0614570 secs]
[GC 1698136K->1452935K(2944192K), 0.0648720 secs]
[GC 1709063K->1455935K(2944192K), 0.0687020 secs]
[GC 1712063K->1471714K(2944192K), 0.0729890 secs]
[GC 1727842K->1465943K(2944192K), 0.0602700 secs]
[GC 1722071K->1497157K(2944192K), 0.0641080 secs]
[GC 1753285K->1485181K(2944192K), 0.0768960 secs]
[GC 1741309K->1513575K(2944192K), 0.0722870 secs]
[GC 1769703K->1510780K(2944192K), 0.0711890 secs]
[GC 1766908K->1509951K(2944192K), 0.0533740 secs]
[GC 1766079K->1525729K(2944192K), 0.0654270 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 29999690. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 37 mins 8 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5708 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 53 ms.
