/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-442 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-442
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0591370 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@500ae176
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5704, using socket ServerSocket[addr=/0.0.0.0,localport=5704], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5704
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 34076 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 53449 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 39433 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5704 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5704 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5704 this
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:50469
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:50469
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37218
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:37218
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:54393
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:54393
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38779
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:38779
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:54827
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:54827
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Creating cache with the following configuration: hzl3-repl-sync.xml
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5711, using socket ServerSocket[addr=/0.0.0.0,localport=5711], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5711 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5711
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5711 [dev] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5711 [dev] Address[127.0.0.1]:5711 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 35579 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 43092 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 44429 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5711 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
 WARN  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5711 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5711 [dev] 

Members [8] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711 this
	Member [127.0.0.1]:5712
	Member [127.0.0.1]:5713
	Member [127.0.0.1]:5714
	Member [127.0.0.1]:5715
	Member [127.0.0.1]:5716
}

 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 44202 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:53453
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:53453
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5713, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5714, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 51708 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 59660 accepted socket connection from /127.0.0.1:5714
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:46842
 INFO  [hz._hzInstance_2_dev.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5715, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5716, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 43984 accepted socket connection from /127.0.0.1:5713
 INFO  [hz._hzInstance_2_dev.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 41470 accepted socket connection from /127.0.0.1:5715
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:46842
 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 56996 accepted socket connection from /127.0.0.1:5716
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:36340
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:36340
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:38110
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:38110
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:56084
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:56084
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:52284
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:52284
[GC 259695K->11688K(2944064K), 0.0395680 secs]
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5711 [dev] Address[127.0.0.1]:5711 is STARTED
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@3dd2790a
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 WARN  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> fc5b8504-3769-48d2-9553-df5d72e24667
 WARN  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> a9256419-e3f3-4a7e-a130-6fe118417182
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 WARN  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> 5ac7f13d-41e1-4e33-accb-9b1a0b2c8ee4
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@3dd2790a, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 267752K->10936K(2944064K), 0.0313420 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 267000K->13061K(2944064K), 0.0288400 secs]
[GC 269125K->14555K(2944064K), 0.0284800 secs]
[GC 270619K->14918K(2944064K), 0.0327290 secs]
[GC 270982K->16768K(2944064K), 0.0329490 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11750. Elapsed time: 20.023 secs. Remaining: 39.977 secs. Total: 1 mins 0 secs
[GC 272832K->18749K(2944064K), 0.0327800 secs]
[GC 274813K->23502K(2944064K), 0.0331720 secs]
[GC 279566K->25857K(2944064K), 0.0342350 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 24800. Elapsed time: 40.153 secs. Remaining: 19.847 secs. Total: 1 mins 0 secs
[GC 281921K->28413K(2944064K), 0.0377350 secs]
[GC 284477K->34911K(2944064K), 0.0325580 secs]
[GC 290975K->27358K(2944064K), 0.0343820 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 10 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 70 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 283422K->33608K(2944064K), 0.0354610 secs]
[GC 289672K->38635K(2944064K), 0.0393770 secs]
[GC 294699K->41954K(2944064K), 0.0363250 secs]
[GC 298018K->49828K(2944064K), 0.0589650 secs]
[GC 305892K->41822K(2944064K), 0.0392830 secs]
[GC 297886K->42768K(2944064K), 0.0408300 secs]
[GC 298832K->55525K(2944064K), 0.0412050 secs]
[GC 311589K->60212K(2944064K), 0.0411410 secs]
[GC 316276K->72172K(2944064K), 0.0457230 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,718,898 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 225165K->54295K(2944064K), 0.3345140 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,889,205 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@3dd2790a, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 310423K->74857K(2944192K), 0.0244690 secs]
[GC 330985K->61279K(2944192K), 0.0279500 secs]
[GC 317407K->63565K(2944192K), 0.0268490 secs]
[GC 319693K->64575K(2944192K), 0.0321710 secs]
[GC 320703K->65905K(2944192K), 0.0322510 secs]
[GC 322033K->71509K(2944192K), 0.0320140 secs]
[GC 327637K->78276K(2944192K), 0.0320410 secs]
[GC 334404K->75522K(2944192K), 0.0305000 secs]
[GC 331650K->78785K(2944192K), 0.0327550 secs]
[GC 334913K->82111K(2944192K), 0.0351860 secs]
[GC 338239K->85484K(2944192K), 0.0329780 secs]
[GC 341612K->88882K(2944192K), 0.0395440 secs]
[GC 345010K->92289K(2944192K), 0.0358040 secs]
[GC 348417K->102620K(2944192K), 0.0394120 secs]
[GC 358748K->106701K(2944192K), 0.0399840 secs]
[GC 362829K->105439K(2944192K), 0.0421520 secs]
[GC 361567K->108338K(2944192K), 0.0471660 secs]
[GC 364466K->119340K(2944192K), 0.0484650 secs]
[GC 375468K->110406K(2944192K), 0.0464860 secs]
[GC 366534K->119471K(2944192K), 0.0458420 secs]
[GC 375599K->126222K(2944192K), 0.0439960 secs]
[GC 382350K->117749K(2944192K), 0.0443390 secs]
[GC 373877K->119033K(2944192K), 0.0484150 secs]
[GC 375161K->125368K(2944192K), 0.0481510 secs]
[GC 381496K->137614K(2944192K), 0.0470740 secs]
[GC 393742K->122618K(2944192K), 0.0401570 secs]
[GC 378746K->137053K(2944192K), 0.0465300 secs]
[GC 393181K->143882K(2944192K), 0.0440790 secs]
[GC 400010K->129634K(2944192K), 0.0496440 secs]
[GC 385762K->144612K(2944192K), 0.0494180 secs]
[GC 400740K->142867K(2944192K), 0.0582380 secs]
[GC 398995K->137242K(2944192K), 0.0494290 secs]
[GC 393370K->148883K(2944192K), 0.0465100 secs]
[GC 405011K->160352K(2944192K), 0.0439950 secs]
[GC 416480K->144649K(2944192K), 0.0441800 secs]
[GC 400777K->150965K(2944192K), 0.0467400 secs]
[GC 407093K->157051K(2944192K), 0.0409960 secs]
[GC 413179K->160614K(2944192K), 0.0462000 secs]
[GC 416742K->163242K(2944192K), 0.0449490 secs]
[GC 419370K->165582K(2944192K), 0.0443150 secs]
[GC 421710K->176936K(2944192K), 0.0443040 secs]
[GC 433064K->161425K(2944192K), 0.0427830 secs]
[GC 417553K->167957K(2944192K), 0.0429040 secs]
[GC 424085K->174249K(2944192K), 0.0444740 secs]
[GC 430377K->177367K(2944192K), 0.0480620 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 433495K->197443K(2944192K), 0.0456020 secs]
[GC 453571K->183869K(2944192K), 0.0477330 secs]
[GC 439997K->198322K(2944192K), 0.0495270 secs]
[GC 454450K->209357K(2944192K), 0.0493550 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 140000. Elapsed time: 20.936 secs. Remaining: 39.064 secs. Total: 1 mins 0 secs
[GC 465485K->216651K(2944192K), 0.0524050 secs]
[GC 472779K->197012K(2944192K), 0.0511290 secs]
[GC 453140K->217633K(2944192K), 0.0506220 secs]
[GC 473761K->230364K(2944192K), 0.0527500 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 220000. Elapsed time: 41.265 secs. Remaining: 18.735 secs. Total: 1 mins 0 secs
[GC 486492K->251673K(2944192K), 0.0539560 secs]
[GC 507801K->215296K(2944192K), 0.0516500 secs]
[GC 471424K->254440K(2944192K), 0.0642410 secs]
[GC 510568K->221632K(2944192K), 0.0503680 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 240000. Elapsed time: 1 mins 4 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 477760K->264454K(2944192K), 0.0531110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 5 mins 34 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using hazelcast3, clusterSize:8, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 520582K->228157K(2944192K), 0.0511460 secs]
[GC 484285K->266253K(2944192K), 0.0522860 secs]
[GC 522381K->233534K(2944192K), 0.0519010 secs]
[GC 489662K->256350K(2944192K), 0.0511370 secs]
[GC 512478K->251392K(2944192K), 0.0514860 secs]
[GC 507520K->240207K(2944192K), 0.0495900 secs]
[GC 496335K->241172K(2944192K), 0.0513270 secs]
[GC 497300K->242557K(2944192K), 0.0483050 secs]
[GC 498685K->245457K(2944192K), 0.0492580 secs]
[GC 501585K->234713K(2944192K), 0.0500050 secs]
[GC 490841K->236713K(2944192K), 0.0482220 secs]
[GC 492841K->248898K(2944192K), 0.0522860 secs]
[GC 505026K->249347K(2944192K), 0.0505140 secs]
[GC 505475K->242689K(2944192K), 0.0512620 secs]
[GC 498817K->250790K(2944192K), 0.0506180 secs]
[GC 506918K->258703K(2944192K), 0.0499070 secs]
[GC 514831K->258482K(2944192K), 0.0507840 secs]
[GC 514610K->260059K(2944192K), 0.0473160 secs]
[GC 516187K->261858K(2944192K), 0.0798610 secs]
[GC 517986K->263779K(2944192K), 0.0426380 secs]
[GC 519907K->265725K(2944192K), 0.0445140 secs]
[GC 521853K->260694K(2944192K), 0.0542000 secs]
[GC 516822K->269744K(2944192K), 0.0487400 secs]
[GC 525872K->271513K(2944192K), 0.0442800 secs]
[GC 527641K->273340K(2944192K), 0.0510320 secs]
[GC 529468K->275587K(2944192K), 0.0477650 secs]
[GC 531715K->280632K(2944192K), 0.0519380 secs]
[GC 536760K->303613K(2944192K), 0.0478110 secs]
[GC 559741K->288386K(2944192K), 0.0496750 secs]
[GC 544514K->312353K(2944192K), 0.0531450 secs]
[GC 568481K->315237K(2944192K), 0.0577680 secs]
[GC 571365K->323659K(2944192K), 0.0529800 secs]
[GC 579787K->331125K(2944192K), 0.0520380 secs]
[GC 587253K->323276K(2944192K), 0.0515070 secs]
[GC 579404K->326093K(2944192K), 0.0529230 secs]
[GC 582221K->328219K(2944192K), 0.0541580 secs]
[GC 584347K->330332K(2944192K), 0.0553700 secs]
[GC 586460K->332357K(2944192K), 0.0537090 secs]
[GC 588485K->334561K(2944192K), 0.0542500 secs]
[GC 590689K->337168K(2944192K), 0.0607400 secs]
[GC 593296K->328279K(2944192K), 0.0560990 secs]
[GC 584407K->317175K(2944192K), 0.0531310 secs]
[GC 573303K->319271K(2944192K), 0.1162550 secs]
[GC 575399K->321705K(2944192K), 0.0536030 secs]
[GC 577833K->334755K(2944192K), 0.0546810 secs]
[GC 590883K->335863K(2944192K), 0.0513590 secs]
[GC 591991K->328059K(2944192K), 0.0509540 secs]
[GC 584187K->335310K(2944192K), 0.0497810 secs]
[GC 591438K->341135K(2944192K), 0.0510770 secs]
[GC 597263K->342074K(2944192K), 0.0479110 secs]
[GC 598202K->336848K(2944192K), 0.0420050 secs]
[GC 592976K->345701K(2944192K), 0.0526090 secs]
[GC 601829K->347756K(2944192K), 0.0449770 secs]
[GC 603884K->342630K(2944192K), 0.0418870 secs]
[GC 598758K->351752K(2944192K), 0.0548320 secs]
[GC 607880K->353768K(2944192K), 0.0421380 secs]
[GC 609896K->362992K(2944192K), 0.0543310 secs]
[GC 619120K->350551K(2944192K), 0.0453350 secs]
[GC 606679K->369106K(2944192K), 0.0452300 secs]
[GC 625234K->353391K(2944192K), 0.0513500 secs]
[GC 609519K->366246K(2944192K), 0.0546430 secs]
[GC 622374K->372121K(2944192K), 0.0514860 secs]
[GC 628249K->360449K(2944192K), 0.0479650 secs]
[GC 616577K->372541K(2944192K), 0.0459910 secs]
[GC 628669K->378275K(2944192K), 0.0431390 secs]
[GC 634403K->366372K(2944192K), 0.0433950 secs]
[GC 622500K->378720K(2944192K), 0.0439640 secs]
[GC 634848K->377179K(2944192K), 0.0418490 secs]
[GC 633307K->379945K(2944192K), 0.0487910 secs]
[GC 636073K->374764K(2944192K), 0.0522920 secs]
[GC 630892K->384283K(2944192K), 0.0556940 secs]
[GC 640411K->386272K(2944192K), 0.0503260 secs]
[GC 642400K->388382K(2944192K), 0.0506880 secs]
[GC 644510K->397815K(2944192K), 0.0547480 secs]
[GC 653943K->384967K(2944192K), 0.0460540 secs]
[GC 641095K->397013K(2944192K), 0.0451740 secs]
[GC 653141K->402745K(2944192K), 0.0427200 secs]
[GC 658873K->395342K(2944192K), 0.0439470 secs]
[GC 651470K->403231K(2944192K), 0.0555500 secs]
[GC 659359K->401521K(2944192K), 0.0536930 secs]
[GC 657649K->404365K(2944192K), 0.0549190 secs]
[GC 660493K->406589K(2944192K), 0.0534930 secs]
[GC 662717K->408646K(2944192K), 0.0539330 secs]
[GC 664774K->410609K(2944192K), 0.0542270 secs]
[GC 666737K->420139K(2944192K), 0.0501090 secs]
[GC 676267K->407089K(2944192K), 0.0443610 secs]
[GC 663217K->425969K(2944192K), 0.0543850 secs]
[GC 682097K->414100K(2944192K), 0.0425210 secs]
[GC 670228K->422654K(2944192K), 0.0417900 secs]
[GC 678782K->421213K(2944192K), 0.0408590 secs]
[GC 677341K->424035K(2944192K), 0.0533310 secs]
[GC 680163K->426104K(2944192K), 0.0462900 secs]
[GC 682232K->428095K(2944192K), 0.0458270 secs]
[GC 684223K->422499K(2944192K), 0.0566370 secs]
[GC 678627K->439241K(2944192K), 0.0512060 secs]
[GC 695369K->426486K(2944192K), 0.0449620 secs]
[GC 682614K->431582K(2944192K), 0.0454180 secs]
[GC 687710K->443773K(2944192K), 0.0432320 secs]
[GC 699901K->431919K(2944192K), 0.0424220 secs]
[GC 688047K->450520K(2944192K), 0.0448450 secs]
[GC 706648K->434618K(2944192K), 0.0455610 secs]
[GC 690746K->453976K(2944192K), 0.0447070 secs]
[GC 710104K->442847K(2944192K), 0.0531950 secs]
[GC 698975K->451339K(2944192K), 0.0529680 secs]
[GC 707467K->449988K(2944192K), 0.0531180 secs]
[GC 706116K->445497K(2944192K), 0.0494270 secs]
[GC 701625K->454929K(2944192K), 0.0457740 secs]
[GC 711057K->456891K(2944192K), 0.0464550 secs]
[GC 713019K->458938K(2944192K), 0.0419830 secs]
[GC 715066K->460883K(2944192K), 0.0454700 secs]
[GC 717011K->455479K(2944192K), 0.0535180 secs]
[GC 711607K->464712K(2944192K), 0.0535220 secs]
[GC 720840K->466770K(2944192K), 0.0556340 secs]
[GC 722898K->475981K(2944192K), 0.0552110 secs]
[GC 732109K->482045K(2944192K), 0.0498530 secs]
[GC 738173K->499615K(2944192K), 0.0514400 secs]
[GC 755743K->485064K(2944192K), 0.0521320 secs]
[GC 741192K->512016K(2944192K), 0.0627150 secs]
[GC 768144K->527991K(2944192K), 0.0657740 secs]
[GC 784119K->507045K(2944192K), 0.0729400 secs]
[GC 763173K->525224K(2944192K), 0.0598680 secs]
[GC 781352K->535838K(2944192K), 0.0615320 secs]
[GC 791966K->511570K(2944192K), 0.0581720 secs]
[GC 767698K->534309K(2944192K), 0.0606030 secs]
[GC 790437K->529988K(2944192K), 0.0568970 secs]
[GC 786116K->534312K(2944192K), 0.0603580 secs]
[GC 790440K->552345K(2944192K), 0.0566540 secs]
[GC 808473K->524781K(2944192K), 0.0646060 secs]
[GC 780909K->537078K(2944192K), 0.0638240 secs]
[GC 793206K->518086K(2944192K), 0.0638450 secs]
[GC 774214K->536324K(2944192K), 0.0573320 secs]
[GC 792452K->537987K(2944192K), 0.0567370 secs]
[GC 794115K->528048K(2944192K), 0.0622710 secs]
[GC 784176K->530688K(2944192K), 0.0609210 secs]
[GC 786816K->542002K(2944192K), 0.0498160 secs]
[GC 798130K->548722K(2944192K), 0.0470210 secs]
[GC 804850K->540921K(2944192K), 0.0599810 secs]
[GC 797049K->542914K(2944192K), 0.0467100 secs]
[GC 799042K->554046K(2944192K), 0.0655560 secs]
[GC 810174K->565121K(2944192K), 0.0501870 secs]
[GC 821249K->549862K(2944192K), 0.0445910 secs]
[GC 805990K->564078K(2944192K), 0.0626240 secs]
[GC 820206K->562152K(2944192K), 0.0469520 secs]
[GC 818280K->556722K(2944192K), 0.0545900 secs]
[GC 812850K->559242K(2944192K), 0.0486890 secs]
[GC 815370K->579415K(2944192K), 0.0568040 secs]
[GC 835543K->564130K(2944192K), 0.0503800 secs]
[GC 820258K->578475K(2944192K), 0.0451770 secs]
[GC 834603K->576527K(2944192K), 0.0589160 secs]
[GC 832655K->579844K(2944192K), 0.0483980 secs]
[GC 835972K->582434K(2944192K), 0.0485350 secs]
[GC 838562K->584785K(2944192K), 0.0561630 secs]
[GC 840913K->587250K(2944192K), 0.0594550 secs]
[GC 843378K->589809K(2944192K), 0.0505370 secs]
[GC 845937K->603799K(2944192K), 0.0523920 secs]
[GC 859927K->613870K(2944192K), 0.0660090 secs]
[GC 869998K->635646K(2944192K), 0.0602440 secs]
[GC 891774K->616122K(2944192K), 0.0585370 secs]
[GC 872250K->650352K(2944192K), 0.0635510 secs]
[GC 906480K->669469K(2944192K), 0.0739280 secs]
[GC 925597K->629954K(2944192K), 0.0678270 secs]
[GC 886082K->672798K(2944192K), 0.0666720 secs]
[GC 928926K->687267K(2944192K), 0.0810840 secs]
[GC 943395K->667424K(2944192K), 0.0783320 secs]
[GC 923552K->710660K(2944192K), 0.0656040 secs]
[GC 966788K->677457K(2944192K), 0.0696640 secs]
[GC 933585K->692487K(2944192K), 0.0685630 secs]
[GC 948615K->725587K(2944192K), 0.0589600 secs]
[GC 981715K->690328K(2944192K), 0.0678920 secs]
[GC 946456K->722679K(2944192K), 0.0648410 secs]
[GC 978807K->744369K(2944192K), 0.0772300 secs]
[GC 1000497K->723935K(2944192K), 0.0851030 secs]
[GC 980063K->753676K(2944192K), 0.0720040 secs]
[GC 1009804K->739671K(2944192K), 0.0742520 secs]
[GC 995799K->768910K(2944192K), 0.0619900 secs]
[GC 1025038K->764056K(2944192K), 0.0714160 secs]
[GC 1020184K->770203K(2944192K), 0.0722710 secs]
[GC 1026331K->794592K(2944192K), 0.0768280 secs]
[GC 1050720K->796247K(2944192K), 0.0899070 secs]
[GC 1052375K->786396K(2944192K), 0.0799100 secs]
[GC 1042524K->839710K(2944192K), 0.0752300 secs]
[GC 1095838K->860388K(2944192K), 0.1007920 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5704 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 61 ms.
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5711 [dev] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Hazelcast Shutdown is completed in 352 ms.
