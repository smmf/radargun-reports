/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-32466 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-32466
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0764290 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@3fbefe6e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=7, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5709, using socket ServerSocket[addr=/0.0.0.0,localport=5709], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5709 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5709
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5709 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5709 [FenixFrameworkGroup] Address[127.0.0.1]:5709 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 60554 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 36115 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 36244 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5709 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5709 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-16] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-16] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 38779 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41879
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 56201 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-15] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 60931 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:41879
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-15] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 44318 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 44504 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:39271
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:39271
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37078
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:37078
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:48133
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:48133
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5709 [FenixFrameworkGroup] Address[127.0.0.1]:5709 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=7, confAttributes={name=hzl3-repl-sync.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Creating cache with the following configuration: hzl3-repl-sync.xml
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5716, using socket ServerSocket[addr=/0.0.0.0,localport=5716], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5716 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5716
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5716 [dev] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5716 [dev] Address[127.0.0.1]:5716 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 48301 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 33680 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 45628 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5716 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
 WARN  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5716 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5716 [dev] 

Members [8] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
	Member [127.0.0.1]:5713
	Member [127.0.0.1]:5714
	Member [127.0.0.1]:5715
	Member [127.0.0.1]:5716 this
}

 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5713, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 38389 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 41723 accepted socket connection from /127.0.0.1:5713
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5714, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 44550 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 36340 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 39069 accepted socket connection from /127.0.0.1:5714
 INFO  [hz._hzInstance_2_dev.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5715, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:54824
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:54824
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:56996
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:56996
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:42168
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:42168
 INFO  [hz._hzInstance_2_dev.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 33541 accepted socket connection from /127.0.0.1:5715
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:33835
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:33835
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:54132
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:54132
[GC 259695K->11901K(2944064K), 0.0393820 secs]
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5716 [dev] Address[127.0.0.1]:5716 is STARTED
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@12328f00
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 WARN  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 21aa702b-e726-488c-be57-a045052d6e56
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 1
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 26944e75-fcde-4f13-a985-7744d29df2f1
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> e69c775f-04c9-4580-b2a3-6f4fee26ed28
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@12328f00, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 267965K->11594K(2944064K), 0.0335690 secs]
[GC 267658K->13168K(2944064K), 0.0272670 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 269232K->14598K(2944064K), 0.0299190 secs]
[GC 270662K->16861K(2944064K), 0.0310380 secs]
[GC 272925K->21016K(2944064K), 0.0460910 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11200. Elapsed time: 20.018 secs. Remaining: 39.982 secs. Total: 1 mins 0 secs
[GC 277080K->17148K(2944064K), 0.0366170 secs]
[GC 273212K->21339K(2944064K), 0.0320830 secs]
[GC 277403K->24767K(2944064K), 0.0344770 secs]
[GC 280831K->27389K(2944064K), 0.0356580 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 22150. Elapsed time: 40.112 secs. Remaining: 19.888 secs. Total: 1 mins 0 secs
[GC 283453K->30000K(2944064K), 0.0341550 secs]
[GC 286064K->32601K(2944064K), 0.0340720 secs]
[GC 288665K->35306K(2944064K), 0.0336820 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 11 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 71 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 291370K->38056K(2944064K), 0.0336850 secs]
[GC 294120K->40721K(2944064K), 0.0349230 secs]
[GC 296785K->47810K(2944064K), 0.0535080 secs]
[GC 303874K->35943K(2944064K), 0.0382210 secs]
[GC 292007K->44335K(2944064K), 0.0347890 secs]
[GC 300399K->44795K(2944064K), 0.0381480 secs]
[GC 300859K->54383K(2944064K), 0.0352290 secs]
[GC 310447K->57869K(2944064K), 0.0377060 secs]
[GC 313933K->61322K(2944064K), 0.0373070 secs]
[GC 317386K->72075K(2944064K), 0.0461210 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,710,978 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 233085K->54789K(2944064K), 0.3105870 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,888,835 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@12328f00, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 310917K->74457K(2944192K), 0.0285830 secs]
[GC 330585K->60044K(2944192K), 0.0278680 secs]
[GC 316172K->61252K(2944192K), 0.0266940 secs]
[GC 317380K->62388K(2944192K), 0.0276670 secs]
[GC 318516K->64403K(2944192K), 0.0261650 secs]
[GC 320531K->66630K(2944192K), 0.0301480 secs]
[GC 322758K->66863K(2944192K), 0.0317970 secs]
[GC 322991K->68784K(2944192K), 0.0319950 secs]
[GC 324912K->70787K(2944192K), 0.0304240 secs]
[GC 326915K->72807K(2944192K), 0.0320590 secs]
[GC 328935K->74831K(2944192K), 0.0325950 secs]
[GC 330959K->76846K(2944192K), 0.0302400 secs]
[GC 332974K->82809K(2944192K), 0.0378940 secs]
[GC 338937K->80781K(2944192K), 0.0351280 secs]
[GC 336909K->87404K(2944192K), 0.0365780 secs]
[GC 343532K->81909K(2944192K), 0.0550780 secs]
[GC 338037K->88386K(2944192K), 0.0350590 secs]
[GC 344514K->89819K(2944192K), 0.0340340 secs]
[GC 345947K->91095K(2944192K), 0.0388050 secs]
[GC 347223K->92483K(2944192K), 0.0362180 secs]
[GC 348611K->98917K(2944192K), 0.0362100 secs]
[GC 355045K->90218K(2944192K), 0.0382680 secs]
[GC 346346K->103170K(2944192K), 0.0380650 secs]
[GC 359298K->92210K(2944192K), 0.0363370 secs]
[GC 348338K->101302K(2944192K), 0.0368070 secs]
[GC 357430K->100342K(2944192K), 0.0376940 secs]
[GC 356470K->102264K(2944192K), 0.0337430 secs]
[GC 358392K->108927K(2944192K), 0.0366830 secs]
[GC 365055K->100083K(2944192K), 0.0386620 secs]
[GC 356211K->113238K(2944192K), 0.0349440 secs]
[GC 369366K->105164K(2944192K), 0.0372550 secs]
[GC 361292K->106423K(2944192K), 0.0357880 secs]
[GC 362551K->105156K(2944192K), 0.0415800 secs]
[GC 361284K->112229K(2944192K), 0.0357590 secs]
[GC 368357K->113855K(2944192K), 0.0387190 secs]
[GC 369983K->115221K(2944192K), 0.0356650 secs]
[GC 371349K->121818K(2944192K), 0.0372070 secs]
[GC 377946K->112824K(2944192K), 0.0362680 secs]
[GC 368952K->121231K(2944192K), 0.0440900 secs]
[GC 377359K->124985K(2944192K), 0.0446280 secs]
[GC 381113K->116692K(2944192K), 0.0389270 secs]
[GC 372820K->125219K(2944192K), 0.0437910 secs]
[GC 381347K->129159K(2944192K), 0.0415790 secs]
[GC 385287K->120949K(2944192K), 0.0404150 secs]
[GC 377077K->137345K(2944192K), 0.0432550 secs]
[GC 393473K->139850K(2944192K), 0.0396360 secs]
[GC 395978K->146020K(2944192K), 0.0392310 secs]
[GC 402148K->151508K(2944192K), 0.0395150 secs]
[GC 407636K->164898K(2944192K), 0.0432500 secs]
[GC 421026K->144448K(2944192K), 0.0396240 secs]
[GC 400576K->161891K(2944192K), 0.0444060 secs]
[GC 418019K->181340K(2944192K), 0.0430650 secs]
[GC 437468K->163130K(2944192K), 0.0406450 secs]
[GC 419258K->186878K(2944192K), 0.0421060 secs]
[GC 443006K->162820K(2944192K), 0.0423900 secs]
[GC 418948K->195487K(2944192K), 0.0454720 secs]
[GC 451615K->169012K(2944192K), 0.0457520 secs]
[GC 425140K->203859K(2944192K), 0.0456130 secs]
[GC 459987K->177426K(2944192K), 0.0479840 secs]
[GC 433554K->201009K(2944192K), 0.0466970 secs]
[GC 457137K->210587K(2944192K), 0.0493110 secs]
[GC 466715K->189113K(2944192K), 0.0509770 secs]
[GC 445241K->208768K(2944192K), 0.0486250 secs]
[GC 464896K->205197K(2944192K), 0.0457250 secs]
[GC 461325K->208880K(2944192K), 0.0461550 secs]
[GC 465008K->211655K(2944192K), 0.0434050 secs]
[GC 467783K->202480K(2944192K), 0.0462270 secs]
[GC 458608K->204809K(2944192K), 0.0440990 secs]
[GC 460937K->216543K(2944192K), 0.0472270 secs]
[GC 472671K->218046K(2944192K), 0.0423150 secs]
[GC 474174K->220622K(2944192K), 0.0416930 secs]
[GC 476750K->223413K(2944192K), 0.0469590 secs]
[GC 479541K->226438K(2944192K), 0.0457000 secs]
[GC 482566K->229505K(2944192K), 0.0430450 secs]
[GC 485633K->232458K(2944192K), 0.0431410 secs]
[GC 488586K->246000K(2944192K), 0.0620420 secs]
[GC 502128K->234415K(2944192K), 0.0618080 secs]
[GC 490543K->235235K(2944192K), 0.0475690 secs]
[GC 491363K->242530K(2944192K), 0.0441740 secs]
[GC 498658K->246475K(2944192K), 0.0438020 secs]
[GC 502603K->249550K(2944192K), 0.0424670 secs]
[GC 505678K->263115K(2944192K), 0.0450030 secs]
[GC 519243K->251430K(2944192K), 0.0430930 secs]
[GC 507558K->261872K(2944192K), 0.0601730 secs]
[GC 518000K->259598K(2944192K), 0.0450520 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 515726K->263709K(2944192K), 0.0477760 secs]
[GC 519837K->283927K(2944192K), 0.0481960 secs]
[GC 540055K->278915K(2944192K), 0.0506310 secs]
[GC 535043K->296611K(2944192K), 0.0470270 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 100000. Elapsed time: 21.096 secs. Remaining: 38.904 secs. Total: 1 mins 0 secs
[GC 552739K->275716K(2944192K), 0.0519830 secs]
[GC 531844K->310883K(2944192K), 0.0538940 secs]
[GC 567011K->282201K(2944192K), 0.0502530 secs]
[GC 538329K->321652K(2944192K), 0.0524900 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 220493. Elapsed time: 41.146 secs. Remaining: 18.854 secs. Total: 1 mins 0 secs
[GC 577780K->290299K(2944192K), 0.0503920 secs]
[GC 546427K->332189K(2944192K), 0.0501210 secs]
[GC 588317K->299528K(2944192K), 0.0516260 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 230000. Elapsed time: 1 mins 1 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 555656K->343334K(2944192K), 0.0515790 secs]
[GC 599462K->308918K(2944192K), 0.0518780 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 10 mins 6 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using hazelcast3, clusterSize:8, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 565046K->344777K(2944192K), 0.0453880 secs]
[GC 600905K->308982K(2944192K), 0.0501460 secs]
[GC 565110K->337842K(2944192K), 0.0527910 secs]
[GC 593970K->331590K(2944192K), 0.0488890 secs]
[GC 587718K->304332K(2944192K), 0.0505110 secs]
[GC 560460K->334723K(2944192K), 0.0513410 secs]
[GC 590851K->334910K(2944192K), 0.0502520 secs]
[GC 591038K->322803K(2944192K), 0.0505420 secs]
[GC 578931K->311637K(2944192K), 0.0493280 secs]
[GC 567765K->324019K(2944192K), 0.0467850 secs]
[GC 580147K->336217K(2944192K), 0.0526810 secs]
[GC 592345K->327646K(2944192K), 0.0522710 secs]
[GC 583774K->331027K(2944192K), 0.0507120 secs]
[GC 587155K->318941K(2944192K), 0.0498340 secs]
[GC 575069K->320361K(2944192K), 0.0456700 secs]
[GC 576489K->326757K(2944192K), 0.0473130 secs]
[GC 582885K->327223K(2944192K), 0.0407410 secs]
[GC 583351K->328521K(2944192K), 0.0389130 secs]
[GC 584649K->336324K(2944192K), 0.0400810 secs]
[GC 592452K->337995K(2944192K), 0.0393870 secs]
[GC 594123K->333471K(2944192K), 0.0433920 secs]
[GC 589599K->347608K(2944192K), 0.0462270 secs]
[GC 603736K->336834K(2944192K), 0.0420530 secs]
[GC 592962K->347268K(2944192K), 0.0420740 secs]
[GC 603396K->352123K(2944192K), 0.0412160 secs]
[GC 608251K->341989K(2944192K), 0.0425670 secs]
[GC 598117K->352350K(2944192K), 0.0392260 secs]
[GC 608478K->357250K(2944192K), 0.0408390 secs]
[GC 613378K->347179K(2944192K), 0.0422230 secs]
[GC 603307K->352012K(2944192K), 0.0453020 secs]
[GC 608140K->356441K(2944192K), 0.0471610 secs]
[GC 612569K->352529K(2944192K), 0.0406060 secs]
[GC 608657K->354425K(2944192K), 0.0379490 secs]
[GC 610553K->362680K(2944192K), 0.0400090 secs]
[GC 618808K->364422K(2944192K), 0.0385080 secs]
[GC 620550K->372757K(2944192K), 0.0394150 secs]
[GC 628885K->365626K(2944192K), 0.0471590 secs]
[GC 621754K->372066K(2944192K), 0.0447250 secs]
[GC 628194K->364293K(2944192K), 0.0462130 secs]
[GC 620421K->366663K(2944192K), 0.0480410 secs]
[GC 622791K->375093K(2944192K), 0.0388790 secs]
[GC 631221K->383550K(2944192K), 0.0433490 secs]
[GC 639678K->372260K(2944192K), 0.0490110 secs]
[GC 628388K->382890K(2944192K), 0.0435730 secs]
[GC 639018K->387931K(2944192K), 0.0419270 secs]
[GC 644059K->381474K(2944192K), 0.0462850 secs]
[GC 637602K->382323K(2944192K), 0.0417230 secs]
[GC 638451K->386959K(2944192K), 0.0395780 secs]
[GC 643087K->382866K(2944192K), 0.0519110 secs]
[GC 638994K->391456K(2944192K), 0.0388850 secs]
[GC 647584K->393265K(2944192K), 0.0433320 secs]
[GC 649393K->401717K(2944192K), 0.0425430 secs]
[GC 657845K->390258K(2944192K), 0.0491300 secs]
[GC 646386K->407303K(2944192K), 0.0424300 secs]
[GC 663431K->392692K(2944192K), 0.0386670 secs]
[GC 648820K->404285K(2944192K), 0.0490430 secs]
[GC 660413K->403027K(2944192K), 0.0411640 secs]
[GC 659155K->398905K(2944192K), 0.0444580 secs]
[GC 655033K->407445K(2944192K), 0.0434840 secs]
[GC 663573K->409210K(2944192K), 0.0408220 secs]
[GC 665338K->404251K(2944192K), 0.0488710 secs]
[GC 660379K->412641K(2944192K), 0.0382580 secs]
[GC 668769K->414273K(2944192K), 0.0407610 secs]
[GC 670401K->415969K(2944192K), 0.0410210 secs]
[GC 672097K->417736K(2944192K), 0.0461410 secs]
[GC 673864K->419465K(2944192K), 0.0487720 secs]
[GC 675593K->414652K(2944192K), 0.0471450 secs]
[GC 670780K->416340K(2944192K), 0.0456610 secs]
[GC 672468K->424475K(2944192K), 0.0462680 secs]
[GC 680603K->426262K(2944192K), 0.0429810 secs]
[GC 682390K->434533K(2944192K), 0.0497440 secs]
[GC 690661K->427320K(2944192K), 0.0463110 secs]
[GC 683448K->433811K(2944192K), 0.0489040 secs]
[GC 689939K->432355K(2944192K), 0.0692970 secs]
[GC 688483K->434810K(2944192K), 0.0457510 secs]
[GC 690938K->430149K(2944192K), 0.0369940 secs]
[GC 686277K->438451K(2944192K), 0.0405490 secs]
[GC 694579K->446793K(2944192K), 0.0476650 secs]
[GC 702921K->435466K(2944192K), 0.0409610 secs]
[GC 691594K->451912K(2944192K), 0.0401560 secs]
[GC 708040K->437729K(2944192K), 0.0374820 secs]
[GC 693857K->449229K(2944192K), 0.0443310 secs]
[GC 705357K->454510K(2944192K), 0.0490080 secs]
[GC 710638K->443955K(2944192K), 0.0394770 secs]
[GC 700083K->454741K(2944192K), 0.0404340 secs]
[GC 710869K->459881K(2944192K), 0.0461840 secs]
[GC 716009K->453289K(2944192K), 0.0441090 secs]
[GC 709417K->465968K(2944192K), 0.0430030 secs]
[GC 722096K->451711K(2944192K), 0.0399590 secs]
[GC 707839K->469048K(2944192K), 0.0389880 secs]
[GC 725176K->455110K(2944192K), 0.0408600 secs]
[GC 711238K->466609K(2944192K), 0.0471640 secs]
[GC 722737K->471742K(2944192K), 0.0424010 secs]
[GC 727870K->482610K(2944192K), 0.0402130 secs]
[GC 738738K->471726K(2944192K), 0.0518090 secs]
[GC 727854K->486064K(2944192K), 0.0506960 secs]
[GC 742192K->507188K(2944192K), 0.0484290 secs]
[GC 763316K->491678K(2944192K), 0.0533250 secs]
[GC 747806K->518310K(2944192K), 0.0553910 secs]
[GC 774438K->521328K(2944192K), 0.0687850 secs]
[GC 777456K->530301K(2944192K), 0.0520230 secs]
[GC 786429K->507957K(2944192K), 0.0562680 secs]
[GC 764085K->529437K(2944192K), 0.0550200 secs]
[GC 785565K->525212K(2944192K), 0.0517930 secs]
[GC 781340K->529045K(2944192K), 0.0533120 secs]
[GC 785173K->531724K(2944192K), 0.0525970 secs]
[GC 787852K->534112K(2944192K), 0.0624100 secs]
[GC 790240K->537494K(2944192K), 0.0538690 secs]
[GC 793622K->542093K(2944192K), 0.0532960 secs]
[GC 798221K->516972K(2944192K), 0.0526460 secs]
[GC 773100K->532117K(2944192K), 0.0533850 secs]
[GC 788245K->545595K(2944192K), 0.0528650 secs]
[GC 801723K->535117K(2944192K), 0.0530140 secs]
[GC 791245K->536614K(2944192K), 0.0575750 secs]
[GC 792742K->528562K(2944192K), 0.0451240 secs]
[GC 784690K->527277K(2944192K), 0.0443770 secs]
[GC 783405K->543692K(2944192K), 0.0408820 secs]
[GC 799820K->545032K(2944192K), 0.0391640 secs]
[GC 801160K->546945K(2944192K), 0.0525730 secs]
[GC 803073K->549002K(2944192K), 0.0405670 secs]
[GC 805130K->543394K(2944192K), 0.0468830 secs]
[GC 799522K->545466K(2944192K), 0.0480400 secs]
[GC 801594K->555395K(2944192K), 0.0414190 secs]
[GC 811523K->557543K(2944192K), 0.0507020 secs]
[GC 813671K->567390K(2944192K), 0.0409570 secs]
[GC 823518K->553877K(2944192K), 0.0486590 secs]
[GC 810005K->566456K(2944192K), 0.0418610 secs]
[GC 822584K->572524K(2944192K), 0.0485100 secs]
[GC 828652K->559878K(2944192K), 0.0443610 secs]
[GC 816006K->572896K(2944192K), 0.0519410 secs]
[GC 829024K->578951K(2944192K), 0.0460730 secs]
[GC 835079K->566208K(2944192K), 0.0485480 secs]
[GC 822336K->586378K(2944192K), 0.0489580 secs]
[GC 842506K->574161K(2944192K), 0.0496800 secs]
[GC 830289K->590481K(2944192K), 0.0514540 secs]
[GC 846609K->573525K(2944192K), 0.0437350 secs]
[GC 829653K->594665K(2944192K), 0.0482460 secs]
[GC 850793K->577835K(2944192K), 0.0436260 secs]
[GC 833963K->598864K(2944192K), 0.0777500 secs]
[GC 854992K->592833K(2944192K), 0.0449680 secs]
[GC 848961K->612653K(2944192K), 0.0472280 secs]
[GC 868781K->627820K(2944192K), 0.0516850 secs]
[GC 883948K->604856K(2944192K), 0.0560950 secs]
[GC 860984K->642443K(2944192K), 0.0598060 secs]
[GC 898571K->646634K(2944192K), 0.0605590 secs]
[GC 902762K->671712K(2944192K), 0.0569270 secs]
[GC 927840K->632144K(2944192K), 0.0602430 secs]
[GC 888272K->670930K(2944192K), 0.0626450 secs]
[GC 927058K->679754K(2944192K), 0.0663150 secs]
[GC 935882K->683515K(2944192K), 0.0739830 secs]
[GC 939643K->686132K(2944192K), 0.0652420 secs]
[GC 942260K->694375K(2944192K), 0.0647950 secs]
[GC 950503K->684684K(2944192K), 0.0618520 secs]
[GC 940812K->688718K(2944192K), 0.0640820 secs]
[GC 944846K->699932K(2944192K), 0.0596250 secs]
[GC 956060K->709723K(2944192K), 0.0626110 secs]
[GC 965851K->721669K(2944192K), 0.0580850 secs]
[GC 977797K->746218K(2944192K), 0.0660520 secs]
[GC 1002346K->721770K(2944192K), 0.0733290 secs]
[GC 977898K->750299K(2944192K), 0.0667380 secs]
[GC 1006427K->752668K(2944192K), 0.0686740 secs]
[GC 1008796K->744139K(2944192K), 0.0689820 secs]
[GC 1000267K->777561K(2944192K), 0.0609840 secs]
[GC 1033689K->751669K(2944192K), 0.0667620 secs]
[GC 1007797K->791866K(2944192K), 0.0656220 secs]
[GC 1047994K->770911K(2944192K), 0.0781500 secs]
[GC 1027039K->812011K(2944192K), 0.0731400 secs]
[GC 1068139K->812030K(2944192K), 0.0805180 secs]
[GC 1068158K->843270K(2944192K), 0.0703420 secs]
[GC 1099398K->858603K(2944192K), 0.0844770 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5709 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 60 ms.
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5711] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5716 [dev] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Hazelcast Shutdown is completed in 358 ms.
