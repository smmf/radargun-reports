/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-16913 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-16913
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0761320 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 3. Sleeping for 6500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 3
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapperLF with classloader java.net.URLClassLoader@2548e059
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=3, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-lf
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-lf.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeTransactionFactory()
Oct 07, 2013 2:15:00 PM jvstm.ActiveTransactionsRecord <clinit>
INFO: ********** AOM reversion = false (disable/enable it in property jvstm.aom.reversion)
Oct 07, 2013 2:15:00 PM jvstm.Transaction <clinit>
INFO: ********** GC vbodies = true (disable/enable it in property jvstm.gc.disabled)
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5704, using socket ServerSocket[addr=/0.0.0.0,localport=5704], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5704
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 36548 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 44557 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 38155 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5704 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704 this
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:41709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:48474
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:48474
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 51653 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 39587 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 51948 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 59432 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:53905
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 39332 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:53905
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 56591 accepted socket connection from /127.0.0.1:5710
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Got (long) serverId: 3
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=3, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 3
[GC 259695K->12456K(2944064K), 0.0424850 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-37857|2] [deimos-esw-37857, deimos-esw-42783, deimos-esw-5634, deimos-esw-43200]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-43200, physical addresses are [127.0.0.1:52003]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-43200] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-37857|3] [deimos-esw-37857, deimos-esw-42783, deimos-esw-5634, deimos-esw-43200, deimos-esw-17807, deimos-esw-17270]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-43200] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-37857|4] [deimos-esw-37857, deimos-esw-42783, deimos-esw-5634, deimos-esw-43200, deimos-esw-17807, deimos-esw-17270, deimos-esw-31623]
 INFO  [Incoming-4,deimos-esw-43200] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-37857|5] [deimos-esw-37857, deimos-esw-42783, deimos-esw-5634, deimos-esw-43200, deimos-esw-17807, deimos-esw-17270, deimos-esw-31623, deimos-esw-3874, deimos-esw-2290]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-43200] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-37857|6] [deimos-esw-37857, deimos-esw-42783, deimos-esw-5634, deimos-esw-43200, deimos-esw-17807, deimos-esw-17270, deimos-esw-31623, deimos-esw-3874, deimos-esw-2290, deimos-esw-56440]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 3, serverOidBase: 3000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.InitTransaction} Waiting for version 4 to have a commitId
 INFO  [pool-1-thread-1] {jvstm.TransactionUtils} Setting the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} Set the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 3: org.radargun.cachewrappers.FFWrapperLF@5e6f7a6e
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@5e6f7a6e, nodeIndex=3, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
[GC 268520K->26908K(2944064K), 0.0596500 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 282972K->48932K(2944064K), 0.0582090 secs]
[GC 304996K->72104K(2944064K), 0.0705590 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5704 [FenixFrameworkGroup] 
memory used=266.0M, free=2.5G, total=2.8G, max=4.7G, used/total=9.25% used/max=5.55%
cpu process-load=8.00%, system-load=83.00%, system-loadaverage=927.00%
[GC 328168K->119496K(2944064K), 0.0831530 secs]
[GC 375560K->146580K(2944064K), 0.1926800 secs]
[GC 402644K->146153K(2944064K), 0.0924720 secs]
[GC 402217K->182164K(2944064K), 0.0892830 secs]
[GC 438228K->222922K(2944064K), 0.1041410 secs]
[GC 478986K->231561K(2944064K), 0.0987600 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 86900. Elapsed time: 20.013 secs. Remaining: 39.987 secs. Total: 1 mins 0 secs
[GC 487625K->239168K(2944064K), 0.1110640 secs]
[GC 495232K->285052K(2944064K), 0.1197770 secs]
[GC 541116K->290408K(2944064K), 0.1192290 secs]
[GC 546472K->328371K(2944064K), 0.1038660 secs]
[GC 584435K->332297K(2944064K), 0.1021480 secs]
[GC 588361K->372668K(2944064K), 0.1073580 secs]
[GC 628732K->396675K(2944064K), 0.1116560 secs]
[GC 652739K->421288K(2944064K), 0.1124630 secs]
[GC 677352K->423597K(2944064K), 0.1112680 secs]
[GC 679661K->468683K(2944064K), 0.1091390 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 175550. Elapsed time: 40.022 secs. Remaining: 19.978 secs. Total: 1 mins 0 secs
[GC 724747K->472126K(2944064K), 0.1149190 secs]
[GC 728190K->491858K(2944064K), 0.1057620 secs]
[GC 747922K->512836K(2944064K), 0.1037980 secs]
[GC 768900K->554239K(2944064K), 0.1129350 secs]
[GC 810303K->559215K(2944064K), 0.1124330 secs]
[GC 815279K->609099K(2944064K), 0.1186100 secs]
[GC 865163K->625403K(2944064K), 0.1078310 secs]
[GC 881467K->644317K(2944064K), 0.1119670 secs]
[GC 900381K->649301K(2944064K), 0.1065440 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 270450. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 6 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 66 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 905365K->688413K(2944064K), 0.1166170 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,252,674 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 691389K->605113K(2944064K), 2.1591830 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,337,542 kb - max:4,906,688 kb- total:2,944,320 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@5e6f7a6e, nodeIndex=3, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
[GC 861369K->681785K(2944320K), 0.0599480 secs]
[GC 938041K->654404K(2944320K), 0.0856820 secs]
[GC 910660K->678516K(2944320K), 0.0912220 secs]
[GC 934772K->708709K(2944320K), 0.1516880 secs]
[GC 964965K->731941K(2944320K), 0.2228880 secs]
[GC 988197K->752978K(2944320K), 0.2057790 secs]
[GC 1009234K->751843K(2944320K), 0.2296450 secs]
[GC 1008099K->785120K(2944320K), 0.2309540 secs]
[GC 1041376K->799187K(2944320K), 0.2103110 secs]
[GC 1055443K->832943K(2944320K), 0.2122060 secs]
[GC 1089199K->816624K(2944320K), 0.2288120 secs]
[GC 1072880K->859232K(2944320K), 0.2196110 secs]
[GC 1115488K->889851K(2944320K), 0.2275330 secs]
[GC 1146107K->867517K(2944320K), 0.2161170 secs]
[GC 1123773K->923930K(2944320K), 0.2455370 secs]
[GC 1180186K->897791K(2944320K), 0.2618520 secs]
[GC 1154047K->955947K(2944320K), 0.2624860 secs]
[GC 1212203K->972535K(2944320K), 0.2605270 secs]
[GC 1228791K->959691K(2944320K), 0.2434800 secs]
[GC 1215947K->998618K(2944320K), 0.2725690 secs]
[GC 1254874K->988994K(2944320K), 0.2083460 secs]
[GC 1245250K->1041961K(2944320K), 0.2362900 secs]
[GC 1298217K->1026450K(2944320K), 0.2718810 secs]
[GC 1282706K->1071172K(2944320K), 0.2248110 secs]
[GC 1327428K->1060521K(2944320K), 0.2216620 secs]
[GC 1316777K->1110729K(2944320K), 0.2130460 secs]
[GC 1366985K->1093152K(2944320K), 0.2110880 secs]
[GC 1349408K->1130507K(2944320K), 0.2190010 secs]
[GC 1386763K->1160769K(2944320K), 0.2562400 secs]
[GC 1417025K->1181977K(2944320K), 0.2186430 secs]
[GC 1438233K->1186593K(2944320K), 0.2399950 secs]
[GC 1442849K->1208125K(2944320K), 0.2284230 secs]
[GC 1464381K->1236038K(2944320K), 0.2837720 secs]
[GC 1492294K->1248098K(2944320K), 0.2852180 secs]
[GC 1504354K->1249538K(2944320K), 0.2764990 secs]
[GC 1505794K->1294737K(2944320K), 0.1680770 secs]
[GC 1550993K->1304709K(2944320K), 0.2224480 secs]
[GC 1560965K->1307190K(2944320K), 0.2665540 secs]
[GC 1563446K->1321153K(2944320K), 0.2660690 secs]
[GC 1577409K->1356877K(2944320K), 0.2409590 secs]
[GC 1613133K->1377589K(2944320K), 0.2156750 secs]
[GC 1633845K->1398615K(2944320K), 0.2720350 secs]
[GC 1654871K->1414043K(2944320K), 0.2607540 secs]
[GC 1414157K(2944320K), 0.1422870 secs]
[GC 1670299K->1433531K(2944320K), 0.2582990 secs]
[GC 1571098K(2944320K), 0.1281360 secs]
[GC 1435274K->1173309K(2944320K), 0.2383610 secs]
[GC 1425214K->1217748K(2944320K), 0.2194950 secs]
[GC 1474004K->1198471K(2944320K), 0.2394020 secs]
[GC 1454727K->1241676K(2944320K), 0.2327740 secs]
[GC 1497932K->1250326K(2944320K), 0.2160830 secs]
[GC 1506582K->1269129K(2944320K), 0.2221290 secs]
[GC 1525385K->1296595K(2944320K), 0.2207620 secs]
[GC 1552851K->1278818K(2944320K), 0.1964970 secs]
[GC 1535074K->1317786K(2944320K), 0.1980960 secs]
[GC 1574042K->1347106K(2944320K), 0.2122750 secs]
[GC 1603362K->1352189K(2944320K), 0.2250770 secs]
[GC 1608445K->1352055K(2944320K), 0.2084990 secs]
[GC 1608311K->1387935K(2944320K), 0.2317460 secs]
[GC 1644191K->1404118K(2944320K), 0.2179340 secs]
[GC 1660374K->1420030K(2944320K), 0.2178480 secs]
[GC 1676286K->1441169K(2944320K), 0.2472500 secs]
[GC 1697425K->1443094K(2944320K), 0.2176120 secs]
[GC 1699350K->1473620K(2944320K), 0.2056210 secs]
[GC 1729876K->1473855K(2944320K), 0.2077060 secs]
[GC 1730111K->1522309K(2944320K), 0.2278350 secs]
[GC 1778565K->1505206K(2944320K), 0.2444110 secs]
[GC 1761462K->1547404K(2944320K), 0.2119170 secs]
[GC 1803660K->1577256K(2944320K), 0.2098890 secs]
[GC 1833512K->1596376K(2944320K), 0.2290490 secs]
[GC 1852632K->1583540K(2944320K), 0.2176740 secs]
[GC 1839796K->1625569K(2944320K), 0.2270830 secs]
[GC 1881825K->1634740K(2944320K), 0.2423150 secs]
[GC 1890996K->1636483K(2944320K), 0.2270080 secs]
[GC 1892739K->1654337K(2944320K), 0.2042680 secs]
[GC 1910593K->1692215K(2944320K), 0.1967260 secs]
[GC 1948471K->1706230K(2944320K), 0.2202890 secs]
[GC 1962486K->1737568K(2944320K), 0.2110830 secs]
[GC 1993824K->1721321K(2944320K), 0.1905830 secs]
[GC 1977577K->1777072K(2944320K), 0.2430930 secs]
[GC 2033328K->1766724K(2944320K), 0.2422050 secs]
[GC 2022765K->1792000K(2944320K), 0.2712050 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2048256K->1845142K(2944320K), 0.1661290 secs]
[GC 2101398K->1871807K(2944320K), 0.1511590 secs]
[GC 2128063K->1892658K(2944320K), 0.1651590 secs]
[GC 2148914K->1925173K(2944320K), 0.1215530 secs]
[GC 2181429K->1979238K(2944320K), 0.1227250 secs]
[GC 2235494K->1973981K(2944320K), 0.1181720 secs]
[GC 2230237K->2023199K(2944320K), 0.1343650 secs]
[GC 2279455K->2059380K(2944320K), 0.1286850 secs]
[GC 2315636K->2088415K(2944320K), 0.1263180 secs]
[GC 2344640K->2121144K(2944320K), 0.1341800 secs]
[GC 2377400K->2135625K(2944320K), 0.1263420 secs]
[GC 2391881K->2185309K(2944320K), 0.1268730 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 490000. Elapsed time: 20.108 secs. Remaining: 39.892 secs. Total: 1 mins 0 secs
[GC 2441565K->2234513K(2944320K), 0.1338730 secs]
[GC 2490769K->2232639K(2944320K), 0.1230010 secs]
[GC 2488895K->2288676K(2944320K), 0.1345340 secs]
[GC 2544932K->2321508K(2944320K), 0.1276680 secs]
[GC 2577764K->2356043K(2944320K), 0.1203600 secs]
[GC 2612292K->2351668K(2944320K), 0.1199140 secs]
[GC 2607924K->2421860K(2944320K), 0.1215130 secs]
[GC 2421958K(2944320K), 0.0665420 secs]
[GC 2677972K->2442237K(2944320K), 0.1350090 secs]
[GC 2698493K->2487291K(2944320K), 0.1438940 secs]
[GC 2743547K->2485406K(2944320K), 0.1559150 secs]
[GC 2671958K(2944320K), 0.1312080 secs]
[GC 2719697K->2514947K(2944320K), 0.1754210 secs]
[GC 2436872K->2199585K(2944320K), 0.1437910 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1560000. Elapsed time: 40.193 secs. Remaining: 19.807 secs. Total: 1 mins 0 secs
[GC 2392542K->2193029K(3787252K), 0.1453790 secs]
[GC 2449285K->2225078K(3787252K), 0.1510520 secs]
[GC 2481334K->2238242K(3787252K), 0.1466990 secs]
[GC 2494478K->2285631K(3787252K), 0.1445090 secs]
[GC 2541887K->2296533K(3787252K), 0.1420260 secs]
[GC 2552789K->2343424K(3787252K), 0.1483820 secs]
[GC 2598829K->2372557K(3787252K), 0.1367270 secs]
[GC 2628813K->2408360K(3787252K), 0.1416110 secs]
[GC 2664348K->2438551K(3787252K), 0.1684490 secs]
[GC 2694406K->2458943K(3787252K), 0.1586630 secs]
[GC 2715199K->2503592K(3787252K), 0.1555890 secs]
[GC 2759848K->2517201K(3787252K), 0.1440960 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2190000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2773457K->2532176K(3787252K), 0.1427340 secs]
[GC 2788432K->2572198K(3787252K), 0.1372180 secs]
[GC 2828454K->2615562K(3787252K), 0.1050010 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 5 mins 37 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapperLF using infinispan52, clusterSize:10, nodeIndex:3, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5704 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 53 ms.
