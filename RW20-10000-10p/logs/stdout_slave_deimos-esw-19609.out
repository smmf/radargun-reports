/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-19609 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-19609
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0703570 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 4. Sleeping for 7000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 4
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapperLF with classloader java.net.URLClassLoader@a2e02b2
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-lf
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-lf.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeTransactionFactory()
Oct 07, 2013 2:22:57 PM jvstm.ActiveTransactionsRecord <clinit>
INFO: ********** AOM reversion = false (disable/enable it in property jvstm.aom.reversion)
Oct 07, 2013 2:22:57 PM jvstm.Transaction <clinit>
INFO: ********** GC vbodies = true (disable/enable it in property jvstm.gc.disabled)
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5705, using socket ServerSocket[addr=/0.0.0.0,localport=5705], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5705
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 55145 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 55579 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 42457 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5705 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705 this
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:40917
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:40917
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:48003
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:48003
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 49014 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 44353 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 60517 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 52971 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37236
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 36404 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 47611 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 43150 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 45875 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:37236
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34529
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:34529
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:35459
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:35459
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:51733
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:51733
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:60023
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:60023
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Got (long) serverId: 3
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 4
[GC 259695K->14174K(2944064K), 0.0438790 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|2] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-23668, physical addresses are [127.0.0.1:52003]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-23668] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|3] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668, deimos-esw-30156]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-23668] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|4] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668, deimos-esw-30156, deimos-esw-21002, deimos-esw-40435]
 INFO  [Incoming-4,deimos-esw-23668] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|5] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668, deimos-esw-30156, deimos-esw-21002, deimos-esw-40435, deimos-esw-41704, deimos-esw-18438]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-23668] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|6] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668, deimos-esw-30156, deimos-esw-21002, deimos-esw-40435, deimos-esw-41704, deimos-esw-18438, deimos-esw-270, deimos-esw-52266]
 INFO  [Incoming-4,deimos-esw-23668] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57872|7] [deimos-esw-57872, deimos-esw-21787, deimos-esw-53911, deimos-esw-23668, deimos-esw-30156, deimos-esw-21002, deimos-esw-40435, deimos-esw-41704, deimos-esw-18438, deimos-esw-270, deimos-esw-52266, deimos-esw-62495]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 3, serverOidBase: 3000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.InitTransaction} Waiting for version 3 to have a commitId
 INFO  [pool-1-thread-1] {jvstm.TransactionUtils} Setting the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} Set the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 4: org.radargun.cachewrappers.FFWrapperLF@655b395e
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@655b395e, nodeIndex=4, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
[GC 270238K->28098K(2944064K), 0.0624140 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.003 secs. Remaining: 59.997 secs. Total: 1 mins 0 secs
[GC 284162K->43399K(2944064K), 0.0575770 secs]
[GC 299463K->66228K(2944064K), 0.0639780 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=207.8M, free=2.6G, total=2.8G, max=4.7G, used/total=7.23% used/max=4.34%
cpu process-load=7.00%, system-load=83.00%, system-loadaverage=1214.00%
[GC 322292K->122014K(2944064K), 0.0818290 secs]
[GC 378078K->122869K(2944064K), 0.2051190 secs]
[GC 378933K->171301K(2944064K), 0.0944420 secs]
[GC 427365K->165724K(2944064K), 0.0880020 secs]
[GC 421788K->220342K(2944064K), 0.0858350 secs]
[GC 476406K->206870K(2944064K), 0.0915030 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 55250. Elapsed time: 20.009 secs. Remaining: 39.991 secs. Total: 1 mins 0 secs
[GC 462934K->258490K(2944064K), 0.1100470 secs]
[GC 514554K->289829K(2944064K), 0.1031510 secs]
[GC 545893K->283066K(2944064K), 0.1035000 secs]
[GC 539130K->301733K(2944064K), 0.0991850 secs]
[GC 557797K->357929K(2944064K), 0.1108590 secs]
[GC 613993K->380350K(2944064K), 0.1005850 secs]
[GC 636414K->403747K(2944064K), 0.1146690 secs]
[GC 659811K->424403K(2944064K), 0.1134430 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 133900. Elapsed time: 40.015 secs. Remaining: 19.985 secs. Total: 1 mins 0 secs
[GC 680467K->402570K(2944064K), 0.1077260 secs]
[GC 658634K->439564K(2944064K), 0.1063750 secs]
[GC 695628K->495697K(2944064K), 0.1101490 secs]
[GC 751761K->517987K(2944064K), 0.1143450 secs]
[GC 774051K->541576K(2944064K), 0.1218190 secs]
[GC 797623K->520876K(2944064K), 0.1116740 secs]
[GC 776940K->588643K(2944064K), 0.1110450 secs]
[GC 844707K->576302K(2944064K), 0.1013670 secs]
[GC 832366K->633974K(2944064K), 0.1110600 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 192600. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 8 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 68 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,298,113 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 645950K->552893K(2944064K), 2.1154910 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,389,565 kb - max:4,906,688 kb- total:2,944,320 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@655b395e, nodeIndex=4, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
[GC 809149K->630950K(2944320K), 0.0566160 secs]
[GC 887206K->602563K(2944320K), 0.0950140 secs]
[GC 858819K->628982K(2944320K), 0.1217800 secs]
[GC 885238K->650888K(2944320K), 0.1529460 secs]
[GC 907144K->675197K(2944320K), 0.2317210 secs]
[GC 931453K->695891K(2944320K), 0.2339510 secs]
[GC 952147K->710193K(2944320K), 0.2154480 secs]
[GC 966449K->726435K(2944320K), 0.2369110 secs]
[GC 982691K->742072K(2944320K), 0.2135970 secs]
[GC 998328K->761397K(2944320K), 0.2080840 secs]
[GC 1017653K->793700K(2944320K), 0.2413010 secs]
[GC 1049956K->798400K(2944320K), 0.2169500 secs]
[GC 1054656K->814595K(2944320K), 0.2022950 secs]
[GC 1070851K->830885K(2944320K), 0.2276340 secs]
[GC 1087141K->849410K(2944320K), 0.2125190 secs]
[GC 1105666K->865983K(2944320K), 0.2243620 secs]
[GC 1122239K->878262K(2944320K), 0.2145410 secs]
[GC 1134518K->914607K(2944320K), 0.2573020 secs]
[GC 1170863K->908427K(2944320K), 0.2186620 secs]
[GC 1164683K->937468K(2944320K), 0.2428280 secs]
[GC 1193724K->947963K(2944320K), 0.2635330 secs]
[GC 1204219K->949248K(2944320K), 0.2568250 secs]
[GC 1205504K->963854K(2944320K), 0.2655340 secs]
[GC 1220110K->995056K(2944320K), 0.2205030 secs]
[GC 1251312K->1010724K(2944320K), 0.2520420 secs]
[GC 1266980K->1050008K(2944320K), 0.2408320 secs]
[GC 1306264K->1027709K(2944320K), 0.2351450 secs]
[GC 1283965K->1081451K(2944320K), 0.2459460 secs]
[GC 1337707K->1084318K(2944320K), 0.2441820 secs]
[GC 1340574K->1099052K(2944320K), 0.2186130 secs]
[GC 1355308K->1133845K(2944320K), 0.2673930 secs]
[GC 1390101K->1122627K(2944320K), 0.2247820 secs]
[GC 1378883K->1153568K(2944320K), 0.2479660 secs]
[GC 1409824K->1181440K(2944320K), 0.2301180 secs]
[GC 1437696K->1150490K(2944320K), 0.2578870 secs]
[GC 1406746K->1203222K(2944320K), 0.2340900 secs]
[GC 1459478K->1235713K(2944320K), 0.2494590 secs]
[GC 1491969K->1216685K(2944320K), 0.2573450 secs]
[GC 1472941K->1265380K(2944320K), 0.2578820 secs]
[GC 1521636K->1273238K(2944320K), 0.2431750 secs]
[GC 1529494K->1292244K(2944320K), 0.2628420 secs]
[GC 1548500K->1324013K(2944320K), 0.2308200 secs]
[GC 1580269K->1310371K(2944320K), 0.2286620 secs]
[GC 1566627K->1324296K(2944320K), 0.2519390 secs]
[GC 1580552K->1338928K(2944320K), 0.2462790 secs]
[GC 1595184K->1336080K(2944320K), 0.2555740 secs]
[GC 1592336K->1402298K(2944320K), 0.2304340 secs]
[GC 1402883K(2944320K), 0.1177250 secs]
[GC 1658554K->1384814K(2944320K), 0.2402390 secs]
[GC 1558252K(2944320K), 0.1604330 secs]
[GC 1385392K->1170605K(2944320K), 0.2612160 secs]
[GC 1426861K->1167645K(2944320K), 0.2269630 secs]
[GC 1423901K->1197815K(2944320K), 0.2264040 secs]
[GC 1454071K->1210240K(2944320K), 0.2255210 secs]
[GC 1466496K->1209046K(2944320K), 0.2467220 secs]
[GC 1465302K->1240127K(2944320K), 0.2546420 secs]
[GC 1496383K->1258275K(2944320K), 0.2008810 secs]
[GC 1514531K->1287391K(2944320K), 0.2271550 secs]
[GC 1543647K->1306777K(2944320K), 0.2137590 secs]
[GC 1563033K->1286853K(2944320K), 0.2365700 secs]
[GC 1543109K->1328892K(2944320K), 0.2358690 secs]
[GC 1585148K->1324801K(2944320K), 0.2311580 secs]
[GC 1581057K->1369938K(2944320K), 0.2145070 secs]
[GC 1626194K->1349697K(2944320K), 0.2140810 secs]
[GC 1605953K->1387616K(2944320K), 0.2252230 secs]
[GC 1643872K->1414457K(2944320K), 0.2118380 secs]
[GC 1670713K->1401015K(2944320K), 0.2310100 secs]
[GC 1657271K->1435688K(2944320K), 0.2174750 secs]
[GC 1691944K->1449753K(2944320K), 0.2179470 secs]
[GC 1706009K->1480701K(2944320K), 0.2323340 secs]
[GC 1736957K->1463609K(2944320K), 0.1985270 secs]
[GC 1719865K->1488550K(2944320K), 0.2377160 secs]
[GC 1744806K->1528503K(2944320K), 0.2130550 secs]
[GC 1784759K->1532234K(2944320K), 0.2346500 secs]
[GC 1788490K->1567814K(2944320K), 0.2143600 secs]
[GC 1824070K->1577812K(2944320K), 0.2293390 secs]
[GC 1834068K->1576355K(2944320K), 0.2363430 secs]
[GC 1832611K->1568786K(2944320K), 0.2531300 secs]
[GC 1825042K->1633475K(2944320K), 0.2560600 secs]
[GC 1889731K->1614544K(2944320K), 0.2273280 secs]
[GC 1870800K->1655591K(2944320K), 0.2455950 secs]
[GC 1911847K->1686650K(2944320K), 0.2251650 secs]
[GC 1942906K->1667967K(2944320K), 0.2661020 secs]
[GC 1924223K->1720165K(2944320K), 0.2472150 secs]
[GC 1976421K->1704905K(2944320K), 0.2564580 secs]
[GC 1961161K->1744480K(2944320K), 0.2405690 secs]
[GC 2000736K->1750856K(2944320K), 0.2499520 secs]
[GC 2007112K->1785200K(2944320K), 0.2350490 secs]
[GC 2041456K->1766969K(2944320K), 0.2127530 secs]
[GC 2023225K->1809594K(2944320K), 0.2255460 secs]
[GC 2065850K->1818679K(2944320K), 0.2358100 secs]
[GC 2074935K->1820009K(2944320K), 0.2275350 secs]
[GC 2076265K->1862316K(2944320K), 0.2009770 secs]
[GC 2118572K->1857932K(2944320K), 0.2332140 secs]
[GC 2114188K->1888108K(2944320K), 0.2465940 secs]
[GC 2144364K->1916077K(2944320K), 0.2317610 secs]
[GC 2172333K->1921812K(2944320K), 0.2488280 secs]
[GC 2178055K->1953912K(2944320K), 0.2579870 secs]
[GC 2210168K->1973512K(2944320K), 0.2517910 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2229768K->2010170K(2944320K), 0.2198120 secs]
[GC 2266426K->2051729K(2944320K), 0.1777360 secs]
[GC 2307231K->2046827K(2944320K), 0.1340800 secs]
[GC 2303034K->2103992K(2944320K), 0.1408310 secs]
[GC 2358805K->2154085K(2944320K), 0.1392480 secs]
[GC 2410341K->2151280K(2944320K), 0.1341230 secs]
[GC 2407520K->2208229K(2944320K), 0.1385050 secs]
[GC 2464485K->2228940K(2944320K), 0.1347970 secs]
[GC 2485196K->2263663K(2944320K), 0.1462440 secs]
[GC 2519919K->2276348K(2944320K), 0.1430730 secs]
[GC 2532604K->2311721K(2944320K), 0.1392130 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 410000. Elapsed time: 20.086 secs. Remaining: 39.914 secs. Total: 1 mins 0 secs
[GC 2567977K->2375357K(2944320K), 0.1471550 secs]
[GC 2631601K->2380046K(2944320K), 0.1464230 secs]
[GC 2636302K->2429154K(2944320K), 0.1528320 secs]
[GC 2432469K(2944320K), 0.0931630 secs]
[GC 2685410K->2464206K(2944320K), 0.1571700 secs]
[GC 2720462K->2495081K(2944320K), 0.1455980 secs]
[GC 2674246K(2944320K), 0.0936740 secs]
[GC 2669913K->2412777K(2944320K), 0.1646780 secs]
[GC 2362712K->2165757K(2944320K), 0.1310550 secs]
[GC 2394413K->2158127K(3772816K), 0.1423290 secs]
[GC 2414383K->2210825K(3772816K), 0.1300460 secs]
[GC 2467081K->2215075K(3772816K), 0.1462130 secs]
[GC 2471170K->2247794K(3772816K), 0.1390030 secs]
[GC 2504050K->2270119K(3772816K), 0.1333440 secs]
[GC 2526375K->2305537K(3772816K), 0.1446310 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1340000. Elapsed time: 44.870 secs. Remaining: 15.130 secs. Total: 1 mins 0 secs
[GC 2561793K->2349094K(3772816K), 0.1418410 secs]
[GC 2605350K->2369014K(3772816K), 0.1490200 secs]
[GC 2625270K->2409251K(3772816K), 0.1353780 secs]
[GC 2665507K->2442671K(3772816K), 0.1347620 secs]
[GC 2698927K->2479000K(3772816K), 0.1494730 secs]
[GC 2735256K->2493966K(3772816K), 0.1430650 secs]
[GC 2750222K->2543423K(3772816K), 0.1388730 secs]
[GC 2799679K->2557602K(3772816K), 0.1322690 secs]
[GC 2813858K->2587928K(3772816K), 0.1342170 secs]
[GC 2844184K->2610797K(3772816K), 0.1270770 secs]
[GC 2867053K->2683716K(3772816K), 0.1377920 secs]
[GC 2939972K->2671527K(3772816K), 0.1444840 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 50000. Elapsed time: 1 mins 7 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 7 mins 33 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapperLF using infinispan52, clusterSize:12, nodeIndex:4, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2927783K->2742262K(3772816K), 0.1567670 secs]
[GC 2998518K->2746357K(3772816K), 0.1720320 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5705 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 72 ms.
