/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-16591 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-16591
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0637710 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapperLF with classloader java.net.URLClassLoader@2ca44b35
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-lf
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-lf.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeTransactionFactory()
Oct 07, 2013 2:08:33 PM jvstm.ActiveTransactionsRecord <clinit>
INFO: ********** AOM reversion = false (disable/enable it in property jvstm.aom.reversion)
Oct 07, 2013 2:08:33 PM jvstm.Transaction <clinit>
INFO: ********** GC vbodies = true (disable/enable it in property jvstm.gc.disabled)
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:33125
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:33125
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 51710 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34243
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:34243
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43788
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:43788
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42827
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:42827
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36970
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36970
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38996
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:38996
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 2
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
[GC 259695K->16729K(2944064K), 0.0498510 secs]
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-61818|2] [deimos-esw-61818, deimos-esw-26723, deimos-esw-51760]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-51760, physical addresses are [127.0.0.1:52002]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-51760] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-61818|3] [deimos-esw-61818, deimos-esw-26723, deimos-esw-51760, deimos-esw-45037, deimos-esw-31787]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-51760] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-61818|4] [deimos-esw-61818, deimos-esw-26723, deimos-esw-51760, deimos-esw-45037, deimos-esw-31787, deimos-esw-62203, deimos-esw-19158]
 INFO  [Incoming-3,deimos-esw-51760] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-61818|5] [deimos-esw-61818, deimos-esw-26723, deimos-esw-51760, deimos-esw-45037, deimos-esw-31787, deimos-esw-62203, deimos-esw-19158, deimos-esw-40053]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.InitTransaction} Waiting for version 4 to have a commitId
 INFO  [pool-1-thread-1] {jvstm.TransactionUtils} Setting the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd} Set the last committed TX number to 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapperLF} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapperLF@70a7284e
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@70a7284e, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 272793K->30367K(2944064K), 0.0573230 secs]
[GC 286431K->50465K(2944064K), 0.0615390 secs]
[GC 306529K->83252K(2944064K), 0.0655930 secs]
[GC 339316K->115893K(2944064K), 0.0723770 secs]
[GC 371957K->131523K(2944064K), 0.1572140 secs]
[GC 387587K->163859K(2944064K), 0.1134700 secs]
[GC 419923K->188490K(2944064K), 0.0894350 secs]
[GC 444554K->211389K(2944064K), 0.0958790 secs]
[GC 467453K->234247K(2944064K), 0.1013560 secs]
[GC 490311K->239746K(2944064K), 0.0998520 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 93150. Elapsed time: 20.006 secs. Remaining: 39.994 secs. Total: 1 mins 0 secs
[GC 495810K->242985K(2944064K), 0.1003320 secs]
[GC 499049K->298381K(2944064K), 0.1008100 secs]
[GC 554445K->320074K(2944064K), 0.1053290 secs]
[GC 576138K->324955K(2944064K), 0.0963830 secs]
[GC 581019K->362530K(2944064K), 0.1087270 secs]
[GC 618594K->367576K(2944064K), 0.1004600 secs]
[GC 623640K->387930K(2944064K), 0.1055320 secs]
[GC 643994K->424257K(2944064K), 0.1117750 secs]
[GC 680321K->427238K(2944064K), 0.0996180 secs]
[GC 683302K->461491K(2944064K), 0.1055880 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 258050. Elapsed time: 40.026 secs. Remaining: 19.974 secs. Total: 1 mins 0 secs
[GC 717555K->485488K(2944064K), 0.1142360 secs]
[GC 741552K->527306K(2944064K), 0.1201980 secs]
[GC 783370K->542916K(2944064K), 0.1114410 secs]
[GC 798980K->527092K(2944064K), 0.0974440 secs]
[GC 783156K->583516K(2944064K), 0.1051370 secs]
[GC 839580K->618231K(2944064K), 0.1176430 secs]
[GC 874295K->631438K(2944064K), 0.1172290 secs]
[GC 887502K->659667K(2944064K), 0.1323430 secs]
[GC 915731K->664481K(2944064K), 0.1292400 secs]
[GC 920545K->683667K(2944064K), 0.1172600 secs]
[GC 939731K->718020K(2944064K), 0.1025880 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 4 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 64 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,102,631 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 841432K->636192K(2944064K), 2.6650220 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,305,293 kb - max:4,906,688 kb- total:2,944,320 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@70a7284e, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapperLF using infinispan52
[GC 892448K->709289K(2944320K), 0.0802620 secs]
[GC 965545K->685000K(2944320K), 0.0933070 secs]
[GC 941256K->713837K(2944320K), 0.1275730 secs]
[GC 970093K->738534K(2944320K), 0.1621520 secs]
[GC 994790K->759110K(2944320K), 0.2472010 secs]
[GC 1015366K->787528K(2944320K), 0.1750340 secs]
[GC 1043784K->807463K(2944320K), 0.2560380 secs]
[GC 1063719K->796740K(2944320K), 0.2017940 secs]
[GC 1052996K->841470K(2944320K), 0.2178620 secs]
[GC 1097726K->851187K(2944320K), 0.2142000 secs]
[GC 1107443K->866397K(2944320K), 0.2270510 secs]
[GC 1122653K->903582K(2944320K), 0.2208110 secs]
[GC 1159838K->887593K(2944320K), 0.2413690 secs]
[GC 1143849K->932897K(2944320K), 0.2106170 secs]
[GC 1189153K->961894K(2944320K), 0.2300340 secs]
[GC 1218150K->952925K(2944320K), 0.2244110 secs]
[GC 1209181K->984181K(2944320K), 0.2199240 secs]
[GC 1240437K->1013083K(2944320K), 0.2437370 secs]
[GC 1269194K->1016985K(2944320K), 0.2231220 secs]
[GC 1273241K->998881K(2944320K), 0.2422330 secs]
[GC 1255137K->1030617K(2944320K), 0.2543560 secs]
[GC 1286873K->1067153K(2944320K), 0.2314070 secs]
[GC 1323409K->1068544K(2944320K), 0.2655160 secs]
[GC 1324800K->1108286K(2944320K), 0.2504930 secs]
[GC 1364542K->1129156K(2944320K), 0.2487500 secs]
[GC 1385412K->1159925K(2944320K), 0.2325850 secs]
[GC 1416181K->1142432K(2944320K), 0.2497920 secs]
[GC 1398688K->1185173K(2944320K), 0.2385870 secs]
[GC 1441429K->1176347K(2944320K), 0.2122550 secs]
[GC 1432603K->1229092K(2944320K), 0.2121780 secs]
[GC 1485348K->1210858K(2944320K), 0.2364400 secs]
[GC 1467114K->1256044K(2944320K), 0.2351340 secs]
[GC 1512300K->1283064K(2944320K), 0.2123970 secs]
[GC 1539320K->1277904K(2944320K), 0.2958470 secs]
[GC 1534160K->1324277K(2944320K), 0.1763070 secs]
[GC 1580533K->1310830K(2944320K), 0.2346320 secs]
[GC 1567086K->1347929K(2944320K), 0.2537030 secs]
[GC 1604185K->1382420K(2944320K), 0.2345240 secs]
[GC 1638676K->1362840K(2944320K), 0.2362060 secs]
[GC 1619096K->1418050K(2944320K), 0.2453100 secs]
[GC 1419036K(2944320K), 0.1273740 secs]
[GC 1674306K->1393767K(2944320K), 0.2318350 secs]
[GC 1551815K(2944320K), 0.2418340 secs]
[GC 1391900K->1176632K(2944320K), 0.2433010 secs]
[GC 1432888K->1206376K(2944320K), 0.1994670 secs]
[GC 1462632K->1212196K(2944320K), 0.2528200 secs]
[GC 1468452K->1214538K(2944320K), 0.2239480 secs]
[GC 1470794K->1245232K(2944320K), 0.2534790 secs]
[GC 1501488K->1276485K(2944320K), 0.2172890 secs]
[GC 1532741K->1299074K(2944320K), 0.2449960 secs]
[GC 1555330K->1282047K(2944320K), 0.2279610 secs]
[GC 1538303K->1326643K(2944320K), 0.2442580 secs]
[GC 1582899K->1335211K(2944320K), 0.2128970 secs]
[GC 1591467K->1333884K(2944320K), 0.2455860 secs]
[GC 1590140K->1386845K(2944320K), 0.2180460 secs]
[GC 1643101K->1370193K(2944320K), 0.2190320 secs]
[GC 1626449K->1414787K(2944320K), 0.2395350 secs]
[GC 1671043K->1423674K(2944320K), 0.2040040 secs]
[GC 1679930K->1458395K(2944320K), 0.2397720 secs]
[GC 1714651K->1441065K(2944320K), 0.2309720 secs]
[GC 1697321K->1483273K(2944320K), 0.2078370 secs]
[GC 1739529K->1472153K(2944320K), 0.2114260 secs]
[GC 1728409K->1490840K(2944320K), 0.2073080 secs]
[GC 1747096K->1532730K(2944320K), 0.1823860 secs]
[GC 1788986K->1514222K(2944320K), 0.2713850 secs]
[GC 1770478K->1572575K(2944320K), 0.2272530 secs]
[GC 1828831K->1555927K(2944320K), 0.2224800 secs]
[GC 1812183K->1613737K(2944320K), 0.2142650 secs]
[GC 1869993K->1635763K(2944320K), 0.2249450 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1891315K->1665768K(2944320K), 0.1575970 secs]
[GC 1922024K->1704948K(2944320K), 0.1726670 secs]
[GC 1961097K->1721206K(2944320K), 0.1279180 secs]
[GC 1975518K->1763008K(2944320K), 0.1265250 secs]
[GC 2019264K->1792881K(2944320K), 0.1276740 secs]
[GC 2049084K->1804302K(2944320K), 0.1207230 secs]
[GC 2060558K->1851467K(2944320K), 0.1200260 secs]
[GC 2107723K->1870794K(2944320K), 0.1176190 secs]
[GC 2127005K->1900883K(2944320K), 0.0968880 secs]
[GC 2157139K->1915810K(2944320K), 0.1663610 secs]
[GC 2172066K->1959814K(2944320K), 0.1017020 secs]
[GC 2216070K->1993393K(2944320K), 0.1609260 secs]
[GC 2249649K->2007406K(2944320K), 0.1309650 secs]
[GC 2263610K->2051234K(2944320K), 0.1348830 secs]
[GC 2307490K->2066781K(2944320K), 0.1255930 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1650000. Elapsed time: 20.063 secs. Remaining: 39.937 secs. Total: 1 mins 0 secs
[GC 2323037K->2116417K(2944320K), 0.1304770 secs]
[GC 2372673K->2127627K(2944320K), 0.1219010 secs]
[GC 2383883K->2177098K(2944320K), 0.1230920 secs]
[GC 2433354K->2204248K(2944320K), 0.1259920 secs]
[GC 2460216K->2212666K(2944320K), 0.1244320 secs]
[GC 2468922K->2244593K(2944320K), 0.1224760 secs]
[GC 2500849K->2294091K(2944320K), 0.1208530 secs]
[GC 2550347K->2328727K(2944320K), 0.1314820 secs]
[GC 2584983K->2337584K(2944320K), 0.1053620 secs]
[GC 2593551K->2375439K(2944320K), 0.1757750 secs]
[GC 2379688K(2944320K), 0.0661390 secs]
[GC 2631695K->2408848K(2944320K), 0.1486140 secs]
[GC 2665104K->2458607K(2944320K), 0.1350380 secs]
[GC 2714863K->2455519K(2944320K), 0.1429970 secs]
[GC 2620802K(2944320K), 0.1045650 secs]
[GC 2638385K->2419149K(2944320K), 0.1366900 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 670000. Elapsed time: 40.074 secs. Remaining: 19.926 secs. Total: 1 mins 0 secs
[GC 2426958K->2222319K(2944320K), 0.1388490 secs]
[GC 2345340K->2110566K(3673016K), 0.1383770 secs]
[GC 2366822K->2139783K(3673016K), 0.1465720 secs]
[GC 2396019K->2196115K(3673016K), 0.1503300 secs]
[GC 2452371K->2198491K(3673016K), 0.1497020 secs]
[GC 2454747K->2230824K(3673016K), 0.1433720 secs]
[GC 2487080K->2259867K(3673016K), 0.1410820 secs]
[GC 2515201K->2316916K(3673016K), 0.1480910 secs]
[GC 2573172K->2347091K(3673016K), 0.1389780 secs]
[GC 2603347K->2358407K(3673016K), 0.1299270 secs]
[GC 2614662K->2402246K(3673016K), 0.1335890 secs]
[GC 2658502K->2402890K(3673016K), 0.1274160 secs]
[GC 2659146K->2460160K(3673016K), 0.0994860 secs]
[GC 2716416K->2498188K(3673016K), 0.1761290 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2290000. Elapsed time: 1 mins 1 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2754444K->2489899K(3673016K), 0.1304110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 4 mins 15 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapperLF using infinispan52, clusterSize:8, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 65 ms.
