2013-10-02 18:24:39,441 [main] INFO  [org.radargun.Slave] Attempting to connect to master 127.0.0.1:2103
2013-10-02 18:24:39,447 [main] INFO  [org.radargun.Slave] Successfully established connection with master at: 127.0.0.1:2103
2013-10-02 18:24:41,632 [pool-1-thread-1] INFO  [org.radargun.config.AnnotatedHelper] Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
2013-10-02 18:24:41,779 [pool-1-thread-1] INFO  [org.radargun.config.AnnotatedHelper] Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
2013-10-02 18:24:42,118 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
2013-10-02 18:24:42,118 [pool-1-thread-1] INFO  [org.radargun.stages.DestroyWrapperStage] Received destroy cache wrapper request from master...
2013-10-02 18:24:42,118 [pool-1-thread-1] INFO  [org.radargun.stages.DestroyWrapperStage] No cache wrapper deployed on this slave, nothing to do.
2013-10-02 18:24:42,119 [pool-1-thread-1] INFO  [org.radargun.stages.DestroyWrapperStage] Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
2013-10-02 18:24:42,246 [pool-1-thread-1] INFO  [org.radargun.stages.DestroyWrapperStage] After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
2013-10-02 18:24:42,280 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
2013-10-02 18:24:42,281 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:24:42,322 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
2013-10-02 18:24:42,323 [pool-1-thread-1] INFO  [org.radargun.stages.StartClusterStage]  Startup staggering, starting 4 slaves. This is the slave with index 1. Sleeping for 5500 millis.
2013-10-02 18:24:47,823 [pool-1-thread-1] INFO  [org.radargun.stages.StartClusterStage] Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 1
2013-10-02 18:24:47,845 [pool-1-thread-1] INFO  [org.radargun.utils.ClassLoadHelper] Creating newInstance org.radargun.cachewrappers.FFWrapperLF with classloader java.net.URLClassLoader@52b2f956
2013-10-02 18:24:47,902 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.FFWrapperLF] config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=1, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
2013-10-02 18:24:47,955 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.FFWrapperLF] Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
2013-10-02 18:24:47,956 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.FFWrapperLF] Setting extra config properties for Fenix Framework.
2013-10-02 18:24:47,957 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.FFWrapperLF] Will initialize Fenix Framework with RadarGunDataGridConfig
2013-10-02 18:24:47,958 [pool-1-thread-1] TRACE [pt.ist.fenixframework.FenixFramework] Static initializer block for FenixFramework class [BEGIN]
2013-10-02 18:24:47,959 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Trying auto-initialization with configuration by convention
2013-10-02 18:24:47,959 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Resource 'fenix-framework.properties' not found
2013-10-02 18:24:47,960 [pool-1-thread-1] DEBUG [pt.ist.fenixframework.FenixFramework] Fenix Framework properties after reading default config file:{}
2013-10-02 18:24:47,960 [pool-1-thread-1] DEBUG [pt.ist.fenixframework.FenixFramework] CurrentBackEndName = jvstm-lf
2013-10-02 18:24:47,961 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Resource 'fenix-framework-jvstm-lf.properties' not found
2013-10-02 18:24:47,961 [pool-1-thread-1] DEBUG [pt.ist.fenixframework.FenixFramework] Fenix Framework properties after reading backend config file:{}
2013-10-02 18:24:47,961 [pool-1-thread-1] DEBUG [pt.ist.fenixframework.FenixFramework] Fenix Framework properties after enforcing system properties:{}
2013-10-02 18:24:47,961 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Skipping configuration by convention.
2013-10-02 18:24:47,961 [pool-1-thread-1] TRACE [pt.ist.fenixframework.FenixFramework] Static initializer block for FenixFramework class [END]
2013-10-02 18:24:47,962 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
2013-10-02 18:24:48,114 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd] initializeTransactionFactory()
2013-10-02 18:24:48,150 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd] initializeGroupCommunication()
2013-10-02 18:24:48,179 [pool-1-thread-1] INFO  [com.hazelcast.config.ClasspathXmlConfig] Configuring Hazelcast from 'hazelcast-ff.xml'.
2013-10-02 18:24:48,470 [pool-1-thread-1] INFO  [com.hazelcast.instance.DefaultAddressPicker] Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
2013-10-02 18:24:48,481 [pool-1-thread-1] INFO  [com.hazelcast.instance.DefaultAddressPicker] Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
2013-10-02 18:24:48,623 [pool-1-thread-1] INFO  [com.hazelcast.system] [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5703
2013-10-02 18:24:48,623 [pool-1-thread-1] INFO  [com.hazelcast.system] [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
2013-10-02 18:24:48,632 [pool-1-thread-1] INFO  [com.hazelcast.instance.Node] [127.0.0.1]:5703 [FenixFrameworkGroup] Creating MulticastJoiner
2013-10-02 18:24:48,638 [pool-1-thread-1] INFO  [com.hazelcast.core.LifecycleService] [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
2013-10-02 18:24:49,269 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:55941
2013-10-02 18:24:49,286 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:55941
2013-10-02 18:24:50,266 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
2013-10-02 18:24:52,054 [pool-1-thread-1] INFO  [com.hazelcast.cluster.TcpIpJoiner] [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
2013-10-02 18:24:52,059 [pool-1-thread-1] INFO  [com.hazelcast.cluster.TcpIpJoiner] [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
2013-10-02 18:24:52,060 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
2013-10-02 18:24:52,061 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
2013-10-02 18:24:52,062 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 59827 accepted socket connection from /127.0.0.1:5702
2013-10-02 18:24:52,063 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 52276 accepted socket connection from /127.0.0.1:5701
2013-10-02 18:24:53,065 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
2013-10-02 18:24:53,067 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] WARN  [com.hazelcast.nio.ReadHandler] [127.0.0.1]:5703 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
2013-10-02 18:24:53,177 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43957
2013-10-02 18:24:53,178 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:43957
2013-10-02 18:24:54,278 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:57947
2013-10-02 18:24:54,279 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:57947
2013-10-02 18:25:00,315 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] INFO  [com.hazelcast.cluster.ClusterService] [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [4] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
}

2013-10-02 18:25:03,122 [pool-1-thread-1] INFO  [com.hazelcast.core.LifecycleService] [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
2013-10-02 18:25:03,150 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils] Got (long) serverId: 1
2013-10-02 18:25:03,150 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd] This is NOT the first node.
2013-10-02 18:25:03,151 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.LockFreeClusterUtils] Waiting for startup from first node
2013-10-02 18:25:03,164 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd] initializeRepository()
2013-10-02 18:25:03,191 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator] config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=1, confAttributes={name=hzl3-repl-sync.xml}
2013-10-02 18:25:03,191 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.Hazelcast3Wrapper] Creating cache with the following configuration: hzl3-repl-sync.xml
2013-10-02 18:25:03,218 [pool-1-thread-1] INFO  [com.hazelcast.instance.DefaultAddressPicker] Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
2013-10-02 18:25:03,219 [pool-1-thread-1] INFO  [com.hazelcast.instance.DefaultAddressPicker] Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
2013-10-02 18:25:03,229 [pool-1-thread-1] INFO  [com.hazelcast.system] [127.0.0.1]:5706 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5706
2013-10-02 18:25:03,229 [pool-1-thread-1] INFO  [com.hazelcast.system] [127.0.0.1]:5706 [dev] Copyright (C) 2008-2013 Hazelcast.com
2013-10-02 18:25:03,230 [pool-1-thread-1] INFO  [com.hazelcast.instance.Node] [127.0.0.1]:5706 [dev] Creating MulticastJoiner
2013-10-02 18:25:03,230 [pool-1-thread-1] INFO  [com.hazelcast.core.LifecycleService] [127.0.0.1]:5706 [dev] Address[127.0.0.1]:5706 is STARTING
2013-10-02 18:25:08,361 [pool-1-thread-1] INFO  [com.hazelcast.cluster.TcpIpJoiner] [127.0.0.1]:5706 [dev] Connecting to possible member: Address[127.0.0.1]:5703
2013-10-02 18:25:08,362 [pool-1-thread-1] INFO  [com.hazelcast.cluster.TcpIpJoiner] [127.0.0.1]:5706 [dev] Connecting to possible member: Address[127.0.0.1]:5702
2013-10-02 18:25:08,362 [pool-1-thread-1] INFO  [com.hazelcast.cluster.TcpIpJoiner] [127.0.0.1]:5706 [dev] Connecting to possible member: Address[127.0.0.1]:5701
2013-10-02 18:25:08,363 [hz._hzInstance_2_dev.cached.thread-2] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5706 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
2013-10-02 18:25:08,364 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59055
2013-10-02 18:25:08,364 [hz._hzInstance_2_dev.cached.thread-2] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 59055 accepted socket connection from /127.0.0.1:5703
2013-10-02 18:25:08,364 [hz._hzInstance_2_dev.cached.thread-3] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5706 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
2013-10-02 18:25:08,365 [hz._hzInstance_2_dev.cached.thread-1] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5706 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
2013-10-02 18:25:08,366 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:59055
2013-10-02 18:25:08,366 [hz._hzInstance_2_dev.cached.thread-3] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 52621 accepted socket connection from /127.0.0.1:5702
2013-10-02 18:25:08,366 [hz._hzInstance_2_dev.cached.thread-1] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 34824 accepted socket connection from /127.0.0.1:5701
2013-10-02 18:25:09,052 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:57404
2013-10-02 18:25:09,053 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:57404
2013-10-02 18:25:09,366 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
2013-10-02 18:25:09,367 [hz._hzInstance_2_dev.IO.thread-in-2] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
2013-10-02 18:25:09,367 [hz._hzInstance_2_dev.IO.thread-in-0] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
2013-10-02 18:25:09,369 [hz._hzInstance_2_dev.IO.thread-in-2] WARN  [com.hazelcast.nio.ReadHandler] [127.0.0.1]:5706 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
2013-10-02 18:25:09,370 [hz._hzInstance_2_dev.IO.thread-in-0] WARN  [com.hazelcast.nio.ReadHandler] [127.0.0.1]:5706 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
2013-10-02 18:25:09,751 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43566
2013-10-02 18:25:09,752 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:43566
2013-10-02 18:25:10,053 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
2013-10-02 18:25:10,753 [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
2013-10-02 18:25:15,769 [hz._hzInstance_2_dev.cached.thread-3] INFO  [com.hazelcast.cluster.ClusterService] [127.0.0.1]:5706 [dev] 

Members [4] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
}

2013-10-02 18:25:15,772 [hz._hzInstance_2_dev.cached.thread-9] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5706 [dev] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
2013-10-02 18:25:15,772 [hz._hzInstance_2_dev.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5706 [dev] Accepting socket connection from /127.0.0.1:56691
2013-10-02 18:25:15,774 [hz._hzInstance_2_dev.cached.thread-9] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 49700 accepted socket connection from /127.0.0.1:5707
2013-10-02 18:25:15,774 [hz._hzInstance_2_dev.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 5706 accepted socket connection from /127.0.0.1:56691
2013-10-02 18:25:15,775 [hz._hzInstance_2_dev.IO.thread-Acceptor] INFO  [com.hazelcast.nio.SocketAcceptor] [127.0.0.1]:5706 [dev] Accepting socket connection from /127.0.0.1:40513
2013-10-02 18:25:15,776 [hz._hzInstance_2_dev.cached.thread-9] INFO  [com.hazelcast.nio.SocketConnector] [127.0.0.1]:5706 [dev] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
2013-10-02 18:25:15,776 [hz._hzInstance_2_dev.IO.thread-Acceptor] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 5706 accepted socket connection from /127.0.0.1:40513
2013-10-02 18:25:15,777 [hz._hzInstance_2_dev.cached.thread-9] INFO  [com.hazelcast.nio.TcpIpConnectionManager] [127.0.0.1]:5706 [dev] 39219 accepted socket connection from /127.0.0.1:5708
2013-10-02 18:25:18,371 [pool-1-thread-1] WARN  [com.hazelcast.instance.Node] [127.0.0.1]:5706 [dev] Config seed port is 5701 and cluster size is 4. Some of the ports seem occupied!
2013-10-02 18:25:18,373 [pool-1-thread-1] INFO  [com.hazelcast.core.LifecycleService] [127.0.0.1]:5706 [dev] Address[127.0.0.1]:5706 is STARTED
2013-10-02 18:25:18,375 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.Hazelcast3Wrapper] Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
2013-10-02 18:25:18,383 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Initialization marker is present. Data Grid already existed.
2013-10-02 18:25:18,386 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd] initializeDomainClassInfos
2013-10-02 18:25:18,389 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] serverId: 1, serverOidBase: 1000000000000
2013-10-02 18:25:18,448 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
2013-10-02 18:25:18,448 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
2013-10-02 18:25:18,448 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
2013-10-02 18:25:18,448 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
2013-10-02 18:25:18,449 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
2013-10-02 18:25:18,450 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
2013-10-02 18:25:18,450 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
2013-10-02 18:25:18,450 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
2013-10-02 18:25:18,450 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo] Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
2013-10-02 18:25:18,450 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd] setupJVSTM
2013-10-02 18:25:18,497 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.InitTransaction] Waiting for version 3 to have a commitId
2013-10-02 18:25:20,505 [pool-1-thread-1] INFO  [jvstm.TransactionUtils] Setting the last committed TX number to 4
2013-10-02 18:25:20,506 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.lf.JvstmLockFreeBackEnd] Set the last committed TX number to 4
2013-10-02 18:25:20,506 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd] createDomainRootIfNeeded
2013-10-02 18:25:20,506 [pool-1-thread-1] INFO  [pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd] ensureFenixFrameworkDataExists
2013-10-02 18:25:20,558 [pool-1-thread-1] INFO  [pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig] Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
2013-10-02 18:25:20,558 [pool-1-thread-1] INFO  [pt.ist.fenixframework.FenixFramework] Initialization of Fenix Framework is now complete.
2013-10-02 18:25:20,558 [pool-1-thread-1] INFO  [org.radargun.cachewrappers.FFWrapperLF] FF STARTED=true
2013-10-02 18:25:20,558 [pool-1-thread-1] INFO  [org.radargun.stages.helpers.StartHelper] Number of members is the one expected: 4
2013-10-02 18:25:20,558 [pool-1-thread-1] INFO  [org.radargun.stages.StartClusterStage] Successfully started cache wrapper on slave 1: org.radargun.cachewrappers.FFWrapperLF@55dbc59b
2013-10-02 18:25:20,563 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
2013-10-02 18:25:20,564 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:25:20,975 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
2013-10-02 18:25:21,022 [pool-1-thread-1] INFO  [org.radargun.stages.ClusterValidationStage] Number of caches that replicated here is 3
2013-10-02 18:25:21,023 [pool-1-thread-1] INFO  [org.radargun.stages.ClusterValidationStage] Replication test successfully passed. partialReplication? false, replicationCount = 3
2013-10-02 18:25:21,071 [pool-1-thread-1] INFO  [org.radargun.stages.ClusterValidationStage] Confirm phase successful.
2013-10-02 18:25:21,076 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3 ], useSmartClassLoading=true }
2013-10-02 18:25:21,076 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:25:21,118 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
2013-10-02 18:25:21,125 [pool-1-thread-1] INFO  [org.radargun.stages.StressTestWarmupStage] Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
2013-10-02 18:25:21,137 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Using key generator org.radargun.stressors.StringKeyGenerator, param null
2013-10-02 18:25:21,137 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@55dbc59b, nodeIndex=1, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
2013-10-02 18:25:21,139 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Cache wrapper info is: FFWrapperLF using hazelcast3
2013-10-02 18:25:21,165 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 2) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,166 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 3) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,167 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 4) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,167 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 5) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,168 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 6) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,168 [hz._hzInstance_2_dev.cached.thread-10] WARN  [com.hazelcast.transaction.TransactionManagerService] [127.0.0.1]:5706 [dev] No tx backup log is found, tx -> a278f05e-e41e-48d3-aece-fd731b58d1fb
2013-10-02 18:25:21,173 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 7) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,177 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 8) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,178 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 2) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,181 [hz._hzInstance_2_dev.cached.thread-3] WARN  [com.hazelcast.transaction.TransactionManagerService] [127.0.0.1]:5706 [dev] No tx backup log is found, tx -> 087b80bf-6610-4ceb-a899-ef7ac2da387d
2013-10-02 18:25:21,182 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 9) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,183 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 3) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,187 [Stressor-2] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 10) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,188 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 4) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,192 [Stressor-2] ERROR [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Giving up. Could not perform data grid operation.
2013-10-02 18:25:21,193 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 5) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,198 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 6) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,202 [hz._hzInstance_2_dev.cached.thread-3] WARN  [com.hazelcast.transaction.TransactionManagerService] [127.0.0.1]:5706 [dev] No tx backup log is found, tx -> 807a0bb9-7663-4043-a667-07dfc8667e75
2013-10-02 18:25:21,202 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 7) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,206 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 8) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,212 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 9) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,217 [Stressor-0] WARN  [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Will retry (attemp 10) failed transaction: java.lang.NullPointerException
2013-10-02 18:25:21,223 [Stressor-0] ERROR [pt.ist.fenixframework.backend.jvstm.repository.LockFreeRepository] Giving up. Could not perform data grid operation.
2013-10-02 18:25:22,595 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Started 4 stressor threads.
2013-10-02 18:25:22,599 [Stressor-3] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
2013-10-02 18:25:42,647 [Stressor-0] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 249750. Elapsed time: 20.051 secs. Remaining: 39.949 secs. Total: 1 mins 0 secs
2013-10-02 18:26:02,647 [Stressor-0] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 528779. Elapsed time: 40.051 secs. Remaining: 19.949 secs. Total: 1 mins 0 secs
2013-10-02 18:26:22,607 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Finished generating report. Test duration is: 1 mins 1 secs
2013-10-02 18:26:22,611 [pool-1-thread-1] INFO  [org.radargun.stages.StressTestWarmupStage] The warmup took: 61 seconds.
2013-10-02 18:26:22,623 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
2013-10-02 18:26:22,624 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:26:22,674 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
2013-10-02 18:26:22,676 [pool-1-thread-1] INFO  [org.radargun.stages.ClearClusterStage] Before executing clear, memory looks like this: Memory - free: 2,052,494 kb - max:4,906,688 kb- total:2,944,064 kb
2013-10-02 18:26:24,891 [pool-1-thread-1] INFO  [org.radargun.stages.ClearClusterStage] After executing cleanup, memory looks like this: Memory - free: 2,190,701 kb - max:4,906,688 kb- total:2,944,320 kb
2013-10-02 18:26:24,894 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
2013-10-02 18:26:24,895 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:26:25,098 [pool-1-thread-1] INFO  [org.radargun.Slave] Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=100, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
2013-10-02 18:26:25,103 [pool-1-thread-1] INFO  [org.radargun.stages.StressTestStage] Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=100, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
2013-10-02 18:26:25,110 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Using key generator org.radargun.stressors.StringKeyGenerator, param null
2013-10-02 18:26:25,110 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=100, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapperLF@55dbc59b, nodeIndex=1, useTransactions=true, transactionSize=100, commitTransactions=true, durationMillis=60000}
2013-10-02 18:26:25,112 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Cache wrapper info is: FFWrapperLF using hazelcast3
2013-10-02 18:26:25,493 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Started 4 stressor threads.
2013-10-02 18:26:25,494 [Stressor-3] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
2013-10-02 18:26:45,495 [Stressor-3] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 6964915. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
2013-10-02 18:27:05,495 [Stressor-1] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 13322603. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
2013-10-02 18:27:25,494 [Stressor-0] INFO  [org.radargun.stressors.StressTestStressor] Number of ops executed so far: 20029155. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
2013-10-02 18:27:25,500 [pool-1-thread-1] INFO  [org.radargun.stressors.StressTestStressor] Finished generating report. Test duration is: 1 mins 0 secs
2013-10-02 18:27:25,502 [pool-1-thread-1] INFO  [org.radargun.stages.StressTestStage] size info: FFWrapperLF using hazelcast3, clusterSize:4, nodeIndex:1, cacheSize: -1
2013-10-02 18:27:25,517 [pool-1-thread-1] INFO  [org.radargun.Slave] Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=100, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
2013-10-02 18:27:25,517 [main] INFO  [org.radargun.Slave] Ack successfully sent to the master
2013-10-02 18:27:26,530 [main] INFO  [org.radargun.Slave] Master shutdown!
2013-10-02 18:27:26,533 [Thread-0] INFO  [org.radargun.ShutDownHook] Slave process is being shutdown
2013-10-02 18:27:26,578 [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
2013-10-02 18:27:26,586 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
2013-10-02 18:27:26,587 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
2013-10-02 18:27:26,589 [hz.ShutdownThread] INFO  [com.hazelcast.initializer] [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
2013-10-02 18:27:26,591 [hz.ShutdownThread] INFO  [com.hazelcast.instance.Node] [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 58 ms.
2013-10-02 18:27:27,204 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
2013-10-02 18:27:27,206 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
2013-10-02 18:27:27,206 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
2013-10-02 18:27:27,207 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
2013-10-02 18:27:27,208 [hz.ShutdownThread] INFO  [com.hazelcast.nio.TcpIpConnection] [127.0.0.1]:5706 [dev] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
2013-10-02 18:27:27,209 [hz.ShutdownThread] INFO  [com.hazelcast.initializer] [127.0.0.1]:5706 [dev] Destroying node initializer.
2013-10-02 18:27:27,210 [hz.ShutdownThread] INFO  [com.hazelcast.instance.Node] [127.0.0.1]:5706 [dev] Hazelcast Shutdown is completed in 677 ms.
