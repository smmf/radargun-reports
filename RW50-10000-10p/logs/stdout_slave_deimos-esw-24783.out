/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-24783 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-24783
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0892220 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@60c90207
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5708, using socket ServerSocket[addr=/0.0.0.0,localport=5708], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5708
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 58674 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 36710 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 55160 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5708 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708 this
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 40025 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 35016 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 43931 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 59127 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:55438
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:59414
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:55438
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:59414
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 51403 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 55116 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:33943
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:33943
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:48742
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:48742
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 7
[GC 259695K->12114K(2944064K), 0.0517830 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|5] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-49873, physical addresses are [127.0.0.1:52007]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-49873] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|6] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547, deimos-esw-20378]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@202a2991
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@202a2991, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268178K->22306K(2944064K), 0.0573700 secs]
[GC 278370K->29683K(2944064K), 0.0454960 secs]
[GC 285747K->46199K(2944064K), 0.0516800 secs]
[GC 302263K->73159K(2944064K), 0.0558490 secs]
[GC 329223K->70922K(2944064K), 0.0597130 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 326986K->115674K(2944064K), 0.0670990 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 12750. Elapsed time: 20.037 secs. Remaining: 39.963 secs. Total: 1 mins 0 secs
[GC 371738K->112390K(2944064K), 0.1594240 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 17900. Elapsed time: 40.538 secs. Remaining: 19.462 secs. Total: 1 mins 0 secs
[GC 368454K->157697K(2944064K), 0.0759510 secs]
[GC 413761K->138914K(2944064K), 0.0726820 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 52 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 172 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,637,604 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 306459K->125349K(2944064K), 0.6149560 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,817,164 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@202a2991, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 381477K->188657K(2944192K), 0.0330320 secs]
[GC 444785K->142645K(2944192K), 0.0384550 secs]
[GC 398773K->157592K(2944192K), 0.0388000 secs]
[GC 413720K->168196K(2944192K), 0.0451970 secs]
[GC 424324K->182135K(2944192K), 0.0434130 secs]
[GC 438263K->187971K(2944192K), 0.0511530 secs]
[GC 444099K->201272K(2944192K), 0.0584460 secs]
[GC 457400K->214743K(2944192K), 0.0578530 secs]
[GC 470871K->228012K(2944192K), 0.0648660 secs]
[GC 484140K->248893K(2944192K), 0.0718840 secs]
[GC 505021K->225819K(2944192K), 0.1612790 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 481947K->273686K(2944192K), 0.1195490 secs]
[GC 529814K->239665K(2944192K), 0.0873020 secs]
[GC 495315K->272788K(2944192K), 0.0818060 secs]
[GC 528916K->297112K(2944192K), 0.1044360 secs]
[GC 553240K->329688K(2944192K), 0.0995790 secs]
[GC 583963K->326538K(2944192K), 0.1125100 secs]
[GC 581037K->343549K(2944192K), 0.0918550 secs]
[GC 599677K->376606K(2944192K), 0.0919000 secs]
[GC 632260K->377583K(2944192K), 0.0872470 secs]
[GC 633711K->430702K(2944192K), 0.0823630 secs]
[GC 686548K->415472K(2944192K), 0.0856240 secs]
[GC 671600K->471457K(2944192K), 0.0766240 secs]
[GC 727562K->449978K(2944192K), 0.0894660 secs]
[GC 706106K->509345K(2944192K), 0.0853370 secs]
[GC 765454K->489379K(2944192K), 0.0895630 secs]
[GC 745507K->545095K(2944192K), 0.0836660 secs]
[GC 801180K->526257K(2944192K), 0.0801300 secs]
[GC 782385K->585779K(2944192K), 0.0801500 secs]
[GC 841907K->562675K(2944192K), 0.0872130 secs]
[GC 818787K->623815K(2944192K), 0.0811370 secs]
[GC 879034K->600573K(2944192K), 0.0878520 secs]
[GC 856701K->662409K(2944192K), 0.0911940 secs]
[GC 918537K->654590K(2944192K), 0.0897900 secs]
[GC 909367K->701959K(2944192K), 0.0936320 secs]
[GC 958087K->686243K(2944192K), 0.0848580 secs]
[GC 942110K->692399K(2944192K), 0.0798910 secs]
[GC 948527K->731637K(2944192K), 0.0652470 secs]
[GC 987765K->753622K(2944192K), 0.0893400 secs]
[GC 1009700K->774049K(2944192K), 0.0852240 secs]
[GC 1030177K->783638K(2944192K), 0.0988230 secs]
[GC 1039766K->796083K(2944192K), 0.0797130 secs]
[GC 1052192K->828732K(2944192K), 0.0796550 secs]
[GC 1084860K->868750K(2944192K), 0.0846560 secs]
[GC 1124878K->847994K(2944192K), 0.0814990 secs]
[GC 1104109K->906808K(2944192K), 0.0800910 secs]
[GC 1162936K->893692K(2944192K), 0.0840400 secs]
[GC 1149820K->934039K(2944192K), 0.0827440 secs]
[GC 1190121K->938391K(2944192K), 0.0763120 secs]
[GC 1194519K->975336K(2944192K), 0.0805690 secs]
[GC 1230817K->962196K(2944192K), 0.0902050 secs]
[GC 1218324K->1020228K(2944192K), 0.0848660 secs]
[GC 1276339K->996317K(2944192K), 0.0838320 secs]
[GC 1251237K->1056777K(2944192K), 0.0807310 secs]
[GC 1312905K->1033990K(2944192K), 0.0792050 secs]
[GC 1290111K->1095257K(2944192K), 0.0789750 secs]
[GC 1351385K->1070740K(2944192K), 0.0784780 secs]
[GC 1326832K->1133687K(2944192K), 0.0825240 secs]
[GC 1389815K->1110583K(2944192K), 0.0831700 secs]
[GC 1366711K->1157869K(2944192K), 0.0778000 secs]
[GC 1413997K->1147505K(2944192K), 0.0691000 secs]
[GC 1403633K->1169000K(2944192K), 0.0623620 secs]
[GC 1425128K->1186062K(2944192K), 0.0607900 secs]
[GC 1442190K->1171181K(2944192K), 0.0798850 secs]
[GC 1427309K->1189796K(2944192K), 0.0624340 secs]
[GC 1445924K->1206366K(2944192K), 0.0638620 secs]
[GC 1462494K->1194836K(2944192K), 0.0842460 secs]
[GC 1450964K->1212404K(2944192K), 0.0639870 secs]
[GC 1468532K->1213540K(2944192K), 0.0698880 secs]
[GC 1469668K->1233677K(2944192K), 0.0793260 secs]
[GC 1489805K->1246238K(2944192K), 0.0783360 secs]
[GC 1502366K->1221347K(2944192K), 0.1504910 secs]
[GC 1477475K->1253337K(2944192K), 0.0770190 secs]
[GC 1509465K->1242660K(2944192K), 0.0814230 secs]
[GC 1498788K->1263651K(2944192K), 0.0738370 secs]
[GC 1519779K->1271265K(2944192K), 0.1323350 secs]
[GC 1527393K->1278925K(2944192K), 0.0790510 secs]
[GC 1535053K->1287106K(2944192K), 0.1444590 secs]
[GC 1543234K->1312411K(2944192K), 0.0753200 secs]
[GC 1568539K->1286742K(2944192K), 0.0727050 secs]
[GC 1542870K->1334911K(2944192K), 0.1149530 secs]
[GC 1591039K->1301171K(2944192K), 0.1230850 secs]
[GC 1557299K->1333513K(2944192K), 0.1201820 secs]
[GC 1589641K->1349265K(2944192K), 0.1178740 secs]
[GC 1605393K->1325671K(2944192K), 0.1133190 secs]
[GC 1581799K->1356150K(2944192K), 0.0720370 secs]
[GC 1612278K->1371348K(2944192K), 0.0741560 secs]
[GC 1627476K->1340306K(2944192K), 0.0691590 secs]
[GC 1596434K->1380270K(2944192K), 0.0792170 secs]
[GC 1636398K->1396356K(2944192K), 0.0793900 secs]
[GC 1652484K->1371678K(2944192K), 0.0785620 secs]
[GC 1372707K(2944192K), 0.0590850 secs]
[GC 1429030K(2944192K), 0.0471570 secs]
[GC 1381348K->1156276K(2944192K), 0.0720240 secs]
[GC 1412404K->1181096K(2944192K), 0.0730900 secs]
[GC 1437224K->1167924K(2944192K), 0.0844480 secs]
[GC 1424028K->1213770K(2944192K), 0.0918930 secs]
[GC 1469874K->1232734K(2944192K), 0.0861050 secs]
[GC 1488435K->1216056K(2944192K), 0.0925410 secs]
[GC 1472184K->1243919K(2944192K), 0.0811700 secs]
[GC 1500047K->1279990K(2944192K), 0.0796820 secs]
[GC 1536118K->1265244K(2944192K), 0.0816260 secs]
[GC 1521372K->1299570K(2944192K), 0.0811760 secs]
[GC 1555698K->1335829K(2944192K), 0.0832160 secs]
[GC 1591957K->1337132K(2944192K), 0.0807440 secs]
[GC 1593260K->1355090K(2944192K), 0.0808640 secs]
[GC 1611218K->1390617K(2944192K), 0.0803810 secs]
[GC 1646745K->1407057K(2944192K), 0.0828190 secs]
[GC 1663185K->1424575K(2944192K), 0.0851470 secs]
[GC 1680664K->1428740K(2944192K), 0.0815360 secs]
[GC 1684840K->1480674K(2944192K), 0.0899370 secs]
[GC 1736027K->1464587K(2944192K), 0.0830980 secs]
[GC 1720715K->1522482K(2944192K), 0.0838540 secs]
[GC 1778610K->1499220K(2944192K), 0.0737750 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1755348K->1521857K(2944192K), 0.0575720 secs]
[GC 1777985K->1538380K(2944192K), 0.0612410 secs]
[GC 1794508K->1523632K(2944192K), 0.0779920 secs]
[GC 1779760K->1546394K(2944192K), 0.0574530 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1802522K->1514261K(2944192K), 0.0594700 secs]
[GC 1770389K->1542286K(2944192K), 0.0808150 secs]
[GC 1798414K->1576640K(2944192K), 0.0680340 secs]
[GC 1832768K->1599794K(2944192K), 0.0850380 secs]
[GC 1855922K->1607306K(2944192K), 0.0913210 secs]
[GC 1863434K->1639084K(2944192K), 0.0889950 secs]
[GC 1895212K->1619321K(2944192K), 0.0940660 secs]
[GC 1875449K->1649345K(2944192K), 0.0856280 secs]
[GC 1905473K->1682326K(2944192K), 0.0803240 secs]
[GC 1938454K->1700525K(2944192K), 0.0789170 secs]
[GC 1956653K->1717631K(2944192K), 0.0808960 secs]
[GC 1973759K->1741008K(2944192K), 0.0797170 secs]
[GC 1997136K->1740611K(2944192K), 0.0796490 secs]
[GC 1996739K->1756713K(2944192K), 0.0813910 secs]
[GC 2012841K->1797095K(2944192K), 0.0789590 secs]
[GC 2052501K->1794744K(2944192K), 0.0798640 secs]
[GC 2050686K->1813446K(2944192K), 0.0804200 secs]
[GC 2069297K->1849453K(2944192K), 0.0811630 secs]
[GC 2105581K->1885111K(2944192K), 0.0826530 secs]
[GC 2141239K->1871070K(2944192K), 0.0799440 secs]
[GC 2127198K->1867230K(2944192K), 0.0773530 secs]
[GC 2123358K->1921228K(2944192K), 0.0687290 secs]
[GC 2177356K->1938627K(2944192K), 0.0914650 secs]
[GC 2194724K->1928891K(2944192K), 0.0879950 secs]
[GC 2183599K->1950854K(2944192K), 0.0909350 secs]
[GC 2206982K->1997952K(2944192K), 0.0834940 secs]
[GC 2254080K->2017349K(2944192K), 0.0825420 secs]
[GC 2273443K->2033183K(2944192K), 0.0827060 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2289311K->2034098K(2944192K), 0.0845040 secs]
[GC 2290226K->2057392K(2944192K), 0.0806870 secs]
[GC 2313520K->2089888K(2944192K), 0.0821880 secs]
[GC 2346016K->2111607K(2944192K), 0.0833840 secs]
[GC 2367710K->2095926K(2944192K), 0.0869420 secs]
[GC 2352054K->2129890K(2944192K), 0.0885290 secs]
[GC 2386018K->2148790K(2944192K), 0.0959570 secs]
[GC 2404918K->2199116K(2944192K), 0.0976070 secs]
[GC 2455244K->2171218K(2944192K), 0.0906020 secs]
[GC 2427346K->2188891K(2944192K), 0.0851390 secs]
[GC 2445019K->2240363K(2944192K), 0.0683640 secs]
[GC 2496491K->2223495K(2944192K), 0.0880520 secs]
[GC 2479623K->2242726K(2944192K), 0.0652640 secs]
[GC 2498854K->2263345K(2944192K), 0.0699300 secs]
[GC 2519473K->2249732K(2944192K), 0.0895170 secs]
[GC 2505860K->2269356K(2944192K), 0.0663450 secs]
[GC 2524887K->2299283K(2944192K), 0.0917110 secs]
[GC 2555358K->2319523K(2944192K), 0.1011800 secs]
[GC 2575651K->2341610K(2944192K), 0.1087150 secs]
[GC 2597738K->2362089K(2944192K), 0.1099180 secs]
[GC 2618217K->2359683K(2944192K), 0.1132800 secs]
[GC 2615753K->2359578K(2944192K), 0.1020880 secs]
[GC 2615706K->2398636K(2944192K), 0.0989350 secs]
[GC 2654764K->2398574K(2944192K), 0.0958130 secs]
[GC 2654157K->2449748K(2944192K), 0.0951990 secs]
[GC 2705876K->2434003K(2944192K), 0.0904130 secs]
[GC 2434102K(2944192K), 0.0329800 secs]
[GC 2690131K->2487620K(2944192K), 0.0903230 secs]
[GC 2618647K(2944192K), 0.0533580 secs]
[GC 2416933K->2175973K(3811164K), 0.1021220 secs]
[GC 2432101K->2198580K(3811164K), 0.1015080 secs]
[GC 2454708K->2201522K(3811164K), 0.1089550 secs]
[GC 2457650K->2219691K(3811164K), 0.1006740 secs]
[GC 2475819K->2239193K(3811164K), 0.0974380 secs]
[GC 2495321K->2239048K(3811164K), 0.0977290 secs]
[GC 2495176K->2256824K(3811164K), 0.0865750 secs]
[GC 2512952K->2306833K(3811164K), 0.0707030 secs]
[GC 2562961K->2290139K(3811164K), 0.0859950 secs]
[GC 2546248K->2319997K(3811164K), 0.0780640 secs]
[GC 2576125K->2339734K(3811164K), 0.0963160 secs]
[GC 2595846K->2377356K(3811164K), 0.1005700 secs]
[GC 2633484K->2367949K(3811164K), 0.1014730 secs]
[GC 2624077K->2407823K(3811164K), 0.0905230 secs]
[GC 2663951K->2419351K(3811164K), 0.0962430 secs]
[GC 2673991K->2435247K(3811164K), 0.0995380 secs]
[GC 2691340K->2454288K(3811164K), 0.0971940 secs]
[GC 2708399K->2472924K(3811164K), 0.0932740 secs]
[GC 2729052K->2476202K(3811164K), 0.0929500 secs]
[GC 2732330K->2494559K(3811164K), 0.1016800 secs]
[GC 2750687K->2544933K(3811164K), 0.1057660 secs]
[GC 2801061K->2531563K(3811164K), 0.0944970 secs]
[GC 2787691K->2587609K(3811164K), 0.0959480 secs]
[GC 2843737K->2565574K(3811164K), 0.0987610 secs]
[GC 2819617K->2627292K(3811164K), 0.0994780 secs]
[GC 2883377K->2602223K(3811164K), 0.0977060 secs]
[GC 2858351K->2660189K(3811164K), 0.0979900 secs]
[GC 2916317K->2636635K(3811164K), 0.0865910 secs]
[GC 2892763K->2663011K(3811164K), 0.0775870 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 2919139K->2689696K(3811164K), 0.0954460 secs]
[GC 2945824K->2724223K(3811164K), 0.1048480 secs]
[GC 2979140K->2706245K(3811164K), 0.0789940 secs]
[GC 2962321K->2730515K(3811164K), 0.0740990 secs]
[GC 2985064K->2761688K(3811164K), 0.0914230 secs]
[GC 3017816K->2749623K(3811164K), 0.0912460 secs]
[GC 3005751K->2777704K(3811164K), 0.0745490 secs]
[GC 3031102K->2784391K(3811164K), 0.0969310 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 260000. Elapsed time: 20.183 secs. Remaining: 39.817 secs. Total: 1 mins 0 secs
[GC 3040320K->2776326K(3811164K), 0.0790710 secs]
[GC 3032454K->2814136K(3811164K), 0.0735760 secs]
[GC 3070264K->2805477K(3811164K), 0.0873520 secs]
[GC 3061605K->2845459K(3811164K), 0.0734410 secs]
[GC 3101587K->2834576K(3811164K), 0.0900330 secs]
[GC 3090700K->2849318K(3811164K), 0.0915790 secs]
[GC 3104596K->2877446K(3811164K), 0.0732020 secs]
[GC 3133425K->2879152K(3811164K), 0.0909160 secs]
[GC 3135280K->2895091K(3811164K), 0.0939450 secs]
[GC 3151219K->2928494K(3811164K), 0.0750900 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 570000. Elapsed time: 40.545 secs. Remaining: 19.455 secs. Total: 1 mins 0 secs
[GC 3184622K->2911566K(3811164K), 0.0890030 secs]
[GC 3167691K->2920812K(3811164K), 0.0728910 secs]
[GC 3176289K->2957562K(3811164K), 0.0874690 secs]
[GC 3213690K->2953801K(3811164K), 0.0872770 secs]
[GC 3209929K->2978721K(3811164K), 0.0770170 secs]
[GC 3234849K->3017357K(3811164K), 0.0866540 secs]
[GC 3273485K->2992384K(3811164K), 0.0896870 secs]
[GC 3248512K->3026388K(3811164K), 0.0808220 secs]
[GC 3282465K->3057629K(3811164K), 0.0836820 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 970000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 42 mins 9 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3313757K->3039225K(3811164K), 0.0885920 secs]
[GC 3295321K->3051383K(3811164K), 0.0591970 secs]
[GC 3307511K->3057535K(3811164K), 0.0738630 secs]
[GC 3313663K->3090539K(3811164K), 0.0872880 secs]
[GC 3346667K->3141836K(3811164K), 0.1198870 secs]
[GC 3397964K->3129740K(3811164K), 0.1062600 secs]
[GC 3385868K->3178475K(3811164K), 0.0993600 secs]
[GC 3434549K->3185617K(3811164K), 0.1091360 secs]
[GC 3441745K->3224079K(3811164K), 0.1050810 secs]
[GC 3480207K->3220667K(3811164K), 0.1042540 secs]
[GC 3476795K->3256780K(3811164K), 0.1188040 secs]
[GC 3512908K->3252980K(3811164K), 0.1018920 secs]
[GC 3252992K(3811164K), 0.0394130 secs]
[GC 3509108K->3291623K(3811164K), 0.1062960 secs]
[GC 3420459K(3811164K), 0.0524100 secs]
[GC 3208967K->2971871K(4650880K), 0.1153760 secs]
[GC 3227999K->2993698K(4650880K), 0.1137610 secs]
[GC 3249826K->3013035K(4650880K), 0.1073250 secs]
[GC 3269163K->3048882K(4650880K), 0.1093200 secs]
[GC 3305010K->3040420K(4650880K), 0.1134670 secs]
[GC 3296548K->3084087K(4650880K), 0.1100940 secs]
[GC 3340215K->3055884K(4650880K), 0.1035680 secs]
[GC 3312012K->3078410K(4650880K), 0.0971890 secs]
[GC 3334538K->3133656K(4650880K), 0.0859930 secs]
[GC 3389784K->3152803K(4650880K), 0.1108460 secs]
[GC 3408931K->3156281K(4650880K), 0.1186320 secs]
[GC 3412409K->3176028K(4650880K), 0.1119300 secs]
[GC 3432156K->3210729K(4650880K), 0.1271940 secs]
[GC 3466857K->3216088K(4650880K), 0.1125770 secs]
[GC 3472216K->3266736K(4650880K), 0.1038830 secs]
[GC 3522849K->3254399K(4650880K), 0.0976350 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3510527K->3307780K(4650880K), 0.1017060 secs]
[GC 3563908K->3302231K(4650880K), 0.1052850 secs]
[GC 3558359K->3341831K(4650880K), 0.1157250 secs]
[GC 3597959K->3369065K(4650880K), 0.1042080 secs]
[GC 3623510K->3359593K(4650880K), 0.1119910 secs]
[GC 3615718K->3376474K(4650880K), 0.0960320 secs]
[GC 3632602K->3415786K(4650880K), 0.1032220 secs]
[GC 3671914K->3435546K(4650880K), 0.1039560 secs]
[GC 3691674K->3470995K(4650880K), 0.1109370 secs]
[GC 3727123K->3456984K(4650880K), 0.1038480 secs]
[GC 3713112K->3507210K(4650880K), 0.1060790 secs]
[GC 3763338K->3514479K(4650880K), 0.0964630 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3770607K->3537679K(4650880K), 0.1057850 secs]
[GC 3793807K->3573261K(4650880K), 0.1066250 secs]
[GC 3828081K->3559585K(4650880K), 0.0982710 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5708 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 63 ms.
