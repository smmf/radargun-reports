/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-20772 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-20772
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0757650 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@a2e02b2
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 50064 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 52296 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 55054 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 50862 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 54096 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:45329
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 41257 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:60456
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 42785 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:60456
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 38276 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 33272 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:45329
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:42054
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:42054
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49242 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:54075
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 51013 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:54075
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:50241
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:50241
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->12783K(2944064K), 0.0402860 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|3] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-42077, physical addresses are [127.0.0.1:52004]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-42077] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|4] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-42077] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|5] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207]
 INFO  [Incoming-3,deimos-esw-42077] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|6] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-3,deimos-esw-42077] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|7] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403, deimos-esw-20931, deimos-esw-27783]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 4, serverOidBase: 4000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@6c847916
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 4
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6c847916, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268847K->22364K(2944064K), 0.0571590 secs]
[GC 278428K->33117K(2944064K), 0.0474910 secs]
[GC 289181K->46603K(2944064K), 0.0523320 secs]
[GC 302667K->66038K(2944064K), 0.0534930 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 322102K->79637K(2944064K), 0.0620630 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6750. Elapsed time: 20.074 secs. Remaining: 39.926 secs. Total: 1 mins 0 secs
[GC 335701K->114128K(2944064K), 0.0666620 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16550. Elapsed time: 40.201 secs. Remaining: 19.799 secs. Total: 1 mins 0 secs
[GC 370192K->117155K(2944064K), 0.1322070 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 26300. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 41 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 161 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 373219K->129917K(2944064K), 0.0927990 secs]
[GC 385981K->177473K(2944064K), 0.0731510 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,666,032 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 278031K->129331K(2944064K), 0.5239550 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,644 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6c847916, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 385459K->173903K(2944192K), 0.0356960 secs]
[GC 430031K->154539K(2944192K), 0.0390850 secs]
[GC 410667K->155774K(2944192K), 0.0458840 secs]
[GC 411902K->167351K(2944192K), 0.0440720 secs]
[GC 423479K->183218K(2944192K), 0.0481690 secs]
[GC 439346K->198256K(2944192K), 0.0527200 secs]
[GC 454384K->213572K(2944192K), 0.1503220 secs]
[GC 469700K->216381K(2944192K), 0.0593000 secs]
[GC 472509K->229374K(2944192K), 0.0652020 secs]
[GC 485502K->233775K(2944192K), 0.0728770 secs]
[GC 489903K->244162K(2944192K), 0.0793370 secs]
[GC 500290K->252887K(2944192K), 0.0778150 secs]
[GC 509015K->243924K(2944192K), 0.1712050 secs]
[GC 500052K->285741K(2944192K), 0.0795280 secs]
[GC 541869K->259136K(2944192K), 0.1685640 secs]
[GC 515264K->321593K(2944192K), 0.1716310 secs]
[GC 577694K->320045K(2944192K), 0.0933650 secs]
[GC 575427K->330147K(2944192K), 0.1298970 secs]
[GC 586275K->365213K(2944192K), 0.0944770 secs]
[GC 621290K->386200K(2944192K), 0.1118720 secs]
[GC 642328K->405594K(2944192K), 0.0986050 secs]
[GC 661709K->405270K(2944192K), 0.0908560 secs]
[GC 661398K->461579K(2944192K), 0.0991600 secs]
[GC 717707K->444494K(2944192K), 0.0925840 secs]
[GC 700577K->499484K(2944192K), 0.0887020 secs]
[GC 755612K->475994K(2944192K), 0.0960300 secs]
[GC 732122K->537796K(2944192K), 0.0890650 secs]
[GC 792837K->514204K(2944192K), 0.0936770 secs]
[GC 770332K->574884K(2944192K), 0.0902130 secs]
[GC 830987K->553255K(2944192K), 0.0871640 secs]
[GC 809383K->610610K(2944192K), 0.0885840 secs]
[GC 866714K->590697K(2944192K), 0.0900180 secs]
[GC 846653K->650618K(2944192K), 0.0952620 secs]
[GC 906746K->631100K(2944192K), 0.0920600 secs]
[GC 887228K->647900K(2944192K), 0.0962430 secs]
[GC 904028K->667785K(2944192K), 0.0882400 secs]
[GC 923300K->708332K(2944192K), 0.0746930 secs]
[GC 964460K->707781K(2944192K), 0.0990320 secs]
[GC 962852K->753935K(2944192K), 0.0948610 secs]
[GC 1010063K->735492K(2944192K), 0.0973440 secs]
[GC 991507K->764308K(2944192K), 0.1042160 secs]
[GC 1020436K->782055K(2944192K), 0.0977950 secs]
[GC 1038183K->799641K(2944192K), 0.0975480 secs]
[GC 1054780K->837082K(2944192K), 0.1047490 secs]
[GC 1093210K->822925K(2944192K), 0.0989190 secs]
[GC 1079053K->890728K(2944192K), 0.0996340 secs]
[GC 1146851K->875185K(2944192K), 0.0986460 secs]
[GC 1131313K->933581K(2944192K), 0.1004350 secs]
[GC 1189697K->910426K(2944192K), 0.0958690 secs]
[GC 1166554K->967980K(2944192K), 0.0982040 secs]
[GC 1224108K->948542K(2944192K), 0.0968430 secs]
[GC 1202787K->1004993K(2944192K), 0.1028750 secs]
[GC 1261121K->984050K(2944192K), 0.0979130 secs]
[GC 1240178K->999309K(2944192K), 0.0891540 secs]
[GC 1255388K->1059050K(2944192K), 0.0899170 secs]
[GC 1315178K->1045103K(2944192K), 0.0992070 secs]
[GC 1301231K->1073897K(2944192K), 0.0940820 secs]
[GC 1330025K->1062470K(2944192K), 0.0835440 secs]
[GC 1318598K->1097328K(2944192K), 0.0675360 secs]
[GC 1353456K->1103437K(2944192K), 0.0745220 secs]
[GC 1359565K->1086416K(2944192K), 0.0866200 secs]
[GC 1342544K->1104653K(2944192K), 0.0668530 secs]
[GC 1360781K->1124406K(2944192K), 0.0645090 secs]
[GC 1380534K->1110114K(2944192K), 0.0807210 secs]
[GC 1366242K->1126083K(2944192K), 0.0587560 secs]
[GC 1382211K->1142369K(2944192K), 0.0657630 secs]
[GC 1398497K->1128396K(2944192K), 0.0830740 secs]
[GC 1384524K->1153778K(2944192K), 0.0999260 secs]
[GC 1409906K->1129674K(2944192K), 0.0965620 secs]
[GC 1385802K->1167590K(2944192K), 0.0931120 secs]
[GC 1423718K->1198959K(2944192K), 0.0891260 secs]
[GC 1455087K->1170946K(2944192K), 0.1004450 secs]
[GC 1427074K->1195831K(2944192K), 0.0950030 secs]
[GC 1451959K->1212503K(2944192K), 0.1593170 secs]
[GC 1468631K->1187965K(2944192K), 0.0942000 secs]
[GC 1444093K->1232380K(2944192K), 0.1391180 secs]
[GC 1488508K->1200507K(2944192K), 0.0951610 secs]
[GC 1456635K->1248132K(2944192K), 0.1166390 secs]
[GC 1504260K->1215992K(2944192K), 0.1148100 secs]
[GC 1472120K->1266044K(2944192K), 0.1731560 secs]
[GC 1522172K->1231709K(2944192K), 0.1743800 secs]
[GC 1487837K->1259398K(2944192K), 0.1035160 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1515526K->1282628K(2944192K), 0.0920290 secs]
[GC 1538756K->1259235K(2944192K), 0.0928770 secs]
[GC 1515363K->1288731K(2944192K), 0.0897160 secs]
[GC 1544859K->1303933K(2944192K), 0.1212230 secs]
[GC 1560061K->1281945K(2944192K), 0.1190400 secs]
[GC 1538073K->1327600K(2944192K), 0.0998210 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1583728K->1296980K(2944192K), 0.0866340 secs]
[GC 1553108K->1343221K(2944192K), 0.0840850 secs]
[GC 1599349K->1310209K(2944192K), 0.0857160 secs]
[GC 1566337K->1328929K(2944192K), 0.1573700 secs]
[GC 1585057K->1358175K(2944192K), 0.0800800 secs]
[GC 1614303K->1326712K(2944192K), 0.0740440 secs]
[GC 1582840K->1366442K(2944192K), 0.0869220 secs]
[GC 1622570K->1382739K(2944192K), 0.0794760 secs]
[GC 1638867K->1358047K(2944192K), 0.0795210 secs]
[GC 1614175K->1405128K(2944192K), 0.1632280 secs]
[GC 1661256K->1369687K(2944192K), 0.0765510 secs]
[GC 1370392K(2944192K), 0.0589460 secs]
[GC 1425929K(2944192K), 0.0457850 secs]
[GC 1387807K->1165596K(2944192K), 0.0763560 secs]
[GC 1421724K->1143025K(2944192K), 0.0735630 secs]
[GC 1399153K->1174628K(2944192K), 0.0722670 secs]
[GC 1430756K->1172500K(2944192K), 0.0655520 secs]
[GC 1428628K->1195968K(2944192K), 0.0665660 secs]
[GC 1452096K->1171485K(2944192K), 0.0689310 secs]
[GC 1427613K->1199159K(2944192K), 0.0677300 secs]
[GC 1455287K->1214020K(2944192K), 0.0676190 secs]
[GC 1470148K->1191064K(2944192K), 0.0625730 secs]
[GC 1447192K->1227207K(2944192K), 0.0605300 secs]
[GC 1483335K->1193031K(2944192K), 0.0784230 secs]
[GC 1449159K->1196901K(2944192K), 0.0619470 secs]
[GC 1453029K->1259273K(2944192K), 0.0572530 secs]
[GC 1515401K->1230407K(2944192K), 0.0744560 secs]
[GC 1484962K->1261779K(2944192K), 0.0750640 secs]
[GC 1517271K->1298572K(2944192K), 0.0996580 secs]
[GC 1554675K->1308556K(2944192K), 0.0886390 secs]
[GC 1564684K->1298836K(2944192K), 0.1019580 secs]
[GC 1554960K->1308411K(2944192K), 0.0887110 secs]
[GC 1564539K->1361181K(2944192K), 0.0848010 secs]
[GC 1617309K->1396842K(2944192K), 0.0853660 secs]
[GC 1652970K->1379401K(2944192K), 0.0855040 secs]
[GC 1635529K->1439767K(2944192K), 0.0858810 secs]
[GC 1695527K->1416283K(2944192K), 0.0879060 secs]
[GC 1672411K->1458761K(2944192K), 0.0836960 secs]
[GC 1714873K->1468506K(2944192K), 0.0888020 secs]
[GC 1724634K->1503568K(2944192K), 0.0865870 secs]
[GC 1759686K->1489282K(2944192K), 0.0796420 secs]
[GC 1745373K->1547845K(2944192K), 0.0812440 secs]
[GC 1803973K->1525566K(2944192K), 0.0862510 secs]
[GC 1781694K->1522186K(2944192K), 0.0840950 secs]
[GC 1778314K->1570354K(2944192K), 0.0693780 secs]
[GC 1826482K->1585012K(2944192K), 0.0921440 secs]
[GC 1841140K->1608050K(2944192K), 0.0936760 secs]
[GC 1864178K->1628454K(2944192K), 0.0957380 secs]
[GC 1884582K->1631734K(2944192K), 0.0931520 secs]
[GC 1887862K->1633739K(2944192K), 0.0925840 secs]
[GC 1888045K->1684672K(2944192K), 0.0953490 secs]
[GC 1940800K->1686154K(2944192K), 0.0885320 secs]
[GC 1942282K->1719055K(2944192K), 0.0891110 secs]
[GC 1974919K->1724074K(2944192K), 0.0846710 secs]
[GC 1980164K->1741413K(2944192K), 0.0867070 secs]
[GC 1997541K->1762026K(2944192K), 0.0892140 secs]
[GC 2016586K->1778749K(2944192K), 0.0927430 secs]
[GC 2034865K->1811104K(2944192K), 0.0900160 secs]
[GC 2067232K->1814341K(2944192K), 0.0871440 secs]
[GC 2070469K->1814752K(2944192K), 0.0810680 secs]
[GC 2070880K->1864607K(2944192K), 0.0617180 secs]
[GC 2120735K->1835124K(2944192K), 0.0656820 secs]
[GC 2091252K->1835053K(2944192K), 0.0872160 secs]
[GC 2091181K->1886857K(2944192K), 0.0625150 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2142985K->1884508K(2944192K), 0.0941030 secs]
[GC 2140636K->1936624K(2944192K), 0.0879170 secs]
[GC 2192752K->1926458K(2944192K), 0.0988330 secs]
[GC 2182586K->1955741K(2944192K), 0.0790040 secs]
[GC 2211813K->1945993K(2944192K), 0.0588450 secs]
[GC 2200872K->1969253K(2944192K), 0.0755430 secs]
[GC 2225053K->1990376K(2944192K), 0.0687050 secs]
[GC 2246504K->1992626K(2944192K), 0.0798110 secs]
[GC 2248754K->2008687K(2944192K), 0.0780330 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 370000. Elapsed time: 20.229 secs. Remaining: 39.771 secs. Total: 1 mins 0 secs
[GC 2264815K->2010749K(2944192K), 0.0674100 secs]
[GC 2266877K->2037237K(2944192K), 0.0696460 secs]
[GC 2293326K->2069668K(2944192K), 0.0828400 secs]
[GC 2325513K->2059983K(2944192K), 0.0928230 secs]
[GC 2315744K->2086588K(2944192K), 0.0791400 secs]
[GC 2342302K->2091748K(2944192K), 0.1143640 secs]
[GC 2347876K->2118009K(2944192K), 0.0780950 secs]
[GC 2374137K->2100596K(2944192K), 0.0751860 secs]
[GC 2356724K->2109484K(2944192K), 0.0688410 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 650796. Elapsed time: 40.229 secs. Remaining: 19.771 secs. Total: 1 mins 0 secs
[GC 2364523K->2155059K(2944192K), 0.0878820 secs]
[GC 2408154K->2154285K(2944192K), 0.0890170 secs]
[GC 2408975K->2155339K(2944192K), 0.0769680 secs]
[GC 2411467K->2181838K(2944192K), 0.0712470 secs]
[GC 2437870K->2198571K(2944192K), 0.0777750 secs]
[GC 2454699K->2200031K(2944192K), 0.0746640 secs]
[GC 2456159K->2220697K(2944192K), 0.0672320 secs]
[GC 2476825K->2244827K(2944192K), 0.0844770 secs]
[GC 2497800K->2239370K(2944192K), 0.0928840 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1020000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 46 mins 26 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2495497K->2232584K(2944192K), 0.0723910 secs]
[GC 2488657K->2238324K(2944192K), 0.0647910 secs]
[GC 2494452K->2262517K(2944192K), 0.0831790 secs]
[GC 2518641K->2315770K(2944192K), 0.0997540 secs]
[GC 2571898K->2315443K(2944192K), 0.1260930 secs]
[GC 2570711K->2359166K(2944192K), 0.1074300 secs]
[GC 2615294K->2381711K(2944192K), 0.1065710 secs]
[GC 2637802K->2403349K(2944192K), 0.1136470 secs]
[GC 2658158K->2405628K(2944192K), 0.1247200 secs]
[GC 2661756K->2452110K(2944192K), 0.1150230 secs]
[GC 2708238K->2471456K(2944192K), 0.1075570 secs]
[GC 2727576K->2475518K(2944192K), 0.1068420 secs]
[GC 2476091K(2944192K), 0.0681300 secs]
[GC 2731646K->2523404K(2944192K), 0.1090780 secs]
[GC 2655877K(2944192K), 0.0555040 secs]
[GC 2410833K->2166673K(3761980K), 0.1215580 secs]
[GC 2422801K->2167260K(3761980K), 0.1148780 secs]
[GC 2423388K->2170311K(3761980K), 0.1050250 secs]
[GC 2426439K->2187696K(3761980K), 0.1063690 secs]
[GC 2443824K->2243044K(3761980K), 0.0857380 secs]
[GC 2499172K->2263599K(3761980K), 0.1213980 secs]
[GC 2519727K->2290827K(3761980K), 0.1151100 secs]
[GC 2546955K->2292408K(3761980K), 0.1284550 secs]
[GC 2547828K->2337676K(3761980K), 0.1090440 secs]
[GC 2593804K->2326064K(3761980K), 0.0992360 secs]
[GC 2582155K->2379626K(3761980K), 0.0994390 secs]
[GC 2635754K->2361030K(3761980K), 0.1011070 secs]
[GC 2616735K->2420220K(3761980K), 0.1067790 secs]
[GC 2676348K->2402275K(3761980K), 0.1003420 secs]
[GC 2658071K->2436475K(3761980K), 0.1122320 secs]
[GC 2692552K->2462254K(3761980K), 0.0957080 secs]
[GC 2718382K->2486220K(3761980K), 0.1032990 secs]
[GC 2742348K->2521350K(3761980K), 0.1070750 secs]
[GC 2777478K->2508990K(3761980K), 0.0975810 secs]
[GC 2765118K->2552477K(3761980K), 0.1083190 secs]
[GC 2806985K->2572876K(3761980K), 0.1114980 secs]
[GC 2829004K->2597552K(3761980K), 0.1111440 secs]
[GC 2853680K->2617680K(3761980K), 0.0975220 secs]
[GC 2873774K->2620209K(3761980K), 0.0972910 secs]
[GC 2876337K->2660561K(3761980K), 0.1074100 secs]
[GC 2916651K->2677472K(3761980K), 0.0993560 secs]
[GC 2933600K->2699414K(3761980K), 0.1043580 secs]
[GC 2955205K->2718518K(3761980K), 0.1075550 secs]
[GC 2974646K->2754779K(3761980K), 0.1039020 secs]
[GC 3009672K->2740552K(3761980K), 0.1039780 secs]
[GC 2996680K->2795304K(3761980K), 0.1011290 secs]
[GC 3051432K->2779244K(3761980K), 0.1018440 secs]
[GC 3035372K->2828469K(3761980K), 0.1059590 secs]
[GC 3084597K->2856884K(3761980K), 0.1027170 secs]
[GC 3113012K->2845858K(3761980K), 0.0989400 secs]
[GC 3101795K->2849964K(3761980K), 0.1051850 secs]
[GC 3106092K->2891569K(3761980K), 0.0942130 secs]
[GC 3147697K->2919028K(3761980K), 0.1296220 secs]
[GC 3175059K->2924858K(3761980K), 0.1275190 secs]
[GC 3180986K->2942129K(3761980K), 0.1095760 secs]
[GC 3197565K->2965413K(3761980K), 0.1085570 secs]
[GC 3221541K->2978894K(3761980K), 0.1073640 secs]
[GC 3235022K->3005374K(3761980K), 0.1053310 secs]
[GC 3261471K->3040014K(3761980K), 0.1012180 secs]
[GC 3296142K->3060602K(3761980K), 0.1039260 secs]
[GC 3316730K->3083724K(3761980K), 0.1030820 secs]
[GC 3339852K->3105943K(3761980K), 0.1058970 secs]
[GC 3362071K->3122861K(3761980K), 0.1040660 secs]
[GC 3378941K->3125071K(3761980K), 0.1039460 secs]
[GC 3381199K->3165797K(3761980K), 0.1062450 secs]
[GC 3420888K->3165286K(3761980K), 0.1042730 secs]
[GC 3421414K->3185147K(3761980K), 0.0999960 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 59 ms.
