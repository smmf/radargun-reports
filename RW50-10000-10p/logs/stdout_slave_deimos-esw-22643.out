/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-22643 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-22643
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0922930 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@3fbefe6e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 36352 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 44540 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 42723 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:41803
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:41803
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 42147 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:43931
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:45911
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:43931
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:45911
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 35231 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:51229
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:51229
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 48859 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:49390
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:49390
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 48742 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 45750 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:60884
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:60884
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 5
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->12644K(2944064K), 0.0453930 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|3] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-4805, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-4805] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|4] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-4805] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|5] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547]
 INFO  [Incoming-4,deimos-esw-4805] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|6] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547, deimos-esw-20378]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 5, serverOidBase: 5000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@2f97b981
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2f97b981, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268708K->23010K(2944064K), 0.0579110 secs]
[GC 279060K->32647K(2944064K), 0.0471130 secs]
[GC 288711K->46619K(2944064K), 0.0496760 secs]
[GC 302683K->74371K(2944064K), 0.0579120 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 330435K->83270K(2944064K), 0.0607120 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15900. Elapsed time: 20.080 secs. Remaining: 39.920 secs. Total: 1 mins 0 secs
[GC 339334K->112662K(2944064K), 0.0782160 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 29100. Elapsed time: 40.118 secs. Remaining: 19.882 secs. Total: 1 mins 0 secs
[GC 368726K->111917K(2944064K), 0.0909410 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 40650. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 30 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 150 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 367981K->136726K(2944064K), 0.0739870 secs]
[GC 392790K->168988K(2944064K), 0.0764130 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,700,305 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 243758K->126935K(2944064K), 0.6123010 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,815,801 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2f97b981, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 383063K->196461K(2944192K), 0.0331160 secs]
[GC 452589K->150515K(2944192K), 0.0384070 secs]
[GC 406643K->160216K(2944192K), 0.0505080 secs]
[GC 416344K->165174K(2944192K), 0.0566610 secs]
[GC 421302K->177392K(2944192K), 0.0717630 secs]
[GC 433520K->190313K(2944192K), 0.0843730 secs]
[GC 446441K->203279K(2944192K), 0.0888110 secs]
[GC 459407K->203626K(2944192K), 0.1006990 secs]
[GC 459754K->229587K(2944192K), 0.1321620 secs]
[GC 485715K->234317K(2944192K), 0.1671390 secs]
[GC 490445K->245411K(2944192K), 0.1651930 secs]
[GC 501539K->271541K(2944192K), 0.1420020 secs]
[GC 527669K->244855K(2944192K), 0.1175880 secs]
[GC 500982K->275133K(2944192K), 0.0805070 secs]
[GC 531261K->311670K(2944192K), 0.2473770 secs]
[GC 567798K->325401K(2944192K), 0.1226280 secs]
[GC 581529K->329392K(2944192K), 0.1048410 secs]
[GC 585047K->360355K(2944192K), 0.0969620 secs]
[GC 616483K->379436K(2944192K), 0.0958890 secs]
[GC 635496K->395221K(2944192K), 0.0948630 secs]
[GC 651349K->415336K(2944192K), 0.0889630 secs]
[GC 671464K->438263K(2944192K), 0.0944410 secs]
[GC 694391K->441280K(2944192K), 0.0899980 secs]
[GC 697405K->473315K(2944192K), 0.0820620 secs]
[GC 729443K->491072K(2944192K), 0.0857820 secs]
[GC 747200K->494283K(2944192K), 0.0845060 secs]
[GC 750411K->545979K(2944192K), 0.0907510 secs]
[GC 802107K->529789K(2944192K), 0.0900030 secs]
[GC 785917K->587744K(2944192K), 0.0918540 secs]
[GC 843872K->564171K(2944192K), 0.0852290 secs]
[GC 820274K->612976K(2944192K), 0.0837580 secs]
[GC 867962K->640826K(2944192K), 0.0929320 secs]
[GC 896954K->635743K(2944192K), 0.0938110 secs]
[GC 891871K->684074K(2944192K), 0.0961160 secs]
[GC 938643K->666698K(2944192K), 0.0943850 secs]
[GC 922826K->699590K(2944192K), 0.0888740 secs]
[GC 955715K->685401K(2944192K), 0.1504690 secs]
[GC 941529K->735935K(2944192K), 0.0743880 secs]
[GC 992063K->741121K(2944192K), 0.0874130 secs]
[GC 997249K->771399K(2944192K), 0.0805360 secs]
[GC 1027527K->801869K(2944192K), 0.0956930 secs]
[GC 1057997K->798264K(2944192K), 0.0869250 secs]
[GC 1054392K->815862K(2944192K), 0.0857580 secs]
[GC 1071990K->849524K(2944192K), 0.0814570 secs]
[GC 1105652K->854664K(2944192K), 0.0839420 secs]
[GC 1110792K->869105K(2944192K), 0.0814420 secs]
[GC 1123801K->921431K(2944192K), 0.0806460 secs]
[GC 1177559K->906320K(2944192K), 0.0827100 secs]
[GC 1162436K->950749K(2944192K), 0.0786920 secs]
[GC 1206877K->958451K(2944192K), 0.0853060 secs]
[GC 1213804K->982884K(2944192K), 0.0810230 secs]
[GC 1239012K->1000322K(2944192K), 0.0881180 secs]
[GC 1256157K->1022119K(2944192K), 0.0841510 secs]
[GC 1278247K->1037867K(2944192K), 0.0969780 secs]
[GC 1293995K->1041703K(2944192K), 0.0845410 secs]
[GC 1296359K->1074532K(2944192K), 0.0858270 secs]
[GC 1330660K->1077454K(2944192K), 0.0829200 secs]
[GC 1332627K->1129363K(2944192K), 0.0847820 secs]
[GC 1385491K->1113856K(2944192K), 0.0878560 secs]
[GC 1369194K->1173745K(2944192K), 0.0864710 secs]
[GC 1429873K->1151316K(2944192K), 0.0774100 secs]
[GC 1407444K->1174628K(2944192K), 0.0748150 secs]
[GC 1430756K->1152782K(2944192K), 0.0851060 secs]
[GC 1408910K->1196662K(2944192K), 0.0649690 secs]
[GC 1452790K->1169490K(2944192K), 0.0667200 secs]
[GC 1425618K->1186737K(2944192K), 0.0861910 secs]
[GC 1442865K->1189805K(2944192K), 0.0617790 secs]
[GC 1445933K->1221572K(2944192K), 0.0690380 secs]
[GC 1477700K->1197402K(2944192K), 0.0794120 secs]
[GC 1453530K->1235222K(2944192K), 0.0704660 secs]
[GC 1491350K->1229145K(2944192K), 0.0833840 secs]
[GC 1485273K->1232861K(2944192K), 0.0920960 secs]
[GC 1488989K->1251810K(2944192K), 0.0782370 secs]
[GC 1507938K->1257955K(2944192K), 0.0798130 secs]
[GC 1514083K->1265006K(2944192K), 0.0840970 secs]
[GC 1521134K->1275282K(2944192K), 0.0853820 secs]
[GC 1531410K->1284172K(2944192K), 0.0858220 secs]
[GC 1540300K->1274999K(2944192K), 0.1123800 secs]
[GC 1531127K->1299737K(2944192K), 0.0844580 secs]
[GC 1555865K->1309901K(2944192K), 0.0890230 secs]
[GC 1566029K->1317840K(2944192K), 0.1593560 secs]
[GC 1573968K->1325606K(2944192K), 0.0939570 secs]
[GC 1581734K->1332941K(2944192K), 0.0915200 secs]
[GC 1589069K->1360602K(2944192K), 0.1678400 secs]
[GC 1616730K->1332949K(2944192K), 0.0900880 secs]
[GC 1589077K->1361958K(2944192K), 0.0878590 secs]
[GC 1618086K->1360039K(2944192K), 0.0885480 secs]
[GC 1616167K->1371257K(2944192K), 0.1105990 secs]
[GC 1627385K->1378912K(2944192K), 0.0920530 secs]
[GC 1635040K->1385585K(2944192K), 0.0864500 secs]
[GC 1385852K(2944192K), 0.0542430 secs]
[GC 1446611K(2944192K), 0.0503320 secs]
[GC 1394577K->1130065K(2944192K), 0.0798360 secs]
[GC 1386193K->1158628K(2944192K), 0.0771010 secs]
[GC 1414756K->1156298K(2944192K), 0.0888980 secs]
[GC 1412426K->1164818K(2944192K), 0.0854830 secs]
[GC 1420946K->1156770K(2944192K), 0.0869860 secs]
[GC 1412898K->1204671K(2944192K), 0.0868300 secs]
[GC 1460789K->1191576K(2944192K), 0.1015220 secs]
[GC 1447663K->1244483K(2944192K), 0.1007060 secs]
[GC 1500070K->1222979K(2944192K), 0.1077190 secs]
[GC 1477532K->1252730K(2944192K), 0.0923720 secs]
[GC 1508858K->1269107K(2944192K), 0.0936560 secs]
[GC 1525235K->1289647K(2944192K), 0.0918690 secs]
[GC 1545775K->1309168K(2944192K), 0.0948840 secs]
[GC 1565296K->1329079K(2944192K), 0.0935730 secs]
[GC 1585207K->1345757K(2944192K), 0.0906140 secs]
[GC 1601885K->1365498K(2944192K), 0.0915810 secs]
[GC 1621626K->1383748K(2944192K), 0.0916360 secs]
[GC 1639876K->1404448K(2944192K), 0.0952260 secs]
[GC 1660576K->1421069K(2944192K), 0.0933510 secs]
[GC 1677197K->1439379K(2944192K), 0.0956040 secs]
[GC 1695507K->1455747K(2944192K), 0.0953860 secs]
[GC 1711875K->1517172K(2944192K), 0.1003990 secs]
[GC 1773255K->1492931K(2944192K), 0.0955020 secs]
[GC 1749059K->1534181K(2944192K), 0.0931300 secs]
[GC 1790309K->1511067K(2944192K), 0.0845760 secs]
[GC 1767195K->1559542K(2944192K), 0.0727530 secs]
[GC 1815670K->1530748K(2944192K), 0.0806670 secs]
[GC 1786876K->1532602K(2944192K), 0.0943140 secs]
[GC 1788730K->1583295K(2944192K), 0.0731290 secs]
[GC 1839423K->1552685K(2944192K), 0.0817770 secs]
[GC 1808813K->1551934K(2944192K), 0.0932160 secs]
[GC 1808062K->1604696K(2944192K), 0.0694940 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1860824K->1615423K(2944192K), 0.0879330 secs]
[GC 1871551K->1626890K(2944192K), 0.1259510 secs]
[GC 1882993K->1636671K(2944192K), 0.1061840 secs]
[GC 1892785K->1690460K(2944192K), 0.0889610 secs]
[GC 1945508K->1694854K(2944192K), 0.1180430 secs]
[GC 1950716K->1710896K(2944192K), 0.0763500 secs]
[GC 1965747K->1736294K(2944192K), 0.0832170 secs]
[GC 1991629K->1723710K(2944192K), 0.0707450 secs]
[GC 1979838K->1760633K(2944192K), 0.0688440 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 290000. Elapsed time: 20.231 secs. Remaining: 39.769 secs. Total: 1 mins 0 secs
[GC 2016761K->1811300K(2944192K), 0.1082580 secs]
[GC 2067428K->1794557K(2944192K), 0.0748610 secs]
[GC 2050685K->1823552K(2944192K), 0.0897530 secs]
[GC 2079658K->1868331K(2944192K), 0.0924680 secs]
[GC 2124419K->1866934K(2944192K), 0.0821180 secs]
[GC 2123057K->1893024K(2944192K), 0.0884630 secs]
[GC 2149102K->1893840K(2944192K), 0.0785240 secs]
[GC 2148338K->1918538K(2944192K), 0.0810650 secs]
[GC 2174666K->1981612K(2944192K), 0.1019590 secs]
[GC 2237740K->1956214K(2944192K), 0.0736820 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 693087. Elapsed time: 40.231 secs. Remaining: 19.769 secs. Total: 1 mins 0 secs
[GC 2212342K->2018480K(2944192K), 0.0956820 secs]
[GC 2274608K->1996970K(2944192K), 0.0770840 secs]
[GC 2253098K->2030087K(2944192K), 0.0872030 secs]
[GC 2286215K->2084207K(2944192K), 0.0948860 secs]
[GC 2340335K->2047374K(2944192K), 0.0757650 secs]
[GC 2303502K->2060401K(2944192K), 0.0693800 secs]
[GC 2316529K->2079817K(2944192K), 0.0845720 secs]
[GC 2335945K->2078297K(2944192K), 0.0801170 secs]
[GC 2334425K->2127622K(2944192K), 0.0801060 secs]
[GC 2383750K->2117114K(2944192K), 0.0961940 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 940000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2373242K->2155608K(2944192K), 0.0723950 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 32 mins 23 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2410227K->2107319K(2944192K), 0.0759510 secs]
[GC 2363447K->2124466K(2944192K), 0.0606550 secs]
[GC 2380594K->2160434K(2944192K), 0.0743960 secs]
[GC 2416562K->2202997K(2944192K), 0.0966350 secs]
[GC 2457625K->2218686K(2944192K), 0.1020670 secs]
[GC 2474814K->2256647K(2944192K), 0.1091050 secs]
[GC 2512653K->2242547K(2944192K), 0.0958360 secs]
[GC 2498442K->2297302K(2944192K), 0.0990170 secs]
[GC 2553430K->2280643K(2944192K), 0.0977340 secs]
[GC 2536046K->2329846K(2944192K), 0.1085430 secs]
[GC 2585974K->2358459K(2944192K), 0.1011610 secs]
[GC 2612900K->2344425K(2944192K), 0.1011040 secs]
[GC 2600553K->2389499K(2944192K), 0.1030930 secs]
[GC 2645627K->2420310K(2944192K), 0.1141010 secs]
[GC 2676438K->2427187K(2944192K), 0.1078420 secs]
[GC 2683315K->2430953K(2944192K), 0.1085090 secs]
[GC 2687081K->2430578K(2944192K), 0.0996730 secs]
[GC 2431152K(2944192K), 0.0522980 secs]
[GC 2464868K(2944192K), 0.0392940 secs]
[GC 2230116K->1994560K(3548948K), 0.1100870 secs]
[GC 2250688K->2044729K(3548948K), 0.0963310 secs]
[GC 2298794K->2036446K(3548948K), 0.1341000 secs]
[GC 2292574K->2087456K(3548948K), 0.1238960 secs]
[GC 2342286K->2108519K(3548948K), 0.1322790 secs]
[GC 2364647K->2138745K(3548948K), 0.1173460 secs]
[GC 2394872K->2137966K(3548948K), 0.1243550 secs]
[GC 2394094K->2180585K(3548948K), 0.1194030 secs]
[GC 2436713K->2180751K(3548948K), 0.1157390 secs]
[GC 2436879K->2201434K(3548948K), 0.1146880 secs]
[GC 2457046K->2221757K(3548948K), 0.1117790 secs]
[GC 2477885K->2241542K(3548948K), 0.1136250 secs]
[GC 2497057K->2263420K(3548948K), 0.1092820 secs]
[GC 2519548K->2283383K(3548948K), 0.1144190 secs]
[GC 2539071K->2320272K(3548948K), 0.1148660 secs]
[GC 2576400K->2339755K(3548948K), 0.1077620 secs]
[GC 2595883K->2343378K(3548948K), 0.1041460 secs]
[GC 2599506K->2396252K(3548948K), 0.1112310 secs]
[GC 2652380K->2368098K(3548948K), 0.1013540 secs]
[GC 2624195K->2402022K(3548948K), 0.1185260 secs]
[GC 2658150K->2442538K(3548948K), 0.1010030 secs]
[GC 2697491K->2440340K(3548948K), 0.1344610 secs]
[GC 2696468K->2480208K(3548948K), 0.1168570 secs]
[GC 2736336K->2505191K(3548948K), 0.1035930 secs]
[GC 2761297K->2506343K(3548948K), 0.1055200 secs]
[GC 2762466K->2545165K(3548948K), 0.1058910 secs]
[GC 2801293K->2564734K(3548948K), 0.1052670 secs]
[GC 2820862K->2585789K(3548948K), 0.1042450 secs]
[GC 2841888K->2608232K(3548948K), 0.1100210 secs]
[GC 2864360K->2628045K(3548948K), 0.1156830 secs]
[GC 2882282K->2646004K(3548948K), 0.1043610 secs]
[GC 2902123K->2665700K(3548948K), 0.1083270 secs]
[GC 2921828K->2702835K(3548948K), 0.1059350 secs]
[GC 2958484K->2688361K(3548948K), 0.1030410 secs]
[GC 2944489K->2736973K(3548948K), 0.1076460 secs]
[GC 2993101K->2745624K(3548948K), 0.1065440 secs]
[GC 3001752K->2733427K(3548948K), 0.1062450 secs]
[GC 2989555K->2771555K(3548948K), 0.1019870 secs]
[GC 3026730K->2793195K(3548948K), 0.1071150 secs]
[GC 3049323K->2843310K(3548948K), 0.1049330 secs]
[GC 3099438K->2863667K(3548948K), 0.1054810 secs]
[GC 3119771K->2872630K(3548948K), 0.0979180 secs]
[GC 3128758K->2875264K(3548948K), 0.1033860 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3131392K->2895875K(3548948K), 0.1032820 secs]
[GC 3152003K->2933417K(3548948K), 0.1004050 secs]
[GC 3189545K->2956972K(3548948K), 0.1027680 secs]
[GC 3213076K->2975779K(3548948K), 0.1006870 secs]
[GC 3231907K->2996586K(3548948K), 0.1074070 secs]
[GC 3252701K->2997577K(3548948K), 0.0990670 secs]
[GC 3253705K->3037869K(3548948K), 0.0925530 secs]
[GC 3038438K(3548948K), 0.0384460 secs]
[GC 3293997K->3073346K(3548948K), 0.1088090 secs]
[GC 3227260K(3548948K), 0.0648390 secs]
[GC 3083754K->2815296K(4650880K), 0.1156350 secs]
[GC 3071424K->2834348K(4650880K), 0.1137670 secs]
[GC 3090476K->2874881K(4650880K), 0.1191430 secs]
[GC 3131009K->2903175K(4650880K), 0.1123620 secs]
[GC 3159303K->2936514K(4650880K), 0.1144940 secs]
[GC 3192642K->2920171K(4650880K), 0.1140740 secs]
[GC 3176299K->2976975K(4650880K), 0.1094960 secs]
[GC 3233103K->2961488K(4650880K), 0.1089220 secs]
[GC 3216968K->3010776K(4650880K), 0.1153680 secs]
[GC 3266904K->3038253K(4650880K), 0.1090660 secs]
[GC 3294381K->3023308K(4650880K), 0.1155250 secs]
[GC 3279436K->3078684K(4650880K), 0.1065410 secs]
[GC 3334801K->3065605K(4650880K), 0.1076410 secs]
[GC 3321733K->3106103K(4650880K), 0.1091800 secs]
[GC 3362200K->3106211K(4650880K), 0.1084240 secs]
[GC 3362339K->3146083K(4650880K), 0.1082500 secs]
[GC 3402176K->3165499K(4650880K), 0.1093640 secs]
[GC 3421627K->3201648K(4650880K), 0.1115840 secs]
[GC 3457776K->3189837K(4650880K), 0.1101570 secs]
[GC 3445965K->3192550K(4650880K), 0.1083740 secs]
[GC 3448678K->3211336K(4650880K), 0.1049890 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3467464K->3265727K(4650880K), 0.0918210 secs]
[GC 3521855K->3291244K(4650880K), 0.1205240 secs]
[GC 3547372K->3308195K(4650880K), 0.1187690 secs]
[GC 3564323K->3312985K(4650880K), 0.1175990 secs]
[GC 3569113K->3344007K(4650880K), 0.1061630 secs]
[GC 3600135K->3347772K(4650880K), 0.1045350 secs]
[GC 3603900K->3385191K(4650880K), 0.0988210 secs]
[GC 3641319K->3418910K(4650880K), 0.1066150 secs]
[GC 3675038K->3406311K(4650880K), 0.1009730 secs]
[GC 3662439K->3460160K(4650880K), 0.1037080 secs]
[GC 3716288K->3444615K(4650880K), 0.1124440 secs]
[GC 3699425K->3501017K(4650880K), 0.1054080 secs]
[GC 3756603K->3484433K(4650880K), 0.1049900 secs]
[GC 3740533K->3540971K(4650880K), 0.0981760 secs]
[GC 3797099K->3523866K(4650880K), 0.1063440 secs]
[GC 3779994K->3581783K(4650880K), 0.1054540 secs]
[GC 3837911K->3567697K(4650880K), 0.1001640 secs]
[GC 3823825K->3623104K(4650880K), 0.1000500 secs]
[GC 3879232K->3605766K(4650880K), 0.0977660 secs]
[GC 3861894K->3656693K(4650880K), 0.1001110 secs]
[GC 3912821K->3668188K(4650880K), 0.0961450 secs]
[GC 3924316K->3691366K(4650880K), 0.1097420 secs]
[GC 3946480K->3694398K(4650880K), 0.1052510 secs]
[GC 3950484K->3712852K(4650880K), 0.0983200 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 54 ms.
