/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-18501 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-18501
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0931590 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 6. Sleeping for 8000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 6
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2548e059
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=6, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5707, using socket ServerSocket[addr=/0.0.0.0,localport=5707], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5707 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5707
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5707 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5707 [FenixFrameworkGroup] Address[127.0.0.1]:5707 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 40838 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 52048 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 53849 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5707 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707 this
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:37236
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:37236
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:59127
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 58278 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:43493
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:59127
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:43493
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 49390 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:48859
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:34345
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:48859
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:34345
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 38966 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 is accepting socket connection from /127.0.0.1:48562
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:48562
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5707 [FenixFrameworkGroup] Address[127.0.0.1]:5707 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 6
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=6, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 6
[GC 259695K->12905K(2944064K), 0.0405640 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|4] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-60537, physical addresses are [127.0.0.1:52006]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-60537] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|5] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-60537] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|6] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547, deimos-esw-20378]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 6, serverOidBase: 6000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 6: org.radargun.cachewrappers.FFWrapper@774be8ca
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 1
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@774be8ca, nodeIndex=6, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268969K->22896K(2944064K), 0.0587790 secs]
[GC 278960K->32339K(2944064K), 0.0459610 secs]
[GC 288403K->46696K(2944064K), 0.0493510 secs]
[GC 302760K->65847K(2944064K), 0.0559330 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 321911K->82498K(2944064K), 0.0654540 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 18450. Elapsed time: 20.015 secs. Remaining: 39.985 secs. Total: 1 mins 0 secs
[GC 338562K->106535K(2944064K), 0.0676550 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 32700. Elapsed time: 40.039 secs. Remaining: 19.961 secs. Total: 1 mins 0 secs
[GC 362599K->116477K(2944064K), 0.1573430 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 54400. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 31 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 151 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 372541K->157732K(2944064K), 0.0727930 secs]
[GC 413796K->136206K(2944064K), 0.0743180 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,700,572 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 243491K->126733K(2944064K), 0.5686530 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,816,056 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@774be8ca, nodeIndex=6, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 382861K->188371K(2944192K), 0.0347830 secs]
[GC 444499K->147841K(2944192K), 0.0387900 secs]
[GC 403969K->158797K(2944192K), 0.0425020 secs]
[GC 414925K->169910K(2944192K), 0.0488910 secs]
[GC 426038K->183964K(2944192K), 0.0495680 secs]
[GC 440092K->198648K(2944192K), 0.0569920 secs]
[GC 454776K->213539K(2944192K), 0.0782790 secs]
[GC 469667K->228391K(2944192K), 0.0603240 secs]
[GC 484519K->229233K(2944192K), 0.0853300 secs]
[GC 485361K->233769K(2944192K), 0.1194640 secs]
[GC 489897K->244499K(2944192K), 0.0700960 secs]
[GC 500627K->253249K(2944192K), 0.0748200 secs]
[GC 509377K->261519K(2944192K), 0.0780940 secs]
[GC 517647K->286018K(2944192K), 0.1456640 secs]
[GC 540660K->306331K(2944192K), 0.0865380 secs]
[GC 562459K->324913K(2944192K), 0.0971340 secs]
[GC 581041K->328880K(2944192K), 0.1116300 secs]
[GC 585008K->322245K(2944192K), 0.0840040 secs]
[GC 578373K->359148K(2944192K), 0.0842880 secs]
[GC 615276K->361046K(2944192K), 0.0907170 secs]
[GC 617174K->399328K(2944192K), 0.0900800 secs]
[GC 655456K->432098K(2944192K), 0.0793520 secs]
[GC 686922K->449940K(2944192K), 0.0839910 secs]
[GC 706068K->482966K(2944192K), 0.0884310 secs]
[GC 739094K->470137K(2944192K), 0.0837910 secs]
[GC 726265K->509538K(2944192K), 0.0892890 secs]
[GC 765612K->507245K(2944192K), 0.0819480 secs]
[GC 763373K->560911K(2944192K), 0.0819940 secs]
[GC 817037K->543938K(2944192K), 0.0796080 secs]
[GC 800019K->603341K(2944192K), 0.0835420 secs]
[GC 859469K->580850K(2944192K), 0.0825150 secs]
[GC 836978K->641761K(2944192K), 0.0875690 secs]
[GC 897300K->620639K(2944192K), 0.0874750 secs]
[GC 875524K->671248K(2944192K), 0.0919140 secs]
[GC 927376K->700968K(2944192K), 0.1007850 secs]
[GC 957096K->684889K(2944192K), 0.0907820 secs]
[GC 941017K->692403K(2944192K), 0.0775810 secs]
[GC 948530K->734070K(2944192K), 0.0606550 secs]
[GC 990198K->733849K(2944192K), 0.0844100 secs]
[GC 989977K->754589K(2944192K), 0.0877110 secs]
[GC 1010717K->758697K(2944192K), 0.0828670 secs]
[GC 1014816K->793375K(2944192K), 0.0824480 secs]
[GC 1049503K->828776K(2944192K), 0.0786140 secs]
[GC 1084904K->828144K(2944192K), 0.0800580 secs]
[GC 1084255K->865489K(2944192K), 0.0806540 secs]
[GC 1120022K->866857K(2944192K), 0.0790200 secs]
[GC 1122985K->901598K(2944192K), 0.0764680 secs]
[GC 1157686K->886769K(2944192K), 0.0785560 secs]
[GC 1142897K->937903K(2944192K), 0.0777760 secs]
[GC 1194031K->927818K(2944192K), 0.0768930 secs]
[GC 1182132K->959042K(2944192K), 0.0798160 secs]
[GC 1215170K->1012518K(2944192K), 0.0732830 secs]
[GC 1266778K->999613K(2944192K), 0.0802700 secs]
[GC 1255741K->1055402K(2944192K), 0.0776700 secs]
[GC 1311494K->1033978K(2944192K), 0.0774300 secs]
[GC 1289704K->1090666K(2944192K), 0.0808130 secs]
[GC 1346783K->1069869K(2944192K), 0.0835610 secs]
[GC 1324620K->1127193K(2944192K), 0.0827080 secs]
[GC 1383321K->1116512K(2944192K), 0.0792970 secs]
[GC 1372547K->1169927K(2944192K), 0.0794410 secs]
[GC 1426055K->1147392K(2944192K), 0.0810130 secs]
[GC 1403520K->1173570K(2944192K), 0.0631700 secs]
[GC 1429698K->1150495K(2944192K), 0.0909410 secs]
[GC 1406623K->1199824K(2944192K), 0.0756560 secs]
[GC 1455952K->1175794K(2944192K), 0.1008030 secs]
[GC 1431922K->1197405K(2944192K), 0.0913570 secs]
[GC 1453533K->1185709K(2944192K), 0.0855220 secs]
[GC 1441837K->1217526K(2944192K), 0.0926860 secs]
[GC 1473654K->1220412K(2944192K), 0.1196260 secs]
[GC 1476540K->1232888K(2944192K), 0.0705130 secs]
[GC 1489016K->1241679K(2944192K), 0.0807630 secs]
[GC 1497807K->1242513K(2944192K), 0.0744310 secs]
[GC 1498641K->1264216K(2944192K), 0.1312180 secs]
[GC 1520344K->1241264K(2944192K), 0.1373580 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5707 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1497392K->1256432K(2944192K), 0.0798710 secs]
[GC 1512560K->1255296K(2944192K), 0.1349540 secs]
[GC 1511424K->1297005K(2944192K), 0.1550620 secs]
[GC 1553133K->1273806K(2944192K), 0.0770680 secs]
[GC 1529934K->1305766K(2944192K), 0.1521690 secs]
[GC 1561894K->1321792K(2944192K), 0.1417060 secs]
[GC 1577920K->1300074K(2944192K), 0.1431370 secs]
[GC 1556202K->1325466K(2944192K), 0.0836200 secs]
[GC 1581594K->1349982K(2944192K), 0.1576680 secs]
[GC 1606110K->1333412K(2944192K), 0.1595390 secs]
[GC 1589540K->1361445K(2944192K), 0.0992530 secs]
[GC 1617573K->1334182K(2944192K), 0.1335770 secs]
[GC 1590310K->1381872K(2944192K), 0.0811690 secs]
[GC 1638000K->1351511K(2944192K), 0.0801170 secs]
[GC 1607639K->1384631K(2944192K), 0.0789010 secs]
[GC 1640759K->1399474K(2944192K), 0.0817760 secs]
[GC 1399886K(2944192K), 0.0637810 secs]
[GC 1463274K(2944192K), 0.0504660 secs]
[GC 1408035K->1129562K(2944192K), 0.0780310 secs]
[GC 1385690K->1162131K(2944192K), 0.0636300 secs]
[GC 1418259K->1134575K(2944192K), 0.0771940 secs]
[GC 1390703K->1163533K(2944192K), 0.0769070 secs]
[GC 1419661K->1178168K(2944192K), 0.0653090 secs]
[GC 1434296K->1192983K(2944192K), 0.0723050 secs]
[GC 1449111K->1166892K(2944192K), 0.0742630 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 1423019K->1217491K(2944192K), 0.0827260 secs]
[GC 1473614K->1232518K(2944192K), 0.1014340 secs]
[GC 1488312K->1251235K(2944192K), 0.0858770 secs]
[GC 1506038K->1270331K(2944192K), 0.0983340 secs]
[GC 1524445K->1272401K(2944192K), 0.0788630 secs]
[GC 1528529K->1312679K(2944192K), 0.0953450 secs]
[GC 1568807K->1313011K(2944192K), 0.0709320 secs]
[GC 1569139K->1368633K(2944192K), 0.0803910 secs]
[GC 1624761K->1374131K(2944192K), 0.0853560 secs]
[GC 1630225K->1346754K(2944192K), 0.0665720 secs]
[GC 1602882K->1375181K(2944192K), 0.0562320 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 490000. Elapsed time: 20.037 secs. Remaining: 39.963 secs. Total: 1 mins 0 secs
[GC 1631272K->1410468K(2944192K), 0.0864330 secs]
[GC 1665672K->1402803K(2944192K), 0.0813190 secs]
[GC 1658769K->1458576K(2944192K), 0.0774910 secs]
[GC 1714704K->1409988K(2944192K), 0.0645320 secs]
[GC 1666116K->1474524K(2944192K), 0.0646220 secs]
[GC 1730652K->1528456K(2944192K), 0.1007560 secs]
[GC 1784584K->1527897K(2944192K), 0.0777480 secs]
[GC 1783981K->1532352K(2944192K), 0.0827860 secs]
[GC 1786590K->1571403K(2944192K), 0.0910250 secs]
[GC 1826613K->1551702K(2944192K), 0.0788250 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 830000. Elapsed time: 40.074 secs. Remaining: 19.926 secs. Total: 1 mins 0 secs
[GC 1807225K->1569409K(2944192K), 0.0733300 secs]
[GC 1825481K->1564739K(2944192K), 0.0690140 secs]
[GC 1820867K->1580205K(2944192K), 0.0559920 secs]
[GC 1836333K->1630961K(2944192K), 0.0710970 secs]
[GC 1887089K->1633250K(2944192K), 0.0909680 secs]
[GC 1889378K->1666267K(2944192K), 0.0664040 secs]
[GC 1920660K->1674701K(2944192K), 0.0970020 secs]
[GC 1930804K->1678461K(2944192K), 0.0756400 secs]
[GC 1934544K->1695576K(2944192K), 0.0698600 secs]
[GC 1951701K->1691783K(2944192K), 0.0836810 secs]
[GC 1947903K->1727599K(2944192K), 0.0631440 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1220000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 27 mins 33 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:6, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1983727K->1695411K(2944192K), 0.0709530 secs]
[GC 1951539K->1705140K(2944192K), 0.0647100 secs]
[GC 1961268K->1729650K(2944192K), 0.0820920 secs]
[GC 1985778K->1768469K(2944192K), 0.0980510 secs]
[GC 2022651K->1739516K(2944192K), 0.1129100 secs]
[GC 1995644K->1797004K(2944192K), 0.1240820 secs]
[GC 2053132K->1815437K(2944192K), 0.1159150 secs]
[GC 2071520K->1841218K(2944192K), 0.1176820 secs]
[GC 2097346K->1839308K(2944192K), 0.0957530 secs]
[GC 2095436K->1891096K(2944192K), 0.0981360 secs]
[GC 2147224K->1887277K(2944192K), 0.0928580 secs]
[GC 2143405K->1924632K(2944192K), 0.0969170 secs]
[GC 2180283K->1918059K(2944192K), 0.0922750 secs]
[GC 2174187K->1955980K(2944192K), 0.0923750 secs]
[GC 2212108K->1978956K(2944192K), 0.0963790 secs]
[GC 2235049K->2012798K(2944192K), 0.1002760 secs]
[GC 2268920K->2000234K(2944192K), 0.0908380 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5707 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2256362K->2053984K(2944192K), 0.0927380 secs]
[GC 2308194K->2036635K(2944192K), 0.0910180 secs]
[GC 2292735K->2094567K(2944192K), 0.0867070 secs]
[GC 2350695K->2076688K(2944192K), 0.0941750 secs]
[GC 2332816K->2129606K(2944192K), 0.0874040 secs]
[GC 2385706K->2156025K(2944192K), 0.1024530 secs]
[GC 2412153K->2149789K(2944192K), 0.1062030 secs]
[GC 2405897K->2193137K(2944192K), 0.0953980 secs]
[GC 2449265K->2224557K(2944192K), 0.0943690 secs]
[GC 2480077K->2208489K(2944192K), 0.0924240 secs]
[GC 2464617K->2256181K(2944192K), 0.0961700 secs]
[GC 2512309K->2271517K(2944192K), 0.0935620 secs]
[GC 2527627K->2305835K(2944192K), 0.0976470 secs]
[GC 2561963K->2292283K(2944192K), 0.0907550 secs]
[GC 2547232K->2347463K(2944192K), 0.0945140 secs]
[GC 2603591K->2329486K(2944192K), 0.0888630 secs]
[GC 2584473K->2388218K(2944192K), 0.0921100 secs]
[GC 2644346K->2370317K(2944192K), 0.0938200 secs]
[GC 2625230K->2422294K(2944192K), 0.0970870 secs]
[GC 2678422K->2432701K(2944192K), 0.0948250 secs]
[GC 2688829K->2418971K(2944192K), 0.0965920 secs]
[GC 2675099K->2437674K(2944192K), 0.0936980 secs]
[GC 2438930K(2944192K), 0.0544160 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5707 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2475274K(2944192K), 0.0394830 secs]
[GC 2273016K->2067062K(3632716K), 0.0896490 secs]
[GC 2323190K->2066886K(3632716K), 0.1305050 secs]
[GC 2322433K->2116092K(3632716K), 0.1183890 secs]
[GC 2372220K->2132923K(3632716K), 0.1268780 secs]
[GC 2389051K->2155934K(3632716K), 0.1095230 secs]
[GC 2412062K->2179173K(3632716K), 0.1127480 secs]
[GC 2435301K->2184648K(3632716K), 0.1094490 secs]
[GC 2440776K->2225599K(3632716K), 0.1194890 secs]
[GC 2481105K->2245330K(3632716K), 0.1055520 secs]
[GC 2501458K->2266875K(3632716K), 0.1091340 secs]
[GC 2522958K->2265810K(3632716K), 0.1048730 secs]
[GC 2521938K->2284573K(3632716K), 0.1022060 secs]
[GC 2540701K->2339336K(3632716K), 0.1047890 secs]
[GC 2595436K->2328254K(3632716K), 0.1017970 secs]
[GC 2584382K->2366901K(3632716K), 0.1005010 secs]
[GC 2623029K->2384576K(3632716K), 0.0979160 secs]
[GC 2640704K->2388661K(3632716K), 0.0958980 secs]
[GC 2644789K->2390451K(3632716K), 0.0980110 secs]
[GC 2646579K->2426228K(3632716K), 0.0962730 secs]
[GC 2682348K->2462182K(3632716K), 0.1062190 secs]
[GC 2718310K->2489602K(3632716K), 0.0828430 secs]
[GC 2745730K->2512702K(3632716K), 0.1160950 secs]
[GC 2767455K->2510479K(3632716K), 0.1070820 secs]
[GC 2766607K->2529477K(3632716K), 0.0969020 secs]
[GC 2785605K->2583774K(3632716K), 0.1066710 secs]
[GC 2839555K->2569990K(3632716K), 0.1025150 secs]
[GC 2826100K->2623926K(3632716K), 0.0962970 secs]
[GC 2880054K->2610082K(3632716K), 0.0939810 secs]
[GC 2866128K->2664034K(3632716K), 0.1024820 secs]
[GC 2920162K->2646389K(3632716K), 0.1020190 secs]
[GC 2902517K->2705297K(3632716K), 0.1013220 secs]
[GC 2960082K->2687631K(3632716K), 0.0989480 secs]
[GC 2943759K->2746144K(3632716K), 0.0970110 secs]
[GC 3000540K->2750751K(3632716K), 0.0965130 secs]
[GC 3006879K->2770386K(3632716K), 0.0927190 secs]
[GC 3026514K->2757228K(3632716K), 0.1013060 secs]
[GC 3013314K->2807645K(3632716K), 0.0996100 secs]
[GC 3063773K->2833645K(3632716K), 0.1103030 secs]
[GC 3089773K->2868952K(3632716K), 0.0930540 secs]
[GC 3125062K->2851947K(3632716K), 0.0956160 secs]
[GC 3108075K->2899660K(3632716K), 0.1022530 secs]
[GC 3154536K->2914404K(3632716K), 0.1056370 secs]
[GC 3170532K->2936828K(3632716K), 0.0939900 secs]
[GC 3192018K->2940821K(3632716K), 0.1051410 secs]
[GC 3196949K->2979711K(3632716K), 0.1025890 secs]
[GC 3233806K->2979479K(3632716K), 0.1067040 secs]
[GC 3235607K->3020285K(3632716K), 0.0917440 secs]
[GC 3276413K->3055167K(3632716K), 0.1066490 secs]
[GC 3311264K->3042336K(3632716K), 0.0993970 secs]
[GC 3298464K->3081666K(3632716K), 0.0953140 secs]
[GC 3337766K->3080920K(3632716K), 0.0924880 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5707 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3337048K->3121860K(3632716K), 0.1055620 secs]
[GC 3122124K(3632716K), 0.0418950 secs]
[GC 3376645K->3159393K(3632716K), 0.1105450 secs]
[GC 3299364K(3632716K), 0.0496300 secs]
[GC 3156442K->2890562K(4650880K), 0.1272550 secs]
[GC 3146690K->2931710K(4650880K), 0.1094940 secs]
[GC 3187838K->2964815K(4650880K), 0.1137870 secs]
[GC 3220943K->2974697K(4650880K), 0.1045330 secs]
[GC 3230825K->3006399K(4650880K), 0.1047070 secs]
[GC 3261220K->2995413K(4650880K), 0.1093150 secs]
[GC 3251541K->3034960K(4650880K), 0.1131740 secs]
[GC 3291088K->3033469K(4650880K), 0.1073300 secs]
[GC 3289597K->3073175K(4650880K), 0.1118280 secs]
[GC 3329303K->3096752K(4650880K), 0.1055440 secs]
[GC 3352880K->3116172K(4650880K), 0.1101640 secs]
[GC 3372300K->3118582K(4650880K), 0.1069710 secs]
[GC 3374710K->3136714K(4650880K), 0.1034780 secs]
[GC 3392798K->3174429K(4650880K), 0.1080000 secs]
[GC 3430557K->3195608K(4650880K), 0.1031000 secs]
[GC 3450758K->3196678K(4650880K), 0.1093760 secs]
[GC 3452806K->3197907K(4650880K), 0.1071170 secs]
[GC 3454035K->3218925K(4650880K), 0.1037520 secs]
[GC 3475053K->3274915K(4650880K), 0.0938820 secs]
[GC 3531043K->3292271K(4650880K), 0.1176850 secs]
[GC 3548399K->3296398K(4650880K), 0.1118690 secs]
[GC 3552526K->3321075K(4650880K), 0.1144410 secs]
[GC 3577203K->3355053K(4650880K), 0.1082050 secs]
[GC 3611181K->3376294K(4650880K), 0.1116180 secs]
[GC 3630635K->3372951K(4650880K), 0.1005530 secs]
[GC 3629079K->3411494K(4650880K), 0.1009480 secs]
[GC 3666667K->3434226K(4650880K), 0.1007140 secs]
[GC 3690018K->3451327K(4650880K), 0.1013790 secs]
[GC 3707455K->3487593K(4650880K), 0.1079830 secs]
[GC 3743721K->3478085K(4650880K), 0.1044300 secs]
[GC 3734213K->3495073K(4650880K), 0.0987920 secs]
[GC 3751201K->3519334K(4650880K), 0.1033850 secs]
[GC 3775462K->3538236K(4650880K), 0.0962550 secs]
[GC 3792422K->3556370K(4650880K), 0.1019770 secs]
[GC 3812037K->3595648K(4650880K), 0.1013730 secs]
[GC 3851776K->3631671K(4650880K), 0.0981380 secs]
[GC 3886061K->3637533K(4650880K), 0.1001700 secs]
[GC 3893661K->3638250K(4650880K), 0.1012140 secs]
[GC 3892467K->3660173K(4650880K), 0.1055200 secs]
[GC 3916301K->3681218K(4650880K), 0.1068350 secs]
[GC 3937346K->3717325K(4650880K), 0.1061600 secs]
[GC 3973453K->3742181K(4650880K), 0.1077070 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5707 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5707 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 47 ms.
