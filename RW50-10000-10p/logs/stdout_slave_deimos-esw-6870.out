/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-6870 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-6870
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0818200 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 1. Sleeping for 5500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 1
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2527bdee
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=1, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5702, using socket ServerSocket[addr=/0.0.0.0,localport=5702], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5702 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5702 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5702 [FenixFrameworkGroup] Address[127.0.0.1]:5702 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 34879 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 39920 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:53303
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:53303
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:57691
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:57691
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:42723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:42723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:52048
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:52048
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:36710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:36710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:45743
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:45743
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:41611
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:41611
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5702 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702 this
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5702 [FenixFrameworkGroup] Address[127.0.0.1]:5702 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 1
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=1, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 1
[GC 259695K->12040K(2944064K), 0.0398880 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|1] [deimos-esw-56913, deimos-esw-24151]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-24151, physical addresses are [127.0.0.1:52001]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-24151] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|2] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-24151] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|3] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805]
 INFO  [Incoming-4,deimos-esw-24151] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|4] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-24151] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|5] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547]
 INFO  [Incoming-4,deimos-esw-24151] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|6] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547, deimos-esw-20378]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 1, serverOidBase: 1000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 1: org.radargun.cachewrappers.FFWrapper@1fe569ac
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 6
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@1fe569ac, nodeIndex=1, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268104K->22264K(2944064K), 0.0589990 secs]
[GC 278327K->28732K(2944064K), 0.0490940 secs]
[GC 284796K->49566K(2944064K), 0.0485620 secs]
[GC 305630K->72005K(2944064K), 0.0567950 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 328060K->81247K(2944064K), 0.0593540 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11350. Elapsed time: 20.073 secs. Remaining: 39.927 secs. Total: 1 mins 0 secs
[GC 337311K->115708K(2944064K), 0.0661940 secs]
[GC 371772K->112864K(2944064K), 0.1511780 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 23100. Elapsed time: 40.216 secs. Remaining: 19.784 secs. Total: 1 mins 0 secs
[GC 368915K->138623K(2944064K), 0.0758260 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 40 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 160 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 394687K->154113K(2944064K), 0.0722280 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,668,943 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 275120K->125972K(2944064K), 0.6378770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,816,942 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@1fe569ac, nodeIndex=1, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 382100K->193210K(2944192K), 0.0329690 secs]
[GC 449338K->144245K(2944192K), 0.0385080 secs]
[GC 400373K->158623K(2944192K), 0.0439190 secs]
[GC 414751K->169154K(2944192K), 0.0489350 secs]
[GC 425282K->190259K(2944192K), 0.0588100 secs]
[GC 446387K->179823K(2944192K), 0.0550050 secs]
[GC 435951K->205520K(2944192K), 0.0650380 secs]
[GC 461648K->213345K(2944192K), 0.0888290 secs]
[GC 469473K->227632K(2944192K), 0.0730420 secs]
[GC 483760K->216024K(2944192K), 0.1328340 secs]
[GC 472152K->260905K(2944192K), 0.0787030 secs]
[GC 517033K->235142K(2944192K), 0.0767810 secs]
[GC 491270K->266342K(2944192K), 0.0821610 secs]
[GC 522437K->281900K(2944192K), 0.0836650 secs]
[GC 538028K->308179K(2944192K), 0.2159780 secs]
[GC 564307K->305862K(2944192K), 0.1372990 secs]
[GC 561990K->306686K(2944192K), 0.1099920 secs]
[GC 562406K->358549K(2944192K), 0.0998800 secs]
[GC 614677K->376950K(2944192K), 0.0985850 secs]
[GC 632115K->377081K(2944192K), 0.0955560 secs]
[GC 633209K->433043K(2944192K), 0.0912310 secs]
[GC 688778K->415736K(2944192K), 0.0896230 secs]
[GC 671864K->470800K(2944192K), 0.0842900 secs]
[GC 726920K->451269K(2944192K), 0.0878080 secs]
[GC 706494K->506355K(2944192K), 0.0852950 secs]
[GC 762483K->485148K(2944192K), 0.0862640 secs]
[GC 741256K->546861K(2944192K), 0.0871130 secs]
[GC 802989K->522713K(2944192K), 0.0925400 secs]
[GC 778371K->571541K(2944192K), 0.0943030 secs]
[GC 827669K->598624K(2944192K), 0.0893110 secs]
[GC 854752K->584194K(2944192K), 0.0857210 secs]
[GC 840302K->631463K(2944192K), 0.0938420 secs]
[GC 885719K->640509K(2944192K), 0.1002430 secs]
[GC 896637K->679978K(2944192K), 0.1029880 secs]
[GC 936106K->666329K(2944192K), 0.0977190 secs]
[GC 922457K->694513K(2944192K), 0.0942580 secs]
[GC 950641K->700362K(2944192K), 0.0877730 secs]
[GC 956490K->735209K(2944192K), 0.0819000 secs]
[GC 991324K->755060K(2944192K), 0.0930970 secs]
[GC 1011188K->771520K(2944192K), 0.0953870 secs]
[GC 1027204K->763061K(2944192K), 0.1069750 secs]
[GC 1019189K->792810K(2944192K), 0.0941610 secs]
[GC 1048938K->830449K(2944192K), 0.0887950 secs]
[GC 1086558K->828028K(2944192K), 0.0882400 secs]
[GC 1084156K->865529K(2944192K), 0.0984390 secs]
[GC 1121657K->887641K(2944192K), 0.0902560 secs]
[GC 1143724K->887010K(2944192K), 0.0859180 secs]
[GC 1143138K->922105K(2944192K), 0.0925510 secs]
[GC 1178233K->924347K(2944192K), 0.0862020 secs]
[GC 1180475K->977386K(2944192K), 0.0887800 secs]
[GC 1233514K->961161K(2944192K), 0.0781430 secs]
[GC 1217289K->1017220K(2944192K), 0.0903580 secs]
[GC 1273348K->997074K(2944192K), 0.0802550 secs]
[GC 1253097K->1057488K(2944192K), 0.0919040 secs]
[GC 1313616K->1032595K(2944192K), 0.0832890 secs]
[GC 1288723K->1095315K(2944192K), 0.0868440 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1351443K->1069554K(2944192K), 0.0801210 secs]
[GC 1325682K->1119075K(2944192K), 0.0947660 secs]
[GC 1375203K->1131263K(2944192K), 0.0954760 secs]
[GC 1387391K->1149335K(2944192K), 0.0861970 secs]
[GC 1405463K->1134632K(2944192K), 0.0782840 secs]
[GC 1390760K->1185495K(2944192K), 0.0678980 secs]
[GC 1441623K->1165136K(2944192K), 0.0750870 secs]
[GC 1421264K->1181719K(2944192K), 0.0720880 secs]
[GC 1437847K->1198050K(2944192K), 0.0690950 secs]
[GC 1454178K->1190000K(2944192K), 0.1042410 secs]
[GC 1446128K->1204041K(2944192K), 0.0654030 secs]
[GC 1460169K->1218100K(2944192K), 0.0686470 secs]
[GC 1474228K->1227611K(2944192K), 0.0804290 secs]
[GC 1483739K->1207677K(2944192K), 0.1072180 secs]
[GC 1463805K->1237413K(2944192K), 0.1327530 secs]
[GC 1493541K->1237946K(2944192K), 0.0875070 secs]
[GC 1494074K->1264518K(2944192K), 0.1538230 secs]
[GC 1520646K->1246679K(2944192K), 0.1470410 secs]
[GC 1502807K->1270902K(2944192K), 0.0810300 secs]
[GC 1527030K->1269728K(2944192K), 0.0801290 secs]
[GC 1525856K->1279345K(2944192K), 0.1069400 secs]
[GC 1535473K->1289757K(2944192K), 0.0846890 secs]
[GC 1545885K->1298427K(2944192K), 0.1272260 secs]
[GC 1554555K->1306275K(2944192K), 0.0875790 secs]
[GC 1562403K->1296959K(2944192K), 0.0865140 secs]
[GC 1553087K->1306847K(2944192K), 0.1004420 secs]
[GC 1562975K->1314805K(2944192K), 0.0854250 secs]
[GC 1570933K->1321713K(2944192K), 0.1630400 secs]
[GC 1577841K->1361695K(2944192K), 0.0887390 secs]
[GC 1617823K->1337245K(2944192K), 0.1398810 secs]
[GC 1593373K->1366833K(2944192K), 0.0880220 secs]
[GC 1622961K->1365282K(2944192K), 0.1645670 secs]
[GC 1621410K->1397400K(2944192K), 0.1579750 secs]
[GC 1653528K->1373678K(2944192K), 0.1881160 secs]
[GC 1629806K->1399270K(2944192K), 0.1870570 secs]
[GC 1399863K(2944192K), 0.0451310 secs]
[GC 1462198K(2944192K), 0.0512090 secs]
[GC 1407749K->1132168K(2944192K), 0.0823080 secs]
[GC 1388296K->1137534K(2944192K), 0.0841480 secs]
[GC 1393662K->1177116K(2944192K), 0.0813490 secs]
[GC 1433227K->1161630K(2944192K), 0.0851030 secs]
[GC 1415899K->1214926K(2944192K), 0.1257850 secs]
[GC 1469420K->1233903K(2944192K), 0.1155870 secs]
[GC 1488989K->1216308K(2944192K), 0.1187990 secs]
[GC 1471164K->1244377K(2944192K), 0.1158630 secs]
[GC 1500505K->1278237K(2944192K), 0.1036030 secs]
[GC 1534365K->1298553K(2944192K), 0.0998450 secs]
[GC 1554681K->1317513K(2944192K), 0.0980880 secs]
[GC 1573641K->1337956K(2944192K), 0.0997050 secs]
[GC 1594084K->1355635K(2944192K), 0.0983970 secs]
[GC 1611763K->1373571K(2944192K), 0.0966780 secs]
[GC 1629699K->1376575K(2944192K), 0.0941560 secs]
[GC 1632703K->1391275K(2944192K), 0.1005900 secs]
[GC 1647403K->1425608K(2944192K), 0.1026960 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1681704K->1460954K(2944192K), 0.1013720 secs]
[GC 1717082K->1456774K(2944192K), 0.1115820 secs]
[GC 1712902K->1491691K(2944192K), 0.1060220 secs]
[GC 1747819K->1502509K(2944192K), 0.1084200 secs]
[GC 1758637K->1488216K(2944192K), 0.1019550 secs]
[GC 1744344K->1531546K(2944192K), 0.0847850 secs]
[GC 1787674K->1509093K(2944192K), 0.0991290 secs]
[GC 1765221K->1546723K(2944192K), 0.0822860 secs]
[GC 1802851K->1528107K(2944192K), 0.0957550 secs]
[GC 1784235K->1556397K(2944192K), 0.0674730 secs]
[GC 1812525K->1560070K(2944192K), 0.0723570 secs]
[GC 1816198K->1584455K(2944192K), 0.0800860 secs]
[GC 1840583K->1561373K(2944192K), 0.1021890 secs]
[GC 1817501K->1612272K(2944192K), 0.0981280 secs]
[GC 1868400K->1634869K(2944192K), 0.1146090 secs]
[GC 1890997K->1648414K(2944192K), 0.1140650 secs]
[GC 1904542K->1639508K(2944192K), 0.1136700 secs]
[GC 1895636K->1684982K(2944192K), 0.0990920 secs]
[GC 1941110K->1700832K(2944192K), 0.1016770 secs]
[GC 1956960K->1719108K(2944192K), 0.0979210 secs]
[GC 1974271K->1702935K(2944192K), 0.0997430 secs]
[GC 1959063K->1755061K(2944192K), 0.1031070 secs]
[GC 2010432K->1771826K(2944192K), 0.1053050 secs]
[GC 2026870K->1790166K(2944192K), 0.1003490 secs]
[GC 2046294K->1793847K(2944192K), 0.1001410 secs]
[GC 2049975K->1812824K(2944192K), 0.0990470 secs]
[GC 2068952K->1846333K(2944192K), 0.1019410 secs]
[GC 2102461K->1867279K(2944192K), 0.0999440 secs]
[GC 2123390K->1883561K(2944192K), 0.0915130 secs]
[GC 2139689K->1884461K(2944192K), 0.0931570 secs]
[GC 2140589K->1886510K(2944192K), 0.0849040 secs]
[GC 2142624K->1941902K(2944192K), 0.0808340 secs]
[GC 2198030K->1970082K(2944192K), 0.1119850 secs]
[GC 2226210K->1981185K(2944192K), 0.1020690 secs]
[GC 2237313K->1986750K(2944192K), 0.0986780 secs]
[GC 2242878K->1983668K(2944192K), 0.0912610 secs]
[GC 2239796K->2032451K(2944192K), 0.0925740 secs]
[GC 2288579K->2034405K(2944192K), 0.0929020 secs]
[GC 2290533K->2070073K(2944192K), 0.0925790 secs]
[GC 2326201K->2089904K(2944192K), 0.1007580 secs]
[GC 2345798K->2074419K(2944192K), 0.0947930 secs]
[GC 2330547K->2107797K(2944192K), 0.0941950 secs]
[GC 2363925K->2141969K(2944192K), 0.0889850 secs]
[GC 2398097K->2162596K(2944192K), 0.0946240 secs]
[GC 2418724K->2182193K(2944192K), 0.0943440 secs]
[GC 2438309K->2199646K(2944192K), 0.0959610 secs]
[GC 2455774K->2202135K(2944192K), 0.0942650 secs]
[GC 2458263K->2203387K(2944192K), 0.0886650 secs]
[GC 2459515K->2253229K(2944192K), 0.0737200 secs]
[GC 2509357K->2236738K(2944192K), 0.0855330 secs]
[GC 2492866K->2257433K(2944192K), 0.0690520 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2513561K->2278215K(2944192K), 0.0747570 secs]
[GC 2534343K->2263046K(2944192K), 0.0893150 secs]
[GC 2519174K->2284135K(2944192K), 0.0696680 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2540227K->2318854K(2944192K), 0.0923610 secs]
[GC 2574982K->2321279K(2944192K), 0.1097940 secs]
[GC 2577407K->2335852K(2944192K), 0.0882340 secs]
[GC 2591980K->2359512K(2944192K), 0.1089420 secs]
[GC 2615640K->2362613K(2944192K), 0.0790450 secs]
[GC 2618589K->2402908K(2944192K), 0.0755820 secs]
[GC 2658994K->2408476K(2944192K), 0.1037080 secs]
[GC 2664589K->2412739K(2944192K), 0.0781860 secs]
[GC 2666255K->2439926K(2944192K), 0.0761960 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 260096. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 2694032K->2430184K(2944192K), 0.0923220 secs]
[GC 2686312K->2472568K(2944192K), 0.0741830 secs]
[GC 2728696K->2472146K(2944192K), 0.1026360 secs]
[GC 2472678K(2944192K), 0.0287480 secs]
[GC 2728265K->2473444K(2944192K), 0.0757620 secs]
[GC 2628558K(2944192K), 0.0468210 secs]
[GC 2397779K->2171159K(2944192K), 0.0853910 secs]
[GC 2425765K->2180134K(3827900K), 0.1107250 secs]
[GC 2436262K->2180691K(3827900K), 0.0864400 secs]
[GC 2436819K->2219493K(3827900K), 0.0753980 secs]
[GC 2474762K->2204698K(3827900K), 0.1061530 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 610000. Elapsed time: 40.298 secs. Remaining: 19.702 secs. Total: 1 mins 0 secs
[GC 2460785K->2229831K(3827900K), 0.0708370 secs]
[GC 2485948K->2243511K(3827900K), 0.1032790 secs]
[GC 2499638K->2251744K(3827900K), 0.0789020 secs]
[GC 2507611K->2283086K(3827900K), 0.0728880 secs]
[GC 2539214K->2281152K(3827900K), 0.0890410 secs]
[GC 2537280K->2281069K(3827900K), 0.0913880 secs]
[GC 2537197K->2311999K(3827900K), 0.0759930 secs]
[GC 2568127K->2317781K(3827900K), 0.0880490 secs]
[GC 2573909K->2351510K(3827900K), 0.0733790 secs]
[GC 2607638K->2378775K(3827900K), 0.0988660 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 920000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2634903K->2412992K(3827900K), 0.0807290 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 38 mins 9 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:1, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2669120K->2375975K(3827900K), 0.0808820 secs]
[GC 2632103K->2375692K(3827900K), 0.0644650 secs]
[GC 2631820K->2392231K(3827900K), 0.0786490 secs]
[GC 2648359K->2429864K(3827900K), 0.0903520 secs]
[GC 2684084K->2482317K(3827900K), 0.1358800 secs]
[GC 2738445K->2468571K(3827900K), 0.1071360 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2724699K->2525158K(3827900K), 0.1003210 secs]
[GC 2781286K->2518346K(3827900K), 0.1115790 secs]
[GC 2774410K->2559806K(3827900K), 0.1129850 secs]
[GC 2815934K->2568970K(3827900K), 0.1042390 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2825098K->2592093K(3827900K), 0.1087450 secs]
[GC 2848203K->2626182K(3827900K), 0.1085610 secs]
[GC 2882310K->2623522K(3827900K), 0.1131130 secs]
[GC 2879650K->2660289K(3827900K), 0.1042120 secs]
[GC 2916392K->2672058K(3827900K), 0.0994350 secs]
[GC 2928186K->2692448K(3827900K), 0.0995100 secs]
[GC 2948544K->2714030K(3827900K), 0.0985150 secs]
[GC 2970158K->2736118K(3827900K), 0.1086570 secs]
[GC 2992246K->2717378K(3827900K), 0.0973600 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2973503K->2770191K(3827900K), 0.1056650 secs]
[GC 3026319K->2778140K(3827900K), 0.1070790 secs]
[GC 3034226K->2830073K(3827900K), 0.1058640 secs]
[GC 3085072K->2812169K(3827900K), 0.1040690 secs]
[GC 3068297K->2874900K(3827900K), 0.1008150 secs]
[GC 3130692K->2858893K(3827900K), 0.0993540 secs]
[GC 3115021K->2914693K(3827900K), 0.1094630 secs]
[GC 3170821K->2901463K(3827900K), 0.1058250 secs]
[GC 3157591K->2955445K(3827900K), 0.0967900 secs]
[GC 3211539K->2959397K(3827900K), 0.1050320 secs]
[GC 3215525K->2980087K(3827900K), 0.1057290 secs]
[GC 3236215K->3002279K(3827900K), 0.0985900 secs]
[GC 3258393K->3020685K(3827900K), 0.1069080 secs]
[GC 3276813K->3025095K(3827900K), 0.0974890 secs]
[GC 3280815K->3062557K(3827900K), 0.1040850 secs]
[GC 3318685K->3048001K(3827900K), 0.0973040 secs]
[GC 3304129K->3102434K(3827900K), 0.1060420 secs]
[GC 3358509K->3113076K(3827900K), 0.1072070 secs]
[GC 3369204K->3165238K(3827900K), 0.1015140 secs]
[GC 3421366K->3151469K(3827900K), 0.1048200 secs]
[GC 3407559K->3199017K(3827900K), 0.1153980 secs]
[GC 3455145K->3210066K(3827900K), 0.1050540 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3466194K->3232614K(3827900K), 0.1038140 secs]
[GC 3488730K->3251937K(3827900K), 0.0970330 secs]
[GC 3508065K->3274592K(3827900K), 0.0977130 secs]
[GC 3530720K->3293437K(3827900K), 0.1062880 secs]
[GC 3293744K(3827900K), 0.0393480 secs]
[GC 3547882K->3315011K(3827900K), 0.1017710 secs]
[GC 3446229K(3827900K), 0.0560160 secs]
[GC 3235091K->3014458K(4650880K), 0.1199270 secs]
[GC 3269421K->3002198K(4650880K), 0.1199960 secs]
[GC 3258326K->3054936K(4650880K), 0.1151020 secs]
[GC 3310964K->3038076K(4650880K), 0.1106880 secs]
[GC 3294204K->3085360K(4650880K), 0.1115790 secs]
[GC 3341488K->3102436K(4650880K), 0.1073150 secs]
[GC 3358564K->3101947K(4650880K), 0.1002700 secs]
[GC 3358075K->3104644K(4650880K), 0.1020870 secs]
[GC 3360732K->3159473K(4650880K), 0.0905810 secs]
[GC 3415601K->3184776K(4650880K), 0.1154760 secs]
[GC 3440886K->3201127K(4650880K), 0.1139180 secs]
[GC 3457255K->3181221K(4650880K), 0.1185060 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3437349K->3235566K(4650880K), 0.0984100 secs]
[GC 3491694K->3239083K(4650880K), 0.1002160 secs]
[GC 3495211K->3280528K(4650880K), 0.1007230 secs]
[GC 3536656K->3297585K(4650880K), 0.1070410 secs]
[GC 3553713K->3321739K(4650880K), 0.1010700 secs]
[GC 3577867K->3341046K(4650880K), 0.1010020 secs]
[GC 3597174K->3358436K(4650880K), 0.1044630 secs]
[GC 3614221K->3381396K(4650880K), 0.0947920 secs]
[GC 3636454K->3381487K(4650880K), 0.1001300 secs]
[GC 3637615K->3419158K(4650880K), 0.1072660 secs]
[GC 3675286K->3421584K(4650880K), 0.1007250 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3677712K->3475538K(4650880K), 0.1066440 secs]
[GC 3731666K->3461863K(4650880K), 0.1071140 secs]
[GC 3717991K->3516845K(4650880K), 0.0982700 secs]
[GC 3772973K->3524034K(4650880K), 0.0955460 secs]
[GC 3780162K->3523376K(4650880K), 0.1036930 secs]
[GC 3779504K->3578279K(4650880K), 0.0980490 secs]
[GC 3834407K->3563642K(4650880K), 0.0980380 secs]
[GC 3819770K->3619137K(4650880K), 0.0992020 secs]
[GC 3875257K->3624978K(4650880K), 0.1047940 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5702 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5702 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 52 ms.
