/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-20222 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-20222
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0909420 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 9. Sleeping for 9500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 9
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@a2e02b2
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5710, using socket ServerSocket[addr=/0.0.0.0,localport=5710], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5710
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 57856 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 49231 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 41611 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5710 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 39647 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 39691 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 59414 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 43493 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 is accepting socket connection from /127.0.0.1:51957
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 45911 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 44788 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:51957
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 is accepting socket connection from /127.0.0.1:33508
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:33508
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 is accepting socket connection from /127.0.0.1:55116
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:55116
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 9
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 9
[GC 259695K->12611K(2944064K), 0.0404460 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-56913|6] [deimos-esw-56913, deimos-esw-24151, deimos-esw-47716, deimos-esw-40944, deimos-esw-26764, deimos-esw-4805, deimos-esw-60537, deimos-esw-49873, deimos-esw-17547, deimos-esw-20378]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-20378, physical addresses are [127.0.0.1:52009]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 9, serverOidBase: 9000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 9: org.radargun.cachewrappers.FFWrapper@231d4b69
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@231d4b69, nodeIndex=9, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268675K->22862K(2944064K), 0.0539320 secs]
[GC 278926K->29263K(2944064K), 0.0467690 secs]
[GC 285327K->44165K(2944064K), 0.0459830 secs]
[GC 300229K->62377K(2944064K), 0.0540850 secs]
[GC 318441K->77810K(2944064K), 0.0587400 secs]
[GC 333874K->109077K(2944064K), 0.0616740 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 365141K->110072K(2944064K), 0.1251090 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9100. Elapsed time: 20.222 secs. Remaining: 39.778 secs. Total: 1 mins 0 secs
[GC 366136K->149272K(2944064K), 0.0802260 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 18550. Elapsed time: 41.008 secs. Remaining: 18.992 secs. Total: 1 mins 0 secs
[GC 405336K->124214K(2944064K), 0.0851720 secs]
[GC 380278K->176244K(2944064K), 0.0651960 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 3 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 180 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,671,928 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 272135K->140619K(2944064K), 0.6269720 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,801,578 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@231d4b69, nodeIndex=9, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 396747K->214545K(2944192K), 0.0301810 secs]
[GC 470673K->160311K(2944192K), 0.0375450 secs]
[GC 416439K->169820K(2944192K), 0.0389380 secs]
[GC 425948K->172111K(2944192K), 0.0436470 secs]
[GC 428239K->187598K(2944192K), 0.0454730 secs]
[GC 443726K->199870K(2944192K), 0.0575650 secs]
[GC 455998K->211953K(2944192K), 0.0534690 secs]
[GC 468081K->224241K(2944192K), 0.0768000 secs]
[GC 480369K->206165K(2944192K), 0.0577280 secs]
[GC 462293K->239538K(2944192K), 0.0792920 secs]
[GC 495666K->243809K(2944192K), 0.0927250 secs]
[GC 499937K->262247K(2944192K), 0.1039520 secs]
[GC 518375K->248398K(2944192K), 0.1258830 secs]
[GC 504526K->268266K(2944192K), 0.0740910 secs]
[GC 524394K->266357K(2944192K), 0.0832850 secs]
[GC 522485K->257253K(2944192K), 0.1582320 secs]
[GC 512764K->297793K(2944192K), 0.0762270 secs]
[GC 553921K->322262K(2944192K), 0.1285770 secs]
[GC 578390K->342292K(2944192K), 0.1340230 secs]
[GC 598420K->324027K(2944192K), 0.1184460 secs]
[GC 580155K->375103K(2944192K), 0.0944900 secs]
[GC 630293K->374384K(2944192K), 0.0999660 secs]
[GC 630512K->409873K(2944192K), 0.0899590 secs]
[GC 666001K->412612K(2944192K), 0.0829550 secs]
[GC 667494K->442885K(2944192K), 0.0866460 secs]
[GC 699013K->480430K(2944192K), 0.0896390 secs]
[GC 736558K->466450K(2944192K), 0.0895840 secs]
[GC 722543K->493151K(2944192K), 0.0890190 secs]
[GC 748963K->533337K(2944192K), 0.0911640 secs]
[GC 789465K->519184K(2944192K), 0.0839490 secs]
[GC 775312K->549681K(2944192K), 0.0847560 secs]
[GC 805809K->597615K(2944192K), 0.0863690 secs]
[GC 853743K->577396K(2944192K), 0.0881070 secs]
[GC 833524K->635805K(2944192K), 0.0904870 secs]
[GC 891933K->613693K(2944192K), 0.0944300 secs]
[GC 869032K->674894K(2944192K), 0.1000540 secs]
[GC 930997K->656355K(2944192K), 0.0978500 secs]
[GC 912311K->714239K(2944192K), 0.0986340 secs]
[GC 970367K->694168K(2944192K), 0.0951420 secs]
[GC 950296K->689549K(2944192K), 0.0857480 secs]
[GC 945677K->738261K(2944192K), 0.0745830 secs]
[GC 994382K->754202K(2944192K), 0.1017430 secs]
[GC 1010330K->762586K(2944192K), 0.0913980 secs]
[GC 1018705K->792646K(2944192K), 0.0919000 secs]
[GC 1048774K->829652K(2944192K), 0.0849310 secs]
[GC 1085780K->820876K(2944192K), 0.0848580 secs]
[GC 1077004K->836426K(2944192K), 0.0843760 secs]
[GC 1092528K->852924K(2944192K), 0.0835670 secs]
[GC 1109033K->870887K(2944192K), 0.0818120 secs]
[GC 1125545K->906166K(2944192K), 0.0819420 secs]
[GC 1162294K->925723K(2944192K), 0.0849510 secs]
[GC 1181851K->932472K(2944192K), 0.0815500 secs]
[GC 1188600K->946426K(2944192K), 0.0849380 secs]
[GC 1202554K->955861K(2944192K), 0.0879650 secs]
[GC 1211989K->983005K(2944192K), 0.0768310 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5710 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1238188K->1018729K(2944192K), 0.0814040 secs]
[GC 1274857K->1009539K(2944192K), 0.0844530 secs]
[GC 1265667K->1057451K(2944192K), 0.0856570 secs]
[GC 1313579K->1057386K(2944192K), 0.0804550 secs]
[GC 1312536K->1109578K(2944192K), 0.0901770 secs]
[GC 1365706K->1096091K(2944192K), 0.0808310 secs]
[GC 1352219K->1141866K(2944192K), 0.0819850 secs]
[GC 1396757K->1150335K(2944192K), 0.0781920 secs]
[GC 1406463K->1135723K(2944192K), 0.0800960 secs]
[GC 1391851K->1153011K(2944192K), 0.0716910 secs]
[GC 1409139K->1183620K(2944192K), 0.0566240 secs]
[GC 1439748K->1157650K(2944192K), 0.0630970 secs]
[GC 1413778K->1165287K(2944192K), 0.0819630 secs]
[GC 1421415K->1209865K(2944192K), 0.0954350 secs]
[GC 1465993K->1174318K(2944192K), 0.0948050 secs]
[GC 1430446K->1214769K(2944192K), 0.1029750 secs]
[GC 1470897K->1194901K(2944192K), 0.1277280 secs]
[GC 1451029K->1223835K(2944192K), 0.0615900 secs]
[GC 1479963K->1207841K(2944192K), 0.0657900 secs]
[GC 1463969K->1227773K(2944192K), 0.0677510 secs]
[GC 1483901K->1250750K(2944192K), 0.0805470 secs]
[GC 1506878K->1244904K(2944192K), 0.0785710 secs]
[GC 1501032K->1242016K(2944192K), 0.0941610 secs]
[GC 1498144K->1260491K(2944192K), 0.1270780 secs]
[GC 1516619K->1282822K(2944192K), 0.1280580 secs]
[GC 1538950K->1256715K(2944192K), 0.0804570 secs]
[GC 1512843K->1287036K(2944192K), 0.1387030 secs]
[GC 1543164K->1285382K(2944192K), 0.0783760 secs]
[GC 1541510K->1294629K(2944192K), 0.1167400 secs]
[GC 1550757K->1319339K(2944192K), 0.1235840 secs]
[GC 1575467K->1292063K(2944192K), 0.0812340 secs]
[GC 1548191K->1339134K(2944192K), 0.0850280 secs]
[GC 1595262K->1303585K(2944192K), 0.0839290 secs]
[GC 1559713K->1335769K(2944192K), 0.1150810 secs]
[GC 1591897K->1333530K(2944192K), 0.0807290 secs]
[GC 1589658K->1325282K(2944192K), 0.1716770 secs]
[GC 1581410K->1348549K(2944192K), 0.1507740 secs]
[GC 1604677K->1354532K(2944192K), 0.1239110 secs]
[GC 1610660K->1361077K(2944192K), 0.1171130 secs]
[GC 1617205K->1350353K(2944192K), 0.1292640 secs]
[GC 1606481K->1372309K(2944192K), 0.0819650 secs]
[GC 1628437K->1378858K(2944192K), 0.1413380 secs]
[GC 1379101K(2944192K), 0.0558000 secs]
[GC 1446155K(2944192K), 0.0492280 secs]
[GC 1372094K->1114899K(2944192K), 0.0652710 secs]
[GC 1371027K->1140075K(2944192K), 0.0733820 secs]
[GC 1396203K->1113757K(2944192K), 0.0711520 secs]
[GC 1369885K->1156917K(2944192K), 0.0703400 secs]
[GC 1413045K->1122206K(2944192K), 0.0667810 secs]
[GC 1378334K->1168279K(2944192K), 0.0776160 secs]
[GC 1424407K->1198138K(2944192K), 0.1099540 secs]
[GC 1454266K->1192949K(2944192K), 0.1084760 secs]
[GC 1449077K->1222698K(2944192K), 0.1247080 secs]
[GC 1478826K->1230267K(2944192K), 0.1012790 secs]
[GC 1486395K->1249715K(2944192K), 0.0934000 secs]
[GC 1505220K->1279848K(2944192K), 0.0876410 secs]
[GC 1535944K->1280100K(2944192K), 0.0874810 secs]
[GC 1534898K->1299127K(2944192K), 0.0857190 secs]
[GC 1555238K->1333242K(2944192K), 0.0803460 secs]
[GC 1589370K->1335688K(2944192K), 0.0839030 secs]
[GC 1591816K->1372061K(2944192K), 0.0847440 secs]
[GC 1628189K->1389653K(2944192K), 0.0858990 secs]
[GC 1645781K->1395327K(2944192K), 0.0835000 secs]
[GC 1651455K->1416490K(2944192K), 0.0860230 secs]
[GC 1672618K->1444154K(2944192K), 0.0881170 secs]
[GC 1700282K->1435698K(2944192K), 0.0829360 secs]
[GC 1689844K->1463720K(2944192K), 0.0845770 secs]
[GC 1719848K->1467596K(2944192K), 0.0814500 secs]
[GC 1723724K->1527206K(2944192K), 0.0595950 secs]
[GC 1783334K->1503007K(2944192K), 0.0784910 secs]
[GC 1759135K->1524791K(2944192K), 0.0618700 secs]
[GC 1780919K->1492214K(2944192K), 0.0598980 secs]
[GC 1748342K->1501148K(2944192K), 0.0804040 secs]
[GC 1757276K->1548861K(2944192K), 0.0556090 secs]
[GC 1804989K->1511123K(2944192K), 0.0594700 secs]
[GC 1767251K->1552872K(2944192K), 0.0601000 secs]
[GC 1809000K->1542908K(2944192K), 0.0885460 secs]
[GC 1798100K->1589599K(2944192K), 0.0750140 secs]
[GC 1845665K->1611094K(2944192K), 0.0930740 secs]
[GC 1867222K->1605026K(2944192K), 0.0916210 secs]
[GC 1861154K->1608946K(2944192K), 0.0915760 secs]
[GC 1865074K->1623799K(2944192K), 0.0847060 secs]
[GC 1878524K->1639529K(2944192K), 0.0850930 secs]
[GC 1895657K->1706799K(2944192K), 0.0819560 secs]
[GC 1962927K->1689890K(2944192K), 0.0823580 secs]
[GC 1946018K->1747998K(2944192K), 0.0887590 secs]
[GC 2003790K->1726560K(2944192K), 0.0864600 secs]
[GC 1982631K->1783452K(2944192K), 0.0832210 secs]
[GC 2039536K->1759555K(2944192K), 0.0846820 secs]
[GC 2013780K->1819077K(2944192K), 0.0819450 secs]
[GC 2075205K->1798255K(2944192K), 0.0842790 secs]
[GC 2054383K->1855320K(2944192K), 0.0839980 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5710 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2111448K->1833301K(2944192K), 0.0799580 secs]
[GC 2089429K->1892194K(2944192K), 0.0832410 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5710 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2148322K->1871365K(2944192K), 0.0788850 secs]
[GC 2127464K->1898321K(2944192K), 0.0660450 secs]
[GC 2152934K->1933438K(2944192K), 0.0917150 secs]
[GC 2189566K->1930729K(2944192K), 0.0866570 secs]
[GC 2186857K->1975842K(2944192K), 0.0832280 secs]
[GC 2231970K->1957226K(2944192K), 0.0997690 secs]
[GC 2213354K->1969337K(2944192K), 0.0807680 secs]
[GC 2225465K->2018223K(2944192K), 0.0837800 secs]
[GC 2274318K->2016328K(2944192K), 0.0829870 secs]
[GC 2272456K->2054997K(2944192K), 0.0858870 secs]
[GC 2309428K->2069360K(2944192K), 0.0806200 secs]
[GC 2325488K->2072336K(2944192K), 0.0833180 secs]
[GC 2328464K->2093161K(2944192K), 0.0844640 secs]
[GC 2349235K->2141999K(2944192K), 0.0840600 secs]
[GC 2397212K->2127773K(2944192K), 0.0860560 secs]
[GC 2383901K->2186249K(2944192K), 0.0839060 secs]
[GC 2442377K->2162899K(2944192K), 0.0868500 secs]
[GC 2419027K->2190981K(2944192K), 0.0850420 secs]
[GC 2447109K->2222664K(2944192K), 0.0663750 secs]
[GC 2478792K->2203359K(2944192K), 0.0810790 secs]
[GC 2459487K->2222985K(2944192K), 0.0670790 secs]
[GC 2479113K->2238354K(2944192K), 0.0685300 secs]
[GC 2494482K->2224926K(2944192K), 0.0861450 secs]
[GC 2481054K->2242423K(2944192K), 0.0628260 secs]
[GC 2498551K->2220739K(2944192K), 0.0683660 secs]
[GC 2476867K->2275690K(2944192K), 0.0941280 secs]
[GC 2531617K->2300728K(2944192K), 0.1024830 secs]
[GC 2556846K->2319226K(2944192K), 0.1102810 secs]
[GC 2575354K->2326574K(2944192K), 0.1238240 secs]
[GC 2580983K->2319989K(2944192K), 0.1077580 secs]
[GC 2576062K->2356892K(2944192K), 0.0998180 secs]
[GC 2613020K->2377232K(2944192K), 0.0964490 secs]
[GC 2633360K->2412203K(2944192K), 0.0925660 secs]
[GC 2668331K->2398341K(2944192K), 0.0926360 secs]
[GC 2653651K->2448121K(2944192K), 0.0910640 secs]
[GC 2704198K->2447695K(2944192K), 0.0867240 secs]
[GC 2447801K(2944192K), 0.0361310 secs]
[GC 2703823K->2481787K(2944192K), 0.0904680 secs]
[GC 2612039K(2944192K), 0.0452760 secs]
[GC 2407088K->2195575K(3800652K), 0.1007510 secs]
[GC 2451703K->2171842K(3800652K), 0.0966960 secs]
[GC 2427970K->2231949K(3800652K), 0.0962760 secs]
[GC 2488077K->2213456K(3800652K), 0.0955260 secs]
[GC 2469024K->2265376K(3800652K), 0.0975460 secs]
[GC 2521504K->2243587K(3800652K), 0.0838400 secs]
[GC 2499715K->2264270K(3800652K), 0.0620640 secs]
[GC 2520397K->2233047K(3800652K), 0.0661880 secs]
[GC 2489175K->2304131K(3800652K), 0.0942060 secs]
[GC 2560225K->2290368K(3800652K), 0.0927660 secs]
[GC 2546480K->2333042K(3800652K), 0.0816530 secs]
[GC 2589170K->2315731K(3800652K), 0.1036560 secs]
[GC 2571859K->2361658K(3800652K), 0.0875580 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5710 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2617786K->2364993K(3800652K), 0.0908330 secs]
[GC 2621121K->2401424K(3800652K), 0.0972250 secs]
[GC 2657552K->2419928K(3800652K), 0.0883100 secs]
[GC 2676056K->2438618K(3800652K), 0.0928980 secs]
[GC 2694487K->2437824K(3800652K), 0.0949610 secs]
[GC 2693942K->2473871K(3800652K), 0.0892780 secs]
[GC 2729998K->2492271K(3800652K), 0.0886720 secs]
[GC 2748384K->2525483K(3800652K), 0.0901430 secs]
[GC 2781611K->2511671K(3800652K), 0.0902060 secs]
[GC 2767799K->2556369K(3800652K), 0.0896550 secs]
[GC 2811996K->2549778K(3800652K), 0.0904110 secs]
[GC 2805906K->2587074K(3800652K), 0.0895070 secs]
[GC 2843202K->2569036K(3800652K), 0.0891600 secs]
[GC 2825164K->2586158K(3800652K), 0.0788280 secs]
[GC 2842286K->2634375K(3800652K), 0.0648030 secs]
[GC 2890503K->2633188K(3800652K), 0.0774270 secs]
[GC 2889316K->2671048K(3800652K), 0.1069720 secs]
[GC 2925566K->2666274K(3800652K), 0.1015540 secs]
[GC 2922346K->2669986K(3800652K), 0.1034440 secs]
[GC 2925850K->2696994K(3800652K), 0.0915420 secs]
[GC 2953121K->2728772K(3800652K), 0.0930960 secs]
[GC 2984900K->2749330K(3800652K), 0.0907160 secs]
[GC 3005458K->2751157K(3800652K), 0.0898680 secs]
[GC 3007285K->2805112K(3800652K), 0.0967870 secs]
[GC 3061240K->2787634K(3800652K), 0.0887840 secs]
[GC 3043762K->2846806K(3800652K), 0.0885510 secs]
[GC 3102180K->2822167K(3800652K), 0.0960170 secs]
[GC 3078295K->2864301K(3800652K), 0.0965230 secs]
[GC 3119322K->2891620K(3800652K), 0.1593950 secs]
[GC 3147745K->2876977K(3800652K), 0.0901280 secs]
[GC 3133105K->2932978K(3800652K), 0.0885000 secs]
[GC 3189106K->2912368K(3800652K), 0.0861750 secs]
[GC 3168496K->2943282K(3800652K), 0.0729210 secs]
[GC 3197650K->2971173K(3800652K), 0.0998900 secs]
[GC 3226303K->2983249K(3800652K), 0.1002700 secs]
[GC 3239377K->3018797K(3800652K), 0.1054070 secs]
[GC 3274925K->3010745K(3800652K), 0.1014380 secs]
[GC 3264787K->3032284K(3800652K), 0.0898410 secs]
[GC 3288412K->3038079K(3800652K), 0.0894550 secs]
[GC 3294201K->3059007K(3800652K), 0.0879320 secs]
[GC 3315104K->3091075K(3800652K), 0.0834700 secs]
[GC 3346942K->3093780K(3800652K), 0.0917960 secs]
[GC 3349507K->3128421K(3800652K), 0.0936790 secs]
[GC 3384119K->3130936K(3800652K), 0.0945230 secs]
[GC 3387064K->3182662K(3800652K), 0.0902570 secs]
[GC 3438790K->3171050K(3800652K), 0.0907100 secs]
[GC 3427178K->3186182K(3800652K), 0.0863830 secs]
[GC 3442310K->3209080K(3800652K), 0.0899960 secs]
[GC 3465208K->3243282K(3800652K), 0.0861370 secs]
[GC 3499410K->3256521K(3800652K), 0.0907640 secs]
[GC 3256526K(3800652K), 0.0333540 secs]
[GC 3512649K->3291215K(3800652K), 0.0886000 secs]
[GC 3444296K(3800652K), 0.0556290 secs]
[GC 3257418K->2989029K(4650880K), 0.1007560 secs]
[GC 3245157K->3016286K(4650880K), 0.0990970 secs]
[GC 3272414K->3049251K(4650880K), 0.0808160 secs]
[GC 3305379K->3035624K(4650880K), 0.1089640 secs]
[GC 3291752K->3054247K(4650880K), 0.0992100 secs]
[GC 3310375K->3086043K(4650880K), 0.0755810 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3341195K->3069314K(4650880K), 0.0994850 secs]
[GC 3325442K->3103376K(4650880K), 0.0816110 secs]
[GC 3359504K->3095192K(4650880K), 0.0848320 secs]
[GC 3351320K->3139958K(4650880K), 0.0723470 secs]
[GC 3394961K->3133112K(4650880K), 0.0950330 secs]
[GC 3388302K->3129046K(4650880K), 0.0915310 secs]
[GC 3384213K->3171273K(4650880K), 0.0746400 secs]
[GC 3425627K->3158578K(4650880K), 0.0867050 secs]
[GC 3412745K->3197853K(4650880K), 0.0714250 secs]
[GC 3452424K->3195520K(4650880K), 0.0858400 secs]
[GC 3451648K->3187879K(4650880K), 0.0780720 secs]
[GC 3443521K->3231335K(4650880K), 0.0711870 secs]
[GC 3484971K->3235166K(4650880K), 0.0928510 secs]
[GC 3487325K->3248195K(4650880K), 0.0794260 secs]
[GC 3501506K->3272400K(4650880K), 0.0701260 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 562139. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 3527964K->3265368K(4650880K), 0.0859200 secs]
[GC 3521496K->3309914K(4650880K), 0.0739360 secs]
[GC 3565349K->3291311K(4650880K), 0.0899940 secs]
[GC 3546684K->3299034K(4650880K), 0.0710660 secs]
[GC 3555162K->3346953K(4650880K), 0.0863360 secs]
[GC 3603081K->3332158K(4650880K), 0.0842530 secs]
[GC 3588286K->3341421K(4650880K), 0.0710150 secs]
[GC 3597380K->3378966K(4650880K), 0.0802640 secs]
[GC 3635094K->3371152K(4650880K), 0.0854570 secs]
[GC 3626988K->3396053K(4650880K), 0.0698010 secs]
[GC 3652181K->3412445K(4650880K), 0.0879420 secs]
[GC 3667363K->3405121K(4650880K), 0.0740140 secs]
[GC 3661249K->3449391K(4650880K), 0.0783760 secs]
[GC 3705519K->3450454K(4650880K), 0.0904780 secs]
[GC 3705781K->3451067K(4650880K), 0.0603440 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 990000. Elapsed time: 40.019 secs. Remaining: 19.981 secs. Total: 1 mins 0 secs
[GC 3706476K->3496096K(4650880K), 0.0787000 secs]
[GC 3751614K->3489532K(4650880K), 0.0913680 secs]
[GC 3744429K->3503383K(4650880K), 0.0611350 secs]
[GC 3758638K->3509010K(4650880K), 0.0716060 secs]
[GC 3763753K->3526054K(4650880K), 0.0688390 secs]
[GC 3780470K->3541950K(4650880K), 0.0863700 secs]
[GC 3798078K->3555604K(4650880K), 0.0770490 secs]
[GC 3811680K->3572908K(4650880K), 0.0780940 secs]
[GC 3829035K->3609875K(4650880K), 0.0873870 secs]
[GC 3861854K->3586049K(4650880K), 0.0858470 secs]
[GC 3842024K->3620940K(4650880K), 0.0677590 secs]
[GC 3876329K->3605925K(4650880K), 0.0792720 secs]
[GC 3860501K->3652483K(4650880K), 0.0632230 secs]
[GC 3907867K->3680034K(4650880K), 0.0906710 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1530000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 3933846K->3688771K(4650880K), 0.0726770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 45 mins 36 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:9, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5710 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 50 ms.
