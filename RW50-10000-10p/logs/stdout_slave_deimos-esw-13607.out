/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-13607 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-13607
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0777410 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Startup staggering, number of slaves to start is 12 This is the slave with index 0, not sleeping
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@3fbefe6e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5701, using socket ServerSocket[addr=/0.0.0.0,localport=5701], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5701
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5703. Reason: ConnectException[Connection refused]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5702. Reason: ConnectException[Connection refused]
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.cluster.MulticastJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTED
 INFO  [pool-1-thread-1] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Initializing cluster partition table first arrangement...
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is the first node!
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 0
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|0] [deimos-esw-1852]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-1852, physical addresses are [127.0.0.1:52000]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:44384
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:44384
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker not present. Data Grid is being initialized for the first time.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 0, serverOidBase: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.DomainRoot} Created DomainRoot instance
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Notify other nodes that startup completed
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:50118
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:50118
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:44824
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:44824
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:37321
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:37321
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:52296
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:52296
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:46695
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:46695
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:59886
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59886
[GC 259695K->20903K(2944064K), 0.0592260 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:37886
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:37886
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:33224
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:33224
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:40535
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:40535
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:53960
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:53960
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5701 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701 this
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 0: org.radargun.cachewrappers.FFWrapper@68163524
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] All migration tasks has been completed, queues are empty.
[GC 276967K->13636K(2944064K), 0.0342140 secs]
 INFO  [Incoming-1,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|1] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881]
 INFO  [Incoming-3,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|2] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454]
 INFO  [Incoming-4,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|3] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077]
 INFO  [Incoming-4,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|4] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272]
 INFO  [Incoming-4,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|5] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207]
 INFO  [Incoming-4,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|6] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403]
 INFO  [Incoming-4,deimos-esw-1852] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|7] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403, deimos-esw-20931, deimos-esw-27783]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@68163524, nodeIndex=0, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269700K->24523K(2944064K), 0.0459590 secs]
[GC 280587K->37475K(2944064K), 0.0520990 secs]
[GC 293539K->51711K(2944064K), 0.0530260 secs]
[GC 307775K->76485K(2944064K), 0.0588110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 332549K->85526K(2944064K), 0.0632970 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11550. Elapsed time: 20.039 secs. Remaining: 39.961 secs. Total: 1 mins 0 secs
[GC 341585K->114570K(2944064K), 0.1043300 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 17100. Elapsed time: 40.382 secs. Remaining: 19.618 secs. Total: 1 mins 0 secs
[GC 370634K->119874K(2944064K), 0.0880020 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 43 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 163 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 375938K->138982K(2944064K), 0.0807190 secs]
[GC 395024K->166088K(2944064K), 0.0851250 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,733,576 kb - max:4,906,688 kb- total:2,944,064 kb
 WARN  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Fenix Framework never forgets...
[Full GC 210487K->129766K(2944064K), 0.5992920 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,476 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@68163524, nodeIndex=0, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 385894K->207921K(2944192K), 0.0322460 secs]
[GC 464049K->150740K(2944192K), 0.0392060 secs]
[GC 406868K->154532K(2944192K), 0.0612210 secs]
[GC 410660K->166259K(2944192K), 0.0792100 secs]
[GC 422387K->171202K(2944192K), 0.0772000 secs]
[GC 427330K->190071K(2944192K), 0.0949710 secs]
[GC 446199K->192466K(2944192K), 0.1042550 secs]
[GC 448594K->203806K(2944192K), 0.1188400 secs]
[GC 459934K->229052K(2944192K), 0.1168300 secs]
[GC 485180K->249314K(2944192K), 0.1597500 secs]
[GC 505442K->226605K(2944192K), 0.1507460 secs]
[GC 482733K->242924K(2944192K), 0.0716400 secs]
[GC 499052K->274128K(2944192K), 0.0829000 secs]
[GC 530256K->250124K(2944192K), 0.1372940 secs]
[GC 506252K->282756K(2944192K), 0.1490220 secs]
[GC 538884K->315064K(2944192K), 0.0864470 secs]
[GC 571192K->332698K(2944192K), 0.1501350 secs]
[GC 588826K->316190K(2944192K), 0.1310570 secs]
[GC 572318K->349065K(2944192K), 0.0894910 secs]
[GC 605193K->366292K(2944192K), 0.0909850 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 621860K->381822K(2944192K), 0.0863960 secs]
[GC 637950K->418960K(2944192K), 0.0821670 secs]
[GC 675088K->443717K(2944192K), 0.0868710 secs]
[GC 699845K->462750K(2944192K), 0.0833520 secs]
[GC 718878K->483436K(2944192K), 0.0863600 secs]
[GC 739564K->484262K(2944192K), 0.0920970 secs]
[GC 740380K->535883K(2944192K), 0.0880990 secs]
[GC 792011K->520390K(2944192K), 0.0928780 secs]
[GC 776462K->549950K(2944192K), 0.0809600 secs]
[GC 806078K->587657K(2944192K), 0.0830870 secs]
[GC 843785K->593542K(2944192K), 0.0834240 secs]
[GC 849670K->610562K(2944192K), 0.0869210 secs]
[GC 866668K->649905K(2944192K), 0.0839830 secs]
[GC 906033K->634696K(2944192K), 0.0889050 secs]
[GC 890824K->679364K(2944192K), 0.0901800 secs]
[GC 935492K->653515K(2944192K), 0.0939380 secs]
[GC 909643K->705032K(2944192K), 0.0823890 secs]
[GC 961111K->719305K(2944192K), 0.1068950 secs]
[GC 975433K->728219K(2944192K), 0.1009870 secs]
[GC 984316K->729020K(2944192K), 0.0982710 secs]
[GC 985145K->760475K(2944192K), 0.0832880 secs]
[GC 1016569K->795955K(2944192K), 0.0890670 secs]
[GC 1052083K->814305K(2944192K), 0.0809490 secs]
[GC 1070395K->832072K(2944192K), 0.0845210 secs]
[GC 1087081K->850494K(2944192K), 0.1005350 secs]
[GC 1104714K->870009K(2944192K), 0.0944930 secs]
[GC 1124446K->889827K(2944192K), 0.1024080 secs]
[GC 1145930K->891647K(2944192K), 0.0850280 secs]
[GC 1146943K->924336K(2944192K), 0.0965990 secs]
[GC 1179230K->943040K(2944192K), 0.0938950 secs]
[GC 1199168K->963833K(2944192K), 0.0877780 secs]
[GC 1219961K->979781K(2944192K), 0.0883040 secs]
[GC 1235890K->998132K(2944192K), 0.0823200 secs]
[GC 1254246K->1016442K(2944192K), 0.0945650 secs]
[GC 1272570K->1016963K(2944192K), 0.0922020 secs]
[GC 1273047K->1068289K(2944192K), 0.0844090 secs]
[GC 1324240K->1054789K(2944192K), 0.0976480 secs]
[GC 1310917K->1097742K(2944192K), 0.0850000 secs]
[GC 1353870K->1073440K(2944192K), 0.0793700 secs]
[GC 1329568K->1121607K(2944192K), 0.0616110 secs]
[GC 1377735K->1092120K(2944192K), 0.0661550 secs]
[GC 1348248K->1105795K(2944192K), 0.0928220 secs]
[GC 1361923K->1127743K(2944192K), 0.0600260 secs]
[GC 1383871K->1146969K(2944192K), 0.0678580 secs]
[GC 1403097K->1133581K(2944192K), 0.0822400 secs]
[GC 1389709K->1149598K(2944192K), 0.0600030 secs]
[GC 1405726K->1136138K(2944192K), 0.0674630 secs]
[GC 1392266K->1159171K(2944192K), 0.0795390 secs]
[GC 1415299K->1168669K(2944192K), 0.1204790 secs]
[GC 1424797K->1178006K(2944192K), 0.1573650 secs]
[GC 1434134K->1179641K(2944192K), 0.1223390 secs]
[GC 1435769K->1192876K(2944192K), 0.1465660 secs]
[GC 1449004K->1181218K(2944192K), 0.1830070 secs]
[GC 1437346K->1199663K(2944192K), 0.1670920 secs]
[GC 1455791K->1206650K(2944192K), 0.0772980 secs]
[GC 1462778K->1213090K(2944192K), 0.0809110 secs]
[GC 1469218K->1235240K(2944192K), 0.1356350 secs]
[GC 1491368K->1221473K(2944192K), 0.0817820 secs]
[GC 1477601K->1225962K(2944192K), 0.0824070 secs]
[GC 1482090K->1242167K(2944192K), 0.1531360 secs]
[GC 1498295K->1251188K(2944192K), 0.1081620 secs]
[GC 1507316K->1258229K(2944192K), 0.0919010 secs]
[GC 1514357K->1257803K(2944192K), 0.0899700 secs]
[GC 1513931K->1275523K(2944192K), 0.1676600 secs]
[GC 1531651K->1288076K(2944192K), 0.1386600 secs]
[GC 1544204K->1296626K(2944192K), 0.1888110 secs]
[GC 1552754K->1298568K(2944192K), 0.1189680 secs]
[GC 1554696K->1307000K(2944192K), 0.0870950 secs]
[GC 1563128K->1313385K(2944192K), 0.0839160 secs]
[GC 1569513K->1319697K(2944192K), 0.0841140 secs]
[GC 1575825K->1328601K(2944192K), 0.0848930 secs]
[GC 1584729K->1318501K(2944192K), 0.1310400 secs]
[GC 1574629K->1348308K(2944192K), 0.0773590 secs]
[GC 1604436K->1349194K(2944192K), 0.0906260 secs]
[GC 1605322K->1358384K(2944192K), 0.1770040 secs]
[GC 1614512K->1350099K(2944192K), 0.0856990 secs]
[GC 1606227K->1355903K(2944192K), 0.0880300 secs]
[GC 1612031K->1378618K(2944192K), 0.1757350 secs]
[GC 1634746K->1387676K(2944192K), 0.1620860 secs]
[GC 1388476K(2944192K), 0.0567520 secs]
[GC 1443572K(2944192K), 0.0483660 secs]
[GC 1401699K->1116865K(2944192K), 0.0806060 secs]
[GC 1372993K->1176412K(2944192K), 0.0730000 secs]
[GC 1432540K->1139896K(2944192K), 0.0848080 secs]
[GC 1396024K->1187105K(2944192K), 0.0803990 secs]
[GC 1443233K->1152712K(2944192K), 0.0796990 secs]
[GC 1408840K->1200679K(2944192K), 0.0786620 secs]
[GC 1456807K->1165208K(2944192K), 0.0778670 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1421336K->1214608K(2944192K), 0.0801880 secs]
[GC 1470736K->1179348K(2944192K), 0.0782660 secs]
[GC 1435476K->1226045K(2944192K), 0.0799710 secs]
[GC 1482173K->1192445K(2944192K), 0.0741080 secs]
[GC 1448573K->1240916K(2944192K), 0.0807680 secs]
[GC 1497044K->1213388K(2944192K), 0.0844870 secs]
[GC 1469516K->1245954K(2944192K), 0.0703310 secs]
[GC 1502082K->1247529K(2944192K), 0.0880630 secs]
[GC 1502148K->1288367K(2944192K), 0.1108780 secs]
[GC 1544471K->1302369K(2944192K), 0.0980130 secs]
[GC 1558497K->1310349K(2944192K), 0.1022290 secs]
[GC 1566477K->1317730K(2944192K), 0.0884400 secs]
[GC 1573180K->1347804K(2944192K), 0.0936630 secs]
[GC 1603932K->1331320K(2944192K), 0.0878320 secs]
[GC 1587448K->1367153K(2944192K), 0.0921220 secs]
[GC 1621545K->1415509K(2944192K), 0.0912120 secs]
[GC 1671637K->1402283K(2944192K), 0.0910790 secs]
[GC 1658336K->1446293K(2944192K), 0.0895190 secs]
[GC 1702421K->1468933K(2944192K), 0.0900510 secs]
[GC 1725061K->1455869K(2944192K), 0.0850530 secs]
[GC 1711997K->1514577K(2944192K), 0.0890640 secs]
[GC 1769415K->1493037K(2944192K), 0.0939880 secs]
[GC 1749165K->1535740K(2944192K), 0.0969080 secs]
[GC 1791868K->1513769K(2944192K), 0.0863760 secs]
[GC 1769897K->1564298K(2944192K), 0.1080330 secs]
[GC 1819158K->1569716K(2944192K), 0.1181560 secs]
[GC 1825844K->1563550K(2944192K), 0.0956870 secs]
[GC 1817800K->1630302K(2944192K), 0.0925890 secs]
[GC 1886430K->1616708K(2944192K), 0.0966690 secs]
[GC 1872836K->1672274K(2944192K), 0.0913500 secs]
[GC 1927319K->1647735K(2944192K), 0.0883280 secs]
[GC 1903863K->1706124K(2944192K), 0.0963610 secs]
[GC 1961248K->1683311K(2944192K), 0.0941720 secs]
[GC 1939439K->1740393K(2944192K), 0.1008990 secs]
[GC 1995135K->1720370K(2944192K), 0.0942390 secs]
[GC 1976498K->1776339K(2944192K), 0.1014680 secs]
[GC 2032466K->1756008K(2944192K), 0.0950320 secs]
[GC 2012136K->1811463K(2944192K), 0.0878340 secs]
[GC 2065819K->1792713K(2944192K), 0.1002380 secs]
[GC 2048841K->1849285K(2944192K), 0.0923210 secs]
[GC 2105413K->1815116K(2944192K), 0.0766320 secs]
[GC 2071244K->1827764K(2944192K), 0.0872730 secs]
[GC 2083892K->1867825K(2944192K), 0.0750300 secs]
[GC 2123953K->1850179K(2944192K), 0.0836070 secs]
[GC 2106307K->1866551K(2944192K), 0.0633120 secs]
[GC 2122679K->1870724K(2944192K), 0.0760600 secs]
[GC 2126852K->1918210K(2944192K), 0.0959860 secs]
[GC 2174315K->1895719K(2944192K), 0.1064970 secs]
[GC 2151833K->1915114K(2944192K), 0.0950790 secs]
[GC 2171242K->1927393K(2944192K), 0.0914990 secs]
[GC 2183521K->1976246K(2944192K), 0.0907480 secs]
[GC 2232374K->1981114K(2944192K), 0.0899640 secs]
[GC 2237242K->2014121K(2944192K), 0.0889700 secs]
[GC 2270027K->2017996K(2944192K), 0.0935900 secs]
[GC 2274124K->2051000K(2944192K), 0.0881570 secs]
[GC 2306522K->2055342K(2944192K), 0.0898020 secs]
[GC 2311470K->2070751K(2944192K), 0.0891650 secs]
[GC 2326879K->2088235K(2944192K), 0.0874680 secs]
[GC 2344363K->2108879K(2944192K), 0.0912140 secs]
[GC 2365007K->2129002K(2944192K), 0.0893550 secs]
[GC 2385130K->2145878K(2944192K), 0.0875450 secs]
[GC 2402006K->2147067K(2944192K), 0.0833230 secs]
[GC 2403195K->2195354K(2944192K), 0.0697930 secs]
[GC 2451444K->2194629K(2944192K), 0.0805140 secs]
[GC 2450128K->2229808K(2944192K), 0.1029810 secs]
[GC 2485936K->2247930K(2944192K), 0.1035050 secs]
[GC 2504058K->2239182K(2944192K), 0.1218780 secs]
[GC 2495310K->2269818K(2944192K), 0.1030310 secs]
[GC 2525946K->2309878K(2944192K), 0.1092230 secs]
[GC 2566006K->2326750K(2944192K), 0.1060680 secs]
[GC 2582864K->2329605K(2944192K), 0.1067810 secs]
[GC 2585733K->2366799K(2944192K), 0.1081820 secs]
[GC 2622896K->2388543K(2944192K), 0.1082000 secs]
[GC 2644671K->2391045K(2944192K), 0.1065110 secs]
[GC 2647173K->2427001K(2944192K), 0.1070210 secs]
[GC 2683076K->2446917K(2944192K), 0.1029250 secs]
[GC 2703045K->2446848K(2944192K), 0.0964170 secs]
[GC 2447286K(2944192K), 0.0433380 secs]
[GC 2702976K->2468888K(2944192K), 0.1025000 secs]
[GC 2610595K(2944192K), 0.0570970 secs]
[GC 2397119K->2137501K(3800236K), 0.1067880 secs]
[GC 2393629K->2196562K(3800236K), 0.0770950 secs]
[GC 2452690K->2175733K(3800236K), 0.1013960 secs]
[GC 2431861K->2199043K(3800236K), 0.0776580 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2455065K->2194515K(3800236K), 0.1026950 secs]
[GC 2450643K->2241612K(3800236K), 0.0812840 secs]
[GC 2497740K->2253996K(3800236K), 0.1179470 secs]
[GC 2510124K->2265234K(3800236K), 0.0940330 secs]
[GC 2519576K->2314067K(3800236K), 0.0922570 secs]
[GC 2568816K->2313724K(3800236K), 0.1004350 secs]
[GC 2569605K->2373511K(3800236K), 0.0929150 secs]
[GC 2629639K->2328700K(3800236K), 0.0672840 secs]
[GC 2584828K->2358661K(3800236K), 0.0642960 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 290000. Elapsed time: 20.318 secs. Remaining: 39.682 secs. Total: 1 mins 0 secs
[GC 2614758K->2389154K(3800236K), 0.0798540 secs]
[GC 2644481K->2379827K(3800236K), 0.0778900 secs]
[GC 2635955K->2411133K(3800236K), 0.0787440 secs]
[GC 2667261K->2453975K(3800236K), 0.1007220 secs]
[GC 2710103K->2475014K(3800236K), 0.0880330 secs]
[GC 2731093K->2529521K(3800236K), 0.0904690 secs]
[GC 2783248K->2503661K(3800236K), 0.0648550 secs]
[GC 2759789K->2517470K(3800236K), 0.0614190 secs]
[GC 2773598K->2544913K(3800236K), 0.0819420 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 470000. Elapsed time: 40.354 secs. Remaining: 19.646 secs. Total: 1 mins 0 secs
[GC 2801041K->2623640K(3800236K), 0.0984460 secs]
[GC 2879744K->2647643K(3800236K), 0.0850880 secs]
[GC 2903493K->2687692K(3800236K), 0.0914420 secs]
[GC 2943820K->2708310K(3800236K), 0.0907350 secs]
[GC 2964438K->2688139K(3800236K), 0.0711710 secs]
[GC 2944241K->2698269K(3800236K), 0.0723020 secs]
[GC 2954397K->2731148K(3800236K), 0.0657110 secs]
[GC 2987276K->2764206K(3800236K), 0.0952100 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 920000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 3020334K->2804261K(3800236K), 0.0838120 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 51 mins 26 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:0, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3060388K->2729945K(3800236K), 0.0631640 secs]
[GC 2986073K->2757603K(3800236K), 0.0675130 secs]
[GC 3013691K->2783408K(3800236K), 0.0784650 secs]
[GC 3039536K->2839181K(3800236K), 0.1008140 secs]
[GC 3095309K->2864368K(3800236K), 0.1034920 secs]
[GC 3120441K->2848402K(3800236K), 0.1053050 secs]
[GC 3104530K->2906235K(3800236K), 0.0992280 secs]
[GC 3162363K->2912981K(3800236K), 0.1057000 secs]
[GC 3169064K->2928818K(3800236K), 0.0987970 secs]
[GC 3184946K->2948674K(3800236K), 0.1078860 secs]
[GC 3204802K->2971191K(3800236K), 0.1060610 secs]
[GC 3227319K->2988281K(3800236K), 0.1056090 secs]
[GC 3244409K->3010546K(3800236K), 0.1050400 secs]
[GC 3266674K->3047705K(3800236K), 0.1027690 secs]
[GC 3303833K->3033732K(3800236K), 0.1046250 secs]
[GC 3289860K->3087334K(3800236K), 0.0985920 secs]
[GC 3343462K->3068940K(3800236K), 0.0951130 secs]
[GC 3324913K->3097671K(3800236K), 0.0927840 secs]
[GC 3353799K->3133865K(3800236K), 0.1206080 secs]
[GC 3389993K->3128167K(3800236K), 0.1134950 secs]
[GC 3384295K->3156168K(3800236K), 0.1292100 secs]
[GC 3412296K->3170911K(3800236K), 0.1128950 secs]
[GC 3427014K->3223302K(3800236K), 0.1004100 secs]
[GC 3479430K->3207646K(3800236K), 0.0994460 secs]
[GC 3463774K->3254859K(3800236K), 0.1035710 secs]
[GC 3510959K->3264857K(3800236K), 0.1062250 secs]
[GC 3264942K(3800236K), 0.0397560 secs]
[GC 3520985K->3288295K(3800236K), 0.1105660 secs]
[GC 3422891K(3800236K), 0.0501620 secs]
[GC 3070585K->2832264K(4650880K), 0.1192880 secs]
[GC 3088392K->2853736K(4650880K), 0.1183220 secs]
[GC 3109864K->2890624K(4650880K), 0.1134000 secs]
[GC 3146752K->2873525K(4650880K), 0.1086850 secs]
[GC 3129616K->2920863K(4650880K), 0.1045950 secs]
[GC 3175593K->2929477K(4650880K), 0.1117210 secs]
[GC 3185605K->2951397K(4650880K), 0.0965690 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5701 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 52 ms.
