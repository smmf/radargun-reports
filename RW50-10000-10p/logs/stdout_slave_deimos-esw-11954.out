/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-11954 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-11954
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0683770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@49de5afd
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 34638 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 39760 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 47409 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 52713 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 44950 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 34506 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:58527
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:58527
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 47021 accepted socket connection from /127.0.0.1:5708
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 5
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->10867K(2944064K), 0.0367170 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-29231|4] [deimos-esw-29231, deimos-esw-877, deimos-esw-54848, deimos-esw-58796, deimos-esw-38580, deimos-esw-23679, deimos-esw-16133]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-23679, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-23679] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-29231|5] [deimos-esw-29231, deimos-esw-877, deimos-esw-54848, deimos-esw-58796, deimos-esw-38580, deimos-esw-23679, deimos-esw-16133, deimos-esw-39823]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 5, serverOidBase: 5000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@1be02476
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@1be02476, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 266931K->22142K(2944064K), 0.0543230 secs]
[GC 278206K->31785K(2944064K), 0.0470600 secs]
[GC 287849K->50037K(2944064K), 0.0486820 secs]
[GC 306101K->73497K(2944064K), 0.0533640 secs]
[GC 329561K->83265K(2944064K), 0.0580660 secs]
[GC 339329K->106442K(2944064K), 0.0645850 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 362506K->115187K(2944064K), 0.1472320 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8950. Elapsed time: 20.387 secs. Remaining: 39.613 secs. Total: 1 mins 0 secs
[GC 371251K->145675K(2944064K), 0.0767560 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 25600. Elapsed time: 40.434 secs. Remaining: 19.566 secs. Total: 1 mins 0 secs
[GC 401739K->162122K(2944064K), 0.0730900 secs]
[GC 418186K->156623K(2944064K), 0.0703540 secs]
[GC 412686K->187239K(2944064K), 0.0809460 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 50 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 170 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,703,912 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 240151K->158445K(2944064K), 0.6255850 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,783,798 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@1be02476, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 414573K->225017K(2944192K), 0.0304120 secs]
[GC 481145K->176750K(2944192K), 0.0361090 secs]
[GC 432878K->193244K(2944192K), 0.0395760 secs]
[GC 449372K->205158K(2944192K), 0.0459670 secs]
[GC 461286K->220668K(2944192K), 0.0505720 secs]
[GC 476796K->236227K(2944192K), 0.0518210 secs]
[GC 492355K->252573K(2944192K), 0.0576240 secs]
[GC 507353K->269043K(2944192K), 0.0653120 secs]
[GC 525171K->294078K(2944192K), 0.0844140 secs]
[GC 550206K->311526K(2944192K), 0.0897890 secs]
[GC 567619K->305205K(2944192K), 0.0938540 secs]
[GC 561333K->343217K(2944192K), 0.0884750 secs]
[GC 599345K->324593K(2944192K), 0.0834950 secs]
[GC 578905K->360288K(2944192K), 0.0813340 secs]
[GC 616416K->379103K(2944192K), 0.0985940 secs]
[GC 635231K->400814K(2944192K), 0.0897330 secs]
[GC 656942K->413963K(2944192K), 0.0810120 secs]
[GC 670091K->472027K(2944192K), 0.0852990 secs]
[GC 728155K->452950K(2944192K), 0.0737920 secs]
[GC 709078K->500826K(2944192K), 0.0786960 secs]
[GC 755461K->509955K(2944192K), 0.0758730 secs]
[GC 766083K->546424K(2944192K), 0.0897930 secs]
[GC 802552K->529873K(2944192K), 0.0814540 secs]
[GC 786001K->578221K(2944192K), 0.0809840 secs]
[GC 834349K->607923K(2944192K), 0.0823470 secs]
[GC 864051K->591197K(2944192K), 0.0916740 secs]
[GC 847319K->646166K(2944192K), 0.0821790 secs]
[GC 902294K->634413K(2944192K), 0.0815530 secs]
[GC 890521K->684784K(2944192K), 0.0827650 secs]
[GC 940912K->670748K(2944192K), 0.0902990 secs]
[GC 926857K->720232K(2944192K), 0.0855990 secs]
[GC 976360K->731037K(2944192K), 0.0906410 secs]
[GC 987165K->716850K(2944192K), 0.0770480 secs]
[GC 972978K->731111K(2944192K), 0.0721340 secs]
[GC 987239K->780534K(2944192K), 0.0619640 secs]
[GC 1036662K->763223K(2944192K), 0.0775890 secs]
[GC 1019351K->777922K(2944192K), 0.0619330 secs]
[GC 1034050K->794391K(2944192K), 0.0653450 secs]
[GC 1050510K->784909K(2944192K), 0.0833230 secs]
[GC 1041037K->816590K(2944192K), 0.0653790 secs]
[GC 1072674K->835837K(2944192K), 0.0970210 secs]
[GC 1091965K->860573K(2944192K), 0.0892000 secs]
[GC 1116701K->857453K(2944192K), 0.0848230 secs]
[GC 1113565K->878371K(2944192K), 0.0790170 secs]
[GC 1134499K->913306K(2944192K), 0.0811780 secs]
[GC 1167731K->916277K(2944192K), 0.0839540 secs]
[GC 1172405K->951144K(2944192K), 0.0834640 secs]
[GC 1207272K->958841K(2944192K), 0.0846860 secs]
[GC 1214969K->988889K(2944192K), 0.0826430 secs]
[GC 1245017K->992768K(2944192K), 0.0782880 secs]
[GC 1248896K->1012225K(2944192K), 0.0842480 secs]
[GC 1268353K->1046052K(2944192K), 0.0777630 secs]
[GC 1301792K->1052623K(2944192K), 0.0770990 secs]
[GC 1308713K->1082264K(2944192K), 0.0752940 secs]
[GC 1338392K->1102384K(2944192K), 0.0770900 secs]
[GC 1357673K->1124278K(2944192K), 0.0744510 secs]
[GC 1380406K->1145150K(2944192K), 0.0811480 secs]
[GC 1401278K->1161325K(2944192K), 0.0846530 secs]
[GC 1417426K->1182800K(2944192K), 0.0798990 secs]
[GC 1438928K->1202278K(2944192K), 0.0778770 secs]
[GC 1456670K->1219975K(2944192K), 0.0820030 secs]
[GC 1476103K->1239855K(2944192K), 0.0797510 secs]
[GC 1495726K->1264080K(2944192K), 0.0899590 secs]
[GC 1520208K->1245917K(2944192K), 0.0877890 secs]
[GC 1502045K->1268340K(2944192K), 0.0820930 secs]
[GC 1524468K->1306238K(2944192K), 0.0674920 secs]
[GC 1562366K->1285847K(2944192K), 0.0858610 secs]
[GC 1541975K->1332136K(2944192K), 0.0744730 secs]
[GC 1588264K->1301853K(2944192K), 0.0677920 secs]
[GC 1557981K->1306770K(2944192K), 0.1021590 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1562898K->1337617K(2944192K), 0.0636760 secs]
[GC 1593745K->1344493K(2944192K), 0.0647130 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1600621K->1364848K(2944192K), 0.0812150 secs]
[GC 1620976K->1341936K(2944192K), 0.1227300 secs]
[GC 1598064K->1387426K(2944192K), 0.0991240 secs]
[GC 1643554K->1355968K(2944192K), 0.1115770 secs]
[GC 1612096K->1388322K(2944192K), 0.1631030 secs]
[GC 1389014K(2944192K), 0.0498160 secs]
[GC 1445094K(2944192K), 0.0430370 secs]
[GC 1379684K->1124173K(2944192K), 0.0706310 secs]
[GC 1380301K->1139087K(2944192K), 0.0648550 secs]
[GC 1395215K->1155558K(2944192K), 0.0748460 secs]
[GC 1411686K->1129809K(2944192K), 0.0719860 secs]
[GC 1385937K->1160812K(2944192K), 0.0718140 secs]
[GC 1416940K->1176718K(2944192K), 0.0697220 secs]
[GC 1432846K->1151386K(2944192K), 0.0732090 secs]
[GC 1407514K->1182314K(2944192K), 0.0708490 secs]
[GC 1438442K->1181400K(2944192K), 0.0696390 secs]
[GC 1437528K->1190212K(2944192K), 0.0745900 secs]
[GC 1446340K->1181519K(2944192K), 0.0747690 secs]
[GC 1437647K->1206595K(2944192K), 0.0710780 secs]
[GC 1462723K->1212469K(2944192K), 0.0724800 secs]
[GC 1468597K->1219718K(2944192K), 0.0719590 secs]
[GC 1475377K->1246482K(2944192K), 0.0738330 secs]
[GC 1502610K->1228046K(2944192K), 0.0822100 secs]
[GC 1484174K->1286159K(2944192K), 0.0913130 secs]
[GC 1542287K->1298973K(2944192K), 0.0921470 secs]
[GC 1555101K->1304495K(2944192K), 0.0945090 secs]
[GC 1560619K->1300010K(2944192K), 0.0826680 secs]
[GC 1556138K->1332723K(2944192K), 0.0799940 secs]
[GC 1588821K->1347198K(2944192K), 0.0794090 secs]
[GC 1603326K->1383538K(2944192K), 0.0794100 secs]
[GC 1639666K->1403919K(2944192K), 0.0874940 secs]
[GC 1660047K->1424885K(2944192K), 0.0854210 secs]
[GC 1681013K->1439479K(2944192K), 0.0827790 secs]
[GC 1695607K->1457263K(2944192K), 0.0819300 secs]
[GC 1713391K->1460997K(2944192K), 0.0812780 secs]
[GC 1717105K->1493430K(2944192K), 0.0842660 secs]
[GC 1749558K->1495743K(2944192K), 0.0817960 secs]
[GC 1751871K->1517424K(2944192K), 0.0844570 secs]
[GC 1773552K->1519425K(2944192K), 0.0849040 secs]
[GC 1775553K->1536211K(2944192K), 0.0748990 secs]
[GC 1792339K->1582509K(2944192K), 0.0608810 secs]
[GC 1838637K->1553216K(2944192K), 0.0668820 secs]
[GC 1809344K->1553652K(2944192K), 0.0819360 secs]
[GC 1809780K->1602919K(2944192K), 0.0609270 secs]
[GC 1859047K->1629832K(2944192K), 0.0874880 secs]
[GC 1885129K->1608488K(2944192K), 0.0911920 secs]
[GC 1864616K->1666985K(2944192K), 0.0843780 secs]
[GC 1923113K->1665859K(2944192K), 0.0948190 secs]
[GC 1921987K->1678232K(2944192K), 0.0830240 secs]
[GC 1934360K->1709590K(2944192K), 0.0823580 secs]
[GC 1965699K->1713242K(2944192K), 0.0864540 secs]
[GC 1969370K->1746502K(2944192K), 0.0830990 secs]
[GC 2002630K->1748869K(2944192K), 0.0833270 secs]
[GC 2003177K->1768084K(2944192K), 0.0857280 secs]
[GC 2022328K->1785253K(2944192K), 0.0865300 secs]
[GC 2040423K->1803382K(2944192K), 0.0870020 secs]
[GC 2057533K->1837441K(2944192K), 0.0846920 secs]
[GC 2093109K->1840312K(2944192K), 0.0856480 secs]
[GC 2096165K->1861339K(2944192K), 0.0850370 secs]
[GC 2116489K->1876088K(2944192K), 0.0864560 secs]
[GC 2132216K->1913913K(2944192K), 0.0844140 secs]
[GC 2170041K->1900856K(2944192K), 0.0786280 secs]
[GC 2156984K->1953383K(2944192K), 0.0698660 secs]
[GC 2209511K->1961608K(2944192K), 0.0916590 secs]
[GC 2217328K->1969123K(2944192K), 0.0894450 secs]
[GC 2225158K->2012579K(2944192K), 0.0845890 secs]
[GC 2268097K->1995733K(2944192K), 0.0981690 secs]
[GC 2251320K->2024187K(2944192K), 0.0889330 secs]
[GC 2280303K->2058236K(2944192K), 0.0878540 secs]
[GC 2313944K->2076096K(2944192K), 0.0840230 secs]
[GC 2332224K->2077105K(2944192K), 0.0855780 secs]
[GC 2333233K->2097686K(2944192K), 0.0869580 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2353814K->2114050K(2944192K), 0.0917110 secs]
[GC 2370178K->2136479K(2944192K), 0.0856370 secs]
[GC 2392600K->2169865K(2944192K), 0.0856950 secs]
[GC 2425982K->2189025K(2944192K), 0.0848860 secs]
[GC 2445153K->2226730K(2944192K), 0.0877920 secs]
[GC 2482858K->2214672K(2944192K), 0.0907600 secs]
[GC 2469868K->2253099K(2944192K), 0.0956520 secs]
[GC 2507936K->2292155K(2944192K), 0.1074650 secs]
[GC 2548229K->2279854K(2944192K), 0.1062030 secs]
[GC 2535943K->2334079K(2944192K), 0.1084170 secs]
[GC 2590207K->2319996K(2944192K), 0.1502950 secs]
[GC 2576124K->2314382K(2944192K), 0.0995460 secs]
[GC 2570510K->2364309K(2944192K), 0.0747090 secs]
[GC 2620437K->2328099K(2944192K), 0.0864160 secs]
[GC 2584227K->2357410K(2944192K), 0.1014970 secs]
[GC 2613538K->2375357K(2944192K), 0.0728940 secs]
[GC 2631485K->2395677K(2944192K), 0.0818210 secs]
[GC 2651805K->2370877K(2944192K), 0.0925130 secs]
[GC 2627005K->2404502K(2944192K), 0.0858840 secs]
[GC 2660630K->2435882K(2944192K), 0.1086700 secs]
[GC 2691055K->2447222K(2944192K), 0.1158940 secs]
[GC 2701734K->2471276K(2944192K), 0.1056830 secs]
[GC 2727378K->2456127K(2944192K), 0.1101950 secs]
[GC 2456663K(2944192K), 0.0388240 secs]
[GC 2710330K->2481199K(2944192K), 0.0971630 secs]
[GC 2613313K(2944192K), 0.0499480 secs]
[GC 2431907K->2209076K(3863808K), 0.1178170 secs]
[GC 2465178K->2229625K(3863808K), 0.1119420 secs]
[GC 2485753K->2246936K(3863808K), 0.1083150 secs]
[GC 2503064K->2266056K(3863808K), 0.1055250 secs]
[GC 2522184K->2300197K(3863808K), 0.1046340 secs]
[GC 2556325K->2284145K(3863808K), 0.1010070 secs]
[GC 2540273K->2342227K(3863808K), 0.1016090 secs]
[GC 2598347K->2318949K(3863808K), 0.1022710 secs]
[GC 2575077K->2373729K(3863808K), 0.1037200 secs]
[GC 2629695K->2357185K(3863808K), 0.1041530 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2613313K->2416546K(3863808K), 0.1050280 secs]
[GC 2672655K->2415700K(3863808K), 0.1096770 secs]
[GC 2671729K->2429098K(3863808K), 0.0985230 secs]
[GC 2685226K->2452123K(3863808K), 0.0998430 secs]
[GC 2708251K->2447391K(3863808K), 0.0936620 secs]
[GC 2703519K->2492191K(3863808K), 0.0958450 secs]
[GC 2746136K->2474580K(3863808K), 0.0931460 secs]
[GC 2727649K->2500320K(3863808K), 0.0842610 secs]
[GC 2756448K->2515887K(3863808K), 0.0840370 secs]
[GC 2771078K->2522816K(3863808K), 0.1093440 secs]
[GC 2778944K->2561829K(3863808K), 0.1022970 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 350000. Elapsed time: 20.444 secs. Remaining: 39.556 secs. Total: 1 mins 0 secs
[GC 2816494K->2583103K(3863808K), 0.1011560 secs]
[GC 2839231K->2600300K(3863808K), 0.1028460 secs]
[GC 2855393K->2585105K(3863808K), 0.0952540 secs]
[GC 2841233K->2644898K(3863808K), 0.1137610 secs]
[GC 2901012K->2643658K(3863808K), 0.1127850 secs]
[GC 2897774K->2639404K(3863808K), 0.0627630 secs]
[GC 2895532K->2671168K(3863808K), 0.0803620 secs]
[GC 2927252K->2712385K(3863808K), 0.0980290 secs]
[GC 2968513K->2699928K(3863808K), 0.0931210 secs]
[GC 2952137K->2726224K(3863808K), 0.0931500 secs]
[GC 2982352K->2762808K(3863808K), 0.0952650 secs]
[GC 3018931K->2754783K(3863808K), 0.0978220 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 584270. Elapsed time: 40.444 secs. Remaining: 19.556 secs. Total: 1 mins 0 secs
[GC 3010911K->2801024K(3863808K), 0.1039460 secs]
[GC 3057152K->2788601K(3863808K), 0.0992810 secs]
[GC 3044729K->2797618K(3863808K), 0.0760810 secs]
[GC 3052230K->2836048K(3863808K), 0.1049000 secs]
[GC 3092173K->2847283K(3863808K), 0.0939620 secs]
[GC 3103411K->2880680K(3863808K), 0.0942450 secs]
[GC 3135315K->2869459K(3863808K), 0.0938970 secs]
[GC 3124567K->2909925K(3863808K), 0.0983560 secs]
[GC 3166053K->2928261K(3863808K), 0.1038900 secs]
[GC 3183203K->2947230K(3863808K), 0.0932530 secs]
[GC 3203358K->2932838K(3863808K), 0.0941290 secs]
[GC 3188966K->2974444K(3863808K), 0.0959200 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 910000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 3230566K->2981063K(3863808K), 0.0915160 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 33 mins 17 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:8, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3237191K->3022568K(3863808K), 0.0957060 secs]
[GC 3276954K->3007602K(3863808K), 0.0956260 secs]
[GC 3263730K->3059591K(3863808K), 0.0997080 secs]
[GC 3315081K->3065588K(3863808K), 0.1057070 secs]
[GC 3321716K->3069585K(3863808K), 0.1045950 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 56 ms.
