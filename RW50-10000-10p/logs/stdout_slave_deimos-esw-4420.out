/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-4420 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-4420
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0851940 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2ca44b35
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5708, using socket ServerSocket[addr=/0.0.0.0,localport=5708], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5708
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 34870 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 50200 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 54495 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5708 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 54937 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 58013 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 58527 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 44205 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:47021
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:47021
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
[GC 259695K->10389K(2944064K), 0.0354220 secs]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 7
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-29231|5] [deimos-esw-29231, deimos-esw-877, deimos-esw-54848, deimos-esw-58796, deimos-esw-38580, deimos-esw-23679, deimos-esw-16133, deimos-esw-39823]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-39823, physical addresses are [127.0.0.1:52007]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@317fd5ad
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@317fd5ad, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 266453K->22994K(2944064K), 0.0590800 secs]
[GC 279058K->26999K(2944064K), 0.0477430 secs]
[GC 283063K->44751K(2944064K), 0.0523650 secs]
[GC 300815K->65067K(2944064K), 0.0557130 secs]
[GC 321131K->82844K(2944064K), 0.0609840 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 338908K->121149K(2944064K), 0.0652960 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9200. Elapsed time: 20.938 secs. Remaining: 39.062 secs. Total: 1 mins 0 secs
[GC 377195K->116574K(2944064K), 0.1567410 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 21100. Elapsed time: 41.232 secs. Remaining: 18.768 secs. Total: 1 mins 0 secs
[GC 372638K->145487K(2944064K), 0.0809420 secs]
[GC 401543K->160684K(2944064K), 0.0796330 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 34 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 154 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 416748K->174949K(2944064K), 0.0793990 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,734,238 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 209825K->140199K(2944064K), 0.5870510 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,802,737 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@317fd5ad, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 396327K->214692K(2944192K), 0.0344410 secs]
[GC 470820K->160474K(2944192K), 0.0398600 secs]
[GC 416602K->176432K(2944192K), 0.0453070 secs]
[GC 432560K->187120K(2944192K), 0.0514950 secs]
[GC 443248K->201911K(2944192K), 0.0556730 secs]
[GC 458039K->208208K(2944192K), 0.0602920 secs]
[GC 464336K->222443K(2944192K), 0.0618980 secs]
[GC 478208K->249768K(2944192K), 0.0678780 secs]
[GC 505896K->276054K(2944192K), 0.0883410 secs]
[GC 532182K->293502K(2944192K), 0.1537600 secs]
[GC 549603K->277870K(2944192K), 0.0960340 secs]
[GC 533998K->322392K(2944192K), 0.1072200 secs]
[GC 578520K->338408K(2944192K), 0.0923710 secs]
[GC 594491K->338010K(2944192K), 0.0934110 secs]
[GC 594138K->392129K(2944192K), 0.0993050 secs]
[GC 648257K->376801K(2944192K), 0.0971540 secs]
[GC 632929K->422824K(2944192K), 0.0882010 secs]
[GC 678952K->411289K(2944192K), 0.0882880 secs]
[GC 666424K->427080K(2944192K), 0.0843760 secs]
[GC 683208K->483793K(2944192K), 0.0870380 secs]
[GC 738840K->468114K(2944192K), 0.0871860 secs]
[GC 724242K->526964K(2944192K), 0.0869620 secs]
[GC 783092K->506482K(2944192K), 0.0831460 secs]
[GC 762610K->556314K(2944192K), 0.0933670 secs]
[GC 812414K->550075K(2944192K), 0.0896590 secs]
[GC 806203K->585893K(2944192K), 0.0908070 secs]
[GC 841989K->603086K(2944192K), 0.0900680 secs]
[GC 859214K->639086K(2944192K), 0.0916220 secs]
[GC 895214K->647056K(2944192K), 0.0959610 secs]
[GC 903184K->682213K(2944192K), 0.1009920 secs]
[GC 938341K->669106K(2944192K), 0.1006930 secs]
[GC 925234K->723100K(2944192K), 0.0983210 secs]
[GC 979228K->703934K(2944192K), 0.0900760 secs]
[GC 960062K->700418K(2944192K), 0.0890840 secs]
[GC 956546K->754428K(2944192K), 0.0677950 secs]
[GC 1010556K->738113K(2944192K), 0.0854980 secs]
[GC 994241K->755004K(2944192K), 0.0662210 secs]
[GC 1011132K->770961K(2944192K), 0.0711410 secs]
[GC 1025489K->762650K(2944192K), 0.0934790 secs]
[GC 1018778K->791907K(2944192K), 0.0758780 secs]
[GC 1047077K->822234K(2944192K), 0.1069330 secs]
[GC 1078191K->817257K(2944192K), 0.1199410 secs]
[GC 1073385K->850989K(2944192K), 0.0909390 secs]
[GC 1107117K->853152K(2944192K), 0.0875960 secs]
[GC 1109001K->869543K(2944192K), 0.0910700 secs]
[GC 1125671K->891316K(2944192K), 0.0809550 secs]
[GC 1146419K->925355K(2944192K), 0.0857440 secs]
[GC 1181483K->942644K(2944192K), 0.0879610 secs]
[GC 1197249K->947303K(2944192K), 0.0903450 secs]
[GC 1203431K->965949K(2944192K), 0.0887260 secs]
[GC 1221664K->985976K(2944192K), 0.0898680 secs]
[GC 1242104K->1036486K(2944192K), 0.1275940 secs]
[GC 1292614K->1020525K(2944192K), 0.0901120 secs]
[GC 1276231K->1079406K(2944192K), 0.0886510 secs]
[GC 1335534K->1058400K(2944192K), 0.0881450 secs]
[GC 1314528K->1105271K(2944192K), 0.0888580 secs]
[GC 1361372K->1115713K(2944192K), 0.0862450 secs]
[GC 1371841K->1156057K(2944192K), 0.0849370 secs]
[GC 1410916K->1136532K(2944192K), 0.0898950 secs]
[GC 1392660K->1194442K(2944192K), 0.0895700 secs]
[GC 1450570K->1173009K(2944192K), 0.0918790 secs]
[GC 1429137K->1232997K(2944192K), 0.0946300 secs]
[GC 1489125K->1217383K(2944192K), 0.0925270 secs]
[GC 1473511K->1266718K(2944192K), 0.0977530 secs]
[GC 1522846K->1240363K(2944192K), 0.0985430 secs]
[GC 1496491K->1282329K(2944192K), 0.0762140 secs]
[GC 1538457K->1262154K(2944192K), 0.0933670 secs]
[GC 1518282K->1295705K(2944192K), 0.0685520 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1551833K->1301317K(2944192K), 0.0742370 secs]
[GC 1557445K->1288854K(2944192K), 0.0927950 secs]
[GC 1544982K->1317253K(2944192K), 0.0710920 secs]
[GC 1573381K->1336273K(2944192K), 0.0742400 secs]
[GC 1592401K->1308729K(2944192K), 0.0880790 secs]
[GC 1564857K->1355919K(2944192K), 0.0859530 secs]
[GC 1612047K->1323351K(2944192K), 0.1639550 secs]
[GC 1579479K->1370140K(2944192K), 0.0852730 secs]
[GC 1626268K->1339319K(2944192K), 0.0844030 secs]
[GC 1595447K->1371908K(2944192K), 0.0848940 secs]
[GC 1628036K->1372123K(2944192K), 0.0824000 secs]
[GC 1628251K->1397322K(2944192K), 0.0879480 secs]
[GC 1398270K(2944192K), 0.0417210 secs]
[GC 1455876K(2944192K), 0.0458270 secs]
[GC 1410711K->1129720K(2944192K), 0.0779280 secs]
[GC 1385848K->1161516K(2944192K), 0.0660400 secs]
[GC 1417644K->1171088K(2944192K), 0.0767780 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1427216K->1158390K(2944192K), 0.0754610 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1414518K->1179560K(2944192K), 0.0756860 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1435688K->1195603K(2944192K), 0.0795790 secs]
[GC 1451731K->1170850K(2944192K), 0.0758620 secs]
[GC 1426978K->1216207K(2944192K), 0.0758610 secs]
[GC 1472335K->1182677K(2944192K), 0.0732650 secs]
[GC 1438805K->1230301K(2944192K), 0.0781450 secs]
[GC 1486429K->1197134K(2944192K), 0.0739900 secs]
[GC 1453262K->1245506K(2944192K), 0.0762360 secs]
[GC 1501634K->1221986K(2944192K), 0.0794540 secs]
[GC 1478114K->1271925K(2944192K), 0.0909160 secs]
[GC 1527996K->1270571K(2944192K), 0.1038080 secs]
[GC 1526685K->1310732K(2944192K), 0.0944060 secs]
[GC 1566860K->1315680K(2944192K), 0.1059450 secs]
[GC 1571808K->1324542K(2944192K), 0.0875750 secs]
[GC 1580628K->1341775K(2944192K), 0.0858270 secs]
[GC 1597903K->1374402K(2944192K), 0.0883780 secs]
[GC 1630530K->1390279K(2944192K), 0.0877720 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1646407K->1407839K(2944192K), 0.0869760 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1663967K->1443643K(2944192K), 0.0914450 secs]
[GC 1698395K->1433791K(2944192K), 0.0892150 secs]
[GC 1689904K->1466978K(2944192K), 0.0862040 secs]
[GC 1723013K->1483208K(2944192K), 0.0880080 secs]
[GC 1739310K->1501630K(2944192K), 0.0874140 secs]
[GC 1757758K->1520446K(2944192K), 0.0909900 secs]
[GC 1776574K->1538686K(2944192K), 0.0872430 secs]
[GC 1794814K->1526818K(2944192K), 0.0841040 secs]
[GC 1782946K->1583829K(2944192K), 0.0697570 secs]
[GC 1839957K->1562417K(2944192K), 0.0815400 secs]
[GC 1818545K->1583700K(2944192K), 0.0655060 secs]
[GC 1839828K->1599731K(2944192K), 0.0679050 secs]
[GC 1855030K->1585359K(2944192K), 0.0917070 secs]
[GC 1841455K->1638595K(2944192K), 0.0851360 secs]
[GC 1894723K->1627088K(2944192K), 0.0850560 secs]
[GC 1881826K->1663673K(2944192K), 0.1001660 secs]
[GC 1918520K->1663283K(2944192K), 0.0871820 secs]
[GC 1919411K->1699070K(2944192K), 0.0833410 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1955198K->1714426K(2944192K), 0.0868010 secs]
[GC 1970554K->1737714K(2944192K), 0.0885890 secs]
[GC 1991918K->1759370K(2944192K), 0.0922830 secs]
[GC 2015498K->1777325K(2944192K), 0.0891920 secs]
[GC 2033453K->1793302K(2944192K), 0.0874130 secs]
[GC 2049430K->1808667K(2944192K), 0.0894820 secs]
[GC 2064737K->1830708K(2944192K), 0.0863450 secs]
[GC 2086836K->1846676K(2944192K), 0.0931550 secs]
[GC 2102804K->1868341K(2944192K), 0.0849180 secs]
[GC 2124469K->1884176K(2944192K), 0.0897830 secs]
[GC 2140287K->1903571K(2944192K), 0.0852740 secs]
[GC 2159699K->1888547K(2944192K), 0.0834420 secs]
[GC 2144675K->1947935K(2944192K), 0.0711950 secs]
[GC 2204063K->1930296K(2944192K), 0.0928410 secs]
[GC 2184679K->1967036K(2944192K), 0.0970420 secs]
[GC 2221148K->1991157K(2944192K), 0.0990100 secs]
[GC 2247240K->1982496K(2944192K), 0.0896690 secs]
[GC 2238581K->2031341K(2944192K), 0.0845100 secs]
[GC 2287469K->2047777K(2944192K), 0.0838560 secs]
[GC 2303603K->2049947K(2944192K), 0.0906750 secs]
[GC 2305154K->2086916K(2944192K), 0.0903230 secs]
[GC 2343044K->2101695K(2944192K), 0.0881120 secs]
[GC 2357823K->2123999K(2944192K), 0.0890650 secs]
[GC 2380127K->2140813K(2944192K), 0.0877470 secs]
[GC 2396941K->2164387K(2944192K), 0.0881930 secs]
[GC 2420515K->2183477K(2944192K), 0.0933390 secs]
[GC 2439605K->2200038K(2944192K), 0.0933890 secs]
[GC 2456166K->2223530K(2944192K), 0.0948470 secs]
[GC 2479658K->2241974K(2944192K), 0.0958530 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2498088K->2264287K(2944192K), 0.0971450 secs]
[GC 2520415K->2302939K(2944192K), 0.1039140 secs]
[GC 2559008K->2289853K(2944192K), 0.1078940 secs]
[GC 2545981K->2320194K(2944192K), 0.0984910 secs]
[GC 2576322K->2312167K(2944192K), 0.0903810 secs]
[GC 2568295K->2350106K(2944192K), 0.0704740 secs]
[GC 2606234K->2334042K(2944192K), 0.0873780 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2590170K->2363820K(2944192K), 0.0652690 secs]
[GC 2619948K->2383004K(2944192K), 0.0700400 secs]
[GC 2639132K->2368225K(2944192K), 0.0875280 secs]
[GC 2624353K->2393055K(2944192K), 0.0701290 secs]
[GC 2648637K->2409337K(2944192K), 0.0681340 secs]
[GC 2665465K->2401548K(2944192K), 0.0893620 secs]
[GC 2657676K->2446643K(2944192K), 0.1054360 secs]
[GC 2701998K->2456042K(2944192K), 0.1028110 secs]
[GC 2712170K->2465589K(2944192K), 0.1013770 secs]
[GC 2466031K(2944192K), 0.0253000 secs]
[GC 2721700K->2458653K(2944192K), 0.0855480 secs]
[GC 2586738K(2944192K), 0.0564010 secs]
[GC 2410980K->2202018K(3855340K), 0.0989090 secs]
[GC 2458141K->2222807K(3855340K), 0.1009640 secs]
[GC 2478935K->2242738K(3855340K), 0.0959890 secs]
[GC 2498866K->2260578K(3855340K), 0.0942980 secs]
[GC 2516706K->2277547K(3855340K), 0.0934630 secs]
[GC 2533136K->2278146K(3855340K), 0.0910290 secs]
[GC 2534218K->2296749K(3855340K), 0.0859050 secs]
[GC 2552851K->2345964K(3855340K), 0.0881070 secs]
[GC 2602092K->2331269K(3855340K), 0.0841180 secs]
[GC 2586354K->2392766K(3855340K), 0.0885980 secs]
[GC 2647343K->2367785K(3855340K), 0.0891750 secs]
[GC 2623913K->2428740K(3855340K), 0.0915820 secs]
[GC 2684868K->2410760K(3855340K), 0.0880390 secs]
[GC 2666780K->2469344K(3855340K), 0.0897870 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2721914K->2463797K(3855340K), 0.0893400 secs]
[GC 2719925K->2496377K(3855340K), 0.0912560 secs]
[GC 2752104K->2503984K(3855340K), 0.0877300 secs]
[GC 2760112K->2507602K(3855340K), 0.0890010 secs]
[GC 2763721K->2534448K(3855340K), 0.0857350 secs]
[GC 2790576K->2563488K(3855340K), 0.0845850 secs]
[GC 2819614K->2566834K(3855340K), 0.0845460 secs]
[GC 2822962K->2621949K(3855340K), 0.0858370 secs]
[GC 2878043K->2596868K(3855340K), 0.0830620 secs]
[GC 2852996K->2650528K(3855340K), 0.0879710 secs]
[GC 2906411K->2640511K(3855340K), 0.0860410 secs]
[GC 2896639K->2683284K(3855340K), 0.1065410 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 289924. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 2939412K->2665739K(3855340K), 0.0934030 secs]
[GC 2921867K->2707705K(3855340K), 0.0654580 secs]
[GC 2963784K->2710783K(3855340K), 0.0825640 secs]
[GC 2966911K->2730223K(3855340K), 0.0854750 secs]
[GC 2986351K->2756319K(3855340K), 0.0819630 secs]
[GC 3012447K->2750660K(3855340K), 0.0831090 secs]
[GC 3006751K->2789292K(3855340K), 0.0856250 secs]
[GC 3045420K->2820058K(3855340K), 0.0810320 secs]
[GC 3076186K->2809529K(3855340K), 0.0818690 secs]
[GC 3064858K->2845812K(3855340K), 0.0863840 secs]
[GC 3098310K->2851236K(3855340K), 0.0828780 secs]
[GC 3107364K->2874995K(3855340K), 0.0819480 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 570000. Elapsed time: 40.002 secs. Remaining: 19.998 secs. Total: 1 mins 0 secs
[GC 3131123K->2903739K(3855340K), 0.0847750 secs]
[GC 3158523K->2897786K(3855340K), 0.0899570 secs]
[GC 3153914K->2925963K(3855340K), 0.0824810 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3181781K->2943722K(3855340K), 0.0954780 secs]
[GC 3199850K->2947854K(3855340K), 0.0856880 secs]
[GC 3202443K->2980125K(3855340K), 0.0860060 secs]
[GC 3236253K->2988668K(3855340K), 0.0815280 secs]
[GC 3244796K->3008154K(3855340K), 0.0772500 secs]
[GC 3264282K->3014439K(3855340K), 0.0801320 secs]
[GC 3270567K->3025083K(3855340K), 0.0784250 secs]
[GC 3281211K->3043762K(3855340K), 0.0626560 secs]
[GC 3298821K->3066799K(3855340K), 0.0788330 secs]
[GC 3322810K->3101591K(3855340K), 0.0850650 secs]
[GC 3357719K->3097645K(3855340K), 0.0838710 secs]
[GC 3353773K->3170382K(3855340K), 0.0696410 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 975309. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 33 mins 29 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:8, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5708 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 64 ms.
