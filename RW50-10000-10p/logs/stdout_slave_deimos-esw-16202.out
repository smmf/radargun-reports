/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-16202 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-16202
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0668420 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 3. Sleeping for 6500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 3
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@3bbce0d6
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=3, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5704, using socket ServerSocket[addr=/0.0.0.0,localport=5704], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5704
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 44824 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 50727 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 59417 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5704 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704 this
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:60202
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:50862
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:50976
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:60202
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:50862
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:52845
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:50976
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:52845
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:51661
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:51661
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:42154
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:42154
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 46710 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 49046 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 55245 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:33764
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:33764
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 53636 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 is accepting socket connection from /127.0.0.1:42065
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:42065
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=3, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 3
[GC 259695K->11964K(2944064K), 0.0397040 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|1] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-64881, physical addresses are [127.0.0.1:52002]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|2] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|3] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077]
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|4] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|5] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207]
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|6] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403]
 INFO  [Incoming-4,deimos-esw-64881] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|7] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403, deimos-esw-20931, deimos-esw-27783]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 3: org.radargun.cachewrappers.FFWrapper@6c4ac28a
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6c4ac28a, nodeIndex=3, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268028K->22360K(2944064K), 0.0620660 secs]
[GC 278412K->30891K(2944064K), 0.0451380 secs]
[GC 286955K->49173K(2944064K), 0.0507860 secs]
[GC 305237K->62479K(2944064K), 0.0532790 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 318543K->77650K(2944064K), 0.0570980 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9600. Elapsed time: 20.070 secs. Remaining: 39.930 secs. Total: 1 mins 0 secs
[GC 333714K->84355K(2944064K), 0.0684570 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 18750. Elapsed time: 40.071 secs. Remaining: 19.929 secs. Total: 1 mins 0 secs
[GC 340419K->127689K(2944064K), 0.1178840 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 26600. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 39 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 159 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 383753K->148669K(2944064K), 0.0762980 secs]
[GC 404733K->161938K(2944064K), 0.0893670 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,649,175 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 294888K->129403K(2944064K), 0.6354870 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,881 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6c4ac28a, nodeIndex=3, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 385531K->202010K(2944192K), 0.0327930 secs]
[GC 458138K->149001K(2944192K), 0.0356620 secs]
[GC 405129K->162159K(2944192K), 0.0371690 secs]
[GC 418287K->170819K(2944192K), 0.0429320 secs]
[GC 426947K->184340K(2944192K), 0.0480710 secs]
[GC 440468K->181200K(2944192K), 0.0507650 secs]
[GC 437328K->213095K(2944192K), 0.0556390 secs]
[GC 469223K->215904K(2944192K), 0.0583850 secs]
[GC 472032K->228577K(2944192K), 0.0590700 secs]
[GC 484705K->248787K(2944192K), 0.0739330 secs]
[GC 504915K->226157K(2944192K), 0.1342270 secs]
[GC 482285K->257490K(2944192K), 0.1009590 secs]
[GC 513618K->257196K(2944192K), 0.0729400 secs]
[GC 513324K->283265K(2944192K), 0.1173430 secs]
[GC 539393K->268176K(2944192K), 0.0787300 secs]
[GC 523740K->314747K(2944192K), 0.1502120 secs]
[GC 568822K->332758K(2944192K), 0.1018960 secs]
[GC 588886K->349986K(2944192K), 0.1193950 secs]
[GC 606114K->336503K(2944192K), 0.1103750 secs]
[GC 590824K->382356K(2944192K), 0.0860140 secs]
[GC 638484K->418243K(2944192K), 0.0841130 secs]
[GC 674318K->400756K(2944192K), 0.0773280 secs]
[GC 656884K->441020K(2944192K), 0.0826150 secs]
[GC 697148K->457656K(2944192K), 0.0814180 secs]
[GC 713775K->472370K(2944192K), 0.0804000 secs]
[GC 726493K->493962K(2944192K), 0.0958870 secs]
[GC 750090K->508885K(2944192K), 0.0869290 secs]
[GC 765006K->530588K(2944192K), 0.0903730 secs]
[GC 786716K->566089K(2944192K), 0.0929110 secs]
[GC 822194K->553064K(2944192K), 0.0912890 secs]
[GC 809192K->607766K(2944192K), 0.0888160 secs]
[GC 863843K->588037K(2944192K), 0.0902880 secs]
[GC 844019K->645711K(2944192K), 0.0909360 secs]
[GC 901839K->635981K(2944192K), 0.0982100 secs]
[GC 892109K->660230K(2944192K), 0.0948280 secs]
[GC 916358K->665125K(2944192K), 0.0916540 secs]
[GC 921253K->705355K(2944192K), 0.0774010 secs]
[GC 960862K->721515K(2944192K), 0.1063750 secs]
[GC 977643K->723521K(2944192K), 0.0908940 secs]
[GC 979649K->745052K(2944192K), 0.0992350 secs]
[GC 1001180K->760298K(2944192K), 0.0828640 secs]
[GC 1016425K->796340K(2944192K), 0.0850510 secs]
[GC 1052468K->811949K(2944192K), 0.0842010 secs]
[GC 1068077K->817450K(2944192K), 0.0866540 secs]
[GC 1073546K->849276K(2944192K), 0.0822330 secs]
[GC 1104089K->866478K(2944192K), 0.0904110 secs]
[GC 1122606K->887809K(2944192K), 0.0879110 secs]
[GC 1143937K->908420K(2944192K), 0.0837650 secs]
[GC 1163756K->909019K(2944192K), 0.0862790 secs]
[GC 1165147K->929595K(2944192K), 0.0886730 secs]
[GC 1185649K->963614K(2944192K), 0.0886590 secs]
[GC 1219742K->980352K(2944192K), 0.0866730 secs]
[GC 1236435K->1017407K(2944192K), 0.0899940 secs]
[GC 1273535K->1000353K(2944192K), 0.0833390 secs]
[GC 1256481K->1031569K(2944192K), 0.0835390 secs]
[GC 1287683K->1038951K(2944192K), 0.0854600 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5704 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1294455K->1073785K(2944192K), 0.0848350 secs]
[GC 1329913K->1060997K(2944192K), 0.0827290 secs]
[GC 1317125K->1097747K(2944192K), 0.0630400 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5704 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1353875K->1076844K(2944192K), 0.0850980 secs]
[GC 1332972K->1122324K(2944192K), 0.0814750 secs]
[GC 1378452K->1083661K(2944192K), 0.0840330 secs]
[GC 1339789K->1094560K(2944192K), 0.1012110 secs]
[GC 1350688K->1139425K(2944192K), 0.1181390 secs]
[GC 1395553K->1111645K(2944192K), 0.1334700 secs]
[GC 1367773K->1147132K(2944192K), 0.1219830 secs]
[GC 1403260K->1146055K(2944192K), 0.1463950 secs]
[GC 1402183K->1137158K(2944192K), 0.1058060 secs]
[GC 1393286K->1143236K(2944192K), 0.1272910 secs]
[GC 1399364K->1173715K(2944192K), 0.1277900 secs]
[GC 1429843K->1162387K(2944192K), 0.1634950 secs]
[GC 1418515K->1198172K(2944192K), 0.1566900 secs]
[GC 1454300K->1171951K(2944192K), 0.0811430 secs]
[GC 1428079K->1215529K(2944192K), 0.1061690 secs]
[GC 1471657K->1181528K(2944192K), 0.0787430 secs]
[GC 1437656K->1230434K(2944192K), 0.1505510 secs]
[GC 1486562K->1196914K(2944192K), 0.1042530 secs]
[GC 1453042K->1231705K(2944192K), 0.0817610 secs]
[GC 1487833K->1247426K(2944192K), 0.1128000 secs]
[GC 1503554K->1222663K(2944192K), 0.0966270 secs]
[GC 1478791K->1271156K(2944192K), 0.0782290 secs]
[GC 1527284K->1235797K(2944192K), 0.1548630 secs]
[GC 1491925K->1247012K(2944192K), 0.0893320 secs]
[GC 1503140K->1270014K(2944192K), 0.0983800 secs]
[GC 1526142K->1300618K(2944192K), 0.1389950 secs]
[GC 1556746K->1274488K(2944192K), 0.1815130 secs]
[GC 1530616K->1300212K(2944192K), 0.0852490 secs]
[GC 1556340K->1300892K(2944192K), 0.1186780 secs]
[GC 1557020K->1309632K(2944192K), 0.0844310 secs]
[GC 1565760K->1316496K(2944192K), 0.0865140 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5704 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1572624K->1308912K(2944192K), 0.0869380 secs]
[GC 1565040K->1331943K(2944192K), 0.0855210 secs]
[GC 1588071K->1341083K(2944192K), 0.0868100 secs]
[GC 1597211K->1331210K(2944192K), 0.0986950 secs]
[GC 1587338K->1376981K(2944192K), 0.0793660 secs]
[GC 1633109K->1343940K(2944192K), 0.0877020 secs]
[GC 1600068K->1392654K(2944192K), 0.0885050 secs]
[GC 1648782K->1358456K(2944192K), 0.1042430 secs]
[GC 1614584K->1390561K(2944192K), 0.0847880 secs]
[GC 1391171K(2944192K), 0.0551110 secs]
[GC 1449937K(2944192K), 0.0488550 secs]
[GC 1410139K->1168039K(2944192K), 0.0815030 secs]
[GC 1424167K->1141590K(2944192K), 0.0829010 secs]
[GC 1397718K->1183333K(2944192K), 0.0836060 secs]
[GC 1439461K->1152175K(2944192K), 0.0791150 secs]
[GC 1408303K->1196599K(2944192K), 0.0815290 secs]
[GC 1452727K->1166494K(2944192K), 0.0742290 secs]
[GC 1422622K->1188725K(2944192K), 0.0889550 secs]
[GC 1444853K->1220681K(2944192K), 0.0769270 secs]
[GC 1476809K->1192772K(2944192K), 0.0884550 secs]
[GC 1448900K->1224293K(2944192K), 0.0751290 secs]
[GC 1480421K->1206494K(2944192K), 0.0859890 secs]
[GC 1462622K->1209781K(2944192K), 0.0782490 secs]
[GC 1465909K->1255511K(2944192K), 0.0727340 secs]
[GC 1511639K->1226245K(2944192K), 0.0829190 secs]
[GC 1482373K->1257648K(2944192K), 0.0763730 secs]
[GC 1513776K->1273734K(2944192K), 0.0847210 secs]
[GC 1529862K->1248978K(2944192K), 0.0850520 secs]
[GC 1505106K->1317527K(2944192K), 0.1028590 secs]
[GC 1573655K->1307494K(2944192K), 0.0927100 secs]
[GC 1562147K->1313875K(2944192K), 0.1110310 secs]
[GC 1568101K->1341191K(2944192K), 0.0907370 secs]
[GC 1597279K->1358047K(2944192K), 0.0890170 secs]
[GC 1614138K->1408849K(2944192K), 0.0889880 secs]
[GC 1664977K->1393459K(2944192K), 0.0911190 secs]
[GC 1647478K->1449769K(2944192K), 0.0938260 secs]
[GC 1705896K->1428237K(2944192K), 0.0921080 secs]
[GC 1684343K->1486986K(2944192K), 0.0878920 secs]
[GC 1743114K->1463131K(2944192K), 0.0902740 secs]
[GC 1719259K->1523243K(2944192K), 0.0919100 secs]
[GC 1779345K->1501451K(2944192K), 0.0898380 secs]
[GC 1757579K->1561734K(2944192K), 0.0897330 secs]
[GC 1817862K->1539735K(2944192K), 0.0898440 secs]
[GC 1795863K->1569222K(2944192K), 0.0759010 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1824446K->1607776K(2944192K), 0.1019130 secs]
[GC 1863904K->1619704K(2944192K), 0.1019380 secs]
[GC 1875832K->1644763K(2944192K), 0.1083840 secs]
[GC 1900891K->1683931K(2944192K), 0.1019880 secs]
[GC 1939205K->1691719K(2944192K), 0.1101200 secs]
[GC 1947739K->1749014K(2944192K), 0.0987270 secs]
[GC 2005142K->1720000K(2944192K), 0.0678990 secs]
[GC 1976128K->1747605K(2944192K), 0.0738470 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 350000. Elapsed time: 20.235 secs. Remaining: 39.765 secs. Total: 1 mins 0 secs
[GC 2003733K->1773918K(2944192K), 0.0798270 secs]
[GC 2030020K->1822819K(2944192K), 0.0935820 secs]
[GC 2076181K->1854308K(2944192K), 0.0902480 secs]
[GC 2109579K->1877148K(2944192K), 0.0925720 secs]
[GC 2133276K->1906934K(2944192K), 0.0985830 secs]
[GC 2163062K->1917490K(2944192K), 0.0781350 secs]
[GC 2173618K->1927740K(2944192K), 0.0821900 secs]
[GC 2183301K->1944289K(2944192K), 0.0893560 secs]
[GC 2197075K->1971189K(2944192K), 0.0900030 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 460000. Elapsed time: 40.289 secs. Remaining: 19.711 secs. Total: 1 mins 0 secs
[GC 2226288K->1996859K(2944192K), 0.0818430 secs]
[GC 2252987K->2001204K(2944192K), 0.0799380 secs]
[GC 2255446K->2049223K(2944192K), 0.0949720 secs]
[GC 2303573K->2112567K(2944192K), 0.1148330 secs]
[GC 2368371K->2080783K(2944192K), 0.0710620 secs]
[GC 2336911K->2146504K(2944192K), 0.0866440 secs]
[GC 2402632K->2112829K(2944192K), 0.0907520 secs]
[GC 2368918K->2141759K(2944192K), 0.0822530 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 970000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 42 mins 46 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:3, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2397886K->2130717K(2944192K), 0.0903950 secs]
[GC 2386845K->2121666K(2944192K), 0.0523260 secs]
[GC 2377684K->2138324K(2944192K), 0.0689970 secs]
[GC 2394452K->2176209K(2944192K), 0.0804550 secs]
[GC 2432337K->2225759K(2944192K), 0.1087640 secs]
[GC 2481863K->2243057K(2944192K), 0.1221070 secs]
[GC 2499185K->2225005K(2944192K), 0.0975310 secs]
[GC 2481133K->2298500K(2944192K), 0.1054870 secs]
[GC 2554626K->2284087K(2944192K), 0.1000160 secs]
[GC 2540215K->2338740K(2944192K), 0.0971320 secs]
[GC 2593419K->2322881K(2944192K), 0.0965750 secs]
[GC 2579009K->2379475K(2944192K), 0.0994710 secs]
[GC 2635031K->2363375K(2944192K), 0.1058450 secs]
[GC 2619503K->2419950K(2944192K), 0.0980730 secs]
[GC 2676078K->2429032K(2944192K), 0.1034030 secs]
[GC 2685114K->2460679K(2944192K), 0.1008820 secs]
[GC 2716807K->2446685K(2944192K), 0.0943650 secs]
[GC 2702813K->2502185K(2944192K), 0.0958400 secs]
[GC 2502258K(2944192K), 0.0440060 secs]
[GC 2533873K(2944192K), 0.0346190 secs]
[GC 2233475K->1960959K(3466332K), 0.1141020 secs]
[GC 2217087K->2025452K(3466332K), 0.1151510 secs]
[GC 2281580K->2004090K(3466332K), 0.1119230 secs]
[GC 2260215K->2064310K(3466332K), 0.1048080 secs]
[GC 2320438K->2086253K(3466332K), 0.1116700 secs]
[GC 2342381K->2108069K(3466332K), 0.1137580 secs]
[GC 2363086K->2120472K(3466332K), 0.1160470 secs]
[GC 2376600K->2148386K(3466332K), 0.1112130 secs]
[GC 2404497K->2148643K(3466332K), 0.1169070 secs]
[GC 2404771K->2197633K(3466332K), 0.1147010 secs]
[GC 2452084K->2196982K(3466332K), 0.1185670 secs]
[GC 2453110K->2215934K(3466332K), 0.1123200 secs]
[GC 2470579K->2238737K(3466332K), 0.1097400 secs]
[GC 2494865K->2256555K(3466332K), 0.1094240 secs]
[GC 2512683K->2275805K(3466332K), 0.1026480 secs]
[GC 2531933K->2277002K(3466332K), 0.1041290 secs]
[GC 2533130K->2295227K(3466332K), 0.1149200 secs]
[GC 2551355K->2349503K(3466332K), 0.0879500 secs]
[GC 2605596K->2370931K(3466332K), 0.1194470 secs]
[GC 2627059K->2376486K(3466332K), 0.1159030 secs]
[GC 2632103K->2395726K(3466332K), 0.1102560 secs]
[GC 2651854K->2415196K(3466332K), 0.1018460 secs]
[GC 2669570K->2433626K(3466332K), 0.1039390 secs]
[GC 2689754K->2488051K(3466332K), 0.1036330 secs]
[GC 2743617K->2476438K(3466332K), 0.1081230 secs]
[GC 2732566K->2513153K(3466332K), 0.1094240 secs]
[GC 2767831K->2517276K(3466332K), 0.1044800 secs]
[GC 2773362K->2553629K(3466332K), 0.1009870 secs]
[GC 2809757K->2575934K(3466332K), 0.1062750 secs]
[GC 2832017K->2593720K(3466332K), 0.1098590 secs]
[GC 2849848K->2614086K(3466332K), 0.1113290 secs]
[GC 2870214K->2653642K(3466332K), 0.1049070 secs]
[GC 2907835K->2641363K(3466332K), 0.1226700 secs]
[GC 2897491K->2703966K(3466332K), 0.1088260 secs]
[GC 2958496K->2681376K(3466332K), 0.1094550 secs]
[GC 2937504K->2741354K(3466332K), 0.0991550 secs]
[GC 2997482K->2723701K(3466332K), 0.0998770 secs]
[GC 2979787K->2773540K(3466332K), 0.1104000 secs]
[GC 3029668K->2802601K(3466332K), 0.1092080 secs]
[GC 3058729K->2788269K(3466332K), 0.1021040 secs]
[GC 3044397K->2843366K(3466332K), 0.1036290 secs]
[GC 3097980K->2827004K(3466332K), 0.1113460 secs]
[GC 3083132K->2875639K(3466332K), 0.1023610 secs]
[GC 3131767K->2904844K(3466332K), 0.0979250 secs]
[GC 3160970K->2888798K(3466332K), 0.1045770 secs]
[GC 3144926K->2945576K(3466332K), 0.1006650 secs]
[GC 3201704K->2930594K(3466332K), 0.0979920 secs]
[GC 2931123K(3466332K), 0.0336310 secs]
[GC 2968625K(3466332K), 0.0366560 secs]
[GC 2943029K->2695404K(4650880K), 0.1154940 secs]
[GC 2951532K->2736222K(4650880K), 0.0939040 secs]
[GC 2992350K->2759767K(4650880K), 0.1312110 secs]
[GC 3014467K->2772310K(4650880K), 0.1379210 secs]
[GC 3028438K->2805146K(4650880K), 0.1070820 secs]
[GC 3061274K->2828957K(4650880K), 0.1169510 secs]
[GC 3085085K->2827365K(4650880K), 0.1131720 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5704 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3083493K->2881374K(4650880K), 0.1133900 secs]
[GC 3137235K->2866641K(4650880K), 0.1194360 secs]
[GC 3122769K->2912413K(4650880K), 0.1149880 secs]
[GC 3168541K->2942853K(4650880K), 0.1141820 secs]
[GC 3198958K->2928620K(4650880K), 0.1075750 secs]
[GC 3184748K->2983052K(4650880K), 0.1092270 secs]
[GC 3238635K->2966927K(4650880K), 0.1114620 secs]
[GC 3223055K->3024038K(4650880K), 0.1139610 secs]
[GC 3278913K->3007719K(4650880K), 0.1124250 secs]
[GC 3263847K->3054028K(4650880K), 0.1159260 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5704 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 61 ms.
