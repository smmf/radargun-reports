/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-19456 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-19456
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0662090 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@6b4f7392
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5708, using socket ServerSocket[addr=/0.0.0.0,localport=5708], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5708
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 47606 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 37822 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 59886 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5708 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708 this
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:36539
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:41257
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:48142
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:41257
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:36539
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:48142
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:37403
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:37403
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:46710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:46710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 33764 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 34539 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:38264
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:38264
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 53221 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 56679 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:37522
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:37522
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:45390
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:45390
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 6
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 7
[GC 259695K->12221K(2944064K), 0.0417410 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|4] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-40246, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-40246] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|5] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-40246] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|6] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403]
 INFO  [Incoming-3,deimos-esw-40246] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-1852|7] [deimos-esw-1852, deimos-esw-43043, deimos-esw-64881, deimos-esw-44454, deimos-esw-42077, deimos-esw-40246, deimos-esw-53272, deimos-esw-29961, deimos-esw-58207, deimos-esw-12403, deimos-esw-20931, deimos-esw-27783]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 6, serverOidBase: 6000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@5c35d5da
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@5c35d5da, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268285K->22862K(2944064K), 0.0573220 secs]
[GC 278926K->32244K(2944064K), 0.0466680 secs]
[GC 288308K->46158K(2944064K), 0.0479000 secs]
[GC 302222K->65669K(2944064K), 0.0549300 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 321733K->68616K(2944064K), 0.0607100 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6650. Elapsed time: 20.452 secs. Remaining: 39.548 secs. Total: 1 mins 0 secs
[GC 324680K->98158K(2944064K), 0.0652790 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16150. Elapsed time: 40.592 secs. Remaining: 19.408 secs. Total: 1 mins 0 secs
[GC 354222K->116058K(2944064K), 0.1194600 secs]
[GC 372122K->131041K(2944064K), 0.0868310 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 52 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 172 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 387105K->137617K(2944064K), 0.0681970 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,667,609 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 276454K->128569K(2944064K), 0.6325180 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,814,795 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@5c35d5da, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 384697K->198963K(2944192K), 0.0340280 secs]
[GC 455091K->147635K(2944192K), 0.0360680 secs]
[GC 403763K->161087K(2944192K), 0.0406800 secs]
[GC 417215K->170636K(2944192K), 0.0424870 secs]
[GC 426764K->183907K(2944192K), 0.0499060 secs]
[GC 440035K->198388K(2944192K), 0.0507930 secs]
[GC 454516K->213576K(2944192K), 0.0544080 secs]
[GC 469704K->216132K(2944192K), 0.0656360 secs]
[GC 472260K->229479K(2944192K), 0.0678620 secs]
[GC 485607K->233915K(2944192K), 0.0902180 secs]
[GC 490043K->244007K(2944192K), 0.1640400 secs]
[GC 500135K->269793K(2944192K), 0.1316470 secs]
[GC 525921K->243659K(2944192K), 0.1138860 secs]
[GC 499787K->290367K(2944192K), 0.1604990 secs]
[GC 546495K->266245K(2944192K), 0.1636440 secs]
[GC 522373K->321085K(2944192K), 0.1423580 secs]
[GC 577173K->338907K(2944192K), 0.1055560 secs]
[GC 595035K->343649K(2944192K), 0.1218130 secs]
[GC 599777K->357418K(2944192K), 0.0896740 secs]
[GC 612654K->372081K(2944192K), 0.0920180 secs]
[GC 628209K->389988K(2944192K), 0.0859560 secs]
[GC 646087K->408129K(2944192K), 0.0852890 secs]
[GC 664257K->442556K(2944192K), 0.0878390 secs]
[GC 698684K->447488K(2944192K), 0.0894540 secs]
[GC 703560K->465375K(2944192K), 0.0913230 secs]
[GC 721503K->481404K(2944192K), 0.0884170 secs]
[GC 737532K->503222K(2944192K), 0.0880290 secs]
[GC 758211K->535590K(2944192K), 0.0807000 secs]
[GC 791718K->556097K(2944192K), 0.0854240 secs]
[GC 810369K->575816K(2944192K), 0.0952650 secs]
[GC 831944K->611458K(2944192K), 0.0909050 secs]
[GC 867562K->617526K(2944192K), 0.0839560 secs]
[GC 871952K->650846K(2944192K), 0.0936970 secs]
[GC 906974K->648993K(2944192K), 0.1001170 secs]
[GC 905121K->635796K(2944192K), 0.0848510 secs]
[GC 891917K->694730K(2944192K), 0.0751500 secs]
[GC 950858K->717371K(2944192K), 0.0955290 secs]
[GC 973499K->736170K(2944192K), 0.0970960 secs]
[GC 992298K->754392K(2944192K), 0.1016190 secs]
[GC 1010136K->750667K(2944192K), 0.0851040 secs]
[GC 1006795K->784320K(2944192K), 0.0817570 secs]
[GC 1040448K->786989K(2944192K), 0.0866370 secs]
[GC 1042837K->841145K(2944192K), 0.0864050 secs]
[GC 1097273K->836144K(2944192K), 0.0794160 secs]
[GC 1092272K->868175K(2944192K), 0.0787710 secs]
[GC 1123985K->856049K(2944192K), 0.0821810 secs]
[GC 1112177K->902712K(2944192K), 0.0813550 secs]
[GC 1158840K->935040K(2944192K), 0.0822120 secs]
[GC 1191072K->916691K(2944192K), 0.0862610 secs]
[GC 1172819K->976669K(2944192K), 0.0963750 secs]
[GC 1232797K->956568K(2944192K), 0.0841440 secs]
[GC 1212696K->996685K(2944192K), 0.0820780 secs]
[GC 1252813K->1027490K(2944192K), 0.0844840 secs]
[GC 1283587K->1010039K(2944192K), 0.0772050 secs]
[GC 1266167K->1069041K(2944192K), 0.0777060 secs]
[GC 1325169K->1048093K(2944192K), 0.0758840 secs]
[GC 1304221K->1092573K(2944192K), 0.0740670 secs]
[GC 1348701K->1083018K(2944192K), 0.0707620 secs]
[GC 1339146K->1099069K(2944192K), 0.0508280 secs]
[GC 1355197K->1114116K(2944192K), 0.0574200 secs]
[GC 1370244K->1101676K(2944192K), 0.0788840 secs]
[GC 1357804K->1118257K(2944192K), 0.0568760 secs]
[GC 1374385K->1098037K(2944192K), 0.0604770 secs]
[GC 1354165K->1135340K(2944192K), 0.0658700 secs]
[GC 1391468K->1112027K(2944192K), 0.0834130 secs]
[GC 1368155K->1163383K(2944192K), 0.0610910 secs]
[GC 1419511K->1129760K(2944192K), 0.0735120 secs]
[GC 1385888K->1174379K(2944192K), 0.1235450 secs]
[GC 1430507K->1152357K(2944192K), 0.0722440 secs]
[GC 1408485K->1189842K(2944192K), 0.1112150 secs]
[GC 1445970K->1157151K(2944192K), 0.0755120 secs]
[GC 1413279K->1202437K(2944192K), 0.0734300 secs]
[GC 1458565K->1171647K(2944192K), 0.0747780 secs]
[GC 1427775K->1218800K(2944192K), 0.0759720 secs]
[GC 1474928K->1197672K(2944192K), 0.0750170 secs]
[GC 1453800K->1220209K(2944192K), 0.1400350 secs]
[GC 1476337K->1219660K(2944192K), 0.1329770 secs]
[GC 1475788K->1230538K(2944192K), 0.1500430 secs]
[GC 1486666K->1239229K(2944192K), 0.1631930 secs]
[GC 1495357K->1246483K(2944192K), 0.0852390 secs]
[GC 1502611K->1255951K(2944192K), 0.1632750 secs]
[GC 1512079K->1246174K(2944192K), 0.1295230 secs]
[GC 1502302K->1279740K(2944192K), 0.1866100 secs]
[GC 1535868K->1280358K(2944192K), 0.0844330 secs]
[GC 1536486K->1286188K(2944192K), 0.0834360 secs]
[GC 1542316K->1278736K(2944192K), 0.0799080 secs]
[GC 1534864K->1302099K(2944192K), 0.0854770 secs]
[GC 1558227K->1308964K(2944192K), 0.1653870 secs]
[GC 1565092K->1317087K(2944192K), 0.1490170 secs]
[GC 1573215K->1341027K(2944192K), 0.0825160 secs]
[GC 1597155K->1316178K(2944192K), 0.0831440 secs]
[GC 1572306K->1331482K(2944192K), 0.0759590 secs]
[GC 1587610K->1367552K(2944192K), 0.1498440 secs]
[GC 1623680K->1335083K(2944192K), 0.1791360 secs]
[GC 1591211K->1354357K(2944192K), 0.0846700 secs]
[GC 1610485K->1385141K(2944192K), 0.1591640 secs]
[GC 1641269K->1360245K(2944192K), 0.1808320 secs]
[GC 1616373K->1407478K(2944192K), 0.0840330 secs]
[GC 1407718K(2944192K), 0.0535190 secs]
[GC 1461380K(2944192K), 0.0433700 secs]
[GC 1424942K->1133608K(2944192K), 0.0798660 secs]
[GC 1389736K->1175233K(2944192K), 0.0815260 secs]
[GC 1431361K->1135409K(2944192K), 0.0695570 secs]
[GC 1391537K->1173600K(2944192K), 0.0776860 secs]
[GC 1429728K->1192229K(2944192K), 0.0828820 secs]
[GC 1448357K->1166167K(2944192K), 0.0801790 secs]
[GC 1422295K->1211988K(2944192K), 0.0792510 secs]
[GC 1468116K->1177075K(2944192K), 0.0754520 secs]
[GC 1433203K->1225282K(2944192K), 0.0754120 secs]
[GC 1481410K->1199820K(2944192K), 0.0732310 secs]
[GC 1455948K->1239478K(2944192K), 0.0778700 secs]
[GC 1495606K->1203653K(2944192K), 0.0801470 secs]
[GC 1459781K->1230826K(2944192K), 0.0861390 secs]
[GC 1486954K->1267629K(2944192K), 0.0833680 secs]
[GC 1523757K->1286495K(2944192K), 0.1006880 secs]
[GC 1542623K->1304765K(2944192K), 0.0944750 secs]
[GC 1560893K->1295735K(2944192K), 0.1022060 secs]
[GC 1551863K->1322668K(2944192K), 0.0910950 secs]
[GC 1578796K->1357825K(2944192K), 0.0921050 secs]
[GC 1613953K->1356710K(2944192K), 0.0890180 secs]
[GC 1612838K->1408605K(2944192K), 0.0902180 secs]
[GC 1664733K->1393847K(2944192K), 0.0914970 secs]
[GC 1649975K->1445863K(2944192K), 0.0903770 secs]
[GC 1701991K->1425627K(2944192K), 0.0868080 secs]
[GC 1681755K->1487758K(2944192K), 0.0895530 secs]
[GC 1743886K->1465084K(2944192K), 0.0844580 secs]
[GC 1721212K->1525894K(2944192K), 0.0875000 secs]
[GC 1782022K->1500048K(2944192K), 0.0887170 secs]
[GC 1756176K->1500594K(2944192K), 0.0830020 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1756716K->1556780K(2944192K), 0.0671740 secs]
[GC 1812883K->1540222K(2944192K), 0.0943400 secs]
[GC 1796350K->1607168K(2944192K), 0.0906580 secs]
[GC 1863296K->1579187K(2944192K), 0.0890070 secs]
[GC 1835315K->1621639K(2944192K), 0.0940190 secs]
[GC 1877576K->1609065K(2944192K), 0.0908480 secs]
[GC 1864126K->1661906K(2944192K), 0.0917100 secs]
[GC 1918034K->1679354K(2944192K), 0.0918540 secs]
[GC 1935482K->1698360K(2944192K), 0.0896290 secs]
[GC 1954488K->1717599K(2944192K), 0.1001480 secs]
[GC 1973727K->1734879K(2944192K), 0.0886910 secs]
[GC 1990964K->1739280K(2944192K), 0.0903080 secs]
[GC 1995408K->1773971K(2944192K), 0.0863940 secs]
[GC 2030099K->1789213K(2944192K), 0.0945290 secs]
[GC 2045297K->1793957K(2944192K), 0.0866920 secs]
[GC 2050085K->1794344K(2944192K), 0.0841940 secs]
[GC 2050472K->1849484K(2944192K), 0.0644860 secs]
[GC 2105612K->1828447K(2944192K), 0.0878730 secs]
[GC 2084575K->1849282K(2944192K), 0.0670690 secs]
[GC 2105410K->1835705K(2944192K), 0.0676700 secs]
[GC 2091833K->1860066K(2944192K), 0.0880800 secs]
[GC 2116194K->1889023K(2944192K), 0.0761340 secs]
[GC 2145151K->1918516K(2944192K), 0.1008410 secs]
[GC 2174644K->1931857K(2944192K), 0.0992630 secs]
[GC 2187985K->1923735K(2944192K), 0.1024790 secs]
[GC 2179863K->1948143K(2944192K), 0.0868320 secs]
[GC 2204271K->1985842K(2944192K), 0.0866920 secs]
[GC 2241970K->1982555K(2944192K), 0.0920800 secs]
[GC 2238683K->2022698K(2944192K), 0.0890130 secs]
[GC 2278826K->2020803K(2944192K), 0.0917740 secs]
[GC 2276571K->2041041K(2944192K), 0.0919250 secs]
[GC 2297129K->2057999K(2944192K), 0.0846390 secs]
[GC 2314091K->2092454K(2944192K), 0.0899110 secs]
[GC 2348569K->2109088K(2944192K), 0.0928600 secs]
[GC 2365216K->2129098K(2944192K), 0.0906150 secs]
[GC 2385226K->2147437K(2944192K), 0.0887830 secs]
[GC 2403565K->2136104K(2944192K), 0.0828810 secs]
[GC 2392232K->2172001K(2944192K), 0.0665460 secs]
[GC 2428129K->2186720K(2944192K), 0.1204770 secs]
[GC 2442848K->2194352K(2944192K), 0.0979430 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2450480K->2237088K(2944192K), 0.0791430 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2493216K->2242855K(2944192K), 0.1170560 secs]
[GC 2498983K->2277127K(2944192K), 0.0975720 secs]
[GC 2531515K->2279960K(2944192K), 0.1015760 secs]
[GC 2536070K->2317915K(2944192K), 0.1034280 secs]
[GC 2573155K->2337668K(2944192K), 0.1122900 secs]
[GC 2592284K->2357644K(2944192K), 0.1013760 secs]
[GC 2613756K->2380609K(2944192K), 0.1070170 secs]
[GC 2636737K->2397925K(2944192K), 0.1004090 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2654053K->2400054K(2944192K), 0.1059380 secs]
[GC 2656182K->2418997K(2944192K), 0.0969220 secs]
[GC 2675125K->2458848K(2944192K), 0.0963670 secs]
[GC 2714976K->2459895K(2944192K), 0.0940530 secs]
[GC 2460107K(2944192K), 0.0383250 secs]
[GC 2573046K(2944192K), 0.1621290 secs]
[GC 2388504K->2133857K(3786856K), 0.1025980 secs]
[GC 2389985K->2169678K(3786856K), 0.0736830 secs]
[GC 2425806K->2149232K(3786856K), 0.0981620 secs]
[GC 2405103K->2180197K(3786856K), 0.0724530 secs]
[GC 2436325K->2202778K(3786856K), 0.0809930 secs]
[GC 2458906K->2222868K(3786856K), 0.1146970 secs]
[GC 2478996K->2237724K(3786856K), 0.1063560 secs]
[GC 2493852K->2258371K(3786856K), 0.1278280 secs]
[GC 2514499K->2262914K(3786856K), 0.1077770 secs]
[GC 2519017K->2280571K(3786856K), 0.1051950 secs]
[GC 2536682K->2295568K(3786856K), 0.1038960 secs]
[GC 2551696K->2314022K(3786856K), 0.1109270 secs]
[GC 2570150K->2333462K(3786856K), 0.1001520 secs]
[GC 2589590K->2358076K(3786856K), 0.1078940 secs]
[GC 2613472K->2369719K(3786856K), 0.1136530 secs]
[GC 2625234K->2389105K(3786856K), 0.1110960 secs]
[GC 2645202K->2423605K(3786856K), 0.0983070 secs]
[GC 2679733K->2427993K(3786856K), 0.0944390 secs]
[GC 2684121K->2444833K(3786856K), 0.0989800 secs]
[GC 2700930K->2463431K(3786856K), 0.0925850 secs]
[GC 2718736K->2501581K(3786856K), 0.0859070 secs]
[GC 2757709K->2530625K(3786856K), 0.1103660 secs]
[GC 2785402K->2527984K(3786856K), 0.1053230 secs]
[GC 2782625K->2529711K(3786856K), 0.1122960 secs]
[GC 2785790K->2577640K(3786856K), 0.0978240 secs]
[GC 2833768K->2575672K(3786856K), 0.0928390 secs]
[GC 2831800K->2595646K(3786856K), 0.0980320 secs]
[GC 2850330K->2614356K(3786856K), 0.1003580 secs]
[GC 2869697K->2631158K(3786856K), 0.1011240 secs]
[GC 2887286K->2649820K(3786856K), 0.0984690 secs]
[GC 2905948K->2681465K(3786856K), 0.0944890 secs]
[GC 2936342K->2688957K(3786856K), 0.0969930 secs]
[GC 2943238K->2737099K(3786856K), 0.0980980 secs]
[GC 2993227K->2723063K(3786856K), 0.0926910 secs]
[GC 2979191K->2766352K(3786856K), 0.0989240 secs]
[GC 3022480K->2760706K(3786856K), 0.0961280 secs]
[GC 3016834K->2761399K(3786856K), 0.0899010 secs]
[GC 3017527K->2809537K(3786856K), 0.0761020 secs]
[GC 3065665K->2781673K(3786856K), 0.0838250 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3037801K->2832241K(3786856K), 0.1005090 secs]
[GC 3088001K->2855499K(3786856K), 0.1064020 secs]
[GC 3110855K->2878112K(3786856K), 0.1021450 secs]
[GC 3134240K->2876678K(3786856K), 0.0940580 secs]
[GC 3132660K->2864059K(3786856K), 0.0800230 secs]
[GC 3120187K->2904320K(3786856K), 0.0669760 secs]
[GC 3160383K->2910244K(3786856K), 0.0961690 secs]
[GC 3166372K->2913162K(3786856K), 0.0823420 secs]
[GC 3169290K->2932756K(3786856K), 0.0816810 secs]
[GC 3188427K->2961596K(3786856K), 0.0875740 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 300000. Elapsed time: 20.110 secs. Remaining: 39.890 secs. Total: 1 mins 0 secs
[GC 3217715K->2983286K(3786856K), 0.0842440 secs]
[GC 3237556K->2977128K(3786856K), 0.0824860 secs]
[GC 3232052K->2989148K(3786856K), 0.0843350 secs]
[GC 3244316K->3002611K(3786856K), 0.0806220 secs]
[GC 3258739K->3023770K(3786856K), 0.0839290 secs]
[GC 3279898K->3040162K(3786856K), 0.0874090 secs]
[GC 3295555K->3055672K(3786856K), 0.0873030 secs]
[GC 3311786K->3076273K(3786856K), 0.0817030 secs]
[GC 3332354K->3089407K(3786856K), 0.0820530 secs]
[GC 3341606K->3085127K(3786856K), 0.0743220 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 690000. Elapsed time: 40.142 secs. Remaining: 19.858 secs. Total: 1 mins 0 secs
[GC 3341255K->3108156K(3786856K), 0.0744920 secs]
[GC 3364284K->3106404K(3786856K), 0.0983690 secs]
[GC 3362532K->3122137K(3786856K), 0.0821870 secs]
[GC 3376429K->3147259K(3786856K), 0.0832140 secs]
[GC 3403366K->3157280K(3786856K), 0.0768610 secs]
[GC 3411395K->3168692K(3786856K), 0.0803530 secs]
[GC 3424820K->3173958K(3786856K), 0.0793500 secs]
[GC 3430086K->3187442K(3786856K), 0.0747190 secs]
[GC 3443570K->3198989K(3786856K), 0.0945290 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1050000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 55 mins 37 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3455117K->3204514K(3786856K), 0.0828640 secs]
[GC 3204590K(3786856K), 0.0190630 secs]
[GC 3241570K(3786856K), 0.0290390 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5708 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 57 ms.
