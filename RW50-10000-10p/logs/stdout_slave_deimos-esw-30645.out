/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-30645 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-30645
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0888550 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@a2e02b2
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5704, using socket ServerSocket[addr=/0.0.0.0,localport=5704], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5704
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5704 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 35468 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 37554 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 36782 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5704 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5704 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5704 this
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:57698
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:57698
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59613
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:59613
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 52956 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43832
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:43832
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 37682 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5704 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 44191 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:53467
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:53467
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5704 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34852
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5704 [FenixFrameworkGroup] 5704 accepted socket connection from /127.0.0.1:34852
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5704 [FenixFrameworkGroup] Address[127.0.0.1]:5704 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=2, confAttributes={name=hzl3-repl-sync.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Creating cache with the following configuration: hzl3-repl-sync.xml
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5711, using socket ServerSocket[addr=/0.0.0.0,localport=5711], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5711 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5711
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5711 [dev] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5711 [dev] Address[127.0.0.1]:5711 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5711 [dev] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 59940 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 49072 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 50040 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5711 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
 WARN  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5711 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5711 [dev] 

Members [8] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711 this
	Member [127.0.0.1]:5712
	Member [127.0.0.1]:5713
	Member [127.0.0.1]:5714
	Member [127.0.0.1]:5715
	Member [127.0.0.1]:5716
}

[GC 259695K->10684K(2944064K), 0.0427780 secs]
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:44748
 INFO  [hz._hzInstance_2_dev.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:44748
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 37484 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5713, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 56990 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 44100 accepted socket connection from /127.0.0.1:5713
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:33673
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:33673
 INFO  [hz._hzInstance_2_dev.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5715, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5714, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:54983
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5711 [dev] Connecting to /127.0.0.1:5716, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 36992 accepted socket connection from /127.0.0.1:5715
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:54983
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 36823 accepted socket connection from /127.0.0.1:5714
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 55034 accepted socket connection from /127.0.0.1:5716
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:57272
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:57272
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:45131
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:45131
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5711 [dev] Accepting socket connection from /127.0.0.1:60914
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5711 [dev] 5711 accepted socket connection from /127.0.0.1:60914
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5711 [dev] Address[127.0.0.1]:5711 is STARTED
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@2fe19787
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> e83a5b0c-4fea-428b-a4bf-6306207f60b3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 1
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> 74e9e115-5d6b-4d18-b59b-7f355460f81e
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5711 [dev] No tx backup log is found, tx -> 33d4300b-6dd5-41a1-9cc1-55ca8da6111d
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2fe19787, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 266748K->11552K(2944064K), 0.0340580 secs]
 INFO  [hz._hzInstance_2_dev.scheduled] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5711 [dev] Re-sending sync replica request for partition: 0, replica: 4
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 267616K->13552K(2944064K), 0.0301320 secs]
[GC 269616K->14915K(2944064K), 0.0351120 secs]
[GC 270979K->15236K(2944064K), 0.0336300 secs]
[GC 271300K->17015K(2944064K), 0.0348080 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11700. Elapsed time: 20.008 secs. Remaining: 39.992 secs. Total: 1 mins 0 secs
[GC 273079K->21374K(2944064K), 0.0348820 secs]
[GC 277438K->20739K(2944064K), 0.0375530 secs]
[GC 276803K->25898K(2944064K), 0.0386400 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 27950. Elapsed time: 40.044 secs. Remaining: 19.956 secs. Total: 1 mins 0 secs
[GC 281962K->28281K(2944064K), 0.0397670 secs]
[GC 284345K->30822K(2944064K), 0.0374780 secs]
[GC 286886K->33381K(2944064K), 0.0402320 secs]
[GC 289445K->36064K(2944064K), 0.0372130 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 51300. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 11 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 71 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 292128K->38786K(2944064K), 0.0374140 secs]
[GC 294850K->41699K(2944064K), 0.0366270 secs]
[GC 297763K->48539K(2944064K), 0.0598840 secs]
[GC 304603K->42016K(2944064K), 0.0404490 secs]
[GC 298080K->42051K(2944064K), 0.0407720 secs]
[GC 298115K->48120K(2944064K), 0.0418130 secs]
[GC 304184K->52140K(2944064K), 0.0399990 secs]
[GC 308204K->63141K(2944064K), 0.0449880 secs]
[GC 319205K->77760K(2944064K), 0.0468610 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,860,223 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 83840K->53040K(2944064K), 0.2664200 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,890,288 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2fe19787, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 309168K->91443K(2944192K), 0.0271790 secs]
[GC 347571K->63072K(2944192K), 0.0311940 secs]
[GC 319200K->60185K(2944192K), 0.0299410 secs]
[GC 316313K->65662K(2944192K), 0.0308950 secs]
[GC 321790K->66123K(2944192K), 0.0345790 secs]
[GC 322251K->67178K(2944192K), 0.0333730 secs]
[GC 323306K->73013K(2944192K), 0.0326590 secs]
[GC 329141K->73152K(2944192K), 0.0340910 secs]
[GC 329280K->76244K(2944192K), 0.0383130 secs]
[GC 332372K->83836K(2944192K), 0.0358650 secs]
[GC 339964K->82713K(2944192K), 0.0373120 secs]
[GC 338841K->86004K(2944192K), 0.0400490 secs]
[GC 342132K->89264K(2944192K), 0.0415660 secs]
[GC 345392K->85939K(2944192K), 0.0388590 secs]
[GC 342067K->103020K(2944192K), 0.0388650 secs]
[GC 359148K->101861K(2944192K), 0.0503530 secs]
[GC 357989K->96864K(2944192K), 0.0464300 secs]
[GC 352992K->99368K(2944192K), 0.0448470 secs]
[GC 355496K->117965K(2944192K), 0.0427430 secs]
[GC 374093K->109225K(2944192K), 0.0459150 secs]
[GC 365353K->117668K(2944192K), 0.0435730 secs]
[GC 373796K->108015K(2944192K), 0.0443020 secs]
[GC 364143K->127902K(2944192K), 0.0465350 secs]
[GC 384030K->113787K(2944192K), 0.0483620 secs]
[GC 369915K->127829K(2944192K), 0.0416600 secs]
[GC 383957K->117759K(2944192K), 0.0432650 secs]
[GC 373887K->129260K(2944192K), 0.0446880 secs]
[GC 385388K->123177K(2944192K), 0.0452740 secs]
[GC 379305K->134189K(2944192K), 0.0417740 secs]
[GC 390317K->127975K(2944192K), 0.0458530 secs]
[GC 384103K->130442K(2944192K), 0.0426780 secs]
[GC 386570K->141548K(2944192K), 0.0418820 secs]
[GC 397676K->135162K(2944192K), 0.0451500 secs]
[GC 391290K->137464K(2944192K), 0.0439700 secs]
[GC 393592K->139732K(2944192K), 0.0442620 secs]
[GC 395860K->150750K(2944192K), 0.0475920 secs]
[GC 406878K->153010K(2944192K), 0.0421640 secs]
[GC 409138K->155322K(2944192K), 0.0460170 secs]
[GC 411450K->157682K(2944192K), 0.0607720 secs]
[GC 413810K->151312K(2944192K), 0.0428550 secs]
[GC 407440K->170842K(2944192K), 0.0451590 secs]
[GC 426970K->155749K(2944192K), 0.0428990 secs]
[GC 411877K->161936K(2944192K), 0.0427260 secs]
[GC 418064K->176276K(2944192K), 0.0447880 secs]
[GC 432404K->162571K(2944192K), 0.0466080 secs]
[GC 418699K->168870K(2944192K), 0.0581390 secs]
[GC 424998K->174500K(2944192K), 0.0475560 secs]
[GC 430628K->177633K(2944192K), 0.0477820 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 433761K->197092K(2944192K), 0.0513150 secs]
[GC 453220K->178818K(2944192K), 0.0566610 secs]
[GC 434946K->208697K(2944192K), 0.0506280 secs]
[GC 464825K->187830K(2944192K), 0.0502560 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 50000. Elapsed time: 21.369 secs. Remaining: 38.631 secs. Total: 1 mins 0 secs
[GC 443958K->220816K(2944192K), 0.0716090 secs]
[GC 476944K->197130K(2944192K), 0.0676580 secs]
[GC 453258K->231700K(2944192K), 0.0517920 secs]
[GC 487828K->205485K(2944192K), 0.0523480 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 80000. Elapsed time: 41.741 secs. Remaining: 18.259 secs. Total: 1 mins 0 secs
[GC 461613K->243217K(2944192K), 0.0527480 secs]
[GC 499345K->214372K(2944192K), 0.0734110 secs]
[GC 470500K->254081K(2944192K), 0.0696040 secs]
[GC 510209K->222711K(2944192K), 0.0561650 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 110000. Elapsed time: 1 mins 4 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 478839K->264241K(2944192K), 0.0526750 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 5 mins 42 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using hazelcast3, clusterSize:8, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=50 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 520369K->228624K(2944192K), 0.0493300 secs]
[GC 484752K->265883K(2944192K), 0.0510100 secs]
[GC 522011K->234339K(2944192K), 0.0548950 secs]
[GC 490467K->269205K(2944192K), 0.0515050 secs]
[GC 525333K->236663K(2944192K), 0.0512670 secs]
[GC 492791K->270295K(2944192K), 0.0511720 secs]
[GC 526423K->239883K(2944192K), 0.0523020 secs]
[GC 496011K->258430K(2944192K), 0.0545410 secs]
[GC 514558K->242937K(2944192K), 0.0510110 secs]
[GC 499065K->245725K(2944192K), 0.0531460 secs]
[GC 501853K->236838K(2944192K), 0.0527720 secs]
[GC 492966K->238788K(2944192K), 0.0541960 secs]
[GC 494916K->240455K(2944192K), 0.0540600 secs]
[GC 496583K->242118K(2944192K), 0.0521070 secs]
[GC 498246K->250707K(2944192K), 0.0508940 secs]
[GC 506835K->250616K(2944192K), 0.0546290 secs]
[GC 506743K->251272K(2944192K), 0.0539990 secs]
[GC 507400K->252836K(2944192K), 0.0434110 secs]
[GC 508964K->261471K(2944192K), 0.0427790 secs]
[GC 517599K->263441K(2944192K), 0.0511150 secs]
[GC 519569K->258451K(2944192K), 0.0451240 secs]
[GC 514579K->260289K(2944192K), 0.0459570 secs]
[GC 516417K->276051K(2944192K), 0.0462440 secs]
[GC 532179K->264034K(2944192K), 0.0519420 secs]
[GC 520162K->281615K(2944192K), 0.0488780 secs]
[GC 537743K->272059K(2944192K), 0.0480200 secs]
[GC 528187K->292060K(2944192K), 0.0542190 secs]
[GC 548188K->295564K(2944192K), 0.0542530 secs]
[GC 551692K->313088K(2944192K), 0.0513110 secs]
[GC 569200K->295931K(2944192K), 0.0544440 secs]
[GC 552059K->321244K(2944192K), 0.0578110 secs]
[GC 577372K->323575K(2944192K), 0.0601320 secs]
[GC 579703K->331780K(2944192K), 0.0564000 secs]
[GC 587908K->308975K(2944192K), 0.0599360 secs]
[GC 565103K->341431K(2944192K), 0.0578790 secs]
[GC 597559K->310870K(2944192K), 0.0566160 secs]
[GC 566998K->333140K(2944192K), 0.0548720 secs]
[GC 589268K->329191K(2944192K), 0.0551760 secs]
[GC 585319K->346626K(2944192K), 0.0519400 secs]
[GC 602754K->323610K(2944192K), 0.0571120 secs]
[GC 579738K->345452K(2944192K), 0.0581130 secs]
[GC 601580K->327264K(2944192K), 0.0577050 secs]
[GC 583392K->346114K(2944192K), 0.0571920 secs]
[GC 602242K->330388K(2944192K), 0.0552400 secs]
[GC 586516K->336691K(2944192K), 0.0526230 secs]
[GC 592819K->324008K(2944192K), 0.0525230 secs]
[GC 580136K->326443K(2944192K), 0.0572100 secs]
[GC 582571K->331665K(2944192K), 0.0465900 secs]
[GC 587793K->332405K(2944192K), 0.0531750 secs]
[GC 588533K->340988K(2944192K), 0.0516450 secs]
[GC 597116K->342852K(2944192K), 0.0456170 secs]
[GC 598980K->344823K(2944192K), 0.0520680 secs]
[GC 600951K->346860K(2944192K), 0.0460330 secs]
[GC 602988K->355883K(2944192K), 0.0443440 secs]
[GC 612011K->343641K(2944192K), 0.0438170 secs]
[GC 599769K->355304K(2944192K), 0.0498530 secs]
[GC 611432K->360840K(2944192K), 0.0427280 secs]
[GC 616968K->349311K(2944192K), 0.0546540 secs]
[GC 605439K->361332K(2944192K), 0.0453550 secs]
[GC 617460K->366999K(2944192K), 0.0537830 secs]
[GC 623127K->355315K(2944192K), 0.0536200 secs]
[GC 611443K->360755K(2944192K), 0.0517480 secs]
[GC 616883K->358872K(2944192K), 0.0437110 secs]
[GC 615000K->361475K(2944192K), 0.0552140 secs]
[GC 617603K->370849K(2944192K), 0.0456560 secs]
[GC 626977K->380281K(2944192K), 0.0462740 secs]
[GC 636409K->367676K(2944192K), 0.0516070 secs]
[GC 623804K->372929K(2944192K), 0.1161960 secs]
[GC 629057K->385129K(2944192K), 0.0462660 secs]
[GC 641257K->373298K(2944192K), 0.0533290 secs]
[GC 629426K->385533K(2944192K), 0.0445620 secs]
[GC 641661K->384035K(2944192K), 0.0545600 secs]
[GC 640163K->394189K(2944192K), 0.0465970 secs]
[GC 650317K->381572K(2944192K), 0.0439830 secs]
[GC 637700K->400362K(2944192K), 0.0444840 secs]
[GC 656490K->384269K(2944192K), 0.1241460 secs]
[GC 640397K->397322K(2944192K), 0.0442390 secs]
[GC 653450K->395936K(2944192K), 0.0496950 secs]
[GC 652064K->398701K(2944192K), 0.0512350 secs]
[GC 654829K->401049K(2944192K), 0.0505360 secs]
[GC 657177K->403102K(2944192K), 0.0544550 secs]
[GC 659230K->405073K(2944192K), 0.0544470 secs]
[GC 661201K->407065K(2944192K), 0.0489020 secs]
[GC 663193K->416492K(2944192K), 0.0445010 secs]
[GC 672620K->403555K(2944192K), 0.0443910 secs]
[GC 659683K->415533K(2944192K), 0.0458480 secs]
[GC 671661K->421087K(2944192K), 0.0466680 secs]
[GC 677215K->409125K(2944192K), 0.0473710 secs]
[GC 665253K->421369K(2944192K), 0.0476020 secs]
[GC 677497K->419782K(2944192K), 0.0439530 secs]
[GC 675910K->429766K(2944192K), 0.0426610 secs]
[GC 685894K->417245K(2944192K), 0.0459440 secs]
[GC 673373K->429347K(2944192K), 0.0402650 secs]
[GC 685475K->434975K(2944192K), 0.0551370 secs]
[GC 691103K->422938K(2944192K), 0.0519760 secs]
[GC 679066K->442054K(2944192K), 0.0474560 secs]
[GC 698182K->430432K(2944192K), 0.0525070 secs]
[GC 686560K->445595K(2944192K), 0.0511290 secs]
[GC 701723K->429759K(2944192K), 0.0445220 secs]
[GC 685887K->449663K(2944192K), 0.0510020 secs]
[GC 705791K->433730K(2944192K), 0.0455340 secs]
[GC 689858K->446913K(2944192K), 0.0451750 secs]
[GC 703041K->438259K(2944192K), 0.0416790 secs]
[GC 694387K->455629K(2944192K), 0.0470120 secs]
[GC 711757K->443009K(2944192K), 0.0456380 secs]
[GC 699137K->455206K(2944192K), 0.0425300 secs]
[GC 711334K->460850K(2944192K), 0.0452460 secs]
[GC 716978K->453314K(2944192K), 0.0462030 secs]
[GC 709442K->472797K(2944192K), 0.0910070 secs]
[GC 728925K->487151K(2944192K), 0.0571590 secs]
[GC 743279K->473428K(2944192K), 0.0597270 secs]
[GC 729556K->491388K(2944192K), 0.0573580 secs]
[GC 747516K->505712K(2944192K), 0.0653790 secs]
[GC 761840K->516289K(2944192K), 0.0603810 secs]
[GC 772417K->524671K(2944192K), 0.0637670 secs]
[GC 780799K->499357K(2944192K), 0.0609340 secs]
[GC 755485K->535759K(2944192K), 0.0625250 secs]
[GC 791887K->502011K(2944192K), 0.0583290 secs]
[GC 758139K->541040K(2944192K), 0.0671310 secs]
[GC 797168K->506948K(2944192K), 0.0613530 secs]
[GC 763076K->532695K(2944192K), 0.0594660 secs]
[GC 788823K->543517K(2944192K), 0.0669120 secs]
[GC 799645K->519684K(2944192K), 0.0643390 secs]
[GC 775812K->544504K(2944192K), 0.0596330 secs]
[GC 800632K->524644K(2944192K), 0.0617010 secs]
[GC 780772K->533415K(2944192K), 0.0578670 secs]
[GC 789543K->528057K(2944192K), 0.0610150 secs]
[GC 784185K->520008K(2944192K), 0.0540320 secs]
[GC 776136K->522127K(2944192K), 0.0601550 secs]
[GC 778255K->538651K(2944192K), 0.0507760 secs]
[GC 794779K->539355K(2944192K), 0.0486370 secs]
[GC 795483K->541399K(2944192K), 0.0578860 secs]
[GC 797527K->561109K(2944192K), 0.0593540 secs]
[GC 817237K->540580K(2944192K), 0.0620760 secs]
[GC 796708K->574805K(2944192K), 0.0544040 secs]
[GC 830933K->592555K(2944192K), 0.0603480 secs]
[GC 848683K->572852K(2944192K), 0.0631320 secs]
[GC 828980K->594437K(2944192K), 0.0623290 secs]
[GC 850565K->593766K(2944192K), 0.0617560 secs]
[GC 849894K->615230K(2944192K), 0.0635120 secs]
[GC 871358K->587190K(2944192K), 0.0645910 secs]
[GC 843318K->612758K(2944192K), 0.0633310 secs]
[GC 868886K->624161K(2944192K), 0.0666410 secs]
[GC 880289K->598374K(2944192K), 0.0710240 secs]
[GC 854502K->622299K(2944192K), 0.0682130 secs]
[GC 878427K->607824K(2944192K), 0.0670450 secs]
[GC 863952K->650403K(2944192K), 0.0640500 secs]
[GC 906531K->605537K(2944192K), 0.0671750 secs]
[GC 861665K->624079K(2944192K), 0.0735900 secs]
[GC 880207K->603735K(2944192K), 0.0735770 secs]
[GC 859863K->608778K(2944192K), 0.0711940 secs]
[GC 864906K->625826K(2944192K), 0.0714340 secs]
[GC 881954K->651757K(2944192K), 0.0706300 secs]
[GC 907885K->630798K(2944192K), 0.0601240 secs]
[GC 886926K->673355K(2944192K), 0.0638980 secs]
[GC 929483K->694531K(2944192K), 0.0760070 secs]
[GC 950659K->662871K(2944192K), 0.0722330 secs]
[GC 918999K->707118K(2944192K), 0.0766700 secs]
[GC 963246K->677979K(2944192K), 0.0667080 secs]
[GC 934107K->699142K(2944192K), 0.0694350 secs]
[GC 955270K->723227K(2944192K), 0.0669260 secs]
[GC 979355K->685777K(2944192K), 0.0713310 secs]
[GC 941905K->699080K(2944192K), 0.0694500 secs]
[GC 955208K->714849K(2944192K), 0.0615220 secs]
[GC 970977K->704598K(2944192K), 0.0619490 secs]
[GC 960726K->687128K(2944192K), 0.0716280 secs]
[GC 943256K->729988K(2944192K), 0.0616790 secs]
[GC 986116K->710650K(2944192K), 0.0668940 secs]
[GC 966778K->739013K(2944192K), 0.0705080 secs]
[GC 995141K->723331K(2944192K), 0.0791510 secs]
[GC 979459K->765760K(2944192K), 0.0877660 secs]
[GC 1021888K->735131K(2944192K), 0.0944610 secs]
[GC 991259K->774150K(2944192K), 0.0813680 secs]
[GC 1030278K->776899K(2944192K), 0.0890860 secs]
[GC 1033027K->797444K(2944192K), 0.0704210 secs]
[GC 1053572K->775383K(2944192K), 0.0739370 secs]
[GC 1031511K->812536K(2944192K), 0.0959530 secs]
[GC 1068664K->844418K(2944192K), 0.0811930 secs]
[GC 1100546K->866303K(2944192K), 0.0941980 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5704 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5704 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5704 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 65 ms.
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5716] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5711 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5711 [dev] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5711 [dev] Hazelcast Shutdown is completed in 320 ms.
