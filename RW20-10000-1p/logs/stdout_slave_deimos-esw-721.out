/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-721 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-721
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0782720 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Startup staggering, number of slaves to start is 12 This is the slave with index 0, not sleeping
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2548e059
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5701, using socket ServerSocket[addr=/0.0.0.0,localport=5701], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5701
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5701 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5703. Reason: SocketException[Connection refused to address /127.0.0.1:5703]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5702. Reason: SocketException[Connection refused to address /127.0.0.1:5702]
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.cluster.MulticastJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTED
 INFO  [pool-1-thread-1] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Initializing cluster partition table first arrangement...
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is the first node!
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 0
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|0] [deimos-esw-32709]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-32709, physical addresses are [127.0.0.1:52000]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41757
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:41757
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker not present. Data Grid is being initialized for the first time.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 0, serverOidBase: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.DomainRoot} Created DomainRoot instance
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Notify other nodes that startup completed
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37221
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:37221
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:58936
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:58936
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52997
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:52997
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37659
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:37659
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:48602
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:48602
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59661
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59661
[GC 259695K->21020K(2944064K), 0.0598080 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59512
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59512
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:39258
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:39258
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41224
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:41224
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42726
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:42726
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5701 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701 this
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 248
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 0: org.radargun.cachewrappers.FFWrapper@52316c66
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] All migration tasks has been completed, queues are empty.
 INFO  [Incoming-1,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|1] [deimos-esw-32709, deimos-esw-52082]
 INFO  [Incoming-3,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|2] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320]
 INFO  [Incoming-4,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|3] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320, deimos-esw-5446, deimos-esw-384]
 INFO  [Incoming-4,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|4] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320, deimos-esw-5446, deimos-esw-384, deimos-esw-33290]
 INFO  [Incoming-4,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|5] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320, deimos-esw-5446, deimos-esw-384, deimos-esw-33290, deimos-esw-26599, deimos-esw-57166]
 INFO  [Incoming-4,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|6] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320, deimos-esw-5446, deimos-esw-384, deimos-esw-33290, deimos-esw-26599, deimos-esw-57166, deimos-esw-24518, deimos-esw-42852]
 INFO  [Incoming-4,deimos-esw-32709] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-32709|7] [deimos-esw-32709, deimos-esw-52082, deimos-esw-26320, deimos-esw-5446, deimos-esw-384, deimos-esw-33290, deimos-esw-26599, deimos-esw-57166, deimos-esw-24518, deimos-esw-42852, deimos-esw-35347, deimos-esw-494]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 0
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@52316c66, nodeIndex=0, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 277084K->19230K(2944064K), 0.0458790 secs]
[GC 275294K->29226K(2944064K), 0.0464840 secs]
[GC 285290K->49030K(2944064K), 0.0536230 secs]
[GC 305094K->63742K(2944064K), 0.0578060 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 319806K->68373K(2944064K), 0.0620430 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8350. Elapsed time: 20.338 secs. Remaining: 39.662 secs. Total: 1 mins 0 secs
[GC 324437K->98152K(2944064K), 0.0665760 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 14700. Elapsed time: 40.477 secs. Remaining: 19.523 secs. Total: 1 mins 0 secs
[GC 354216K->113162K(2944064K), 0.1259250 secs]
[GC 369226K->126941K(2944064K), 0.0879000 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 39 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 159 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 383005K->152217K(2944064K), 0.0735380 secs]
[GC 408281K->175906K(2944064K), 0.0713620 secs]
[GC 431970K->198483K(2944064K), 0.0873970 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,615,299 kb - max:4,906,688 kb- total:2,944,064 kb
 WARN  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Fenix Framework never forgets...
[Full GC 328764K->166859K(2944064K), 0.7149410 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,776,486 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=1, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@52316c66, nodeIndex=0, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 422987K->244744K(2944192K), 0.0381140 secs]
[GC 500872K->187861K(2944192K), 0.0384020 secs]
[GC 443989K->200954K(2944192K), 0.0458150 secs]
[GC 457082K->210995K(2944192K), 0.0520680 secs]
[GC 467123K->224593K(2944192K), 0.0603850 secs]
[GC 480721K->239781K(2944192K), 0.0780540 secs]
[GC 495909K->254727K(2944192K), 0.0925240 secs]
[GC 510855K->270745K(2944192K), 0.1043520 secs]
[GC 526873K->239338K(2944192K), 0.1101660 secs]
[GC 495466K->296923K(2944192K), 0.1285580 secs]
[GC 553051K->312900K(2944192K), 0.0837200 secs]
[GC 569028K->319937K(2944192K), 0.1536610 secs]
[GC 576028K->313504K(2944192K), 0.1037450 secs]
[GC 569632K->345748K(2944192K), 0.0898960 secs]
[GC 601876K->381772K(2944192K), 0.0892520 secs]
[GC 637900K->399733K(2944192K), 0.0828640 secs]
[GC 655861K->436603K(2944192K), 0.0803680 secs]
[GC 692731K->420505K(2944192K), 0.0819320 secs]
[GC 676633K->463061K(2944192K), 0.0786550 secs]
[GC 719189K->441306K(2944192K), 0.0771620 secs]
[GC 697434K->497796K(2944192K), 0.0593490 secs]
[GC 753924K->478001K(2944192K), 0.0959120 secs]
[GC 734129K->496199K(2944192K), 0.0572250 secs]
[GC 752327K->513333K(2944192K), 0.0667010 secs]
[GC 769461K->491938K(2944192K), 0.0836580 secs]
[GC 748066K->518869K(2944192K), 0.0999530 secs]
[GC 774877K->558010K(2944192K), 0.1139700 secs]
[GC 814138K->539251K(2944192K), 0.0903030 secs]
[GC 795379K->581261K(2944192K), 0.1357810 secs]
[GC 837389K->580661K(2944192K), 0.0924870 secs]
[GC 836789K->619495K(2944192K), 0.0940470 secs]
[GC 875457K->659100K(2944192K), 0.0948220 secs]
[GC 915228K->643316K(2944192K), 0.0999200 secs]
[GC 899444K->687022K(2944192K), 0.0958560 secs]
[GC 943150K->663306K(2944192K), 0.0955780 secs]
[GC 919434K->681119K(2944192K), 0.0816420 secs]
[GC 937247K->710449K(2944192K), 0.0638780 secs]
[GC 966577K->715883K(2944192K), 0.0697980 secs]
[GC 972011K->704472K(2944192K), 0.0915970 secs]
[GC 960600K->731330K(2944192K), 0.1057920 secs]
[GC 987458K->714773K(2944192K), 0.1251810 secs]
[GC 970901K->749759K(2944192K), 0.1374480 secs]
[GC 1005887K->721296K(2944192K), 0.1477510 secs]
[GC 977424K->760326K(2944192K), 0.1048200 secs]
[GC 1016454K->759985K(2944192K), 0.1444910 secs]
[GC 1016113K->784112K(2944192K), 0.0757320 secs]
[GC 1040240K->769949K(2944192K), 0.0789080 secs]
[GC 1026077K->804674K(2944192K), 0.1441410 secs]
[GC 1060802K->780327K(2944192K), 0.0808040 secs]
[GC 1036455K->803342K(2944192K), 0.1202780 secs]
[GC 1059470K->801957K(2944192K), 0.0813730 secs]
[GC 1058085K->827159K(2944192K), 0.1588320 secs]
[GC 1083287K->802926K(2944192K), 0.1194210 secs]
[GC 1059054K->816971K(2944192K), 0.0786370 secs]
[GC 1073099K->833148K(2944192K), 0.1344950 secs]
[GC 1089276K->858145K(2944192K), 0.0775480 secs]
[GC 1114273K->830698K(2944192K), 0.1596200 secs]
[GC 1086826K->878730K(2944192K), 0.0859310 secs]
[GC 1134858K->842968K(2944192K), 0.1470590 secs]
[GC 1099096K->873335K(2944192K), 0.0825990 secs]
[GC 1129463K->892178K(2944192K), 0.0765020 secs]
[GC 1148306K->877307K(2944192K), 0.0853060 secs]
[GC 1133435K->895553K(2944192K), 0.1619910 secs]
[GC 1151681K->913250K(2944192K), 0.1503590 secs]
[GC 1169378K->887713K(2944192K), 0.1507470 secs]
[GC 1143841K->902008K(2944192K), 0.0917850 secs]
[GC 1158136K->918254K(2944192K), 0.1584060 secs]
[GC 1174382K->926878K(2944192K), 0.1061100 secs]
[GC 1183006K->936663K(2944192K), 0.1024560 secs]
[GC 1192791K->943368K(2944192K), 0.0787890 secs]
[GC 1199496K->949132K(2944192K), 0.0807280 secs]
[GC 1205260K->958112K(2944192K), 0.0837420 secs]
[GC 1214240K->964932K(2944192K), 0.1740840 secs]
[GC 1221060K->996486K(2944192K), 0.0940860 secs]
[GC 1252491K->1004077K(2944192K), 0.1233140 secs]
[GC 1260205K->1007575K(2944192K), 0.1523900 secs]
[GC 1263703K->1051965K(2944192K), 0.1238310 secs]
[GC 1307960K->1059557K(2944192K), 0.0921240 secs]
[GC 1315685K->1078959K(2944192K), 0.1025610 secs]
[GC 1335087K->1054829K(2944192K), 0.0918170 secs]
[GC 1310957K->1065878K(2944192K), 0.0910060 secs]
[GC 1322006K->1085606K(2944192K), 0.1028790 secs]
[GC 1341734K->1104694K(2944192K), 0.1062020 secs]
[GC 1360822K->1086544K(2944192K), 0.1150890 secs]
[GC 1342672K->1106655K(2944192K), 0.0658910 secs]
[GC 1362783K->1110772K(2944192K), 0.0721380 secs]
[GC 1366900K->1121831K(2944192K), 0.0878920 secs]
[GC 1377959K->1145679K(2944192K), 0.0635280 secs]
[GC 1401807K->1158747K(2944192K), 0.0795870 secs]
[GC 1414875K->1134453K(2944192K), 0.1430470 secs]
[GC 1390581K->1181238K(2944192K), 0.0753040 secs]
[GC 1437366K->1147836K(2944192K), 0.1534960 secs]
[GC 1403964K->1181747K(2944192K), 0.0836120 secs]
[GC 1437875K->1199714K(2944192K), 0.1170950 secs]
[GC 1455842K->1182314K(2944192K), 0.0920070 secs]
[GC 1438442K->1205546K(2944192K), 0.0800270 secs]
[GC 1461674K->1221921K(2944192K), 0.0833570 secs]
[GC 1478030K->1198330K(2944192K), 0.0865340 secs]
[GC 1454458K->1258644K(2944192K), 0.1000600 secs]
[GC 1514654K->1235844K(2944192K), 0.1029580 secs]
[GC 1491972K->1293003K(2944192K), 0.1065250 secs]
[GC 1549131K->1309561K(2944192K), 0.0897290 secs]
[GC 1565689K->1327679K(2944192K), 0.1015520 secs]
 INFO  [Stressor-1] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=416229 <= mostRecentNum=416235.
[GC 1583807K->1319503K(2944192K), 0.1146810 secs]
[GC 1575631K->1365657K(2944192K), 0.0921430 secs]
[GC 1621785K->1369566K(2944192K), 0.0945450 secs]
[GC 1625694K->1409931K(2944192K), 0.0938070 secs]
[GC 1410185K(2944192K), 0.0375960 secs]
[GC 1621541K(2944192K), 0.2044330 secs]
[GC 1448302K->1214875K(2944192K), 0.1012000 secs]
[GC 1470837K->1217902K(2944192K), 0.0959920 secs]
[GC 1474030K->1258257K(2944192K), 0.0990410 secs]
[GC 1514385K->1280149K(2944192K), 0.0975210 secs]
[GC 1536277K->1264430K(2944192K), 0.0911880 secs]
[GC 1520558K->1284832K(2944192K), 0.0812100 secs]
[GC 1540960K->1329629K(2944192K), 0.0642310 secs]
[GC 1585757K->1290290K(2944192K), 0.0682930 secs]
[GC 1546418K->1299098K(2944192K), 0.0846030 secs]
[GC 1555226K->1348543K(2944192K), 0.0657760 secs]
[GC 1604664K->1320710K(2944192K), 0.0676020 secs]
[GC 1576838K->1382495K(2944192K), 0.0913540 secs]
[GC 1638623K->1368184K(2944192K), 0.0879160 secs]
[GC 1624312K->1410834K(2944192K), 0.1031840 secs]
[GC 1666962K->1428919K(2944192K), 0.0988450 secs]
[GC 1685047K->1438200K(2944192K), 0.0985080 secs]
[GC 1694328K->1455961K(2944192K), 0.0979370 secs]
[GC 1712089K->1453637K(2944192K), 0.0905280 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1709763K->1465959K(2944192K), 0.0927680 secs]
[GC 1722054K->1481300K(2944192K), 0.0865940 secs]
[GC 1737373K->1501899K(2944192K), 0.0815140 secs]
[GC 1757931K->1521781K(2944192K), 0.0715620 secs]
[GC 1777909K->1527343K(2944192K), 0.0935120 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2040000. Elapsed time: 20.113 secs. Remaining: 39.887 secs. Total: 1 mins 0 secs
[GC 1783471K->1530962K(2944192K), 0.0626080 secs]
[GC 1787090K->1537457K(2944192K), 0.0736050 secs]
[GC 1793585K->1541667K(2944192K), 0.0733010 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3160000. Elapsed time: 40.196 secs. Remaining: 19.804 secs. Total: 1 mins 0 secs
[GC 1797795K->1534888K(2944192K), 0.0605510 secs]
[GC 1791016K->1554717K(2944192K), 0.0620630 secs]
[GC 1810845K->1574656K(2944192K), 0.0828560 secs]
[GC 1830784K->1550156K(2944192K), 0.0583690 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 5020000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 1806284K->1577728K(2944192K), 0.0613080 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 44 mins 52 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:0, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=1, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1833722K->1570683K(2944192K), 0.0671540 secs]
[GC 1826750K->1585950K(2944192K), 0.0677100 secs]
[GC 1842078K->1605396K(2944192K), 0.0807080 secs]
[GC 1861524K->1665101K(2944192K), 0.1117330 secs]
[GC 1921129K->1650485K(2944192K), 0.1002270 secs]
[GC 1906455K->1708631K(2944192K), 0.1030110 secs]
[GC 1964759K->1693062K(2944192K), 0.1025710 secs]
[GC 1949190K->1754739K(2944192K), 0.1114180 secs]
[GC 2010867K->1780712K(2944192K), 0.1131970 secs]
[GC 2036840K->1801636K(2944192K), 0.1099880 secs]
[GC 2057764K->1822417K(2944192K), 0.1129720 secs]
[GC 2078545K->1851010K(2944192K), 0.1122060 secs]
[GC 2107138K->1876346K(2944192K), 0.1055750 secs]
[GC 2132474K->1901770K(2944192K), 0.1072320 secs]
[GC 2157898K->1926858K(2944192K), 0.1144870 secs]
[GC 2182986K->1951514K(2944192K), 0.1072370 secs]
[GC 2207553K->1955373K(2944192K), 0.1052050 secs]
[GC 2211501K->1979584K(2944192K), 0.1025940 secs]
[GC 2235712K->2002099K(2944192K), 0.1083290 secs]
[GC 2258227K->2024511K(2944192K), 0.1043920 secs]
[GC 2280639K->2080258K(2944192K), 0.1049900 secs]
[GC 2336386K->2063375K(2944192K), 0.0950170 secs]
[GC 2319503K->2116580K(2944192K), 0.1013670 secs]
[GC 2372708K->2129800K(2944192K), 0.1029830 secs]
[GC 2385928K->2154206K(2944192K), 0.0971310 secs]
[GC 2410186K->2185133K(2944192K), 0.1038210 secs]
[GC 2441261K->2198782K(2944192K), 0.0980690 secs]
[GC 2454910K->2221056K(2944192K), 0.0955180 secs]
[GC 2477030K->2243236K(2944192K), 0.0993770 secs]
[GC 2499364K->2245430K(2944192K), 0.1015670 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
[GC 2501558K->2295324K(2944192K), 0.1074940 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5701 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 163 ms.
