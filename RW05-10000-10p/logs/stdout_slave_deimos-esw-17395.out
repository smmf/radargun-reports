/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-17395 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-17395
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0660540 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 6. Sleeping for 8000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 6
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2548e059
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=6, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5707, using socket ServerSocket[addr=/0.0.0.0,localport=5707], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5707 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5707
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5707 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5707 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5707 [FenixFrameworkGroup] Address[127.0.0.1]:5707 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 40700 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 60062 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 57614 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5707 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707 this
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:50538
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:50538
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:60792
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:60792
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45755
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:45755
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 34960 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42546
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:42546
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45161
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 40940 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5707 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:45161
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 39757 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5707 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:37959
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5707 [FenixFrameworkGroup] 5707 accepted socket connection from /127.0.0.1:37959
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5707 [FenixFrameworkGroup] Address[127.0.0.1]:5707 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 6
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=6, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 6
[GC 259695K->13001K(2944064K), 0.0349940 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|5] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660, deimos-esw-47278, deimos-esw-57185]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-47278, physical addresses are [127.0.0.1:52006]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-47278] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|6] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660, deimos-esw-47278, deimos-esw-57185, deimos-esw-33880, deimos-esw-45371]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 6, serverOidBase: 6000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 6: org.radargun.cachewrappers.FFWrapper@54c8ab35
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@54c8ab35, nodeIndex=6, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269065K->22435K(2944064K), 0.0565470 secs]
[GC 278499K->32679K(2944064K), 0.0509760 secs]
[GC 288743K->52144K(2944064K), 0.0501940 secs]
[GC 308208K->76591K(2944064K), 0.0589430 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 332655K->85159K(2944064K), 0.0623930 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 14700. Elapsed time: 20.113 secs. Remaining: 39.887 secs. Total: 1 mins 0 secs
[GC 341223K->107032K(2944064K), 0.0682430 secs]
[GC 363096K->116605K(2944064K), 0.1624470 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 33350. Elapsed time: 40.505 secs. Remaining: 19.495 secs. Total: 1 mins 0 secs
[GC 372669K->124613K(2944064K), 0.0832070 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 30 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 150 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 380677K->155229K(2944064K), 0.0714590 secs]
[GC 411293K->189915K(2944064K), 0.0732900 secs]
[GC 445979K->200624K(2944064K), 0.0856800 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,702,035 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 242028K->163717K(2944064K), 0.7257580 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,779,268 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@54c8ab35, nodeIndex=6, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 419845K->241239K(2944192K), 0.0370410 secs]
[GC 497367K->184842K(2944192K), 0.0394360 secs]
[GC 440970K->201411K(2944192K), 0.0428910 secs]
[GC 457539K->213213K(2944192K), 0.0523710 secs]
[GC 469341K->229247K(2944192K), 0.0558630 secs]
[GC 485375K->234928K(2944192K), 0.0637020 secs]
[GC 491056K->261164K(2944192K), 0.0680250 secs]
[GC 517292K->262442K(2944192K), 0.0666530 secs]
[GC 518570K->300568K(2944192K), 0.0871570 secs]
[GC 556271K->274741K(2944192K), 0.0900650 secs]
[GC 530869K->326034K(2944192K), 0.1273000 secs]
[GC 582162K->327301K(2944192K), 0.1110480 secs]
[GC 582640K->355493K(2944192K), 0.1010030 secs]
[GC 611621K->357529K(2944192K), 0.0935670 secs]
[GC 613614K->375350K(2944192K), 0.0895910 secs]
[GC 631478K->412706K(2944192K), 0.0908480 secs]
[GC 668061K->431079K(2944192K), 0.0907380 secs]
[GC 687207K->451675K(2944192K), 0.0952130 secs]
[GC 707801K->450473K(2944192K), 0.0901920 secs]
[GC 706601K->488771K(2944192K), 0.0995000 secs]
[GC 744899K->490028K(2944192K), 0.0861260 secs]
[GC 746156K->545954K(2944192K), 0.0894380 secs]
[GC 802082K->526643K(2944192K), 0.0902210 secs]
[GC 782771K->569541K(2944192K), 0.0848620 secs]
[GC 823761K->593529K(2944192K), 0.0852720 secs]
[GC 849657K->580820K(2944192K), 0.0904370 secs]
[GC 836948K->640802K(2944192K), 0.0893870 secs]
[GC 895907K->618983K(2944192K), 0.0948060 secs]
[GC 875111K->680029K(2944192K), 0.0940520 secs]
[GC 936157K->661914K(2944192K), 0.0881970 secs]
[GC 918042K->693181K(2944192K), 0.0877130 secs]
[GC 949309K->681899K(2944192K), 0.0843310 secs]
[GC 938027K->729920K(2944192K), 0.0625210 secs]
[GC 986048K->690019K(2944192K), 0.0671140 secs]
[GC 946147K->701300K(2944192K), 0.0853540 secs]
[GC 957428K->737734K(2944192K), 0.0653230 secs]
[GC 993862K->761137K(2944192K), 0.0865750 secs]
[GC 1017265K->787439K(2944192K), 0.0998810 secs]
[GC 1043567K->772320K(2944192K), 0.1000450 secs]
[GC 1028441K->819361K(2944192K), 0.1077610 secs]
[GC 1074672K->801560K(2944192K), 0.0925480 secs]
[GC 1057688K->858676K(2944192K), 0.0864760 secs]
[GC 1114781K->836353K(2944192K), 0.0843510 secs]
[GC 1092481K->895152K(2944192K), 0.0881910 secs]
[GC 1151280K->876471K(2944192K), 0.0863840 secs]
[GC 1131219K->936210K(2944192K), 0.0848960 secs]
[GC 1192338K->909902K(2944192K), 0.0817040 secs]
[GC 1165980K->958203K(2944192K), 0.0775480 secs]
[GC 1214331K->992453K(2944192K), 0.0821770 secs]
[GC 1248581K->972400K(2944192K), 0.0773160 secs]
[GC 1228510K->1015341K(2944192K), 0.0777730 secs]
[GC 1271469K->1023896K(2944192K), 0.0869710 secs]
[GC 1280024K->1015201K(2944192K), 0.0846270 secs]
[GC 1271321K->1046811K(2944192K), 0.0780510 secs]
[GC 1302327K->1065253K(2944192K), 0.0815020 secs]
[GC 1321381K->1102914K(2944192K), 0.0870420 secs]
[GC 1359042K->1119329K(2944192K), 0.0821360 secs]
[GC 1375457K->1140542K(2944192K), 0.0885570 secs]
[GC 1396666K->1141861K(2944192K), 0.0818950 secs]
[GC 1397989K->1142010K(2944192K), 0.0810910 secs]
[GC 1398138K->1198701K(2944192K), 0.0604090 secs]
[GC 1454829K->1179247K(2944192K), 0.0782190 secs]
[GC 1435375K->1199792K(2944192K), 0.0700050 secs]
[GC 1455920K->1217336K(2944192K), 0.0880220 secs]
[GC 1473464K->1203767K(2944192K), 0.1133480 secs]
[GC 1459895K->1224573K(2944192K), 0.0637260 secs]
[GC 1480701K->1225627K(2944192K), 0.0679270 secs]
[GC 1481755K->1234283K(2944192K), 0.0879880 secs]
[GC 1490411K->1261421K(2944192K), 0.1431930 secs]
[GC 1517549K->1236817K(2944192K), 0.1686810 secs]
[GC 1492945K->1247495K(2944192K), 0.0784180 secs]
[GC 1503623K->1276707K(2944192K), 0.1501210 secs]
[GC 1532835K->1272152K(2944192K), 0.0824560 secs]
[GC 1528280K->1280827K(2944192K), 0.0809090 secs]
[GC 1536955K->1288636K(2944192K), 0.0767440 secs]
[GC 1544764K->1296730K(2944192K), 0.1635920 secs]
[GC 1552858K->1306881K(2944192K), 0.1167910 secs]
[GC 1563009K->1296365K(2944192K), 0.1584560 secs]
[GC 1552493K->1320451K(2944192K), 0.0782860 secs]
[GC 1576579K->1327332K(2944192K), 0.0779050 secs]
[GC 1583460K->1336756K(2944192K), 0.1526000 secs]
[GC 1592884K->1327663K(2944192K), 0.0815350 secs]
[GC 1583791K->1334559K(2944192K), 0.0821340 secs]
[GC 1590687K->1356756K(2944192K), 0.1519370 secs]
[GC 1612884K->1349401K(2944192K), 0.1478520 secs]
[GC 1605529K->1372893K(2944192K), 0.1408720 secs]
[GC 1629021K->1387742K(2944192K), 0.0756640 secs]
[GC 1643870K->1404795K(2944192K), 0.0855860 secs]
[GC 1405502K(2944192K), 0.0647710 secs]
[GC 1477605K(2944192K), 0.0533890 secs]
[GC 1434396K->1143737K(2944192K), 0.0827320 secs]
[GC 1399865K->1168487K(2944192K), 0.0606570 secs]
[GC 1424615K->1197109K(2944192K), 0.0801250 secs]
[GC 1453237K->1172722K(2944192K), 0.0797050 secs]
[GC 1428850K->1188249K(2944192K), 0.0770880 secs]
[GC 1444377K->1202016K(2944192K), 0.0783940 secs]
[GC 1458144K->1209750K(2944192K), 0.0805350 secs]
[GC 1465878K->1219761K(2944192K), 0.0765990 secs]
[GC 1475889K->1226539K(2944192K), 0.0779360 secs]
[GC 1482667K->1232374K(2944192K), 0.0754980 secs]
[GC 1488502K->1221648K(2944192K), 0.0726610 secs]
[GC 1477776K->1248221K(2944192K), 0.0742370 secs]
[GC 1504349K->1278731K(2944192K), 0.0761870 secs]
[GC 1534859K->1253869K(2944192K), 0.0889100 secs]
[GC 1509997K->1305710K(2944192K), 0.0910670 secs]
[GC 1561838K->1305364K(2944192K), 0.1048500 secs]
[GC 1561492K->1328892K(2944192K), 0.0983390 secs]
[GC 1585020K->1322976K(2944192K), 0.0836350 secs]
[GC 1579104K->1356209K(2944192K), 0.0873540 secs]
[GC 1612337K->1373574K(2944192K), 0.0867910 secs]
[GC 1629702K->1396639K(2944192K), 0.0880570 secs]
[GC 1652767K->1428638K(2944192K), 0.0862530 secs]
[GC 1684766K->1459489K(2944192K), 0.0897680 secs]
[GC 1715617K->1466860K(2944192K), 0.0868180 secs]
[GC 1722988K->1484808K(2944192K), 0.0892730 secs]
[GC 1740936K->1486964K(2944192K), 0.1006980 secs]
[GC 1743092K->1523128K(2944192K), 0.0975990 secs]
[GC 1779256K->1541831K(2944192K), 0.0945520 secs]
[GC 1797959K->1557121K(2944192K), 0.0994140 secs]
[GC 1812105K->1578279K(2944192K), 0.1022800 secs]
[GC 1834407K->1595804K(2944192K), 0.0888990 secs]
[GC 1851932K->1578368K(2944192K), 0.0801130 secs]
[GC 1834496K->1632139K(2944192K), 0.0648740 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1888267K->1621517K(2944192K), 0.0877210 secs]
[GC 1877645K->1654244K(2944192K), 0.0887220 secs]
[GC 1909477K->1675531K(2944192K), 0.0806390 secs]
[GC 1931659K->1667596K(2944192K), 0.0876720 secs]
[GC 1921929K->1686618K(2944192K), 0.0800290 secs]
[GC 1942746K->1685604K(2944192K), 0.0616170 secs]
[GC 1941732K->1705574K(2944192K), 0.0636820 secs]
[GC 1961702K->1714831K(2944192K), 0.0672990 secs]
[GC 1970959K->1731830K(2944192K), 0.0640650 secs]
[GC 1987184K->1761915K(2944192K), 0.0811580 secs]
[GC 2018043K->1802608K(2944192K), 0.0732960 secs]
[GC 2058700K->1822304K(2944192K), 0.0750770 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3428088. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 2074987K->1835289K(2944192K), 0.0759780 secs]
[GC 2091417K->1861114K(2944192K), 0.0755990 secs]
[GC 2115680K->1894195K(2944192K), 0.0835580 secs]
[GC 2150323K->1887276K(2944192K), 0.0806390 secs]
[GC 2140377K->1893505K(2944192K), 0.0660850 secs]
[GC 2147833K->1894406K(2944192K), 0.0491320 secs]
[GC 2149175K->1919090K(2944192K), 0.0610100 secs]
[GC 2175218K->1916820K(2944192K), 0.0909530 secs]
[GC 2172948K->1925863K(2944192K), 0.0609160 secs]
[GC 2181991K->1948463K(2944192K), 0.0562180 secs]
[GC 2204540K->1953540K(2944192K), 0.0748930 secs]
[GC 2209668K->2017316K(2944192K), 0.0860070 secs]
[GC 2273444K->2021045K(2944192K), 0.0746690 secs]
[GC 2277173K->2036500K(2944192K), 0.0711430 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8799556. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 2292625K->2066265K(2944192K), 0.0720510 secs]
[GC 2322393K->2046019K(2944192K), 0.0640380 secs]
[GC 2302147K->2121851K(2944192K), 0.0693590 secs]
[GC 2377979K->2100126K(2944192K), 0.0752150 secs]
[GC 2355942K->2113289K(2944192K), 0.0654730 secs]
[GC 2368746K->2136454K(2944192K), 0.0690520 secs]
[GC 2390400K->2181660K(2944192K), 0.0768560 secs]
[GC 2437788K->2158288K(2944192K), 0.0646660 secs]
[GC 2414416K->2253390K(2944192K), 0.0700080 secs]
[GC 2506469K->2240320K(2944192K), 0.0731650 secs]
[GC 2494313K->2242813K(2944192K), 0.0930740 secs]
[GC 2496359K->2300845K(2944192K), 0.0834640 secs]
[GC 2556973K->2289175K(2944192K), 0.0653200 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9900000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2545303K->2341637K(2944192K), 0.0679800 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 29 mins 2 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:6, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2597765K->2276646K(2944192K), 0.0607950 secs]
[GC 2532774K->2300826K(2944192K), 0.0628610 secs]
[GC 2556727K->2323857K(2944192K), 0.0772480 secs]
[GC 2579978K->2378377K(2944192K), 0.1059610 secs]
[GC 2634505K->2404197K(2944192K), 0.1005620 secs]
[GC 2658959K->2428893K(2944192K), 0.0994180 secs]
[GC 2685021K->2415624K(2944192K), 0.1079980 secs]
[GC 2671752K->2470173K(2944192K), 0.1102620 secs]
[GC 2725652K->2452675K(2944192K), 0.1033470 secs]
[GC 2455554K(2944192K), 0.0408940 secs]
[GC 2708803K->2511062K(2944192K), 0.1094620 secs]
[GC 2642090K(2944192K), 0.0485660 secs]
[GC 2200567K->1927044K(3411584K), 0.1326650 secs]
[GC 2183172K->1984983K(3411584K), 0.1217890 secs]
[GC 2240659K->1990692K(3411584K), 0.1182230 secs]
[GC 2246814K->2026329K(3411584K), 0.1102470 secs]
[GC 2282457K->2014939K(3411584K), 0.1211440 secs]
[GC 2271062K->2068132K(3411584K), 0.1104130 secs]
[GC 2324260K->2079978K(3411584K), 0.1189300 secs]
[GC 2336106K->2112813K(3411584K), 0.1206520 secs]
[GC 2368941K->2089636K(3411584K), 0.1227760 secs]
[GC 2345764K->2112251K(3411584K), 0.1161320 secs]
[GC 2368379K->2132853K(3411584K), 0.1115920 secs]
[GC 2388981K->2175065K(3411584K), 0.0991560 secs]
[GC 2431193K->2161526K(3411584K), 0.1230740 secs]
[GC 2417625K->2194455K(3411584K), 0.1002130 secs]
[GC 2450583K->2240313K(3411584K), 0.1348140 secs]
[GC 2496441K->2220544K(3411584K), 0.1263840 secs]
[GC 2476672K->2273244K(3411584K), 0.1087790 secs]
[GC 2529372K->2295795K(3411584K), 0.1090150 secs]
[GC 2551923K->2313694K(3411584K), 0.1072370 secs]
[GC 2569822K->2317236K(3411584K), 0.1108820 secs]
[GC 2573364K->2334642K(3411584K), 0.1048570 secs]
[GC 2590770K->2390238K(3411584K), 0.1070580 secs]
[GC 2646347K->2376542K(3411584K), 0.1142070 secs]
[GC 2632670K->2431249K(3411584K), 0.1032110 secs]
[GC 2687377K->2412692K(3411584K), 0.1035300 secs]
[GC 2668820K->2471793K(3411584K), 0.1021100 secs]
[GC 2727879K->2458433K(3411584K), 0.1054080 secs]
[GC 2714561K->2499417K(3411584K), 0.1054820 secs]
[GC 2755029K->2516577K(3411584K), 0.1039540 secs]
[GC 2772705K->2538001K(3411584K), 0.1075910 secs]
[GC 2794129K->2559400K(3411584K), 0.1074700 secs]
[GC 2815528K->2578195K(3411584K), 0.1096440 secs]
[GC 2833203K->2572769K(3411584K), 0.1076490 secs]
[GC 2828897K->2641256K(3411584K), 0.1004610 secs]
[GC 2896180K->2629271K(3411584K), 0.1022910 secs]
[GC 2885399K->2667260K(3411584K), 0.1114650 secs]
[GC 2923388K->2671274K(3411584K), 0.0990640 secs]
[GC 2927402K->2723757K(3411584K), 0.1032560 secs]
[GC 2979885K->2710355K(3411584K), 0.1012660 secs]
[GC 2966457K->2764661K(3411584K), 0.0962090 secs]
[GC 3020787K->2747981K(3411584K), 0.1053860 secs]
[GC 3004109K->2805363K(3411584K), 0.0963890 secs]
[GC 3061104K->2809113K(3411584K), 0.0984180 secs]
[GC 3065215K->2830727K(3411584K), 0.0972290 secs]
[GC 3086855K->2867010K(3411584K), 0.1041920 secs]
[GC 3123138K->2853598K(3411584K), 0.1023260 secs]
[GC 3109726K->2907293K(3411584K), 0.1070610 secs]
[GC 3163399K->2894027K(3411584K), 0.1024170 secs]
[GC 2894300K(3411584K), 0.0370500 secs]
[GC 3109002K(3411584K), 0.1879200 secs]
[GC 2918626K->2662851K(4650880K), 0.1159380 secs]
[GC 2918979K->2740244K(4650880K), 0.1249990 secs]
[GC 2996372K->2764312K(4650880K), 0.1186420 secs]
[GC 3020424K->2757638K(4650880K), 0.1176960 secs]
[GC 3013766K->2808465K(4650880K), 0.1126970 secs]
[GC 3064593K->2795608K(4650880K), 0.1123220 secs]
[GC 3051736K->2848955K(4650880K), 0.1112240 secs]
[GC 3105083K->2832769K(4650880K), 0.1147200 secs]
[GC 3088861K->2890355K(4650880K), 0.1078540 secs]
[GC 3146483K->2872558K(4650880K), 0.1129150 secs]
[GC 3128686K->2923770K(4650880K), 0.1242010 secs]
[GC 3179898K->2934760K(4650880K), 0.1052660 secs]
[GC 3190888K->2957905K(4650880K), 0.1060610 secs]
[GC 3214033K->2979570K(4650880K), 0.1083590 secs]
[GC 3234303K->2997155K(4650880K), 0.1062170 secs]
[GC 3253283K->2998641K(4650880K), 0.1093040 secs]
[GC 3254769K->3039721K(4650880K), 0.1052300 secs]
[GC 3295828K->3060480K(4650880K), 0.1119070 secs]
[GC 3316608K->3060802K(4650880K), 0.1064560 secs]
[GC 3316342K->3097790K(4650880K), 0.1102440 secs]
[GC 3353888K->3122157K(4650880K), 0.1086610 secs]
[GC 3378285K->3144182K(4650880K), 0.1077730 secs]
[GC 3400310K->3162626K(4650880K), 0.1051530 secs]
[GC 3418754K->3166333K(4650880K), 0.1040590 secs]
[GC 3422461K->3189705K(4650880K), 0.1077550 secs]
[GC 3445833K->3226903K(4650880K), 0.1062620 secs]
[GC 3483031K->3253020K(4650880K), 0.1056100 secs]
[GC 3509148K->3268280K(4650880K), 0.1074970 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.3G, free=1.1G, total=4.4G, max=4.7G, used/total=75.43% used/max=71.50%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=333.00%
[GC 3524408K->3290270K(4650880K), 0.1105570 secs]
[GC 3546398K->3308098K(4650880K), 0.1015320 secs]
[GC 3562314K->3331628K(4650880K), 0.1088460 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.3G, free=1.1G, total=4.4G, max=4.7G, used/total=74.56% used/max=70.68%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=329.00%
[GC 3587756K->3351298K(4650880K), 0.1131930 secs]
[GC 3607426K->3372896K(4650880K), 0.1095150 secs]
[GC 3627302K->3375455K(4650880K), 0.1044220 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.4G, free=1.1G, total=4.4G, max=4.7G, used/total=75.97% used/max=72.01%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=285.00%
[GC 3631583K->3394137K(4650880K), 0.1128400 secs]
[GC 3650265K->3417721K(4650880K), 0.1053160 secs]
[GC 3673849K->3467659K(4650880K), 0.1174800 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.4G, free=1015.1M, total=4.4G, max=4.7G, used/total=77.65% used/max=73.60%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=310.00%
[GC 3723787K->3453748K(4650880K), 0.1067670 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.3G, free=1.1G, total=4.4G, max=4.7G, used/total=74.83% used/max=70.93%
cpu process-load=1.00%, system-load=10.00%, system-loadaverage=263.00%
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.4G, free=1.1G, total=4.4G, max=4.7G, used/total=76.20% used/max=72.23%
cpu process-load=1.00%, system-load=9.00%, system-loadaverage=222.00%
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.4G, free=1015.2M, total=4.4G, max=4.7G, used/total=77.65% used/max=73.60%
cpu process-load=1.00%, system-load=9.00%, system-loadaverage=188.00%
[GC 3709876K->3498496K(4650880K), 0.1132750 secs]
[GC 3754624K->3511773K(4650880K), 0.1073340 secs]
[GC 3767901K->3538772K(4650880K), 0.1136130 secs]
[GC 3794900K->3554652K(4650880K), 0.1050300 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.4G, free=1015.2M, total=4.4G, max=4.7G, used/total=77.65% used/max=73.60%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=228.00%
[GC 3810780K->3593062K(4650880K), 0.1044620 secs]
[GC 3849190K->3589867K(4650880K), 0.1092790 secs]
[GC 3845995K->3633795K(4650880K), 0.1014760 secs]
[GC 3889314K->3620525K(4650880K), 0.1001720 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.5G, free=971.7M, total=4.4G, max=4.7G, used/total=78.61% used/max=74.51%
cpu process-load=1.00%, system-load=13.00%, system-loadaverage=240.00%
[GC 3876653K->3658163K(4650880K), 0.0992040 secs]
[GC 3914291K->3664373K(4650880K), 0.1029180 secs]
[GC 3920501K->3700257K(4650880K), 0.1044250 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.7G, free=724.8M, total=4.4G, max=4.7G, used/total=84.04% used/max=79.66%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=264.00%
[GC 3956385K->3705898K(4650880K), 0.1054670 secs]
[GC 3961633K->3741405K(4650880K), 0.1005240 secs]
[GC 3996930K->3743216K(4650880K), 0.1052100 secs]
[GC 3998401K->3781979K(4650880K), 0.1046300 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.8G, free=681.9M, total=4.4G, max=4.7G, used/total=84.99% used/max=80.56%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=279.00%
[GC 4036045K->3800720K(4650880K), 0.1042200 secs]
[GC 4056793K->3803486K(4650880K), 0.0974790 secs]
[GC 4059611K->3841716K(4650880K), 0.1035710 secs]
[GC 4097844K->3863869K(4650880K), 0.1001540 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.8G, free=678.2M, total=4.4G, max=4.7G, used/total=85.07% used/max=80.63%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=372.00%
[GC 4119997K->3885072K(4650880K), 0.1053670 secs]
[GC 4141200K->3919422K(4650880K), 0.0948110 secs]
[GC 4175550K->3907302K(4650880K), 0.1062520 secs]
[GC 4163430K->3928345K(4650880K), 0.1029940 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5707 [FenixFrameworkGroup] 
memory used=3.7G, free=705.2M, total=4.4G, max=4.7G, used/total=84.47% used/max=80.07%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=393.00%
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5707 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5707 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5707 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 53 ms.
