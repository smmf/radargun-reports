/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-16531 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-16531
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0701460 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 9. Sleeping for 9500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 9
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2ca44b35
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5710, using socket ServerSocket[addr=/0.0.0.0,localport=5710], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5710
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5710 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5710 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 53174 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 35688 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 50126 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5710 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43678
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:43678
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36201
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:36201
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 55786 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 37183 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 45755 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 33207 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5710 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 36806 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 38030 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:54362
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:54362
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5710 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:49920
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5710 [FenixFrameworkGroup] 5710 accepted socket connection from /127.0.0.1:49920
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5710 [FenixFrameworkGroup] Address[127.0.0.1]:5710 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 9
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=9, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 9
[GC 259695K->13049K(2944064K), 0.0434810 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|6] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660, deimos-esw-47278, deimos-esw-57185, deimos-esw-33880, deimos-esw-45371]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-45371, physical addresses are [127.0.0.1:52009]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 9, serverOidBase: 9000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 9: org.radargun.cachewrappers.FFWrapper@6328d38b
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 6
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6328d38b, nodeIndex=9, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269113K->22306K(2944064K), 0.0590640 secs]
[GC 278370K->32965K(2944064K), 0.0476220 secs]
[GC 289029K->47384K(2944064K), 0.0539030 secs]
[GC 303448K->75344K(2944064K), 0.0620570 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 331408K->84081K(2944064K), 0.0560860 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 10850. Elapsed time: 20.190 secs. Remaining: 39.810 secs. Total: 1 mins 0 secs
[GC 340145K->120723K(2944064K), 0.0658670 secs]
[GC 376787K->114949K(2944064K), 0.1558610 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 28100. Elapsed time: 40.244 secs. Remaining: 19.756 secs. Total: 1 mins 0 secs
[GC 371013K->142141K(2944064K), 0.0844140 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 48150. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 30 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 150 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 398205K->155083K(2944064K), 0.0796200 secs]
[GC 411147K->189511K(2944064K), 0.0784060 secs]
[GC 445575K->201714K(2944064K), 0.0918030 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,700,701 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 243362K->163726K(2944064K), 0.7082750 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,779,242 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6328d38b, nodeIndex=9, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 419854K->241151K(2944192K), 0.0370740 secs]
[GC 497279K->184826K(2944192K), 0.0423090 secs]
[GC 440954K->201432K(2944192K), 0.0588370 secs]
[GC 457560K->213215K(2944192K), 0.0696930 secs]
[GC 469343K->229280K(2944192K), 0.0868880 secs]
[GC 485408K->245181K(2944192K), 0.0882130 secs]
[GC 501309K->261044K(2944192K), 0.1112980 secs]
[GC 517172K->276352K(2944192K), 0.1111950 secs]
[GC 532480K->252854K(2944192K), 0.1491500 secs]
[GC 508982K->314288K(2944192K), 0.1414910 secs]
[GC 568673K->295782K(2944192K), 0.0972760 secs]
[GC 551910K->333105K(2944192K), 0.1168320 secs]
[GC 589012K->355120K(2944192K), 0.1036320 secs]
[GC 611248K->373915K(2944192K), 0.0980220 secs]
[GC 630036K->359530K(2944192K), 0.0823650 secs]
[GC 615658K->409491K(2944192K), 0.0835660 secs]
[GC 665618K->415082K(2944192K), 0.0782260 secs]
[GC 671210K->464346K(2944192K), 0.0904220 secs]
[GC 720474K->453213K(2944192K), 0.0793080 secs]
[GC 709341K->487681K(2944192K), 0.0996250 secs]
[GC 743809K->490978K(2944192K), 0.0820840 secs]
[GC 745327K->540712K(2944192K), 0.0815550 secs]
[GC 795194K->525017K(2944192K), 0.0829670 secs]
[GC 781145K->581498K(2944192K), 0.0762480 secs]
[GC 837615K->558784K(2944192K), 0.0756590 secs]
[GC 814912K->620145K(2944192K), 0.0816070 secs]
[GC 876265K->600696K(2944192K), 0.0839420 secs]
[GC 856824K->659495K(2944192K), 0.0836590 secs]
[GC 914017K->640691K(2944192K), 0.0988110 secs]
[GC 896819K->699657K(2944192K), 0.0949200 secs]
[GC 955785K->681455K(2944192K), 0.0889040 secs]
[GC 937583K->675617K(2944192K), 0.0797170 secs]
[GC 931745K->726863K(2944192K), 0.0584030 secs]
[GC 982991K->689098K(2944192K), 0.0662990 secs]
[GC 945226K->701304K(2944192K), 0.0848890 secs]
[GC 957432K->751591K(2944192K), 0.0653860 secs]
[GC 1007719K->734496K(2944192K), 0.0830180 secs]
[GC 990624K->787299K(2944192K), 0.1022560 secs]
[GC 1043427K->759342K(2944192K), 0.1551000 secs]
[GC 1015452K->765832K(2944192K), 0.1356800 secs]
[GC 1020736K->817017K(2944192K), 0.0852980 secs]
[GC 1073145K->837143K(2944192K), 0.0842800 secs]
[GC 1093256K->858708K(2944192K), 0.0760700 secs]
[GC 1114836K->873325K(2944192K), 0.0830780 secs]
[GC 1129453K->881576K(2944192K), 0.0830380 secs]
[GC 1137505K->912661K(2944192K), 0.0819770 secs]
[GC 1168789K->930999K(2944192K), 0.0812490 secs]
[GC 1187074K->934864K(2944192K), 0.0791750 secs]
[GC 1190992K->991982K(2944192K), 0.0825300 secs]
[GC 1248110K->971657K(2944192K), 0.0792450 secs]
[GC 1227728K->1029944K(2944192K), 0.0804800 secs]
[GC 1284200K->1007283K(2944192K), 0.0842300 secs]
[GC 1263411K->1061472K(2944192K), 0.0834280 secs]
[GC 1317600K->1042735K(2944192K), 0.0801240 secs]
[GC 1297965K->1105091K(2944192K), 0.0836100 secs]
[GC 1361219K->1081840K(2944192K), 0.0842140 secs]
[GC 1337941K->1127145K(2944192K), 0.0787580 secs]
[GC 1383273K->1152043K(2944192K), 0.0828360 secs]
[GC 1408171K->1144692K(2944192K), 0.0805020 secs]
[GC 1400819K->1142512K(2944192K), 0.0764500 secs]
[GC 1398640K->1183043K(2944192K), 0.0639200 secs]
[GC 1439171K->1163350K(2944192K), 0.0832680 secs]
[GC 1419478K->1183781K(2944192K), 0.0665040 secs]
[GC 1439909K->1182895K(2944192K), 0.0791220 secs]
[GC 1439023K->1208573K(2944192K), 0.0639440 secs]
[GC 1464701K->1229574K(2944192K), 0.0698950 secs]
[GC 1485702K->1213030K(2944192K), 0.0723680 secs]
[GC 1469158K->1225295K(2944192K), 0.0881870 secs]
[GC 1481423K->1222415K(2944192K), 0.1527970 secs]
[GC 1478543K->1230680K(2944192K), 0.0885430 secs]
[GC 1486808K->1254844K(2944192K), 0.0811120 secs]
[GC 1510972K->1262198K(2944192K), 0.1001460 secs]
[GC 1518326K->1272765K(2944192K), 0.0967080 secs]
[GC 1528893K->1264139K(2944192K), 0.0822740 secs]
[GC 1520267K->1305474K(2944192K), 0.0807330 secs]
[GC 1561602K->1279432K(2944192K), 0.1054980 secs]
[GC 1535560K->1313264K(2944192K), 0.1415790 secs]
[GC 1569392K->1311381K(2944192K), 0.0805370 secs]
[GC 1567509K->1319799K(2944192K), 0.1445730 secs]
[GC 1575927K->1330163K(2944192K), 0.1478100 secs]
[GC 1586291K->1337664K(2944192K), 0.1459530 secs]
[GC 1593792K->1343987K(2944192K), 0.1530520 secs]
[GC 1600115K->1349812K(2944192K), 0.0777320 secs]
[GC 1605940K->1358751K(2944192K), 0.0827490 secs]
[GC 1614879K->1349213K(2944192K), 0.0794110 secs]
[GC 1605341K->1372480K(2944192K), 0.1445560 secs]
[GC 1628608K->1382166K(2944192K), 0.0987420 secs]
[GC 1383398K(2944192K), 0.0568730 secs]
[GC 1450180K(2944192K), 0.0505180 secs]
[GC 1411822K->1162581K(2944192K), 0.0788810 secs]
[GC 1418709K->1173796K(2944192K), 0.0682420 secs]
[GC 1429924K->1187907K(2944192K), 0.0809310 secs]
[GC 1444035K->1182417K(2944192K), 0.0802430 secs]
[GC 1438545K->1189894K(2944192K), 0.0779470 secs]
[GC 1446022K->1196352K(2944192K), 0.0763650 secs]
[GC 1452480K->1202469K(2944192K), 0.0831950 secs]
[GC 1458597K->1194059K(2944192K), 0.0838740 secs]
[GC 1450187K->1218344K(2944192K), 0.0802770 secs]
[GC 1474472K->1224091K(2944192K), 0.0798070 secs]
[GC 1480219K->1251023K(2944192K), 0.0793210 secs]
[GC 1507151K->1223248K(2944192K), 0.0781090 secs]
 INFO  [Stressor-3] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=299252 <= mostRecentNum=299255.
 INFO  [Stressor-3] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=299253 <= mostRecentNum=299255.
[GC 1479376K->1252331K(2944192K), 0.0791750 secs]
[GC 1508459K->1266794K(2944192K), 0.0848100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1522897K->1285048K(2944192K), 0.0879040 secs]
[GC 1540550K->1306374K(2944192K), 0.1058020 secs]
[GC 1562502K->1330952K(2944192K), 0.0997180 secs]
[GC 1586158K->1336482K(2944192K), 0.0846580 secs]
[GC 1592610K->1342612K(2944192K), 0.0959870 secs]
[GC 1598740K->1354513K(2944192K), 0.0768210 secs]
[GC 1610641K->1422443K(2944192K), 0.0848450 secs]
[GC 1678549K->1436890K(2944192K), 0.0752610 secs]
[GC 1693018K->1419095K(2944192K), 0.0608590 secs]
[GC 1675223K->1456591K(2944192K), 0.0618350 secs]
[GC 1712719K->1489387K(2944192K), 0.0763480 secs]
[GC 1744686K->1483907K(2944192K), 0.0677310 secs]
[GC 1740035K->1504476K(2944192K), 0.0676970 secs]
[GC 1759348K->1524668K(2944192K), 0.0684360 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 4180058. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 1780767K->1535251K(2944192K), 0.0745430 secs]
[GC 1791379K->1610446K(2944192K), 0.0753270 secs]
[GC 1866574K->1583895K(2944192K), 0.0687130 secs]
[GC 1840023K->1623027K(2944192K), 0.0960940 secs]
[GC 1879155K->1674984K(2944192K), 0.0840860 secs]
[GC 1931112K->1665192K(2944192K), 0.0791670 secs]
[GC 1918779K->1698035K(2944192K), 0.0823350 secs]
[GC 1954163K->1706900K(2944192K), 0.0659410 secs]
[GC 1963022K->1724665K(2944192K), 0.0651410 secs]
[GC 1980793K->1712894K(2944192K), 0.0606440 secs]
[GC 1969022K->1724848K(2944192K), 0.0483230 secs]
[GC 1980976K->1757506K(2944192K), 0.0636640 secs]
[GC 2013618K->1754605K(2944192K), 0.0904370 secs]
[GC 2010733K->1785359K(2944192K), 0.0551360 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7420000. Elapsed time: 40.026 secs. Remaining: 19.974 secs. Total: 1 mins 0 secs
[GC 2041487K->1827986K(2944192K), 0.0746230 secs]
[GC 2084114K->1838091K(2944192K), 0.0869340 secs]
[GC 2094219K->1849207K(2944192K), 0.0737930 secs]
[GC 2105335K->1865182K(2944192K), 0.0693900 secs]
[GC 2121310K->1891349K(2944192K), 0.0741510 secs]
[GC 2147477K->1910783K(2944192K), 0.0732740 secs]
[GC 2166911K->1898605K(2944192K), 0.0698930 secs]
[GC 2154733K->1922823K(2944192K), 0.0532860 secs]
[GC 2175621K->1928653K(2944192K), 0.0660780 secs]
[GC 2184504K->1989082K(2944192K), 0.0744230 secs]
[GC 2245210K->1986404K(2944192K), 0.1033640 secs]
[GC 2241140K->2014993K(2944192K), 0.0675800 secs]
[GC 2271071K->2045383K(2944192K), 0.0827800 secs]
[GC 2301511K->2043479K(2944192K), 0.0579950 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 10680000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 27 mins 8 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:9, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2299607K->2031919K(2944192K), 0.0507800 secs]
[GC 2288047K->2045292K(2944192K), 0.0586010 secs]
[GC 2300246K->2056914K(2944192K), 0.0796180 secs]
[GC 2313042K->2114030K(2944192K), 0.0905280 secs]
[GC 2370158K->2115058K(2944192K), 0.1207870 secs]
[GC 2371186K->2151106K(2944192K), 0.0973810 secs]
[GC 2405688K->2151540K(2944192K), 0.0943800 secs]
[GC 2407668K->2174333K(2944192K), 0.0889280 secs]
[GC 2429899K->2210723K(2944192K), 0.0962500 secs]
[GC 2466845K->2230678K(2944192K), 0.0945900 secs]
[GC 2486806K->2268044K(2944192K), 0.0911760 secs]
[GC 2523068K->2252604K(2944192K), 0.1004350 secs]
[GC 2508717K->2308388K(2944192K), 0.0966970 secs]
[GC 2564516K->2301687K(2944192K), 0.0967400 secs]
[GC 2557804K->2343063K(2944192K), 0.0986640 secs]
[GC 2599191K->2369689K(2944192K), 0.0998680 secs]
[GC 2625555K->2354610K(2944192K), 0.1015820 secs]
[GC 2610738K->2410355K(2944192K), 0.0973670 secs]
[GC 2666483K->2393418K(2944192K), 0.0895080 secs]
[GC 2649546K->2456396K(2944192K), 0.0990880 secs]
[GC 2712517K->2443620K(2944192K), 0.1016800 secs]
[GC 2699742K->2494975K(2944192K), 0.0904900 secs]
[GC 2495493K(2944192K), 0.0382830 secs]
[GC 2751103K->2477006K(2944192K), 0.1019400 secs]
[GC 2607757K(2944192K), 0.0488060 secs]
[GC 2100119K->1897894K(3312520K), 0.1108170 secs]
[GC 2154022K->1926218K(3312520K), 0.1057560 secs]
[GC 2182346K->1913179K(3312520K), 0.0936280 secs]
[GC 2169305K->1967100K(3312520K), 0.0920940 secs]
[GC 2223228K->1950744K(3312520K), 0.0939400 secs]
[GC 2206872K->2008704K(3312520K), 0.0897690 secs]
[GC 2264832K->1990204K(3312520K), 0.0993080 secs]
[GC 2246280K->2043607K(3312520K), 0.1000950 secs]
[GC 2299735K->2055648K(3312520K), 0.0996890 secs]
[GC 2311776K->2091389K(3312520K), 0.0985210 secs]
[GC 2347506K->2104320K(3312520K), 0.1055450 secs]
[GC 2360448K->2125473K(3312520K), 0.1014910 secs]
[GC 2381601K->2151824K(3312520K), 0.1067020 secs]
[GC 2407952K->2136870K(3312520K), 0.1151020 secs]
[GC 2392998K->2156238K(3312520K), 0.1045190 secs]
[GC 2412366K->2174966K(3312520K), 0.1044190 secs]
[GC 2431094K->2217051K(3312520K), 0.0886320 secs]
[GC 2473179K->2202888K(3312520K), 0.1058390 secs]
[GC 2458977K->2236562K(3312520K), 0.1029600 secs]
[GC 2492690K->2284128K(3312520K), 0.1339200 secs]
[GC 2540256K->2285251K(3312520K), 0.1114920 secs]
[GC 2541379K->2300727K(3312520K), 0.1033780 secs]
[GC 2555398K->2321659K(3312520K), 0.1044890 secs]
[GC 2577787K->2340985K(3312520K), 0.0984170 secs]
[GC 2595826K->2359306K(3312520K), 0.1035450 secs]
[GC 2615434K->2398904K(3312520K), 0.1083560 secs]
[GC 2654902K->2399387K(3312520K), 0.0986440 secs]
[GC 2655515K->2421274K(3312520K), 0.0928460 secs]
[GC 2677402K->2440429K(3312520K), 0.1050320 secs]
[GC 2695484K->2480536K(3312520K), 0.1007660 secs]
[GC 2736664K->2481553K(3312520K), 0.0960590 secs]
[GC 2737681K->2520772K(3312520K), 0.0910290 secs]
[GC 2776425K->2555883K(3312520K), 0.0934170 secs]
[GC 2812011K->2542070K(3312520K), 0.0941910 secs]
[GC 2796457K->2589981K(3312520K), 0.0955590 secs]
[GC 2845717K->2599575K(3312520K), 0.0978710 secs]
[GC 2855703K->2621936K(3312520K), 0.0965050 secs]
[GC 2878064K->2653048K(3312520K), 0.1031700 secs]
[GC 2908181K->2684520K(3312520K), 0.0987450 secs]
[GC 2940648K->2668824K(3312520K), 0.0982130 secs]
[GC 2924952K->2719151K(3312520K), 0.1018650 secs]
[GC 2975279K->2727815K(3312520K), 0.1012200 secs]
[GC 2983943K->2734626K(3312520K), 0.0948320 secs]
[GC 2990754K->2770749K(3312520K), 0.0916140 secs]
[GC 3026877K->2808527K(3312520K), 0.1038010 secs]
[GC 3062568K->2815595K(3312520K), 0.0975190 secs]
[GC 2817767K(3312520K), 0.0399370 secs]
[GC 3071674K->2814973K(3312520K), 0.0948440 secs]
[GC 2958450K(3312520K), 0.0539940 secs]
[GC 2848292K->2629043K(4547300K), 0.1192790 secs]
[GC 2884373K->2634046K(4547300K), 0.1195380 secs]
[GC 2890174K->2672322K(4547300K), 0.1070680 secs]
[GC 2928450K->2693847K(4547300K), 0.1098740 secs]
[GC 2949975K->2698541K(4547300K), 0.1022070 secs]
[GC 2954488K->2714696K(4547300K), 0.1132330 secs]
[GC 2970711K->2753778K(4547300K), 0.1182380 secs]
[GC 3009906K->2791832K(4547300K), 0.1076920 secs]
[GC 3047960K->2803822K(4547300K), 0.1129100 secs]
[GC 3059596K->2825298K(4547300K), 0.1176310 secs]
[GC 3081420K->2826359K(4547300K), 0.1060350 secs]
[GC 3082487K->2845994K(4547300K), 0.1146090 secs]
[GC 3102088K->2886335K(4547300K), 0.1103850 secs]
[GC 3142463K->2889632K(4547300K), 0.1017930 secs]
[GC 3144201K->2926221K(4547300K), 0.1228320 secs]
[GC 3182349K->2961843K(4547300K), 0.1166670 secs]
[GC 3217971K->2949822K(4547300K), 0.1158530 secs]
[GC 3205947K->3002489K(4547300K), 0.1046370 secs]
[GC 3258571K->2984843K(4547300K), 0.1047660 secs]
[GC 3240971K->3043328K(4547300K), 0.1083510 secs]
[GC 3299456K->3026327K(4547300K), 0.1105090 secs]
[GC 3282455K->3077400K(4547300K), 0.1022160 secs]
[GC 3333528K->3104958K(4547300K), 0.1178150 secs]
[GC 3360854K->3109359K(4547300K), 0.1142000 secs]
[GC 3365487K->3130509K(4547300K), 0.1059180 secs]
[GC 3385257K->3131469K(4547300K), 0.1092030 secs]
[GC 3387566K->3172796K(4547300K), 0.1046040 secs]
[GC 3428924K->3196884K(4547300K), 0.1067530 secs]
[GC 3453012K->3228335K(4547300K), 0.1007880 secs]
[GC 3484463K->3253063K(4547300K), 0.1112380 secs]
[GC 3508942K->3241444K(4547300K), 0.1125170 secs]
[GC 3497572K->3262818K(4547300K), 0.1044430 secs]
[GC 3518946K->3300447K(4547300K), 0.1105170 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.4G, free=968.3M, total=4.3G, max=4.7G, used/total=78.20% used/max=72.47%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=333.00%
[GC 3556537K->3319478K(4547300K), 0.0974670 secs]
[GC 3575606K->3341153K(4547300K), 0.0972100 secs]
[GC 3597281K->3342764K(4547300K), 0.1043290 secs]
[GC 3598357K->3384028K(4547300K), 0.1103110 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.3G, free=1022.8M, total=4.3G, max=4.7G, used/total=76.97% used/max=71.33%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=329.00%
[GC 3640156K->3417017K(4547300K), 0.1019410 secs]
[GC 3673145K->3402514K(4547300K), 0.1032480 secs]
[GC 3658156K->3450021K(4547300K), 0.1063210 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.4G, free=916.0M, total=4.3G, max=4.7G, used/total=79.37% used/max=73.56%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=285.00%
[GC 3706149K->3478441K(4547300K), 0.0989200 secs]
[GC 3734569K->3465547K(4547300K), 0.1030920 secs]
[GC 3721660K->3518781K(4547300K), 0.0954890 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.5G, free=865.6M, total=4.3G, max=4.7G, used/total=80.51% used/max=74.61%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=310.00%
[GC 3774909K->3502510K(4547300K), 0.0945990 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.3G, free=1013.3M, total=4.3G, max=4.7G, used/total=77.18% used/max=71.53%
cpu process-load=1.00%, system-load=10.00%, system-loadaverage=263.00%
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.4G, free=950.8M, total=4.3G, max=4.7G, used/total=78.59% used/max=72.83%
cpu process-load=1.00%, system-load=9.00%, system-loadaverage=222.00%
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.5G, free=884.5M, total=4.3G, max=4.7G, used/total=80.08% used/max=74.22%
cpu process-load=1.00%, system-load=9.00%, system-loadaverage=188.00%
[GC 3758638K->3548590K(4547300K), 0.1019450 secs]
[GC 3804718K->3547558K(4547300K), 0.1019750 secs]
[GC 3803686K->3588287K(4547300K), 0.1955040 secs]
[GC 3844415K->3615356K(4547300K), 0.1020480 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.5G, free=846.1M, total=4.3G, max=4.7G, used/total=80.95% used/max=75.02%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=228.00%
[GC 3871484K->3630245K(4547300K), 0.0990590 secs]
[GC 3886373K->3651620K(4547300K), 0.1067510 secs]
[GC 3907748K->3685541K(4547300K), 0.1099070 secs]
[GC 3940987K->3675037K(4547300K), 0.0980140 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.6G, free=795.6M, total=4.3G, max=4.7G, used/total=82.08% used/max=76.07%
cpu process-load=1.00%, system-load=13.00%, system-loadaverage=240.00%
[GC 3931165K->3695050K(4547300K), 0.0971190 secs]
[GC 3951178K->3730539K(4547300K), 0.0980830 secs]
[GC 3986667K->3754004K(4547300K), 0.0964320 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.8G, free=555.1M, total=4.3G, max=4.7G, used/total=87.50% used/max=81.09%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=264.00%
[GC 4010132K->3755547K(4547300K), 0.1054850 secs]
[GC 4011108K->3792390K(4547300K), 0.0980040 secs]
[GC 4048113K->3794250K(4547300K), 0.0991700 secs]
[GC 4050378K->3818476K(4547300K), 0.1042250 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.8G, free=545.6M, total=4.3G, max=4.7G, used/total=87.71% used/max=81.29%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=279.00%
[GC 4074059K->3850617K(4547300K), 0.0971570 secs]
[GC 4105203K->3854396K(4547300K), 0.1002490 secs]
[GC 4110524K->3894325K(4547300K), 0.1033390 secs]
[GC 4150397K->3895630K(4547300K), 0.0950430 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.8G, free=520.7M, total=4.3G, max=4.7G, used/total=88.27% used/max=81.81%
cpu process-load=1.00%, system-load=16.00%, system-loadaverage=372.00%
[GC 4151758K->3950355K(4547300K), 0.0904940 secs]
[GC 4206483K->3935903K(4547300K), 0.0925320 secs]
[GC 3936720K(4547300K), 0.0405250 secs]
[GC 4192031K->3991247K(4547300K), 0.0949020 secs]
[GC 4247375K->3979735K(4547300K), 0.0997480 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5710 [FenixFrameworkGroup] 
memory used=3.8G, free=553.6M, total=4.3G, max=4.7G, used/total=87.53% used/max=81.12%
cpu process-load=2.00%, system-load=14.00%, system-loadaverage=393.00%
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5710 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5710 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5710 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 57 ms.
