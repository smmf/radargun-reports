/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-25587 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-25587
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0736450 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Startup staggering, number of slaves to start is 12 This is the slave with index 0, not sleeping
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@54266750
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5701, using socket ServerSocket[addr=/0.0.0.0,localport=5701], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5701
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5702. Reason: ConnectException[Connection refused]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5703. Reason: ConnectException[Connection refused]
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.cluster.MulticastJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTED
 INFO  [pool-1-thread-1] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Initializing cluster partition table first arrangement...
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is the first node!
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 0
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|0] [deimos-esw-45070]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-45070, physical addresses are [127.0.0.1:52000]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:55571
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:55571
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker not present. Data Grid is being initialized for the first time.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 0, serverOidBase: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.DomainRoot} Created DomainRoot instance
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Notify other nodes that startup completed
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:59887
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59887
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:39481
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:39481
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:47631
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:47631
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:46656
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:46656
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:42320
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:42320
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:40397
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:40397
[GC 259695K->20906K(2944064K), 0.0550090 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:59317
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59317
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:36547
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:36547
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:42476
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:42476
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:46083
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:46083
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 12
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5701 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701 this
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 249
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 0: org.radargun.cachewrappers.FFWrapper@2a3df98e
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] All migration tasks has been completed, queues are empty.
 INFO  [Incoming-1,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|1] [deimos-esw-45070, deimos-esw-19293]
 INFO  [Incoming-3,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|2] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066]
[GC 276970K->13650K(2944064K), 0.0310460 secs]
 INFO  [Incoming-4,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|3] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409]
 INFO  [Incoming-4,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|4] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516]
 INFO  [Incoming-4,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|5] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476]
 INFO  [Incoming-4,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|6] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476, deimos-esw-14407]
 INFO  [Incoming-4,deimos-esw-45070] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|7] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476, deimos-esw-14407, deimos-esw-26378, deimos-esw-12182]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2a3df98e, nodeIndex=0, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269714K->23783K(2944064K), 0.0450790 secs]
[GC 279847K->38077K(2944064K), 0.0477910 secs]
[GC 294141K->52416K(2944064K), 0.0503700 secs]
[GC 308480K->77570K(2944064K), 0.0571130 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 333634K->100175K(2944064K), 0.0588990 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8600. Elapsed time: 20.072 secs. Remaining: 39.928 secs. Total: 1 mins 0 secs
[GC 356239K->101558K(2944064K), 0.0979530 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15800. Elapsed time: 40.074 secs. Remaining: 19.926 secs. Total: 1 mins 0 secs
[GC 357622K->104866K(2944064K), 0.0815760 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 24450. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 43 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 163 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 360930K->121340K(2944064K), 0.0746680 secs]
[GC 377404K->148941K(2944064K), 0.0818200 secs]
[GC 405005K->168055K(2944064K), 0.0828070 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,765,039 kb - max:4,906,688 kb- total:2,944,064 kb
 WARN  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Fenix Framework never forgets...
[Full GC 179024K->147533K(2944064K), 0.5920230 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,795,835 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@2a3df98e, nodeIndex=0, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 403661K->223098K(2944192K), 0.0305200 secs]
[GC 479226K->167910K(2944192K), 0.0364390 secs]
[GC 424038K->179979K(2944192K), 0.0366710 secs]
[GC 436107K->188931K(2944192K), 0.0425390 secs]
[GC 445059K->201397K(2944192K), 0.0428610 secs]
[GC 457525K->215589K(2944192K), 0.0572900 secs]
[GC 471717K->230405K(2944192K), 0.0628960 secs]
[GC 486533K->232803K(2944192K), 0.0750330 secs]
[GC 488931K->245455K(2944192K), 0.0812030 secs]
[GC 501583K->234422K(2944192K), 0.1008930 secs]
[GC 490516K->275387K(2944192K), 0.0742730 secs]
[GC 529907K->297079K(2944192K), 0.0867390 secs]
[GC 553207K->317341K(2944192K), 0.0900030 secs]
[GC 573469K->319570K(2944192K), 0.1127610 secs]
[GC 575698K->349062K(2944192K), 0.0870600 secs]
[GC 605190K->349820K(2944192K), 0.0836760 secs]
[GC 604325K->366203K(2944192K), 0.0892960 secs]
[GC 622331K->420337K(2944192K), 0.0846700 secs]
[GC 676465K->401531K(2944192K), 0.0792100 secs]
[GC 657659K->459073K(2944192K), 0.0816970 secs]
[GC 715168K->434630K(2944192K), 0.0791300 secs]
[GC 690444K->493810K(2944192K), 0.0815140 secs]
[GC 749938K->468685K(2944192K), 0.0781820 secs]
[GC 723286K->519655K(2944192K), 0.0741770 secs]
[GC 774758K->542660K(2944192K), 0.0759980 secs]
[GC 798788K->528624K(2944192K), 0.0790180 secs]
[GC 784752K->588999K(2944192K), 0.0771050 secs]
[GC 845127K->565463K(2944192K), 0.0847560 secs]
[GC 821591K->625560K(2944192K), 0.0867430 secs]
[GC 881426K->602060K(2944192K), 0.0837040 secs]
[GC 858188K->650397K(2944192K), 0.0882940 secs]
[GC 906525K->627928K(2944192K), 0.0918860 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 884056K->683178K(2944192K), 0.0610360 secs]
[GC 939306K->662452K(2944192K), 0.0851670 secs]
[GC 918580K->680230K(2944192K), 0.0608880 secs]
[GC 936358K->681824K(2944192K), 0.0652930 secs]
[GC 937917K->671706K(2944192K), 0.0838710 secs]
[GC 926898K->716531K(2944192K), 0.0681810 secs]
[GC 972620K->730098K(2944192K), 0.0780110 secs]
[GC 985956K->740585K(2944192K), 0.1523360 secs]
[GC 995261K->754581K(2944192K), 0.1198490 secs]
[GC 1008726K->782365K(2944192K), 0.0892460 secs]
[GC 1037245K->798021K(2944192K), 0.0863760 secs]
[GC 1052654K->798696K(2944192K), 0.0873310 secs]
[GC 1053784K->833918K(2944192K), 0.0835150 secs]
[GC 1089130K->852542K(2944192K), 0.0833170 secs]
[GC 1108380K->871402K(2944192K), 0.0840440 secs]
[GC 1127530K->889553K(2944192K), 0.0858220 secs]
[GC 1145124K->924042K(2944192K), 0.0825340 secs]
[GC 1179324K->909550K(2944192K), 0.0794790 secs]
[GC 1164534K->951449K(2944192K), 0.0859150 secs]
[GC 1207577K->962946K(2944192K), 0.0873060 secs]
[GC 1219074K->999339K(2944192K), 0.1080070 secs]
[GC 1255467K->984793K(2944192K), 0.0855420 secs]
[GC 1240921K->1027895K(2944192K), 0.0975120 secs]
[GC 1284023K->1021772K(2944192K), 0.0980420 secs]
[GC 1277900K->1060902K(2944192K), 0.1001680 secs]
[GC 1317030K->1074967K(2944192K), 0.0818520 secs]
[GC 1331095K->1060854K(2944192K), 0.0722020 secs]
[GC 1316982K->1097413K(2944192K), 0.0581710 secs]
[GC 1353541K->1078096K(2944192K), 0.0786770 secs]
[GC 1334224K->1095037K(2944192K), 0.0592100 secs]
[GC 1351165K->1124810K(2944192K), 0.0640670 secs]
[GC 1380938K->1098905K(2944192K), 0.0650590 secs]
[GC 1355033K->1100870K(2944192K), 0.0860290 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1356998K->1137681K(2944192K), 0.0592400 secs]
[GC 1393809K->1142551K(2944192K), 0.0622110 secs]
[GC 1398679K->1160894K(2944192K), 0.0773690 secs]
[GC 1417022K->1135050K(2944192K), 0.0723810 secs]
[GC 1391178K->1178247K(2944192K), 0.1331110 secs]
[GC 1434375K->1156202K(2944192K), 0.1233460 secs]
[GC 1412330K->1169676K(2944192K), 0.1244630 secs]
[GC 1425804K->1166097K(2944192K), 0.1463950 secs]
[GC 1422225K->1171745K(2944192K), 0.1300410 secs]
[GC 1427873K->1194267K(2944192K), 0.0884430 secs]
[GC 1450395K->1202877K(2944192K), 0.1452410 secs]
[GC 1459005K->1209782K(2944192K), 0.0775920 secs]
[GC 1465910K->1217185K(2944192K), 0.0785300 secs]
[GC 1473313K->1226721K(2944192K), 0.0759060 secs]
[GC 1482849K->1249786K(2944192K), 0.0854270 secs]
[GC 1505914K->1224184K(2944192K), 0.1391380 secs]
[GC 1480312K->1256247K(2944192K), 0.1092720 secs]
[GC 1512375K->1271903K(2944192K), 0.1039640 secs]
[GC 1528031K->1256193K(2944192K), 0.0887430 secs]
[GC 1512321K->1273910K(2944192K), 0.1444770 secs]
[GC 1530038K->1286603K(2944192K), 0.0764580 secs]
[GC 1542731K->1295072K(2944192K), 0.1104870 secs]
[GC 1551200K->1296707K(2944192K), 0.0818290 secs]
[GC 1552835K->1287683K(2944192K), 0.0828900 secs]
[GC 1543811K->1310171K(2944192K), 0.1436320 secs]
[GC 1566299K->1324217K(2944192K), 0.1326990 secs]
[GC 1580345K->1298842K(2944192K), 0.1781150 secs]
[GC 1554970K->1341014K(2944192K), 0.0714820 secs]
[GC 1597142K->1357230K(2944192K), 0.0796840 secs]
[GC 1613358K->1330784K(2944192K), 0.0934850 secs]
[GC 1586912K->1375989K(2944192K), 0.0821440 secs]
[GC 1632117K->1342030K(2944192K), 0.1510980 secs]
[GC 1598158K->1359305K(2944192K), 0.1417660 secs]
[GC 1615433K->1372522K(2944192K), 0.1535510 secs]
[GC 1628650K->1365963K(2944192K), 0.0823970 secs]
[GC 1366733K(2944192K), 0.0471290 secs]
[GC 1421080K(2944192K), 0.0441210 secs]
[GC 1401621K->1149479K(2944192K), 0.0706080 secs]
[GC 1405607K->1195164K(2944192K), 0.0697210 secs]
[GC 1451287K->1171175K(2944192K), 0.1055490 secs]
[GC 1427303K->1234111K(2944192K), 0.0933410 secs]
[GC 1490239K->1251894K(2944192K), 0.1027820 secs]
[GC 1508022K->1239964K(2944192K), 0.1087030 secs]
[GC 1496061K->1248169K(2944192K), 0.0847980 secs]
[GC 1504297K->1281129K(2944192K), 0.0827280 secs]
[GC 1537257K->1314277K(2944192K), 0.0829200 secs]
[GC 1570405K->1331393K(2944192K), 0.0853850 secs]
[GC 1587510K->1334861K(2944192K), 0.0884230 secs]
[GC 1590238K->1368867K(2944192K), 0.0888600 secs]
[GC 1624995K->1386369K(2944192K), 0.0902710 secs]
[GC 1642497K->1389922K(2944192K), 0.0899430 secs]
[GC 1646050K->1422876K(2944192K), 0.0897820 secs]
[GC 1678955K->1426984K(2944192K), 0.0896600 secs]
[GC 1683057K->1442905K(2944192K), 0.0837660 secs]
[GC 1699033K->1475582K(2944192K), 0.1021440 secs]
[GC 1731710K->1464493K(2944192K), 0.0799540 secs]
[GC 1720621K->1513670K(2944192K), 0.0665400 secs]
[GC 1769798K->1473013K(2944192K), 0.0677360 secs]
[GC 1729141K->1480731K(2944192K), 0.0903180 secs]
[GC 1736859K->1534490K(2944192K), 0.0721920 secs]
[GC 1790618K->1520851K(2944192K), 0.0831460 secs]
[GC 1776979K->1510939K(2944192K), 0.0625080 secs]
[GC 1767067K->1538425K(2944192K), 0.0662110 secs]
[GC 1794553K->1556959K(2944192K), 0.0681830 secs]
[GC 1813087K->1528773K(2944192K), 0.0811240 secs]
[GC 1784901K->1583340K(2944192K), 0.0843230 secs]
[GC 1839239K->1595618K(2944192K), 0.0991520 secs]
[GC 1851746K->1614207K(2944192K), 0.0961130 secs]
[GC 1869239K->1611116K(2944192K), 0.1106040 secs]
[GC 1867244K->1654117K(2944192K), 0.1003850 secs]
[GC 1909022K->1650106K(2944192K), 0.0910370 secs]
[GC 1904682K->1666302K(2944192K), 0.0927050 secs]
[GC 1922430K->1685482K(2944192K), 0.0880400 secs]
[GC 1941610K->1717317K(2944192K), 0.1160850 secs]
[GC 1973445K->1739823K(2944192K), 0.1230870 secs]
[GC 1995898K->1726137K(2944192K), 0.0879070 secs]
[GC 1982265K->1760277K(2944192K), 0.0917000 secs]
[GC 2016405K->1809403K(2944192K), 0.1014720 secs]
[GC 2065531K->1800244K(2944192K), 0.1018800 secs]
[GC 2056372K->1798835K(2944192K), 0.0935800 secs]
[GC 2054963K->1815521K(2944192K), 0.0963400 secs]
[GC 2071649K->1874638K(2944192K), 0.0764500 secs]
[GC 2130766K->1853362K(2944192K), 0.0934900 secs]
[GC 2109490K->1878094K(2944192K), 0.0785930 secs]
[GC 2134222K->1866737K(2944192K), 0.0881540 secs]
[GC 2122865K->1888289K(2944192K), 0.0679860 secs]
[GC 2144417K->1866695K(2944192K), 0.0756360 secs]
[GC 2122823K->1896807K(2944192K), 0.1133210 secs]
[GC 2152883K->1930501K(2944192K), 0.0772500 secs]
[GC 2185707K->1950637K(2944192K), 0.1281210 secs]
[GC 2206765K->1949767K(2944192K), 0.1049530 secs]
[GC 2204580K->1952637K(2944192K), 0.1045960 secs]
[GC 2208763K->1996734K(2944192K), 0.0960950 secs]
[GC 2252819K->1998454K(2944192K), 0.0923520 secs]
[GC 2254582K->2012772K(2944192K), 0.0890010 secs]
[GC 2268444K->2033230K(2944192K), 0.0925930 secs]
[GC 2289358K->2053202K(2944192K), 0.0895220 secs]
[GC 2309330K->2083109K(2944192K), 0.1069530 secs]
[GC 2339192K->2069658K(2944192K), 0.0917090 secs]
[GC 2325786K->2122097K(2944192K), 0.0909990 secs]
[GC 2378224K->2138728K(2944192K), 0.0929150 secs]
[GC 2394856K->2158424K(2944192K), 0.0896520 secs]
[GC 2414552K->2143559K(2944192K), 0.0872230 secs]
[GC 2399687K->2194880K(2944192K), 0.0768640 secs]
[GC 2449819K->2176166K(2944192K), 0.0987980 secs]
[GC 2432294K->2242418K(2944192K), 0.1056950 secs]
[GC 2498546K->2220870K(2944192K), 0.1009790 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2476998K->2273510K(2944192K), 0.1204760 secs]
[GC 2529620K->2298492K(2944192K), 0.1083200 secs]
[GC 2554620K->2284897K(2944192K), 0.1124550 secs]
[GC 2541007K->2343936K(2944192K), 0.1149500 secs]
[GC 2600064K->2324227K(2944192K), 0.1144290 secs]
[GC 2580355K->2384875K(2944192K), 0.1128280 secs]
[GC 2639993K->2364938K(2944192K), 0.1149720 secs]
[GC 2621066K->2425957K(2944192K), 0.1110570 secs]
[GC 2682085K->2405894K(2944192K), 0.1122580 secs]
[GC 2662022K->2452891K(2944192K), 0.1055160 secs]
[GC 2708971K->2447544K(2944192K), 0.0996640 secs]
[GC 2447605K(2944192K), 0.0469330 secs]
[GC 2703672K->2447847K(2944192K), 0.1023700 secs]
[GC 2578181K(2944192K), 0.0479750 secs]
[GC 2377383K->2173078K(3802780K), 0.1335130 secs]
[GC 2429206K->2157637K(3802780K), 0.1006410 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 2413765K->2208707K(3802780K), 0.0749370 secs]
[GC 2464819K->2211674K(3802780K), 0.1134750 secs]
[GC 2467802K->2232724K(3802780K), 0.1178770 secs]
[GC 2485955K->2242725K(3802780K), 0.1066900 secs]
[GC 2498853K->2267942K(3802780K), 0.0745720 secs]
[GC 2524070K->2273254K(3802780K), 0.0974030 secs]
[GC 2529382K->2262964K(3802780K), 0.0629690 secs]
[GC 2519092K->2327848K(3802780K), 0.0695980 secs]
[GC 2583976K->2360180K(3802780K), 0.1014580 secs]
[GC 2615495K->2383570K(3802780K), 0.0851000 secs]
[GC 2639698K->2406488K(3802780K), 0.0762230 secs]
[GC 2662565K->2405609K(3802780K), 0.0691330 secs]
[GC 2660297K->2425369K(3802780K), 0.0643250 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3001507. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 2681497K->2456362K(3802780K), 0.0839920 secs]
[GC 2712490K->2501839K(3802780K), 0.0999820 secs]
[GC 2757929K->2507985K(3802780K), 0.0805290 secs]
[GC 2763183K->2548052K(3802780K), 0.0670010 secs]
[GC 2804180K->2590484K(3802780K), 0.0937520 secs]
[GC 2846612K->2607120K(3802780K), 0.0778400 secs]
[GC 2863230K->2603583K(3802780K), 0.0742860 secs]
[GC 2859711K->2650294K(3802780K), 0.0718280 secs]
[GC 2906333K->2647614K(3802780K), 0.0934620 secs]
[GC 2903692K->2667738K(3802780K), 0.0733100 secs]
[GC 2923816K->2662413K(3802780K), 0.0581250 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 5015498. Elapsed time: 40.001 secs. Remaining: 19.999 secs. Total: 1 mins 0 secs
[GC 2918487K->2733187K(3802780K), 0.0882840 secs]
[GC 2989315K->2715917K(3802780K), 0.0906870 secs]
[GC 2972045K->2744358K(3802780K), 0.0850150 secs]
[GC 3000486K->2716253K(3802780K), 0.0641880 secs]
[GC 2972206K->2737663K(3802780K), 0.0759920 secs]
[GC 2990996K->2755494K(3802780K), 0.0961970 secs]
[GC 3011622K->2762496K(3802780K), 0.0828480 secs]
[GC 3018624K->2832709K(3802780K), 0.1045810 secs]
[GC 3088837K->2809772K(3802780K), 0.0826820 secs]
[GC 3065900K->2839807K(3802780K), 0.0931690 secs]
[GC 3091937K->2862354K(3802780K), 0.0814580 secs]
[GC 3118482K->2875094K(3802780K), 0.0892390 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9000000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 48 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:0, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3131222K->2875270K(3802780K), 0.0811190 secs]
[GC 3131398K->2844287K(3802780K), 0.0583240 secs]
[GC 3100415K->2867708K(3802780K), 0.0834810 secs]
[GC 3123428K->2892072K(3802780K), 0.1016440 secs]
[GC 3148200K->2948610K(3802780K), 0.1205180 secs]
[GC 3204697K->2927322K(3802780K), 0.1261930 secs]
[GC 3183450K->2962739K(3802780K), 0.1127890 secs]
[GC 3218867K->2963185K(3802780K), 0.1095260 secs]
[GC 3218904K->3035033K(3802780K), 0.1142110 secs]
[GC 3291161K->3020900K(3802780K), 0.1098720 secs]
[GC 3277028K->3069130K(3802780K), 0.1041510 secs]
[GC 3324309K->3096694K(3802780K), 0.1091830 secs]
[GC 3352822K->3080725K(3802780K), 0.1069120 secs]
[GC 3336853K->3137259K(3802780K), 0.1050040 secs]
[GC 3393371K->3118480K(3802780K), 0.1095830 secs]
[GC 3374608K->3177888K(3802780K), 0.1335520 secs]
[GC 3434016K->3159277K(3802780K), 0.1132310 secs]
[GC 3415387K->3217288K(3802780K), 0.1213510 secs]
[GC 3473416K->3199594K(3802780K), 0.1141300 secs]
[GC 3455722K->3193762K(3802780K), 0.1091900 secs]
[GC 3449890K->3244916K(3802780K), 0.0960730 secs]
[GC 3501044K->3258442K(3802780K), 0.1258310 secs]
[GC 3259227K(3802780K), 0.0503800 secs]
[GC 3513961K->3301838K(3802780K), 0.1368230 secs]
[GC 3439187K(3802780K), 0.0593120 secs]
[GC 3011796K->2746645K(4650880K), 0.1434740 secs]
[GC 3002773K->2781476K(4650880K), 0.1498000 secs]
[GC 3037604K->2800482K(4650880K), 0.1296340 secs]
[GC 3056610K->2805505K(4650880K), 0.1213320 secs]
[GC 3061613K->2820395K(4650880K), 0.1068600 secs]
[GC 3076523K->2859248K(4650880K), 0.1114600 secs]
[GC 3115376K->2881733K(4650880K), 0.1353080 secs]
[GC 3137861K->2880247K(4650880K), 0.1213280 secs]
[GC 3136375K->2918572K(4650880K), 0.1161700 secs]
[GC 3174700K->2925840K(4650880K), 0.1091400 secs]
[GC 3181941K->2940714K(4650880K), 0.1121380 secs]
[GC 3196842K->2997981K(4650880K), 0.1115690 secs]
[GC 3254072K->2981874K(4650880K), 0.1047320 secs]
[GC 3237995K->3037172K(4650880K), 0.1124600 secs]
[GC 3293300K->3018996K(4650880K), 0.1035500 secs]
[GC 3275124K->3081206K(4650880K), 0.1065560 secs]
[GC 3337334K->3066554K(4650880K), 0.1032240 secs]
[GC 3322327K->3123448K(4650880K), 0.1032040 secs]
[GC 3379576K->3113959K(4650880K), 0.1025010 secs]
[GC 3370087K->3153610K(4650880K), 0.0971160 secs]
[GC 3409683K->3183606K(4650880K), 0.1038770 secs]
[GC 3439734K->3168935K(4650880K), 0.1052610 secs]
[GC 3425063K->3198662K(4650880K), 0.1022680 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3454769K->3244805K(4650880K), 0.1006100 secs]
[GC 3500933K->3239547K(4650880K), 0.1076960 secs]
[GC 3495675K->3277309K(4650880K), 0.1004080 secs]
[GC 3532218K->3284582K(4650880K), 0.1029650 secs]
[GC 3540710K->3307843K(4650880K), 0.1015100 secs]
[GC 3563958K->3345515K(4650880K), 0.1059010 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5701 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 49 ms.
