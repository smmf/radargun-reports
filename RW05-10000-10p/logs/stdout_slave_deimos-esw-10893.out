/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-10893 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-10893
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.1014350 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@5381062e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 51116 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49179 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 41685 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 55440 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:33102
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:33102
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 46410 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:50428
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 37425 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 43049 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 38909 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:47136
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:50428
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 46328 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:47136
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:48658
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:48658
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:58111
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:58111
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 5
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->11804K(2944064K), 0.0464720 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|4] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-178, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-178] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|5] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-178] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|6] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562, deimos-esw-21063]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 5, serverOidBase: 5000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@440ab4a2
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@440ab4a2, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 267868K->22862K(2944064K), 0.0587290 secs]
[GC 278926K->31367K(2944064K), 0.0480080 secs]
[GC 287431K->45959K(2944064K), 0.0496560 secs]
[GC 302023K->65362K(2944064K), 0.0568860 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 321426K->82389K(2944064K), 0.0597980 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8379. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 338453K->116194K(2944064K), 0.0649540 secs]
[GC 372258K->113202K(2944064K), 0.1643670 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 21500. Elapsed time: 40.156 secs. Remaining: 19.844 secs. Total: 1 mins 0 secs
[GC 369266K->139123K(2944064K), 0.0732990 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 35200. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 40 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 160 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 395187K->153035K(2944064K), 0.0759920 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,617,213 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 326850K->130459K(2944064K), 0.6721830 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,812,766 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@440ab4a2, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 386587K->197022K(2944192K), 0.0340340 secs]
[GC 453150K->148631K(2944192K), 0.0377170 secs]
[GC 404759K->162882K(2944192K), 0.0450460 secs]
[GC 419010K->173485K(2944192K), 0.0497570 secs]
[GC 429613K->187677K(2944192K), 0.0532950 secs]
[GC 443805K->202568K(2944192K), 0.0556250 secs]
[GC 458696K->218163K(2944192K), 0.0603100 secs]
[GC 474291K->220609K(2944192K), 0.0630410 secs]
[GC 476737K->248550K(2944192K), 0.0673020 secs]
[GC 504649K->229494K(2944192K), 0.0781690 secs]
[GC 485622K->279281K(2944192K), 0.1026770 secs]
[GC 535386K->281455K(2944192K), 0.0989620 secs]
[GC 536962K->298979K(2944192K), 0.0986990 secs]
[GC 555107K->293835K(2944192K), 0.1214870 secs]
[GC 549956K->341669K(2944192K), 0.0905520 secs]
[GC 597797K->377649K(2944192K), 0.1047080 secs]
[GC 633777K->363295K(2944192K), 0.0872050 secs]
[GC 619423K->403395K(2944192K), 0.0986080 secs]
[GC 659523K->435566K(2944192K), 0.0849190 secs]
[GC 691694K->415398K(2944192K), 0.0824860 secs]
[GC 669633K->450035K(2944192K), 0.0864930 secs]
[GC 706163K->485375K(2944192K), 0.0769330 secs]
[GC 741471K->470645K(2944192K), 0.0733200 secs]
[GC 726773K->528845K(2944192K), 0.0846200 secs]
[GC 784973K->509752K(2944192K), 0.0794520 secs]
[GC 765880K->567509K(2944192K), 0.0825640 secs]
[GC 823603K->547014K(2944192K), 0.0796400 secs]
[GC 803142K->607170K(2944192K), 0.0905080 secs]
[GC 863298K->608550K(2944192K), 0.0862590 secs]
[GC 864678K->641716K(2944192K), 0.0902320 secs]
[GC 897844K->627603K(2944192K), 0.0964900 secs]
[GC 883731K->642679K(2944192K), 0.0865850 secs]
[GC 898807K->647055K(2944192K), 0.0842670 secs]
[GC 903183K->679552K(2944192K), 0.0644100 secs]
[GC 935680K->700649K(2944192K), 0.0815940 secs]
[GC 956777K->687922K(2944192K), 0.1160510 secs]
[GC 943005K->703217K(2944192K), 0.0644470 secs]
[GC 959345K->725458K(2944192K), 0.0726700 secs]
[GC 981586K->725754K(2944192K), 0.1142820 secs]
[GC 981882K->758537K(2944192K), 0.0904590 secs]
[GC 1014665K->767038K(2944192K), 0.0980640 secs]
[GC 1023166K->764800K(2944192K), 0.0840020 secs]
[GC 1019481K->812830K(2944192K), 0.0827820 secs]
[GC 1068958K->819934K(2944192K), 0.0834420 secs]
[GC 1076062K->851482K(2944192K), 0.0864620 secs]
[GC 1107610K->867998K(2944192K), 0.0872730 secs]
[GC 1122070K->887686K(2944192K), 0.0885480 secs]
[GC 1143814K->906212K(2944192K), 0.0842130 secs]
[GC 1162340K->911442K(2944192K), 0.0808130 secs]
[GC 1166115K->966958K(2944192K), 0.0869470 secs]
[GC 1223086K->947244K(2944192K), 0.0863310 secs]
[GC 1203346K->1005205K(2944192K), 0.0814360 secs]
[GC 1261333K->979331K(2944192K), 0.0962440 secs]
[GC 1234644K->1041264K(2944192K), 0.0835880 secs]
[GC 1297392K->1017719K(2944192K), 0.0857470 secs]
[GC 1273828K->1080099K(2944192K), 0.0823280 secs]
[GC 1336067K->1055721K(2944192K), 0.0963830 secs]
[GC 1311849K->1086042K(2944192K), 0.1000650 secs]
[GC 1342170K->1114697K(2944192K), 0.0924970 secs]
[GC 1370825K->1097659K(2944192K), 0.0777820 secs]
[GC 1353787K->1153401K(2944192K), 0.0654360 secs]
[GC 1409529K->1133858K(2944192K), 0.0762840 secs]
[GC 1389986K->1150083K(2944192K), 0.0578050 secs]
[GC 1406211K->1166932K(2944192K), 0.0634150 secs]
[GC 1423060K->1155508K(2944192K), 0.0796840 secs]
[GC 1411636K->1171740K(2944192K), 0.0681810 secs]
[GC 1427868K->1186246K(2944192K), 0.0687750 secs]
[GC 1442374K->1164863K(2944192K), 0.0833690 secs]
[GC 1420991K->1198805K(2944192K), 0.0681450 secs]
[GC 1454933K->1192857K(2944192K), 0.0829830 secs]
[GC 1448985K->1205191K(2944192K), 0.0863910 secs]
[GC 1461319K->1231935K(2944192K), 0.0808680 secs]
[GC 1488063K->1212421K(2944192K), 0.0887240 secs]
[GC 1468549K->1241716K(2944192K), 0.0717500 secs]
[GC 1497844K->1225474K(2944192K), 0.0898840 secs]
[GC 1481602K->1229714K(2944192K), 0.1048190 secs]
[GC 1485842K->1237045K(2944192K), 0.1229840 secs]
[GC 1493173K->1261581K(2944192K), 0.0817090 secs]
[GC 1517709K->1270084K(2944192K), 0.1330750 secs]
[GC 1526212K->1262883K(2944192K), 0.1286630 secs]
[GC 1519011K->1271116K(2944192K), 0.0823190 secs]
[GC 1527244K->1295691K(2944192K), 0.0859410 secs]
[GC 1551819K->1319953K(2944192K), 0.0856770 secs]
[GC 1576081K->1294634K(2944192K), 0.0867560 secs]
[GC 1550762K->1340632K(2944192K), 0.0809520 secs]
[GC 1596760K->1306899K(2944192K), 0.0838410 secs]
[GC 1563027K->1340877K(2944192K), 0.0800420 secs]
[GC 1597005K->1356594K(2944192K), 0.1443530 secs]
[GC 1612722K->1331804K(2944192K), 0.1629550 secs]
[GC 1587932K->1366126K(2944192K), 0.0697120 secs]
[GC 1622254K->1351902K(2944192K), 0.0827440 secs]
[GC 1608030K->1372225K(2944192K), 0.1309030 secs]
[GC 1628353K->1386028K(2944192K), 0.0742090 secs]
[GC 1642156K->1401630K(2944192K), 0.0848570 secs]
[GC 1402187K(2944192K), 0.0561580 secs]
[GC 1559555K(2944192K), 0.0783820 secs]
[GC 1430968K->1149621K(2944192K), 0.0873750 secs]
[GC 1405290K->1209676K(2944192K), 0.1115520 secs]
[GC 1465739K->1229582K(2944192K), 0.1021930 secs]
[GC 1485379K->1210811K(2944192K), 0.1172790 secs]
[GC 1466750K->1237886K(2944192K), 0.1006700 secs]
[GC 1494008K->1272488K(2944192K), 0.0855840 secs]
[GC 1528594K->1289838K(2944192K), 0.0849560 secs]
[GC 1545966K->1290569K(2944192K), 0.0876630 secs]
[GC 1546692K->1325487K(2944192K), 0.0881060 secs]
[GC 1581575K->1328453K(2944192K), 0.0916350 secs]
[GC 1584535K->1362443K(2944192K), 0.0879440 secs]
[GC 1618516K->1364655K(2944192K), 0.0865860 secs]
[GC 1620765K->1400747K(2944192K), 0.0876290 secs]
[GC 1656559K->1419567K(2944192K), 0.0877450 secs]
[GC 1675695K->1438527K(2944192K), 0.0868260 secs]
[GC 1694655K->1461956K(2944192K), 0.0895650 secs]
[GC 1718084K->1493980K(2944192K), 0.0883140 secs]
[GC 1750108K->1481181K(2944192K), 0.0866500 secs]
[GC 1737309K->1509390K(2944192K), 0.0691900 secs]
[GC 1765518K->1482299K(2944192K), 0.0858100 secs]
[GC 1738427K->1522841K(2944192K), 0.0619580 secs]
[GC 1778969K->1500819K(2944192K), 0.0741560 secs]
[GC 1756947K->1547729K(2944192K), 0.0568600 secs]
[GC 1803857K->1519523K(2944192K), 0.0639460 secs]
[GC 1775651K->1530523K(2944192K), 0.0780350 secs]
[GC 1786651K->1567872K(2944192K), 0.0571740 secs]
[GC 1824000K->1538577K(2944192K), 0.0594740 secs]
[GC 1794705K->1586596K(2944192K), 0.0725370 secs]
[GC 1842724K->1554807K(2944192K), 0.0725520 secs]
[GC 1810935K->1600338K(2944192K), 0.0693180 secs]
[GC 1856466K->1567801K(2944192K), 0.0705770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 1823929K->1616491K(2944192K), 0.0785700 secs]
[GC 1872619K->1628115K(2944192K), 0.0915890 secs]
[GC 1884243K->1643780K(2944192K), 0.1133170 secs]
[GC 1899908K->1655249K(2944192K), 0.0762190 secs]
[GC 1911363K->1670140K(2944192K), 0.0954120 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1926268K->1688227K(2944192K), 0.0775150 secs]
[GC 1944355K->1757864K(2944192K), 0.0839180 secs]
[GC 2013368K->1783648K(2944192K), 0.0903530 secs]
[GC 2039599K->1764764K(2944192K), 0.0631730 secs]
[GC 2020892K->1788124K(2944192K), 0.0582740 secs]
[GC 2042505K->1805171K(2944192K), 0.0851940 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2320000. Elapsed time: 20.298 secs. Remaining: 39.702 secs. Total: 1 mins 0 secs
[GC 2059509K->1855354K(2944192K), 0.0697070 secs]
[GC 2108902K->1872318K(2944192K), 0.0959570 secs]
[GC 2128446K->1904650K(2944192K), 0.0800630 secs]
[GC 2160778K->1892346K(2944192K), 0.0681380 secs]
[GC 2148474K->1915565K(2944192K), 0.0796810 secs]
[GC 2171693K->1944891K(2944192K), 0.0894580 secs]
[GC 2201019K->1971820K(2944192K), 0.0771310 secs]
[GC 2227948K->2005758K(2944192K), 0.0816190 secs]
[GC 2261878K->1990673K(2944192K), 0.0595760 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2246801K->2000323K(2944192K), 0.0546570 secs]
[GC 2256407K->2032002K(2944192K), 0.0703620 secs]
[GC 2287248K->2051627K(2944192K), 0.0996520 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 4993682. Elapsed time: 40.298 secs. Remaining: 19.702 secs. Total: 1 mins 0 secs
[GC 2307743K->2050698K(2944192K), 0.0708650 secs]
[GC 2303360K->2097243K(2944192K), 0.0654010 secs]
[GC 2353371K->2098953K(2944192K), 0.0872390 secs]
[GC 2354889K->2111658K(2944192K), 0.0712230 secs]
[GC 2367786K->2139123K(2944192K), 0.0722580 secs]
[GC 2395251K->2137375K(2944192K), 0.0614530 secs]
[GC 2393451K->2187448K(2944192K), 0.0621740 secs]
[GC 2442720K->2193163K(2944192K), 0.0725500 secs]
[GC 2447016K->2204828K(2944192K), 0.0840740 secs]
[GC 2460956K->2212915K(2944192K), 0.0731910 secs]
[GC 2469043K->2224951K(2944192K), 0.0619710 secs]
[GC 2481077K->2244399K(2944192K), 0.0554640 secs]
[GC 2500499K->2265323K(2944192K), 0.0692180 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8160000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 35 mins 1 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2521451K->2248686K(2944192K), 0.0623940 secs]
[GC 2504814K->2247189K(2944192K), 0.0577640 secs]
[GC 2503317K->2270647K(2944192K), 0.0721150 secs]
[GC 2526775K->2320656K(2944192K), 0.0883440 secs]
[GC 2575143K->2353009K(2944192K), 0.1085710 secs]
[GC 2609108K->2338199K(2944192K), 0.0897710 secs]
[GC 2594327K->2393856K(2944192K), 0.0973800 secs]
[GC 2649984K->2376072K(2944192K), 0.0919690 secs]
[GC 2632193K->2428328K(2944192K), 0.0896170 secs]
[GC 2684456K->2455121K(2944192K), 0.0893060 secs]
[GC 2709679K->2439076K(2944192K), 0.0927910 secs]
[GC 2695204K->2488691K(2944192K), 0.0961600 secs]
[GC 2489461K(2944192K), 0.0411720 secs]
[GC 2744088K->2516057K(2944192K), 0.1015070 secs]
[GC 2651844K(2944192K), 0.0524890 secs]
[GC 2198316K->1926522K(3408624K), 0.1034740 secs]
[GC 2182648K->1983218K(3408624K), 0.1016280 secs]
[GC 2239346K->1977869K(3408624K), 0.1024110 secs]
[GC 2233997K->2019949K(3408624K), 0.0952240 secs]
[GC 2276077K->2008800K(3408624K), 0.0965120 secs]
[GC 2264928K->2035811K(3408624K), 0.0868170 secs]
[GC 2291923K->2075483K(3408624K), 0.1182230 secs]
[GC 2331611K->2095044K(3408624K), 0.1167460 secs]
[GC 2351137K->2104338K(3408624K), 0.1195450 secs]
[GC 2360466K->2145940K(3408624K), 0.1125230 secs]
[GC 2402068K->2147762K(3408624K), 0.1101300 secs]
[GC 2403890K->2187079K(3408624K), 0.1108470 secs]
[GC 2441805K->2211223K(3408624K), 0.1080660 secs]
[GC 2467351K->2210885K(3408624K), 0.1085710 secs]
[GC 2467013K->2260428K(3408624K), 0.1114230 secs]
[GC 2516556K->2232711K(3408624K), 0.0978230 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2488839K->2291521K(3408624K), 0.0986100 secs]
[GC 2547649K->2316746K(3408624K), 0.0920310 secs]
[GC 2572874K->2339342K(3408624K), 0.1181960 secs]
[GC 2595444K->2365518K(3408624K), 0.0957060 secs]
[GC 2621646K->2395780K(3408624K), 0.1053260 secs]
[GC 2651908K->2393227K(3408624K), 0.0972470 secs]
[GC 2649355K->2437206K(3408624K), 0.1041320 secs]
[GC 2693334K->2462021K(3408624K), 0.0969900 secs]
[GC 2717162K->2485529K(3408624K), 0.1064510 secs]
[GC 2741657K->2486438K(3408624K), 0.1002600 secs]
[GC 2740525K->2501440K(3408624K), 0.0899000 secs]
[GC 2757531K->2538980K(3408624K), 0.0912850 secs]
[GC 2795108K->2561108K(3408624K), 0.0921050 secs]
[GC 2817236K->2578927K(3408624K), 0.0948130 secs]
[GC 2835055K->2602768K(3408624K), 0.0967890 secs]
[GC 2858889K->2586622K(3408624K), 0.0969300 secs]
[GC 2842750K->2641052K(3408624K), 0.0956190 secs]
[GC 2897180K->2628384K(3408624K), 0.0882870 secs]
[GC 2884512K->2643499K(3408624K), 0.0958980 secs]
[GC 2899627K->2693299K(3408624K), 0.0843050 secs]
[GC 2949427K->2699531K(3408624K), 0.1053930 secs]
[GC 2955659K->2739158K(3408624K), 0.1085100 secs]
[GC 2995286K->2755129K(3408624K), 0.0924510 secs]
[GC 3009799K->2775207K(3408624K), 0.0967140 secs]
[GC 3031335K->2813280K(3408624K), 0.1000190 secs]
[GC 3069408K->2800227K(3408624K), 0.1017200 secs]
[GC 3056355K->2843926K(3408624K), 0.0988720 secs]
[GC 3099934K->2855728K(3408624K), 0.0988940 secs]
[GC 3111813K->2859002K(3408624K), 0.0999250 secs]
[GC 3115130K->2898059K(3408624K), 0.1111930 secs]
[GC 2898638K(3408624K), 0.0423350 secs]
[GC 3154176K->2920676K(3408624K), 0.1024720 secs]
[GC 3085363K(3408624K), 0.0594200 secs]
[GC 2925051K->2704222K(4643168K), 0.1143530 secs]
[GC 2958429K->2690421K(4643168K), 0.1205980 secs]
[GC 2946549K->2737428K(4643168K), 0.1202580 secs]
[GC 2993538K->2729534K(4643168K), 0.1138240 secs]
[GC 2985633K->2788424K(4643168K), 0.1067780 secs]
[GC 3044552K->2778083K(4643168K), 0.1079720 secs]
[GC 3032622K->2826466K(4643168K), 0.1310880 secs]
[GC 3082594K->2839622K(4643168K), 0.1049270 secs]
[GC 3095750K->2876168K(4643168K), 0.1121730 secs]
[GC 3132296K->2873572K(4643168K), 0.1186540 secs]
[GC 3129700K->2911672K(4643168K), 0.1120950 secs]
[GC 3167800K->2923238K(4643168K), 0.1148810 secs]
[GC 3179366K->2942521K(4643168K), 0.1077520 secs]
[GC 3198649K->2964651K(4643168K), 0.1265690 secs]
[GC 3220756K->2967484K(4643168K), 0.1156870 secs]
[GC 3223612K->3002059K(4643168K), 0.1104080 secs]
[GC 3257881K->3024949K(4643168K), 0.1185650 secs]
[GC 3281077K->3027667K(4643168K), 0.1184510 secs]
[GC 3282607K->3064105K(4643168K), 0.1123560 secs]
[GC 3320199K->3064801K(4643168K), 0.1103940 secs]
[GC 3320929K->3122173K(4643168K), 0.1064460 secs]
[GC 3378301K->3121766K(4643168K), 0.1138330 secs]
[GC 3377894K->3168379K(4643168K), 0.1083230 secs]
[GC 3424507K->3153684K(4643168K), 0.1015420 secs]
[GC 3409812K->3206619K(4643168K), 0.1045810 secs]
[GC 3462747K->3231597K(4643168K), 0.1023530 secs]
[GC 3487725K->3217357K(4643168K), 0.1117010 secs]
[GC 3472781K->3267027K(4643168K), 0.1116780 secs]
[GC 3523113K->3257113K(4643168K), 0.1031600 secs]
[GC 3513241K->3276967K(4643168K), 0.1058740 secs]
[GC 3533095K->3318578K(4643168K), 0.1101820 secs]
[GC 3574706K->3342705K(4643168K), 0.1060110 secs]
[GC 3598833K->3374538K(4643168K), 0.1085400 secs]
[GC 3628658K->3381575K(4643168K), 0.1106300 secs]
[GC 3636781K->3400642K(4643168K), 0.1096320 secs]
[GC 3656761K->3401845K(4643168K), 0.1053630 secs]
[GC 3657969K->3439599K(4643168K), 0.1075800 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3695682K->3459403K(4643168K), 0.1031380 secs]
[GC 3715509K->3462004K(4643168K), 0.1046470 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3718132K->3502309K(4643168K), 0.1021000 secs]
[GC 3758437K->3523237K(4643168K), 0.1031770 secs]
[GC 3779365K->3546400K(4643168K), 0.1007140 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 54 ms.
