/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-18643 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-18643
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0691290 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@640fa784
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 37613 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 60312 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49228 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:52916
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:52916
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:47464
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:47464
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 55835 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36557
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 39178 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 45412 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 36925 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:36557
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 34420 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 34070 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 59264 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38283
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 43212 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:38283
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:47947
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:47947
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42693
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:42693
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36198
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:36198
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->13534K(2944064K), 0.0422760 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|3] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-15591, physical addresses are [127.0.0.1:52004]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-15591] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|4] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-15591] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|5] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197]
 INFO  [Incoming-4,deimos-esw-15591] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|6] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197, deimos-esw-13058, deimos-esw-21979]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-15591] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|7] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197, deimos-esw-13058, deimos-esw-21979, deimos-esw-52809, deimos-esw-13191]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 4, serverOidBase: 4000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@416ed704
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 10
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@416ed704, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269598K->22571K(2944064K), 0.0537380 secs]
[GC 278635K->31597K(2944064K), 0.0499310 secs]
[GC 287661K->52788K(2944064K), 0.0510030 secs]
[GC 308852K->76458K(2944064K), 0.0579580 secs]
[GC 332522K->73232K(2944064K), 0.0597100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 329296K->102377K(2944064K), 0.0684800 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6800. Elapsed time: 20.559 secs. Remaining: 39.441 secs. Total: 1 mins 0 secs
[GC 358441K->135535K(2944064K), 0.1277220 secs]
[GC 391599K->133018K(2944064K), 0.0864820 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15900. Elapsed time: 40.786 secs. Remaining: 19.214 secs. Total: 1 mins 0 secs
[GC 389082K->140572K(2944064K), 0.0743180 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 3 mins 3 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 183 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,625,360 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 318703K->130805K(2944064K), 0.6636840 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,812,033 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@416ed704, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 386933K->198631K(2944192K), 0.0321150 secs]
[GC 454759K->153939K(2944192K), 0.0389110 secs]
[GC 410067K->164488K(2944192K), 0.0440150 secs]
[GC 420616K->170077K(2944192K), 0.0522000 secs]
[GC 426205K->190855K(2944192K), 0.0725660 secs]
[GC 446983K->206123K(2944192K), 0.0748600 secs]
[GC 462251K->210051K(2944192K), 0.0919940 secs]
[GC 466179K->223335K(2944192K), 0.1179880 secs]
[GC 479463K->243333K(2944192K), 0.1133540 secs]
[GC 499446K->259079K(2944192K), 0.1442480 secs]
[GC 513883K->293560K(2944192K), 0.0920040 secs]
[GC 549688K->284398K(2944192K), 0.0936640 secs]
[GC 540526K->310397K(2944192K), 0.0813060 secs]
[GC 566155K->335434K(2944192K), 0.0890590 secs]
[GC 591562K->357764K(2944192K), 0.0883540 secs]
[GC 613892K->359739K(2944192K), 0.0877100 secs]
[GC 615867K->412626K(2944192K), 0.0913040 secs]
[GC 668709K->397315K(2944192K), 0.0792080 secs]
[GC 653443K->436699K(2944192K), 0.0791440 secs]
[GC 692827K->455182K(2944192K), 0.0779140 secs]
[GC 710918K->469790K(2944192K), 0.0809800 secs]
[GC 725918K->473870K(2944192K), 0.0757170 secs]
[GC 729998K->492323K(2944192K), 0.0761410 secs]
[GC 748060K->507474K(2944192K), 0.0794490 secs]
[GC 763602K->547472K(2944192K), 0.0794830 secs]
[GC 803542K->563843K(2944192K), 0.0811360 secs]
[GC 818928K->583452K(2944192K), 0.0880720 secs]
[GC 839580K->606824K(2944192K), 0.0882920 secs]
[GC 862926K->622045K(2944192K), 0.0859030 secs]
[GC 878173K->606026K(2944192K), 0.0953800 secs]
[GC 862154K->626570K(2944192K), 0.0891760 secs]
[GC 882698K->659756K(2944192K), 0.0691680 secs]
[GC 915884K->681459K(2944192K), 0.0735310 secs]
[GC 937587K->665690K(2944192K), 0.0921530 secs]
[GC 921818K->685848K(2944192K), 0.0690320 secs]
[GC 941976K->664254K(2944192K), 0.0921700 secs]
[GC 920382K->695596K(2944192K), 0.0667800 secs]
[GC 951681K->723818K(2944192K), 0.0762380 secs]
[GC 979946K->744046K(2944192K), 0.0980110 secs]
[GC 1000174K->764734K(2944192K), 0.1043480 secs]
[GC 1020837K->757806K(2944192K), 0.0949000 secs]
[GC 1013934K->771419K(2944192K), 0.0860760 secs]
[GC 1027547K->787307K(2944192K), 0.0873800 secs]
[GC 1043435K->838307K(2944192K), 0.0830250 secs]
[GC 1094420K->827947K(2944192K), 0.0831750 secs]
[GC 1084075K->860946K(2944192K), 0.0812220 secs]
[GC 1117074K->867736K(2944192K), 0.0804170 secs]
[GC 1123864K->916392K(2944192K), 0.0865250 secs]
[GC 1172520K->905090K(2944192K), 0.0815750 secs]
[GC 1159604K->939881K(2944192K), 0.0865300 secs]
[GC 1196009K->956803K(2944192K), 0.0826650 secs]
[GC 1212887K->958296K(2944192K), 0.0844350 secs]
[GC 1212602K->991235K(2944192K), 0.0901240 secs]
[GC 1247363K->1012686K(2944192K), 0.0897610 secs]
[GC 1268776K->1014922K(2944192K), 0.0831240 secs]
[GC 1269047K->1031104K(2944192K), 0.0845190 secs]
[GC 1287232K->1068943K(2944192K), 0.0803270 secs]
[GC 1325071K->1054138K(2944192K), 0.0821520 secs]
[GC 1310266K->1094438K(2944192K), 0.0661170 secs]
[GC 1350566K->1071459K(2944192K), 0.0797820 secs]
[GC 1327587K->1106279K(2944192K), 0.0734680 secs]
[GC 1362407K->1126011K(2944192K), 0.0684800 secs]
[GC 1382139K->1111783K(2944192K), 0.1172530 secs]
[GC 1367911K->1125951K(2944192K), 0.0640720 secs]
[GC 1382079K->1105011K(2944192K), 0.0721810 secs]
[GC 1361139K->1143941K(2944192K), 0.0883950 secs]
[GC 1400069K->1124798K(2944192K), 0.1146390 secs]
[GC 1380926K->1165203K(2944192K), 0.1360730 secs]
[GC 1421331K->1135656K(2944192K), 0.1241340 secs]
[GC 1391784K->1168145K(2944192K), 0.0851260 secs]
[GC 1424273K->1183822K(2944192K), 0.1405850 secs]
[GC 1439950K->1161108K(2944192K), 0.1719910 secs]
[GC 1417236K->1192709K(2944192K), 0.0884830 secs]
[GC 1448837K->1192308K(2944192K), 0.1378290 secs]
[GC 1448436K->1203064K(2944192K), 0.1716570 secs]
[GC 1459192K->1211809K(2944192K), 0.1224150 secs]
[GC 1467937K->1221370K(2944192K), 0.1398820 secs]
[GC 1477498K->1201814K(2944192K), 0.1473750 secs]
[GC 1457942K->1238049K(2944192K), 0.0821370 secs]
[GC 1494177K->1244555K(2944192K), 0.1195180 secs]
[GC 1500683K->1253456K(2944192K), 0.0813510 secs]
[GC 1509584K->1262324K(2944192K), 0.0880110 secs]
[GC 1518452K->1269847K(2944192K), 0.0857240 secs]
[GC 1525975K->1278446K(2944192K), 0.0846020 secs]
[GC 1534574K->1286227K(2944192K), 0.0850420 secs]
[GC 1542355K->1310430K(2944192K), 0.1584660 secs]
[GC 1566558K->1285160K(2944192K), 0.0858390 secs]
[GC 1541288K->1315427K(2944192K), 0.1162530 secs]
[GC 1571555K->1314244K(2944192K), 0.1586890 secs]
[GC 1570372K->1307497K(2944192K), 0.1269910 secs]
[GC 1563625K->1338804K(2944192K), 0.0747500 secs]
[GC 1594932K->1355696K(2944192K), 0.0896640 secs]
[GC 1611824K->1331275K(2944192K), 0.0813140 secs]
[GC 1587403K->1345598K(2944192K), 0.1609470 secs]
[GC 1601726K->1359382K(2944192K), 0.1593990 secs]
[GC 1615510K->1369027K(2944192K), 0.0819840 secs]
[GC 1625155K->1376424K(2944192K), 0.0788560 secs]
[GC 1632552K->1383377K(2944192K), 0.0762600 secs]
[GC 1384463K(2944192K), 0.0541290 secs]
[GC 1441777K(2944192K), 0.0467840 secs]
[GC 1419620K->1137013K(2944192K), 0.0804160 secs]
[GC 1393141K->1157587K(2944192K), 0.0753720 secs]
[GC 1413715K->1188506K(2944192K), 0.0720380 secs]
[GC 1444634K->1176958K(2944192K), 0.0834330 secs]
[GC 1433086K->1178762K(2944192K), 0.0783760 secs]
[GC 1434890K->1224828K(2944192K), 0.0759160 secs]
[GC 1480956K->1196625K(2944192K), 0.0835470 secs]
[GC 1451419K->1236305K(2944192K), 0.0791520 secs]
[GC 1490460K->1224227K(2944192K), 0.0912190 secs]
[GC 1480355K->1272020K(2944192K), 0.1057020 secs]
[GC 1528148K->1282635K(2944192K), 0.1099820 secs]
[GC 1538731K->1279005K(2944192K), 0.1065220 secs]
[GC 1535133K->1303562K(2944192K), 0.0953020 secs]
[GC 1559690K->1335918K(2944192K), 0.0925890 secs]
[GC 1590057K->1336474K(2944192K), 0.0923140 secs]
[GC 1592602K->1373154K(2944192K), 0.0939190 secs]
[GC 1629254K->1390133K(2944192K), 0.0915550 secs]
[GC 1644501K->1409217K(2944192K), 0.0941050 secs]
[GC 1663418K->1411476K(2944192K), 0.0946130 secs]
[GC 1667604K->1413024K(2944192K), 0.0879360 secs]
[GC 1669152K->1449062K(2944192K), 0.0910140 secs]
[GC 1705190K->1468199K(2944192K), 0.0913170 secs]
[GC 1724327K->1502549K(2944192K), 0.0920260 secs]
[GC 1758677K->1489718K(2944192K), 0.0834850 secs]
[GC 1745846K->1542044K(2944192K), 0.0682080 secs]
[GC 1798172K->1521550K(2944192K), 0.0836170 secs]
[GC 1777678K->1538818K(2944192K), 0.0615870 secs]
[GC 1794946K->1526239K(2944192K), 0.0622600 secs]
[GC 1782367K->1523119K(2944192K), 0.0826580 secs]
[GC 1779247K->1554203K(2944192K), 0.0538620 secs]
[GC 1810331K->1573931K(2944192K), 0.0581250 secs]
[GC 1830059K->1567864K(2944192K), 0.0730320 secs]
[GC 1823541K->1620478K(2944192K), 0.1101070 secs]
[GC 1875202K->1639726K(2944192K), 0.1038550 secs]
[GC 1895854K->1624645K(2944192K), 0.1024060 secs]
[GC 1880773K->1651335K(2944192K), 0.0986220 secs]
[GC 1907463K->1668533K(2944192K), 0.0882140 secs]
[GC 1924661K->1704260K(2944192K), 0.0892520 secs]
[GC 1960388K->1721763K(2944192K), 0.0875870 secs]
[GC 1977891K->1736923K(2944192K), 0.0887210 secs]
[GC 1993051K->1741177K(2944192K), 0.0873450 secs]
[GC 1997305K->1780004K(2944192K), 0.0862200 secs]
[GC 2036132K->1812715K(2944192K), 0.0865980 secs]
[GC 2068816K->1795396K(2944192K), 0.0848670 secs]
[GC 2051524K->1836491K(2944192K), 0.0865180 secs]
[GC 2092619K->1816173K(2944192K), 0.0794080 secs]
[GC 2072301K->1867312K(2944192K), 0.0620900 secs]
[GC 2123440K->1847140K(2944192K), 0.0744690 secs]
[GC 2103261K->1865937K(2944192K), 0.0634780 secs]
[GC 2121248K->1883529K(2944192K), 0.0808350 secs]
[GC 2139604K->1909230K(2944192K), 0.0948250 secs]
[GC 2165308K->1926948K(2944192K), 0.0997970 secs]
[GC 2183076K->1943804K(2944192K), 0.1045650 secs]
[GC 2199932K->1972502K(2944192K), 0.0918430 secs]
[GC 2228630K->1984252K(2944192K), 0.0909670 secs]
[GC 2240380K->2004148K(2944192K), 0.0936100 secs]
[GC 2260276K->2021478K(2944192K), 0.0927490 secs]
[GC 2277560K->2037707K(2944192K), 0.0898590 secs]
[GC 2293835K->2053220K(2944192K), 0.0870120 secs]
[GC 2309348K->2075945K(2944192K), 0.0921760 secs]
[GC 2332073K->2115802K(2944192K), 0.0893990 secs]
[GC 2371930K->2095184K(2944192K), 0.0859420 secs]
[GC 2351312K->2140102K(2944192K), 0.0884450 secs]
[GC 2396230K->2150936K(2944192K), 0.0882440 secs]
[GC 2407014K->2191498K(2944192K), 0.0890500 secs]
[GC 2447626K->2181012K(2944192K), 0.0984190 secs]
[GC 2437140K->2229306K(2944192K), 0.0981000 secs]
[GC 2485434K->2240163K(2944192K), 0.0963140 secs]
[GC 2495420K->2265459K(2944192K), 0.1037460 secs]
[GC 2521532K->2267609K(2944192K), 0.1065890 secs]
[GC 2523709K->2307545K(2944192K), 0.1053850 secs]
[GC 2563635K->2326702K(2944192K), 0.1077960 secs]
[GC 2582830K->2364632K(2944192K), 0.1093420 secs]
[GC 2620760K->2352616K(2944192K), 0.1050280 secs]
[GC 2608744K->2400848K(2944192K), 0.1024980 secs]
[GC 2656976K->2391370K(2944192K), 0.1012550 secs]
[GC 2647498K->2429882K(2944192K), 0.0969410 secs]
[GC 2686005K->2431810K(2944192K), 0.0983040 secs]
[GC 2687938K->2449775K(2944192K), 0.0927460 secs]
[GC 2450130K(2944192K), 0.0367620 secs]
[GC 2705903K->2466199K(2944192K), 0.0962980 secs]
[GC 2529329K(2944192K), 0.0387840 secs]
[GC 2396740K->2144003K(3806056K), 0.1000850 secs]
[GC 2400131K->2194162K(3806056K), 0.0782210 secs]
[GC 2450290K->2186741K(3806056K), 0.1141620 secs]
[GC 2440935K->2208515K(3806056K), 0.1160670 secs]
[GC 2464066K->2257129K(3806056K), 0.0997320 secs]
[GC 2513232K->2231149K(3806056K), 0.1097560 secs]
[GC 2487277K->2263283K(3806056K), 0.1131980 secs]
[GC 2519411K->2279257K(3806056K), 0.1103670 secs]
[GC 2535385K->2316246K(3806056K), 0.1187970 secs]
[GC 2572374K->2333450K(3806056K), 0.1020740 secs]
[GC 2589578K->2339077K(3806056K), 0.1024730 secs]
[GC 2595205K->2388991K(3806056K), 0.1040960 secs]
[GC 2645119K->2376574K(3806056K), 0.1055350 secs]
[GC 2632702K->2427206K(3806056K), 0.1025130 secs]
[GC 2683334K->2416945K(3806056K), 0.1039780 secs]
[GC 2673073K->2469085K(3806056K), 0.1135030 secs]
[GC 2725200K->2446637K(3806056K), 0.1022810 secs]
[GC 2702754K->2502403K(3806056K), 0.1011730 secs]
[GC 2758531K->2480402K(3806056K), 0.0933420 secs]
[GC 2736530K->2506001K(3806056K), 0.0799770 secs]
[GC 2762129K->2484014K(3806056K), 0.0901870 secs]
[GC 2740142K->2531637K(3806056K), 0.0828950 secs]
[GC 2787765K->2563325K(3806056K), 0.1065890 secs]
[GC 2817800K->2582381K(3806056K), 0.1048330 secs]
[GC 2838509K->2562733K(3806056K), 0.1242510 secs]
[GC 2818861K->2593008K(3806056K), 0.0999660 secs]
[GC 2849136K->2610692K(3806056K), 0.1076110 secs]
[GC 2866447K->2643975K(3806056K), 0.1091860 secs]
[GC 2900103K->2685235K(3806056K), 0.1022000 secs]
[GC 2941363K->2672286K(3806056K), 0.1010310 secs]
[GC 2928374K->2730841K(3806056K), 0.1032080 secs]
[GC 2986969K->2713682K(3806056K), 0.1031240 secs]
[GC 2969771K->2774741K(3806056K), 0.1110280 secs]
[GC 3030838K->2757586K(3806056K), 0.1178560 secs]
[GC 3012921K->2817850K(3806056K), 0.1067020 secs]
[GC 3073895K->2800771K(3806056K), 0.1094420 secs]
[GC 3056852K->2861001K(3806056K), 0.1096300 secs]
[GC 3115390K->2844084K(3806056K), 0.1123450 secs]
[GC 3100196K->2894523K(3806056K), 0.1087640 secs]
[GC 3150651K->2888013K(3806056K), 0.1074650 secs]
[GC 3144134K->2908326K(3806056K), 0.1032060 secs]
[GC 3164454K->2944816K(3806056K), 0.1055000 secs]
[GC 3200944K->2948070K(3806056K), 0.1001900 secs]
[GC 3202264K->2977372K(3806056K), 0.1027740 secs]
[GC 3233306K->2983163K(3806056K), 0.0995360 secs]
[GC 3239291K->2981629K(3806056K), 0.0949080 secs]
[GC 3237757K->3037177K(3806056K), 0.0857310 secs]
[GC 3293305K->3019612K(3806056K), 0.0959070 secs]
[GC 3275740K->3044720K(3806056K), 0.0771380 secs]
[GC 3300848K->3041158K(3806056K), 0.0984770 secs]
[GC 3297286K->3073952K(3806056K), 0.0782390 secs]
[GC 3330080K->3087743K(3806056K), 0.1015030 secs]
[GC 3343696K->3110010K(3806056K), 0.0992820 secs]
[GC 3366109K->3128266K(3806056K), 0.1092500 secs]
[GC 3384394K->3131835K(3806056K), 0.1139140 secs]
[GC 3387963K->3141595K(3806056K), 0.1020110 secs]
[GC 3395981K->3171790K(3806056K), 0.1043530 secs]
[GC 3427918K->3172186K(3806056K), 0.1028480 secs]
[GC 3428061K->3192368K(3806056K), 0.1077270 secs]
[GC 3448493K->3208458K(3806056K), 0.0943310 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.3G, free=336.7M, total=3.6G, max=4.7G, used/total=90.94% used/max=70.54%
cpu process-load=3.00%, system-load=20.00%, system-loadaverage=247.00%
[GC 3464556K->3245383K(3806056K), 0.0974950 secs]
[GC 3501494K->3244593K(3806056K), 0.0978590 secs]
[GC 3244733K(3806056K), 0.0330170 secs]
[GC 3500676K->3280942K(3806056K), 0.0977870 secs]
[GC 3426747K(3806056K), 0.0540610 secs]
[GC 3224200K->2986717K(4650880K), 0.1164940 secs]
[GC 3242830K->2987965K(4650880K), 0.1121930 secs]
[GC 3244093K->3006479K(4650880K), 0.1065550 secs]
[GC 3262607K->3029305K(4650880K), 0.1041720 secs]
[GC 3285433K->3027234K(4650880K), 0.0991460 secs]
[GC 3283362K->3086623K(4650880K), 0.0859510 secs]
[GC 3342751K->3068759K(4650880K), 0.1068300 secs]
[GC 3324848K->3120400K(4650880K), 0.1132380 secs]
[GC 3376477K->3103608K(4650880K), 0.1044900 secs]
[GC 3359736K->3127876K(4650880K), 0.1141070 secs]
[GC 3384004K->3162798K(4650880K), 0.1167680 secs]
[GC 3418926K->3164906K(4650880K), 0.0991880 secs]
[GC 3421016K->3168598K(4650880K), 0.1046930 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3424691K->3219283K(4650880K), 0.1077800 secs]
[GC 3475411K->3243781K(4650880K), 0.1298190 secs]
[GC 3499909K->3259875K(4650880K), 0.1200100 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.3G, free=1.2G, total=4.4G, max=4.7G, used/total=73.90% used/max=70.04%
cpu process-load=4.00%, system-load=17.00%, system-loadaverage=325.00%
[GC 3516003K->3278438K(4650880K), 0.0956280 secs]
[GC 3534566K->3290065K(4650880K), 0.0761430 secs]
[GC 3546193K->3322813K(4650880K), 0.0991230 secs]
[GC 3578884K->3328536K(4650880K), 0.1012310 secs]
[GC 3580916K->3344637K(4650880K), 0.1003530 secs]
[GC 3600751K->3341696K(4650880K), 0.0834290 secs]
[GC 3597575K->3359088K(4650880K), 0.0798680 secs]
[GC 3615216K->3392346K(4650880K), 0.1113100 secs]
[GC 3648461K->3433393K(4650880K), 0.1274210 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2876075. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 3689521K->3402337K(4650880K), 0.0932420 secs]
[GC 3658465K->3403726K(4650880K), 0.0645520 secs]
[GC 3659688K->3432892K(4650880K), 0.0862660 secs]
[GC 3689020K->3466192K(4650880K), 0.1175800 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.3G, free=1.1G, total=4.4G, max=4.7G, used/total=74.83% used/max=70.92%
cpu process-load=4.00%, system-load=17.00%, system-loadaverage=356.00%
[GC 3722320K->3477010K(4650880K), 0.1241730 secs]
[GC 3733138K->3482774K(4650880K), 0.0795830 secs]
[GC 3735787K->3496267K(4650880K), 0.0634270 secs]
[GC 3749844K->3530630K(4650880K), 0.0972790 secs]
[GC 3786758K->3549007K(4650880K), 0.1356210 secs]
[GC 3805135K->3583481K(4650880K), 0.0773600 secs]
[GC 3839609K->3656186K(4650880K), 0.0933100 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.5G, free=919.1M, total=4.4G, max=4.7G, used/total=79.76% used/max=75.61%
cpu process-load=4.00%, system-load=16.00%, system-loadaverage=377.00%
[GC 3910945K->3630371K(4650880K), 0.0856750 secs]
[GC 3886499K->3641243K(4650880K), 0.0923660 secs]
[GC 3897371K->3657184K(4650880K), 0.0751400 secs]
[GC 3912087K->3696413K(4650880K), 0.0857430 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6513754. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 3951464K->3756279K(4650880K), 0.0997820 secs]
[GC 4012407K->3771970K(4650880K), 0.1022870 secs]
[GC 4027969K->3791747K(4650880K), 0.0948140 secs]
[GC 4047875K->3831566K(4650880K), 0.0926870 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.9G, free=555.7M, total=4.4G, max=4.7G, used/total=87.77% used/max=83.19%
cpu process-load=5.00%, system-load=15.00%, system-loadaverage=388.00%
[GC 4087694K->3855754K(4650880K), 0.0870710 secs]
[GC 4111859K->3853504K(4650880K), 0.0806240 secs]
[GC 4109632K->3880688K(4650880K), 0.0764670 secs]
[GC 4136816K->3891920K(4650880K), 0.0982060 secs]
[GC 4148048K->3920303K(4650880K), 0.0883780 secs]
[GC 4176384K->3934274K(4650880K), 0.0905100 secs]
[GC 4188399K->3953232K(4650880K), 0.0813700 secs]
[GC 4209360K->4021062K(4650880K), 0.0898950 secs]
[GC 4277190K->4031313K(4650880K), 0.0973660 secs]
[GC 4031319K(4650880K), 0.0128800 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5706 [FenixFrameworkGroup] 
memory used=3.9G, free=550.6M, total=4.4G, max=4.7G, used/total=87.88% used/max=83.30%
cpu process-load=4.00%, system-load=14.00%, system-loadaverage=422.00%
[GC 4287441K->4037151K(4650880K), 0.0783030 secs]
[GC 4293279K->4042904K(4650880K), 0.0748020 secs]
[GC 4299032K->4059059K(4650880K), 0.0604580 secs]
[GC 4315187K->4075111K(4650880K), 0.0788730 secs]
[GC 4215995K(4650880K), 0.0886720 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11554776. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 53 mins 29 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 52 ms.
