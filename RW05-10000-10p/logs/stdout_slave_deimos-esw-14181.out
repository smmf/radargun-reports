/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-14181 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-14181
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.1601790 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@60c90207
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5708, using socket ServerSocket[addr=/0.0.0.0,localport=5708], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5708
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5708 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 42251 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 55009 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 60952 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5708 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708 this
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:46316
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:38909
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:46316
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:38909
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:41719
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:41719
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 51131 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:37140
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:37140
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 56365 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5708 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 35160 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 48658 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:34689
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:34689
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 is accepting socket connection from /127.0.0.1:49290
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5708 [FenixFrameworkGroup] 5708 accepted socket connection from /127.0.0.1:49290
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5708 [FenixFrameworkGroup] Address[127.0.0.1]:5708 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=7, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 7
[GC 259695K->11200K(2944064K), 0.0379160 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|5] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-42503, physical addresses are [127.0.0.1:52007]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-42503] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|6] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562, deimos-esw-21063]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@157052cb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 8
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@157052cb, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 267264K->23286K(2944064K), 0.0582010 secs]
[GC 279350K->30109K(2944064K), 0.0501110 secs]
[GC 286173K->44672K(2944064K), 0.0497300 secs]
[GC 300736K->63917K(2944064K), 0.0580780 secs]
[GC 319981K->80922K(2944064K), 0.0615320 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 336986K->113797K(2944064K), 0.0686650 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9250. Elapsed time: 20.352 secs. Remaining: 39.648 secs. Total: 1 mins 0 secs
[GC 369861K->112391K(2944064K), 0.1656680 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 22250. Elapsed time: 40.612 secs. Remaining: 19.388 secs. Total: 1 mins 0 secs
[GC 368455K->120929K(2944064K), 0.0764110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 44 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 164 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 376993K->136912K(2944064K), 0.0719910 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,599,612 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 344451K->130134K(2944064K), 0.6431770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,221 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@157052cb, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 386262K->196761K(2944192K), 0.0343060 secs]
[GC 452889K->148333K(2944192K), 0.0348070 secs]
[GC 404461K->162635K(2944192K), 0.0416560 secs]
[GC 418763K->173166K(2944192K), 0.0556800 secs]
[GC 429294K->187486K(2944192K), 0.0650460 secs]
[GC 443614K->202285K(2944192K), 0.0854440 secs]
[GC 458413K->217393K(2944192K), 0.0990200 secs]
[GC 473521K->232944K(2944192K), 0.1177120 secs]
[GC 489072K->220018K(2944192K), 0.1132170 secs]
[GC 476146K->259409K(2944192K), 0.1279440 secs]
[GC 515537K->262586K(2944192K), 0.1002130 secs]
[GC 517877K->295556K(2944192K), 0.0923690 secs]
[GC 551684K->300290K(2944192K), 0.0980730 secs]
[GC 556418K->294763K(2944192K), 0.1135020 secs]
[GC 550474K->325042K(2944192K), 0.0854520 secs]
[GC 581170K->360887K(2944192K), 0.0994440 secs]
[GC 617015K->397748K(2944192K), 0.0875230 secs]
[GC 653876K->381661K(2944192K), 0.0913780 secs]
[GC 637789K->424571K(2944192K), 0.0911360 secs]
[GC 680038K->448901K(2944192K), 0.0862880 secs]
[GC 705029K->434858K(2944192K), 0.0812750 secs]
[GC 690986K->464810K(2944192K), 0.0806090 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 720938K->503333K(2944192K), 0.0774950 secs]
[GC 759177K->510686K(2944192K), 0.0846880 secs]
[GC 766814K->548086K(2944192K), 0.0806720 secs]
[GC 804191K->531160K(2944192K), 0.0804530 secs]
[GC 787288K->573439K(2944192K), 0.0843080 secs]
[GC 829567K->583601K(2944192K), 0.0931410 secs]
[GC 838650K->607949K(2944192K), 0.0879830 secs]
[GC 864077K->611434K(2944192K), 0.0864000 secs]
[GC 867562K->649302K(2944192K), 0.0842060 secs]
[GC 905430K->630791K(2944192K), 0.0862940 secs]
[GC 886919K->648552K(2944192K), 0.0803760 secs]
[GC 904680K->679242K(2944192K), 0.0611660 secs]
[GC 935370K->700064K(2944192K), 0.0657180 secs]
[GC 956192K->686942K(2944192K), 0.0859440 secs]
[GC 943021K->703019K(2944192K), 0.0638730 secs]
[GC 957917K->724294K(2944192K), 0.0777770 secs]
[GC 978446K->724071K(2944192K), 0.1042900 secs]
[GC 980199K->770107K(2944192K), 0.0884750 secs]
[GC 1026235K->749348K(2944192K), 0.0919480 secs]
[GC 1004978K->795884K(2944192K), 0.0793060 secs]
[GC 1052012K->814219K(2944192K), 0.0821720 secs]
[GC 1070327K->815791K(2944192K), 0.0789270 secs]
[GC 1071919K->849447K(2944192K), 0.0788840 secs]
[GC 1105575K->857028K(2944192K), 0.0834060 secs]
[GC 1113156K->871653K(2944192K), 0.0824980 secs]
[GC 1126525K->891345K(2944192K), 0.0801600 secs]
[GC 1147473K->926504K(2944192K), 0.0785270 secs]
[GC 1182632K->930222K(2944192K), 0.0810330 secs]
[GC 1186350K->985666K(2944192K), 0.0812070 secs]
[GC 1241794K->966523K(2944192K), 0.0804230 secs]
[GC 1222651K->1024063K(2944192K), 0.0813230 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1280191K->999484K(2944192K), 0.0825620 secs]
[GC 1255612K->1058755K(2944192K), 0.0832360 secs]
[GC 1314846K->1037811K(2944192K), 0.0792370 secs]
[GC 1293572K->1097542K(2944192K), 0.0856210 secs]
[GC 1353670K->1078166K(2944192K), 0.0760920 secs]
[GC 1334294K->1135011K(2944192K), 0.0832900 secs]
[GC 1391139K->1114449K(2944192K), 0.0761540 secs]
[GC 1370577K->1138753K(2944192K), 0.0608770 secs]
[GC 1394881K->1116106K(2944192K), 0.0872890 secs]
[GC 1372234K->1146927K(2944192K), 0.0609950 secs]
[GC 1403055K->1167485K(2944192K), 0.0682350 secs]
[GC 1423613K->1155568K(2944192K), 0.0811060 secs]
[GC 1411696K->1170954K(2944192K), 0.0629970 secs]
[GC 1427082K->1159102K(2944192K), 0.0685460 secs]
[GC 1415230K->1172317K(2944192K), 0.0830180 secs]
[GC 1428445K->1207761K(2944192K), 0.1269190 secs]
[GC 1463889K->1176540K(2944192K), 0.1425270 secs]
[GC 1432668K->1225197K(2944192K), 0.0773690 secs]
[GC 1481325K->1191229K(2944192K), 0.1427360 secs]
[GC 1447357K->1227111K(2944192K), 0.1544630 secs]
[GC 1483239K->1218449K(2944192K), 0.0927700 secs]
[GC 1474577K->1238022K(2944192K), 0.1372610 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1494150K->1261102K(2944192K), 0.0814860 secs]
[GC 1517230K->1237215K(2944192K), 0.1368020 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1493343K->1284304K(2944192K), 0.1358430 secs]
[GC 1540432K->1251327K(2944192K), 0.1542150 secs]
[GC 1507455K->1300814K(2944192K), 0.0867530 secs]
[GC 1556942K->1267527K(2944192K), 0.1497340 secs]
[GC 1523655K->1303504K(2944192K), 0.0828270 secs]
[GC 1559632K->1302749K(2944192K), 0.1504510 secs]
[GC 1558877K->1311413K(2944192K), 0.1253080 secs]
[GC 1567541K->1302286K(2944192K), 0.1559110 secs]
[GC 1558414K->1328113K(2944192K), 0.1332920 secs]
[GC 1584241K->1318581K(2944192K), 0.1405090 secs]
[GC 1574709K->1324914K(2944192K), 0.0798390 secs]
[GC 1581042K->1371233K(2944192K), 0.1306970 secs]
[GC 1627361K->1345759K(2944192K), 0.1713390 secs]
[GC 1601887K->1362053K(2944192K), 0.0747710 secs]
[GC 1618181K->1385615K(2944192K), 0.0862950 secs]
[GC 1641743K->1361218K(2944192K), 0.0809900 secs]
[GC 1617297K->1410050K(2944192K), 0.1461340 secs]
[GC 1410478K(2944192K), 0.0489770 secs]
[GC 1666178K->1431609K(2944192K), 0.1140540 secs]
[GC 1597522K(2944192K), 0.0723130 secs]
[GC 1451799K->1211512K(2944192K), 0.1041630 secs]
[GC 1467640K->1200322K(2944192K), 0.1284370 secs]
[GC 1456450K->1249904K(2944192K), 0.0990760 secs]
[GC 1506032K->1263174K(2944192K), 0.1010750 secs]
[GC 1519302K->1280839K(2944192K), 0.0982640 secs]
[GC 1536967K->1297398K(2944192K), 0.1056860 secs]
[GC 1553526K->1320494K(2944192K), 0.1095940 secs]
[GC 1576622K->1335323K(2944192K), 0.0998380 secs]
[GC 1591451K->1358137K(2944192K), 0.0969120 secs]
[GC 1614265K->1374204K(2944192K), 0.0912100 secs]
[GC 1630332K->1373562K(2944192K), 0.0819440 secs]
[GC 1629676K->1393642K(2944192K), 0.0840140 secs]
[GC 1649770K->1445775K(2944192K), 0.0891440 secs]
[GC 1700882K->1431648K(2944192K), 0.0993160 secs]
[GC 1685943K->1487779K(2944192K), 0.0921410 secs]
[GC 1743907K->1466504K(2944192K), 0.0867110 secs]
[GC 1722632K->1496920K(2944192K), 0.0664540 secs]
[GC 1753048K->1486754K(2944192K), 0.0855080 secs]
[GC 1742882K->1512220K(2944192K), 0.0748880 secs]
[GC 1768348K->1493751K(2944192K), 0.0892540 secs]
[GC 1749879K->1525271K(2944192K), 0.0627820 secs]
[GC 1781399K->1529584K(2944192K), 0.0679130 secs]
[GC 1785712K->1527953K(2944192K), 0.0868910 secs]
[GC 1784081K->1533364K(2944192K), 0.0761570 secs]
[GC 1789492K->1538667K(2944192K), 0.0818250 secs]
[GC 1794795K->1573082K(2944192K), 0.1068060 secs]
[GC 1829210K->1556518K(2944192K), 0.0923550 secs]
[GC 1812646K->1585388K(2944192K), 0.0742200 secs]
[GC 1841516K->1557634K(2944192K), 0.0807570 secs]
[GC 1813762K->1607590K(2944192K), 0.0967480 secs]
[GC 1863718K->1632221K(2944192K), 0.1140290 secs]
[GC 1886798K->1628889K(2944192K), 0.1094770 secs]
[GC 1885017K->1637671K(2944192K), 0.1039940 secs]
[GC 1892066K->1661940K(2944192K), 0.0900600 secs]
[GC 1918068K->1661240K(2944192K), 0.0866370 secs]
[GC 1916237K->1712173K(2944192K), 0.1249090 secs]
[GC 1968301K->1697973K(2944192K), 0.0874370 secs]
[GC 1954101K->1768963K(2944192K), 0.0913560 secs]
[GC 2025091K->1752220K(2944192K), 0.0888200 secs]
[GC 2008348K->1798446K(2944192K), 0.0879300 secs]
[GC 2054574K->1814649K(2944192K), 0.0878610 secs]
[GC 2070036K->1809483K(2944192K), 0.0875560 secs]
[GC 2065483K->1842976K(2944192K), 0.0866040 secs]
[GC 2097352K->1862177K(2944192K), 0.0893430 secs]
[GC 2118305K->1866724K(2944192K), 0.0855310 secs]
[GC 2122852K->1866918K(2944192K), 0.0834610 secs]
[GC 2123046K->1922343K(2944192K), 0.0701230 secs]
[GC 2176970K->1947963K(2944192K), 0.1018550 secs]
[GC 2204036K->1923231K(2944192K), 0.0947590 secs]
[GC 2179359K->1984611K(2944192K), 0.0896690 secs]
[GC 2240739K->1970016K(2944192K), 0.1035850 secs]
[GC 2226144K->2016601K(2944192K), 0.0918270 secs]
[GC 2272729K->2016352K(2944192K), 0.0851540 secs]
[GC 2272480K->2064834K(2944192K), 0.0883550 secs]
[GC 2319143K->2034622K(2944192K), 0.0887610 secs]
[GC 2290750K->2050945K(2944192K), 0.0849720 secs]
[GC 2307073K->2086941K(2944192K), 0.0871120 secs]
[GC 2343069K->2136065K(2944192K), 0.0886990 secs]
[GC 2390809K->2126059K(2944192K), 0.0868720 secs]
[GC 2382135K->2142121K(2944192K), 0.0874080 secs]
[GC 2398249K->2194830K(2944192K), 0.0881830 secs]
[GC 2450958K->2188834K(2944192K), 0.0909770 secs]
[GC 2444962K->2177734K(2944192K), 0.0957820 secs]
[GC 2433862K->2237779K(2944192K), 0.0663930 secs]
[GC 2493907K->2220860K(2944192K), 0.0855060 secs]
[GC 2476988K->2244337K(2944192K), 0.0674000 secs]
[GC 2500465K->2240235K(2944192K), 0.0881700 secs]
[GC 2496363K->2276341K(2944192K), 0.0746180 secs]
[GC 2532031K->2299832K(2944192K), 0.1164600 secs]
[GC 2555927K->2316165K(2944192K), 0.1473350 secs]
[GC 2572293K->2306844K(2944192K), 0.1100060 secs]
[GC 2562972K->2361652K(2944192K), 0.0994430 secs]
[GC 2617780K->2382441K(2944192K), 0.1035950 secs]
[GC 2638524K->2383853K(2944192K), 0.1010110 secs]
[GC 2639809K->2401259K(2944192K), 0.0969260 secs]
[GC 2657354K->2419933K(2944192K), 0.0956860 secs]
[GC 2676005K->2420919K(2944192K), 0.0918350 secs]
[GC 2677047K->2458880K(2944192K), 0.0919480 secs]
[GC 2459673K(2944192K), 0.0437930 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2714958K->2492907K(2944192K), 0.0836950 secs]
[GC 2664189K(2944192K), 0.1007310 secs]
[GC 2422129K->2186889K(3818844K), 0.0953110 secs]
[GC 2441923K->2194990K(3818844K), 0.0904490 secs]
[GC 2449357K->2213946K(3818844K), 0.0911550 secs]
[GC 2469533K->2224235K(3818844K), 0.1041910 secs]
[GC 2480363K->2245513K(3818844K), 0.0879900 secs]
[GC 2501641K->2250357K(3818844K), 0.0829200 secs]
[GC 2506485K->2249712K(3818844K), 0.0839430 secs]
[GC 2505840K->2300713K(3818844K), 0.0781320 secs]
[GC 2556841K->2295008K(3818844K), 0.0993870 secs]
[GC 2551090K->2334959K(3818844K), 0.0809970 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1960000. Elapsed time: 20.176 secs. Remaining: 39.824 secs. Total: 1 mins 0 secs
[GC 2591087K->2328341K(3818844K), 0.0983680 secs]
[GC 2584469K->2345415K(3818844K), 0.0757420 secs]
[GC 2601543K->2361870K(3818844K), 0.0997010 secs]
[GC 2617998K->2357179K(3818844K), 0.0818960 secs]
[GC 2613307K->2382686K(3818844K), 0.0693020 secs]
[GC 2638814K->2372936K(3818844K), 0.0795090 secs]
[GC 2629064K->2413077K(3818844K), 0.0794820 secs]
[GC 2669205K->2393775K(3818844K), 0.0804960 secs]
[GC 2649903K->2412674K(3818844K), 0.0790620 secs]
[GC 2668749K->2410213K(3818844K), 0.0795650 secs]
[GC 2662636K->2447123K(3818844K), 0.0841660 secs]
[GC 2703251K->2436853K(3818844K), 0.0881350 secs]
[GC 2692156K->2443411K(3818844K), 0.0819680 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 5900000. Elapsed time: 40.403 secs. Remaining: 19.597 secs. Total: 1 mins 0 secs
[GC 2699539K->2464543K(3818844K), 0.0808640 secs]
[GC 2719233K->2474639K(3818844K), 0.0742310 secs]
[GC 2730347K->2488982K(3818844K), 0.0827010 secs]
[GC 2742130K->2497899K(3818844K), 0.0890930 secs]
[GC 2753224K->2497064K(3818844K), 0.0774030 secs]
[GC 2753192K->2511075K(3818844K), 0.0648290 secs]
[GC 2767172K->2520388K(3818844K), 0.0707500 secs]
[GC 2776516K->2547086K(3818844K), 0.0843020 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2801956K->2545060K(3818844K), 0.0868420 secs]
[GC 2801188K->2554123K(3818844K), 0.0780000 secs]
[GC 2810251K->2547293K(3818844K), 0.0731950 secs]
[GC 2803421K->2577256K(3818844K), 0.0745060 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8040000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 40 mins 14 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2833384K->2541502K(3818844K), 0.1107350 secs]
[GC 2797630K->2566649K(3818844K), 0.0702310 secs]
[GC 2822690K->2580906K(3818844K), 0.0884770 secs]
[GC 2837034K->2625977K(3818844K), 0.1047830 secs]
[GC 2882105K->2650595K(3818844K), 0.1223330 secs]
[GC 2906723K->2648525K(3818844K), 0.1266600 secs]
[GC 2904632K->2668009K(3818844K), 0.1044050 secs]
[GC 2923584K->2684528K(3818844K), 0.1107870 secs]
[GC 2940656K->2738949K(3818844K), 0.1057840 secs]
[GC 2993531K->2724985K(3818844K), 0.1018930 secs]
[GC 2981113K->2778996K(3818844K), 0.1002340 secs]
[GC 3035124K->2765890K(3818844K), 0.1037430 secs]
[GC 3022018K->2807805K(3818844K), 0.1085490 secs]
[GC 3063933K->2823760K(3818844K), 0.1002370 secs]
[GC 3079888K->2831820K(3818844K), 0.1028840 secs]
[GC 3087948K->2881286K(3818844K), 0.0981970 secs]
[GC 3136243K->2867622K(3818844K), 0.0995150 secs]
[GC 3123750K->2912463K(3818844K), 0.1015280 secs]
[GC 3168591K->2941959K(3818844K), 0.1072290 secs]
[GC 3198062K->2954055K(3818844K), 0.1005600 secs]
[GC 3210183K->2944730K(3818844K), 0.1073180 secs]
[GC 3199546K->3010425K(3818844K), 0.1067280 secs]
[GC 3266536K->2995927K(3818844K), 0.0962260 secs]
[GC 3252055K->3052696K(3818844K), 0.1022560 secs]
[GC 3306712K->3033563K(3818844K), 0.0978010 secs]
[GC 3289691K->3093467K(3818844K), 0.0980230 secs]
[GC 3349595K->3086512K(3818844K), 0.1090420 secs]
[GC 3342640K->3128806K(3818844K), 0.1015780 secs]
[GC 3384934K->3154583K(3818844K), 0.1047970 secs]
[GC 3410678K->3142084K(3818844K), 0.0955560 secs]
[GC 3398212K->3195245K(3818844K), 0.1018340 secs]
[GC 3451373K->3180346K(3818844K), 0.0976910 secs]
[GC 3436474K->3236206K(3818844K), 0.0982210 secs]
[GC 3492334K->3222394K(3818844K), 0.0987080 secs]
[GC 3477832K->3277045K(3818844K), 0.0994520 secs]
[GC 3533173K->3261135K(3818844K), 0.0966410 secs]
[GC 3261237K(3818844K), 0.0410880 secs]
[GC 3517208K->3317789K(3818844K), 0.1070970 secs]
[GC 3573917K->3329083K(3818844K), 0.1074200 secs]
[GC 3493481K(3818844K), 0.0650870 secs]
[GC 3266141K->3033294K(3818844K), 0.1146570 secs]
[GC 3276483K->3041964K(4650880K), 0.1196610 secs]
[GC 3298092K->3041812K(4650880K), 0.1127660 secs]
[GC 3297940K->3066477K(4650880K), 0.1109700 secs]
[GC 3321017K->3102067K(4650880K), 0.1111120 secs]
[GC 3358142K->3121993K(4650880K), 0.1073180 secs]
[GC 3378102K->3158382K(4650880K), 0.1034740 secs]
[GC 3414509K->3142163K(4650880K), 0.0962370 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5708 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3398291K->3198232K(4650880K), 0.0978860 secs]
[GC 3454360K->3180175K(4650880K), 0.1023110 secs]
[GC 3436303K->3214948K(4650880K), 0.1028940 secs]
[GC 3471076K->3259706K(4650880K), 0.1010200 secs]
[GC 3515834K->3246451K(4650880K), 0.1048840 secs]
[GC 3502579K->3301047K(4650880K), 0.0967160 secs]
[GC 3555739K->3306282K(4650880K), 0.1074760 secs]
[GC 3562382K->3325062K(4650880K), 0.1096670 secs]
[GC 3581175K->3344972K(4650880K), 0.1016170 secs]
[GC 3601100K->3367410K(4650880K), 0.0988670 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5708 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5708 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5708 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 61 ms.
