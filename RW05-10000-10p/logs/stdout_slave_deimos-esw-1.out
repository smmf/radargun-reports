/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-1 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-1
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0636100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 4. Sleeping for 7000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 4
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2ca44b35
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5705, using socket ServerSocket[addr=/0.0.0.0,localport=5705], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5705
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 39252 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 32830 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 48578 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5705 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705 this
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 53952 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 47464 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45518
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 48291 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:45518
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:49089
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 49467 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 32904 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:49089
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 38850 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 44337 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:45412
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 40286 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:45412
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:34953
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:34953
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:33011
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:33011
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:38672
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:38672
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 3
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 4
[GC 259695K->13482K(2944064K), 0.0424630 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|2] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-34819, physical addresses are [127.0.0.1:52003]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-34819] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|3] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-34819] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|4] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626]
 INFO  [Incoming-4,deimos-esw-34819] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|5] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-34819] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|6] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197, deimos-esw-13058, deimos-esw-21979]
 INFO  [Incoming-4,deimos-esw-34819] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57427|7] [deimos-esw-57427, deimos-esw-57840, deimos-esw-60507, deimos-esw-34819, deimos-esw-15591, deimos-esw-58608, deimos-esw-20626, deimos-esw-57197, deimos-esw-13058, deimos-esw-21979, deimos-esw-52809, deimos-esw-13191]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 3, serverOidBase: 3000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 4: org.radargun.cachewrappers.FFWrapper@7c465b32
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@7c465b32, nodeIndex=4, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 269546K->23310K(2944064K), 0.0552590 secs]
[GC 279374K->31293K(2944064K), 0.0465500 secs]
[GC 287357K->52218K(2944064K), 0.0534080 secs]
[GC 308282K->75834K(2944064K), 0.0551500 secs]
[GC 331898K->84600K(2944064K), 0.0593700 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 340664K->116032K(2944064K), 0.0654340 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6900. Elapsed time: 20.280 secs. Remaining: 39.720 secs. Total: 1 mins 0 secs
[GC 372096K->118442K(2944064K), 0.1245490 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 13100. Elapsed time: 40.326 secs. Remaining: 19.674 secs. Total: 1 mins 0 secs
[GC 374506K->113468K(2944064K), 0.0866730 secs]
[GC 369532K->156491K(2944064K), 0.0729700 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 26100. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 59 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 179 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,642,262 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 301801K->127395K(2944064K), 0.7175860 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,815,423 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@7c465b32, nodeIndex=4, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 383523K->195013K(2944192K), 0.0316280 secs]
[GC 451141K->145845K(2944192K), 0.0803620 secs]
[GC 401973K->160959K(2944192K), 0.0422230 secs]
[GC 417087K->172071K(2944192K), 0.0462240 secs]
[GC 428199K->187248K(2944192K), 0.0521980 secs]
[GC 443376K->202485K(2944192K), 0.0529580 secs]
[GC 458613K->206310K(2944192K), 0.0580520 secs]
[GC 462438K->220084K(2944192K), 0.0610550 secs]
[GC 476212K->248781K(2944192K), 0.0733000 secs]
[GC 504909K->258977K(2944192K), 0.0972880 secs]
[GC 515105K->278043K(2944192K), 0.0870450 secs]
[GC 534135K->283715K(2944192K), 0.0952730 secs]
[GC 538782K->331810K(2944192K), 0.0875000 secs]
[GC 587938K->315376K(2944192K), 0.0852670 secs]
[GC 571490K->372003K(2944192K), 0.0935980 secs]
[GC 628131K->351867K(2944192K), 0.0904540 secs]
[GC 607952K->411930K(2944192K), 0.0873100 secs]
[GC 668058K->388396K(2944192K), 0.0872350 secs]
[GC 644524K->439285K(2944192K), 0.0817510 secs]
[GC 695380K->446695K(2944192K), 0.0844030 secs]
[GC 702823K->468047K(2944192K), 0.0845800 secs]
[GC 724154K->467817K(2944192K), 0.0780400 secs]
[GC 723945K->501366K(2944192K), 0.0847270 secs]
[GC 757494K->510180K(2944192K), 0.0808580 secs]
[GC 766308K->541244K(2944192K), 0.0777350 secs]
[GC 795998K->558442K(2944192K), 0.0777620 secs]
[GC 814570K->581304K(2944192K), 0.0759480 secs]
[GC 837415K->598222K(2944192K), 0.0792150 secs]
[GC 854350K->635109K(2944192K), 0.0829380 secs]
[GC 891237K->606203K(2944192K), 0.0870580 secs]
[GC 862331K->622887K(2944192K), 0.0823510 secs]
[GC 879015K->657702K(2944192K), 0.0617030 secs]
[GC 913830K->640582K(2944192K), 0.0862250 secs]
[GC 896710K->669018K(2944192K), 0.0829240 secs]
[GC 925146K->675000K(2944192K), 0.0828150 secs]
[GC 931128K->678451K(2944192K), 0.1237290 secs]
[GC 934579K->706875K(2944192K), 0.0622150 secs]
[GC 962994K->705349K(2944192K), 0.0734900 secs]
[GC 961477K->740710K(2944192K), 0.0958340 secs]
[GC 996814K->756360K(2944192K), 0.1505670 secs]
[GC 1012454K->734211K(2944192K), 0.0940790 secs]
[GC 990339K->784318K(2944192K), 0.0812300 secs]
[GC 1040444K->783905K(2944192K), 0.0841270 secs]
[GC 1040033K->835426K(2944192K), 0.0852780 secs]
[GC 1091517K->821996K(2944192K), 0.0881440 secs]
[GC 1078124K->875329K(2944192K), 0.0834960 secs]
[GC 1131457K->855956K(2944192K), 0.0818810 secs]
[GC 1112084K->915740K(2944192K), 0.0947700 secs]
[GC 1171852K->893991K(2944192K), 0.0786390 secs]
[GC 1148768K->954189K(2944192K), 0.0915040 secs]
[GC 1210317K->929409K(2944192K), 0.0877930 secs]
[GC 1185537K->991831K(2944192K), 0.0845420 secs]
[GC 1247854K->965675K(2944192K), 0.0899040 secs]
[GC 1221803K->1014656K(2944192K), 0.0792010 secs]
[GC 1270748K->1039022K(2944192K), 0.0838190 secs]
[GC 1295150K->1024593K(2944192K), 0.0821360 secs]
[GC 1280721K->1074886K(2944192K), 0.0829820 secs]
[GC 1331014K->1047489K(2944192K), 0.0842590 secs]
[GC 1303617K->1105305K(2944192K), 0.0721930 secs]
[GC 1361433K->1084732K(2944192K), 0.0968030 secs]
[GC 1340860K->1105615K(2944192K), 0.0664420 secs]
[GC 1361743K->1082286K(2944192K), 0.0783290 secs]
[GC 1338414K->1084747K(2944192K), 0.0955100 secs]
[GC 1340875K->1120657K(2944192K), 0.0877930 secs]
[GC 1376785K->1142930K(2944192K), 0.1102660 secs]
[GC 1399058K->1121708K(2944192K), 0.1143150 secs]
[GC 1377836K->1147396K(2944192K), 0.1458250 secs]
[GC 1403524K->1140824K(2944192K), 0.1672170 secs]
[GC 1396952K->1151209K(2944192K), 0.1324020 secs]
[GC 1407337K->1142873K(2944192K), 0.0842540 secs]
[GC 1399001K->1167957K(2944192K), 0.1372660 secs]
[GC 1424085K->1192114K(2944192K), 0.1559830 secs]
[GC 1448242K->1166269K(2944192K), 0.1299470 secs]
[GC 1422397K->1198643K(2944192K), 0.0807570 secs]
[GC 1454771K->1198183K(2944192K), 0.1684420 secs]
[GC 1454311K->1224476K(2944192K), 0.0847270 secs]
[GC 1480604K->1206419K(2944192K), 0.0931420 secs]
[GC 1462547K->1230265K(2944192K), 0.0813030 secs]
[GC 1486393K->1251894K(2944192K), 0.0952610 secs]
[GC 1508022K->1227857K(2944192K), 0.1299640 secs]
[GC 1483985K->1269575K(2944192K), 0.0860370 secs]
[GC 1525703K->1247200K(2944192K), 0.1017550 secs]
[GC 1503328K->1287008K(2944192K), 0.0880830 secs]
[GC 1543136K->1254279K(2944192K), 0.1543670 secs]
[GC 1510407K->1301858K(2944192K), 0.0851170 secs]
[GC 1557986K->1270288K(2944192K), 0.1061700 secs]
[GC 1526416K->1304180K(2944192K), 0.1565900 secs]
[GC 1560308K->1318552K(2944192K), 0.1719060 secs]
[GC 1574680K->1295871K(2944192K), 0.1402290 secs]
[GC 1551999K->1331252K(2944192K), 0.1195170 secs]
[GC 1587380K->1325797K(2944192K), 0.1385540 secs]
[GC 1581925K->1337480K(2944192K), 0.0832390 secs]
[GC 1593608K->1345168K(2944192K), 0.0976570 secs]
[GC 1601296K->1335885K(2944192K), 0.1463300 secs]
[GC 1592013K->1359823K(2944192K), 0.1586370 secs]
[GC 1615951K->1366262K(2944192K), 0.1326310 secs]
[GC 1622390K->1357638K(2944192K), 0.1593700 secs]
[GC 1613766K->1381241K(2944192K), 0.1768930 secs]
[GC 1637369K->1404231K(2944192K), 0.1506600 secs]
[GC 1404761K(2944192K), 0.0534230 secs]
[GC 1464659K(2944192K), 0.0484200 secs]
[GC 1441564K->1158711K(2944192K), 0.0754460 secs]
[GC 1414839K->1185261K(2944192K), 0.0720780 secs]
[GC 1441389K->1199261K(2944192K), 0.0775640 secs]
[GC 1455389K->1175627K(2944192K), 0.0748800 secs]
[GC 1431755K->1219230K(2944192K), 0.0726800 secs]
[GC 1475358K->1186336K(2944192K), 0.0706800 secs]
[GC 1442464K->1233838K(2944192K), 0.0738150 secs]
[GC 1489966K->1201316K(2944192K), 0.0729090 secs]
[GC 1457444K->1252017K(2944192K), 0.0873770 secs]
[GC 1508145K->1278621K(2944192K), 0.1000550 secs]
[GC 1534749K->1281321K(2944192K), 0.1052300 secs]
[GC 1537420K->1283959K(2944192K), 0.1004570 secs]
[GC 1540053K->1292030K(2944192K), 0.0885350 secs]
[GC 1548122K->1341315K(2944192K), 0.0912660 secs]
[GC 1597443K->1377802K(2944192K), 0.0974280 secs]
[GC 1633930K->1363523K(2944192K), 0.0929670 secs]
[GC 1619624K->1418463K(2944192K), 0.0902470 secs]
[GC 1674541K->1395805K(2944192K), 0.0897390 secs]
[GC 1651459K->1456648K(2944192K), 0.0870310 secs]
[GC 1712776K->1434645K(2944192K), 0.0871490 secs]
[GC 1690773K->1491626K(2944192K), 0.0880670 secs]
[GC 1747754K->1472032K(2944192K), 0.0890100 secs]
[GC 1728160K->1522907K(2944192K), 0.0896550 secs]
[GC 1779035K->1494731K(2944192K), 0.0832520 secs]
[GC 1750859K->1545651K(2944192K), 0.0664310 secs]
[GC 1801779K->1505423K(2944192K), 0.0676650 secs]
[GC 1761551K->1513015K(2944192K), 0.0818570 secs]
[GC 1769143K->1564520K(2944192K), 0.0627510 secs]
[GC 1820648K->1525916K(2944192K), 0.0690840 secs]
[GC 1782044K->1534082K(2944192K), 0.0838320 secs]
[GC 1790210K->1587552K(2944192K), 0.0573260 secs]
[GC 1841663K->1569201K(2944192K), 0.0850870 secs]
[GC 1825329K->1623888K(2944192K), 0.0985840 secs]
[GC 1880016K->1602731K(2944192K), 0.1107290 secs]
[GC 1858859K->1642057K(2944192K), 0.0966730 secs]
[GC 1898127K->1637855K(2944192K), 0.0900350 secs]
[GC 1893983K->1672577K(2944192K), 0.0900240 secs]
[GC 1928705K->1704132K(2944192K), 0.0877970 secs]
[GC 1960223K->1691129K(2944192K), 0.0887490 secs]
[GC 1946924K->1724437K(2944192K), 0.0886380 secs]
[GC 1980529K->1742452K(2944192K), 0.0858800 secs]
[GC 1998577K->1794775K(2944192K), 0.0898520 secs]
[GC 2050788K->1779925K(2944192K), 0.0929280 secs]
[GC 2036053K->1838120K(2944192K), 0.0869570 secs]
[GC 2094211K->1815715K(2944192K), 0.0870550 secs]
[GC 2071843K->1813247K(2944192K), 0.0784360 secs]
[GC 2069375K->1867010K(2944192K), 0.0615300 secs]
[GC 2123138K->1850882K(2944192K), 0.0781290 secs]
[GC 2107010K->1868782K(2944192K), 0.0557190 secs]
[GC 2124910K->1890019K(2944192K), 0.0762420 secs]
[GC 2146147K->1924870K(2944192K), 0.0948320 secs]
[GC 2180998K->1921251K(2944192K), 0.1047190 secs]
[GC 2177379K->1945564K(2944192K), 0.1084040 secs]
[GC 2201021K->1956228K(2944192K), 0.0956010 secs]
[GC 2212356K->1970842K(2944192K), 0.0865480 secs]
[GC 2226970K->1988211K(2944192K), 0.0929170 secs]
[GC 2244325K->2007139K(2944192K), 0.0883680 secs]
[GC 2263267K->2042099K(2944192K), 0.0905600 secs]
[GC 2298197K->2029356K(2944192K), 0.0873970 secs]
[GC 2285470K->2060805K(2944192K), 0.0849450 secs]
[GC 2316933K->2079958K(2944192K), 0.0909170 secs]
[GC 2336086K->2116314K(2944192K), 0.0880130 secs]
[GC 2372442K->2119566K(2944192K), 0.0892150 secs]
[GC 2375694K->2153715K(2944192K), 0.0911270 secs]
[GC 2409793K->2199606K(2944192K), 0.0969140 secs]
[GC 2455734K->2185161K(2944192K), 0.0998970 secs]
[GC 2441289K->2246107K(2944192K), 0.0997000 secs]
[GC 2502235K->2234703K(2944192K), 0.1016470 secs]
[GC 2490831K->2285399K(2944192K), 0.1024870 secs]
[GC 2539922K->2291959K(2944192K), 0.1114220 secs]
[GC 2548087K->2311358K(2944192K), 0.1024570 secs]
[GC 2567475K->2314045K(2944192K), 0.1106750 secs]
[GC 2570173K->2368117K(2944192K), 0.1044990 secs]
[GC 2624245K->2355567K(2944192K), 0.1006940 secs]
[GC 2611695K->2401974K(2944192K), 0.0979380 secs]
[GC 2658102K->2414895K(2944192K), 0.0978080 secs]
[GC 2671023K->2416099K(2944192K), 0.1019980 secs]
[GC 2672227K->2435138K(2944192K), 0.0954290 secs]
[GC 2691266K->2453005K(2944192K), 0.0883320 secs]
[GC 2454174K(2944192K), 0.0386440 secs]
[GC 2709133K->2488987K(2944192K), 0.0993460 secs]
[GC 2552088K(2944192K), 0.0411620 secs]
[GC 2420201K->2146544K(3813056K), 0.1005310 secs]
[GC 2402646K->2197364K(3813056K), 0.0697060 secs]
[GC 2453453K->2180936K(3813056K), 0.1056580 secs]
[GC 2437064K->2249675K(3813056K), 0.1063380 secs]
[GC 2505803K->2222476K(3813056K), 0.0929530 secs]
[GC 2478604K->2276480K(3813056K), 0.1237870 secs]
[GC 2532608K->2267825K(3813056K), 0.1116490 secs]
[GC 2523953K->2283820K(3813056K), 0.1077650 secs]
[GC 2539948K->2321436K(3813056K), 0.1104480 secs]
[GC 2577088K->2324531K(3813056K), 0.0967370 secs]
[GC 2580659K->2339846K(3813056K), 0.0964840 secs]
[GC 2595974K->2357764K(3813056K), 0.0942920 secs]
[GC 2613892K->2390176K(3813056K), 0.0919760 secs]
[GC 2644561K->2409739K(3813056K), 0.0975840 secs]
[GC 2665170K->2413098K(3813056K), 0.0962990 secs]
[GC 2669180K->2448656K(3813056K), 0.0916510 secs]
[GC 2704784K->2466830K(3813056K), 0.0959070 secs]
[GC 2722958K->2487061K(3813056K), 0.0930130 secs]
[GC 2743189K->2470974K(3813056K), 0.0881970 secs]
[GC 2727102K->2522152K(3813056K), 0.0685320 secs]
[GC 2778280K->2503595K(3813056K), 0.0884600 secs]
[GC 2759723K->2521261K(3813056K), 0.0770150 secs]
[GC 2776938K->2549287K(3813056K), 0.0993040 secs]
[GC 2805415K->2585232K(3813056K), 0.0893670 secs]
[GC 2841360K->2582202K(3813056K), 0.1111900 secs]
[GC 2837445K->2593450K(3813056K), 0.0964820 secs]
[GC 2849528K->2592462K(3813056K), 0.0969380 secs]
[GC 2848547K->2660830K(3813056K), 0.0964390 secs]
[GC 2915668K->2647009K(3813056K), 0.1027420 secs]
[GC 2903137K->2711253K(3813056K), 0.1034020 secs]
[GC 2967381K->2701199K(3813056K), 0.1019720 secs]
[GC 2957327K->2719288K(3813056K), 0.1024730 secs]
[GC 2975416K->2746224K(3813056K), 0.1060880 secs]
[GC 3002352K->2785331K(3813056K), 0.1116960 secs]
[GC 3041459K->2785087K(3813056K), 0.1029990 secs]
[GC 3041215K->2807964K(3813056K), 0.1020690 secs]
[GC 3064092K->2832453K(3813056K), 0.1030250 secs]
[GC 3088573K->2868507K(3813056K), 0.1046160 secs]
[GC 3124635K->2873039K(3813056K), 0.1048340 secs]
[GC 3129167K->2896057K(3813056K), 0.1132700 secs]
[GC 3152163K->2897674K(3813056K), 0.0992720 secs]
[GC 3153802K->2931622K(3813056K), 0.0975730 secs]
[GC 3187750K->2981590K(3813056K), 0.0973980 secs]
[GC 3237718K->2969717K(3813056K), 0.0959950 secs]
[GC 3225845K->2989358K(3813056K), 0.0963640 secs]
[GC 3245486K->2990284K(3813056K), 0.0875490 secs]
[GC 3246412K->3040231K(3813056K), 0.0711570 secs]
[GC 3296359K->3021859K(3813056K), 0.0880840 secs]
[GC 3277987K->3043560K(3813056K), 0.0623230 secs]
[GC 3299688K->3021201K(3813056K), 0.0696730 secs]
[GC 3277329K->3043114K(3813056K), 0.0928790 secs]
[GC 3297963K->3090323K(3813056K), 0.0772070 secs]
[GC 3346451K->3114595K(3813056K), 0.1070640 secs]
[GC 3370723K->3093845K(3813056K), 0.1028130 secs]
[GC 3349973K->3141639K(3813056K), 0.0951240 secs]
[GC 3397767K->3144189K(3813056K), 0.0928380 secs]
[GC 3398563K->3174938K(3813056K), 0.0937010 secs]
[GC 3429516K->3176963K(3813056K), 0.0904980 secs]
[GC 3433091K->3211299K(3813056K), 0.0934810 secs]
[GC 3467427K->3226873K(3813056K), 0.0891310 secs]
[GC 3483001K->3231907K(3813056K), 0.0968110 secs]
[GC 3486550K->3251858K(3813056K), 0.1008170 secs]
[GC 3253995K(3813056K), 0.0321720 secs]
[GC 3507967K->3268551K(3813056K), 0.1011640 secs]
[GC 3435912K(3813056K), 0.0605520 secs]
[GC 3213807K->2975913K(4650880K), 0.1036010 secs]
[GC 3232041K->2994666K(4650880K), 0.1078100 secs]
[GC 3250794K->3010937K(4650880K), 0.1044020 secs]
[GC 3267065K->3032279K(4650880K), 0.0974580 secs]
[GC 3288407K->3035389K(4650880K), 0.0918040 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3291517K->3089343K(4650880K), 0.0755040 secs]
[GC 3345471K->3087812K(4650880K), 0.0972760 secs]
[GC 3343484K->3112238K(4650880K), 0.1068220 secs]
[GC 3368293K->3124957K(4650880K), 0.0733600 secs]
[GC 3380552K->3124642K(4650880K), 0.0760860 secs]
[GC 3380770K->3126718K(4650880K), 0.0556100 secs]
[GC 3382846K->3198752K(4650880K), 0.0794660 secs]
[GC 3454860K->3187743K(4650880K), 0.1072850 secs]
[GC 3443871K->3226075K(4650880K), 0.1005750 secs]
[GC 3481097K->3296781K(4650880K), 0.0821050 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2060000. Elapsed time: 20.020 secs. Remaining: 39.980 secs. Total: 1 mins 0 secs
[GC 3552877K->3287522K(4650880K), 0.0727740 secs]
[GC 3542000K->3319367K(4650880K), 0.0619790 secs]
[GC 3575495K->3307653K(4650880K), 0.0699630 secs]
[GC 3563781K->3358446K(4650880K), 0.0816850 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.4G, free=1015.4M, total=4.4G, max=4.7G, used/total=77.64% used/max=73.60%
cpu process-load=4.00%, system-load=16.00%, system-loadaverage=319.00%
[GC 3614574K->3376426K(4650880K), 0.0953680 secs]
[GC 3632387K->3354191K(4650880K), 0.0724220 secs]
[GC 3608142K->3427077K(4650880K), 0.0847530 secs]
[GC 3683164K->3435484K(4650880K), 0.0885860 secs]
[GC 3691555K->3412120K(4650880K), 0.0930380 secs]
[GC 3668248K->3416689K(4650880K), 0.0610700 secs]
[GC 3672817K->3424472K(4650880K), 0.0695830 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.4G, free=1.1G, total=4.4G, max=4.7G, used/total=75.72% used/max=71.77%
cpu process-load=4.00%, system-load=17.00%, system-loadaverage=325.00%
[GC 3680600K->3462573K(4650880K), 0.0711040 secs]
[GC 3718701K->3460677K(4650880K), 0.0876040 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 5477235. Elapsed time: 40.020 secs. Remaining: 19.980 secs. Total: 1 mins 0 secs
[GC 3716805K->3481801K(4650880K), 0.0900430 secs]
[GC 3737929K->3491380K(4650880K), 0.0990090 secs]
[GC 3747508K->3534810K(4650880K), 0.0726520 secs]
[GC 3789873K->3523093K(4650880K), 0.1046140 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.6G, free=878.4M, total=4.4G, max=4.7G, used/total=80.66% used/max=76.45%
cpu process-load=4.00%, system-load=17.00%, system-loadaverage=327.00%
[GC 3779221K->3535464K(4650880K), 0.0619210 secs]
[GC 3791592K->3563638K(4650880K), 0.0712750 secs]
[GC 3819766K->3584381K(4650880K), 0.0824770 secs]
[GC 3840509K->3587928K(4650880K), 0.0868900 secs]
[GC 3843393K->3605969K(4650880K), 0.0819680 secs]
[GC 3862097K->3609318K(4650880K), 0.0820010 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.7G, free=783.6M, total=4.4G, max=4.7G, used/total=82.75% used/max=78.43%
cpu process-load=3.00%, system-load=17.00%, system-loadaverage=356.00%
[GC 3863792K->3629883K(4650880K), 0.0814090 secs]
[GC 3886011K->3651022K(4650880K), 0.1055920 secs]
[GC 3907150K->3671464K(4650880K), 0.0701910 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8270000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 52 mins 59 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:4, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3927592K->3667749K(4650880K), 0.0913150 secs]
[GC 3923205K->3683145K(4650880K), 0.0716610 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.6G, free=832.2M, total=4.4G, max=4.7G, used/total=81.68% used/max=77.42%
cpu process-load=2.00%, system-load=16.00%, system-loadaverage=377.00%
[GC 3939045K->3706924K(4650880K), 0.0877600 secs]
[GC 3963052K->3735970K(4650880K), 0.1059750 secs]
[GC 3992098K->3762143K(4650880K), 0.1061810 secs]
[GC 4018271K->3780322K(4650880K), 0.1016060 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.6G, free=827.9M, total=4.4G, max=4.7G, used/total=81.77% used/max=77.51%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=388.00%
[GC 4036450K->3805288K(4650880K), 0.1002840 secs]
[GC 4061416K->3823325K(4650880K), 0.1067520 secs]
[GC 4079453K->3843670K(4650880K), 0.0976530 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5705 [FenixFrameworkGroup] 
memory used=3.8G, free=655.1M, total=4.4G, max=4.7G, used/total=85.58% used/max=81.11%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=422.00%
[GC 4099798K->3863916K(4650880K), 0.1078730 secs]
[GC 4120044K->3884704K(4650880K), 0.1033620 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5705 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 51 ms.
