/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-11902 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-11902
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0866110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@52b2f956
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:53991
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:53991
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 57169 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:59862
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:59862
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:56070
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:56070
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:49831
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:49831
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:60062
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:60062
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:42285
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:42285
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:36966
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36966
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:35688
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:35688
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 2
[GC 259695K->12869K(2944064K), 0.0431480 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|2] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-20477, physical addresses are [127.0.0.1:52002]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-20477] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|3] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-20477] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|4] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660]
 INFO  [Incoming-3,deimos-esw-20477] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|5] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660, deimos-esw-47278, deimos-esw-57185]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-3,deimos-esw-20477] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-54793|6] [deimos-esw-54793, deimos-esw-29119, deimos-esw-20477, deimos-esw-3537, deimos-esw-28090, deimos-esw-52660, deimos-esw-47278, deimos-esw-57185, deimos-esw-33880, deimos-esw-45371]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@277b1121
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 8
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@277b1121, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268933K->22338K(2944064K), 0.0564990 secs]
[GC 278402K->31513K(2944064K), 0.0478070 secs]
[GC 287577K->50313K(2944064K), 0.0516810 secs]
[GC 306377K->74699K(2944064K), 0.0548080 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 330763K->83894K(2944064K), 0.0593750 secs]
[GC 339958K->104186K(2944064K), 0.0634860 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 13350. Elapsed time: 20.066 secs. Remaining: 39.934 secs. Total: 1 mins 0 secs
[GC 360250K->113559K(2944064K), 0.1578880 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 22500. Elapsed time: 40.417 secs. Remaining: 19.583 secs. Total: 1 mins 0 secs
[GC 369623K->159242K(2944064K), 0.0735060 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 35 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 155 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 415306K->148618K(2944064K), 0.0711860 secs]
[GC 404682K->171639K(2944064K), 0.0710820 secs]
[GC 427703K->199771K(2944064K), 0.0895850 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,702,389 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 241674K->163092K(2944064K), 0.7074390 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,779,874 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@277b1121, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 419220K->239008K(2944192K), 0.0366850 secs]
[GC 495136K->183799K(2944192K), 0.0398990 secs]
[GC 439927K->200499K(2944192K), 0.0463340 secs]
[GC 456627K->212411K(2944192K), 0.0503860 secs]
[GC 468539K->228470K(2944192K), 0.0553370 secs]
[GC 484598K->244393K(2944192K), 0.0599800 secs]
[GC 500521K->260491K(2944192K), 0.0621720 secs]
[GC 516619K->261677K(2944192K), 0.0683270 secs]
[GC 517805K->284332K(2944192K), 0.0821370 secs]
[GC 538667K->309037K(2944192K), 0.0921920 secs]
[GC 564543K->326178K(2944192K), 0.0872860 secs]
[GC 582306K->323935K(2944192K), 0.1076800 secs]
[GC 579110K->356642K(2944192K), 0.0861830 secs]
[GC 612770K->374262K(2944192K), 0.0840340 secs]
[GC 630383K->395133K(2944192K), 0.0892960 secs]
[GC 651261K->409434K(2944192K), 0.0800860 secs]
[GC 665514K->415032K(2944192K), 0.0783030 secs]
[GC 671160K->449189K(2944192K), 0.0780680 secs]
[GC 705264K->449767K(2944192K), 0.0759560 secs]
[GC 705895K->502811K(2944192K), 0.0778580 secs]
[GC 758939K->486426K(2944192K), 0.0766590 secs]
[GC 742554K->542141K(2944192K), 0.0802540 secs]
[GC 798269K->523279K(2944192K), 0.0723560 secs]
[GC 779395K->567626K(2944192K), 0.0768110 secs]
[GC 823754K->594176K(2944192K), 0.0778990 secs]
[GC 850304K->584187K(2944192K), 0.0813120 secs]
[GC 839272K->620812K(2944192K), 0.0863980 secs]
[GC 876940K->641757K(2944192K), 0.0883150 secs]
[GC 897885K->679516K(2944192K), 0.0877550 secs]
[GC 935630K->666175K(2944192K), 0.0939980 secs]
[GC 922303K->693781K(2944192K), 0.0896250 secs]
[GC 949909K->681779K(2944192K), 0.0869930 secs]
[GC 937907K->714226K(2944192K), 0.0566770 secs]
[GC 970354K->720597K(2944192K), 0.0590050 secs]
[GC 976725K->705595K(2944192K), 0.0842690 secs]
[GC 961723K->739528K(2944192K), 0.0624160 secs]
[GC 995656K->761590K(2944192K), 0.0626370 secs]
[GC 1017345K->771234K(2944192K), 0.0947900 secs]
[GC 1027362K->797530K(2944192K), 0.1473270 secs]
[GC 1053658K->795565K(2944192K), 0.1322190 secs]
[GC 1051688K->805392K(2944192K), 0.0784710 secs]
[GC 1061520K->843280K(2944192K), 0.0788920 secs]
[GC 1099408K->871435K(2944192K), 0.0828750 secs]
[GC 1126430K->858137K(2944192K), 0.0795850 secs]
[GC 1114265K->915969K(2944192K), 0.0816340 secs]
[GC 1172038K->893965K(2944192K), 0.0817350 secs]
[GC 1150093K->952067K(2944192K), 0.0783320 secs]
[GC 1208195K->942838K(2944192K), 0.0755620 secs]
[GC 1197050K->992935K(2944192K), 0.0797720 secs]
[GC 1249063K->971810K(2944192K), 0.0803130 secs]
[GC 1227938K->1012384K(2944192K), 0.0830460 secs]
[GC 1268475K->1025423K(2944192K), 0.0778920 secs]
[GC 1281551K->1048918K(2944192K), 0.0815860 secs]
[GC 1305046K->1064325K(2944192K), 0.0786090 secs]
[GC 1320449K->1084607K(2944192K), 0.0798890 secs]
[GC 1340735K->1121476K(2944192K), 0.0801750 secs]
[GC 1377562K->1105547K(2944192K), 0.0773740 secs]
[GC 1361675K->1159345K(2944192K), 0.0830690 secs]
[GC 1415473K->1140963K(2944192K), 0.1508650 secs]
[GC 1397091K->1155078K(2944192K), 0.0754720 secs]
[GC 1411206K->1195096K(2944192K), 0.0747920 secs]
[GC 1451224K->1177766K(2944192K), 0.0938410 secs]
[GC 1433894K->1196463K(2944192K), 0.0787350 secs]
[GC 1452591K->1211579K(2944192K), 0.0955200 secs]
[GC 1467707K->1200948K(2944192K), 0.1305400 secs]
[GC 1457076K->1217643K(2944192K), 0.0587800 secs]
[GC 1473771K->1220940K(2944192K), 0.0647280 secs]
[GC 1477068K->1228866K(2944192K), 0.0783060 secs]
[GC 1484994K->1237179K(2944192K), 0.0766180 secs]
[GC 1493307K->1262106K(2944192K), 0.1576740 secs]
[GC 1518234K->1237854K(2944192K), 0.1571720 secs]
[GC 1493982K->1270456K(2944192K), 0.1450040 secs]
[GC 1526584K->1270862K(2944192K), 0.0796780 secs]
[GC 1526990K->1279936K(2944192K), 0.1200450 secs]
[GC 1536064K->1271231K(2944192K), 0.1547800 secs]
[GC 1527359K->1298475K(2944192K), 0.0818750 secs]
[GC 1554603K->1288909K(2944192K), 0.1464270 secs]
[GC 1545037K->1296049K(2944192K), 0.1657870 secs]
[GC 1552177K->1336369K(2944192K), 0.0795430 secs]
[GC 1592497K->1310696K(2944192K), 0.1161420 secs]
[GC 1566824K->1341797K(2944192K), 0.1651260 secs]
[GC 1597925K->1356661K(2944192K), 0.0810220 secs]
[GC 1612789K->1333574K(2944192K), 0.1319550 secs]
[GC 1589702K->1377637K(2944192K), 0.0781580 secs]
[GC 1633765K->1337721K(2944192K), 0.0993580 secs]
[GC 1593849K->1394914K(2944192K), 0.0819920 secs]
[GC 1651042K->1369890K(2944192K), 0.1339610 secs]
[GC 1370245K(2944192K), 0.0492760 secs]
[GC 1438788K(2944192K), 0.0717660 secs]
[GC 1399143K->1174460K(2944192K), 0.0635710 secs]
[GC 1430588K->1145163K(2944192K), 0.0719350 secs]
[GC 1401291K->1179078K(2944192K), 0.0701860 secs]
[GC 1435206K->1177931K(2944192K), 0.0735660 secs]
[GC 1434059K->1188333K(2944192K), 0.0685810 secs]
[GC 1444461K->1196123K(2944192K), 0.0696960 secs]
[GC 1452251K->1203605K(2944192K), 0.0740510 secs]
[GC 1459733K->1193293K(2944192K), 0.0746550 secs]
 INFO  [Stressor-1] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=299252 <= mostRecentNum=299255.
 INFO  [Stressor-1] {pt.ist.fenixframework.backend.jvstm.pstm.ClusteredPersistentTransaction} Ignoring outdated remote commit txNum=299253 <= mostRecentNum=299255.
[GC 1449421K->1233973K(2944192K), 0.0731950 secs]
[GC 1490101K->1208401K(2944192K), 0.0705180 secs]
[GC 1464529K->1254097K(2944192K), 0.0725210 secs]
[GC 1508611K->1250388K(2944192K), 0.0836410 secs]
[GC 1506482K->1292383K(2944192K), 0.0920550 secs]
[GC 1548458K->1312051K(2944192K), 0.0950890 secs]
[GC 1566290K->1291866K(2944192K), 0.0993920 secs]
[GC 1547727K->1320894K(2944192K), 0.0858170 secs]
[GC 1577022K->1354254K(2944192K), 0.0818490 secs]
[GC 1610204K->1371160K(2944192K), 0.0839240 secs]
[GC 1627288K->1390344K(2944192K), 0.0876130 secs]
[GC 1645273K->1407959K(2944192K), 0.0868220 secs]
[GC 1664072K->1410016K(2944192K), 0.0821180 secs]
[GC 1665962K->1445074K(2944192K), 0.0911430 secs]
[GC 1701160K->1464723K(2944192K), 0.0891660 secs]
[GC 1719396K->1484097K(2944192K), 0.0831930 secs]
[GC 1740213K->1485169K(2944192K), 0.0834460 secs]
[GC 1741297K->1520193K(2944192K), 0.0865150 secs]
[GC 1776321K->1521488K(2944192K), 0.0855430 secs]
[GC 1777616K->1556322K(2944192K), 0.0900550 secs]
[GC 1812450K->1543165K(2944192K), 0.0861930 secs]
[GC 1799293K->1560557K(2944192K), 0.0822130 secs]
[GC 1816685K->1610515K(2944192K), 0.0635320 secs]
[GC 1866643K->1594655K(2944192K), 0.0883430 secs]
[GC 1850783K->1642423K(2944192K), 0.0905520 secs]
[GC 1898551K->1673943K(2944192K), 0.0841390 secs]
[GC 1930071K->1669804K(2944192K), 0.0975810 secs]
[GC 1925932K->1696273K(2944192K), 0.0841420 secs]
[GC 1952401K->1712837K(2944192K), 0.0857860 secs]
[GC 1968965K->1718055K(2944192K), 0.0874700 secs]
[GC 1974183K->1769226K(2944192K), 0.0879420 secs]
[GC 2025354K->1751506K(2944192K), 0.0858760 secs]
[GC 2007634K->1795745K(2944192K), 0.0863430 secs]
[GC 2051873K->1825862K(2944192K), 0.0854420 secs]
[GC 2081990K->1810968K(2944192K), 0.0868400 secs]
[GC 2065353K->1852648K(2944192K), 0.0954140 secs]
[GC 2108722K->1860266K(2944192K), 0.0934720 secs]
[GC 2116341K->1895937K(2944192K), 0.0963100 secs]
[GC 2152065K->1880181K(2944192K), 0.0990990 secs]
[GC 2136309K->1937542K(2944192K), 0.1021790 secs]
[GC 2193670K->1916478K(2944192K), 0.0954580 secs]
[GC 2172606K->1944784K(2944192K), 0.0820190 secs]
[GC 2200912K->1984348K(2944192K), 0.1139600 secs]
[GC 2240476K->1996593K(2944192K), 0.1035410 secs]
[GC 2252721K->2019319K(2944192K), 0.1100880 secs]
[GC 2275410K->2000078K(2944192K), 0.1095000 secs]
[GC 2256206K->2031132K(2944192K), 0.1007660 secs]
[GC 2287260K->2047072K(2944192K), 0.0991660 secs]
[GC 2303200K->2097693K(2944192K), 0.0961650 secs]
[GC 2353821K->2083597K(2944192K), 0.0986020 secs]
[GC 2339725K->2126585K(2944192K), 0.0968530 secs]
[GC 2381436K->2106273K(2944192K), 0.1007760 secs]
[GC 2362360K->2170102K(2944192K), 0.0981600 secs]
[GC 2426198K->2155933K(2944192K), 0.0986180 secs]
[GC 2412061K->2212959K(2944192K), 0.0998910 secs]
[GC 2469073K->2192249K(2944192K), 0.1041810 secs]
[GC 2448346K->2255423K(2944192K), 0.1020120 secs]
[GC 2511518K->2234367K(2944192K), 0.1049370 secs]
[GC 2489758K->2295326K(2944192K), 0.1100430 secs]
[GC 2551454K->2278565K(2944192K), 0.1125910 secs]
[GC 2534693K->2279380K(2944192K), 0.1024640 secs]
[GC 2535508K->2300471K(2944192K), 0.0944020 secs]
[GC 2556599K->2344632K(2944192K), 0.0708500 secs]
[GC 2600760K->2308548K(2944192K), 0.0742160 secs]
[GC 2564676K->2323078K(2944192K), 0.0994610 secs]
[GC 2579206K->2363607K(2944192K), 0.0673710 secs]
[GC 2619735K->2330782K(2944192K), 0.0696730 secs]
[GC 2586910K->2372316K(2944192K), 0.0846650 secs]
[GC 2628444K->2393048K(2944192K), 0.0734270 secs]
[GC 2649176K->2364506K(2944192K), 0.0820580 secs]
[GC 2619569K->2414652K(2944192K), 0.0916600 secs]
[GC 2670780K->2433346K(2944192K), 0.1051270 secs]
[GC 2689474K->2448231K(2944192K), 0.1052480 secs]
[GC 2704359K->2440936K(2944192K), 0.1097500 secs]
[GC 2441394K(2944192K), 0.0390990 secs]
[GC 2697064K->2469907K(2944192K), 0.0939590 secs]
[GC 2607562K(2944192K), 0.0519010 secs]
[GC 2411972K->2173277K(3824784K), 0.1070840 secs]
[GC 2429348K->2188922K(3824784K), 0.1033320 secs]
[GC 2445038K->2222907K(3824784K), 0.1024800 secs]
[GC 2478981K->2240171K(3824784K), 0.0958030 secs]
[GC 2494360K->2260021K(3824784K), 0.1001460 secs]
[GC 2516149K->2279091K(3824784K), 0.0997710 secs]
[GC 2535219K->2283552K(3824784K), 0.0978830 secs]
[GC 2539159K->2301134K(3824784K), 0.0961820 secs]
[GC 2556239K->2335787K(3824784K), 0.0993580 secs]
[GC 2591865K->2353866K(3824784K), 0.0986330 secs]
[GC 2609973K->2370708K(3824784K), 0.0966660 secs]
[GC 2626803K->2389173K(3824784K), 0.0965210 secs]
[GC 2645286K->2408966K(3824784K), 0.0953360 secs]
[GC 2665094K->2393266K(3824784K), 0.0934890 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 2649338K->2452111K(3824784K), 0.0792830 secs]
[GC 2708239K->2473631K(3824784K), 0.1065900 secs]
[GC 2729701K->2487440K(3824784K), 0.1103490 secs]
[GC 2743568K->2476287K(3824784K), 0.0745180 secs]
[GC 2732415K->2483748K(3824784K), 0.0635450 secs]
[GC 2739053K->2506578K(3824784K), 0.0754340 secs]
[GC 2762706K->2529766K(3824784K), 0.0901410 secs]
[GC 2785894K->2527432K(3824784K), 0.0915710 secs]
[GC 2783560K->2515545K(3824784K), 0.0798440 secs]
[GC 2770087K->2546385K(3824784K), 0.0752790 secs]
[GC 2802513K->2541054K(3824784K), 0.0825720 secs]
[GC 2797182K->2557415K(3824784K), 0.0845490 secs]
[GC 2813286K->2569489K(3824784K), 0.0820820 secs]
[GC 2825558K->2604869K(3824784K), 0.0790450 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3380102. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 2860997K->2592363K(3824784K), 0.0856890 secs]
[GC 2848491K->2600454K(3824784K), 0.0826350 secs]
[GC 2856049K->2618373K(3824784K), 0.0967870 secs]
[GC 2874501K->2601395K(3824784K), 0.0792860 secs]
[GC 2857523K->2642002K(3824784K), 0.0686180 secs]
[GC 2898130K->2626816K(3824784K), 0.0840040 secs]
[GC 2882944K->2635580K(3824784K), 0.0775550 secs]
[GC 2890097K->2659351K(3824784K), 0.0660940 secs]
[GC 2915479K->2657884K(3824784K), 0.0855530 secs]
[GC 2914012K->2690043K(3824784K), 0.0818310 secs]
[GC 2942562K->2682257K(3824784K), 0.0871780 secs]
[GC 2936975K->2703649K(3824784K), 0.0696600 secs]
[GC 2959777K->2710841K(3824784K), 0.0862030 secs]
[GC 2966969K->2710264K(3824784K), 0.0777640 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7309588. Elapsed time: 40.001 secs. Remaining: 19.999 secs. Total: 1 mins 0 secs
[GC 2964607K->2731551K(3824784K), 0.0634890 secs]
[GC 2987679K->2733991K(3824784K), 0.0769940 secs]
[GC 2990119K->2743991K(3824784K), 0.0802390 secs]
[GC 3000119K->2774509K(3824784K), 0.0854160 secs]
[GC 3030637K->2763681K(3824784K), 0.0941790 secs]
[GC 3019243K->2776750K(3824784K), 0.0805140 secs]
[GC 3032878K->2788741K(3824784K), 0.0879400 secs]
[GC 3044869K->2784621K(3824784K), 0.0679510 secs]
[GC 3040749K->2820642K(3824784K), 0.0739880 secs]
[GC 3076770K->2822710K(3824784K), 0.0905760 secs]
[GC 3078838K->2848353K(3824784K), 0.0675000 secs]
[GC 3103816K->2845940K(3824784K), 0.0855200 secs]
[GC 3102068K->2875478K(3824784K), 0.0693980 secs]
[GC 3131606K->2877662K(3824784K), 0.0812680 secs]
[GC 3133790K->2917555K(3824784K), 0.0777760 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 10483571. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 36 mins 55 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3173683K->2867897K(3824784K), 0.0748860 secs]
[GC 3123201K->2884657K(3824784K), 0.0712260 secs]
[GC 3140785K->2913511K(3824784K), 0.0812000 secs]
[GC 3169639K->2964367K(3824784K), 0.1215160 secs]
[GC 3219649K->2974660K(3824784K), 0.1156720 secs]
[GC 3230788K->2999185K(3824784K), 0.1068580 secs]
[GC 3255313K->3017586K(3824784K), 0.1206980 secs]
[GC 3273657K->3021396K(3824784K), 0.1014450 secs]
[GC 3277524K->3041540K(3824784K), 0.1191640 secs]
[GC 3297616K->3094757K(3824784K), 0.1071200 secs]
[GC 3350885K->3079758K(3824784K), 0.1223510 secs]
[GC 3335886K->3136014K(3824784K), 0.1148110 secs]
[GC 3392142K->3121697K(3824784K), 0.1183330 secs]
[GC 3377175K->3144831K(3824784K), 0.1235930 secs]
[GC 3400959K->3182203K(3824784K), 0.1211410 secs]
[GC 3438331K->3203098K(3824784K), 0.1161650 secs]
[GC 3459226K->3207334K(3824784K), 0.1159830 secs]
[GC 3463462K->3225975K(3824784K), 0.1153650 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.3G, free=372.2M, total=3.6G, max=4.7G, used/total=90.03% used/max=70.18%
cpu process-load=1.00%, system-load=13.00%, system-loadaverage=287.00%
[GC 3482103K->3224997K(3824784K), 0.1027400 secs]
[GC 3481125K->3265964K(3824784K), 0.1173610 secs]
[GC 3266459K(3824784K), 0.0391650 secs]
[GC 3522092K->3324748K(3824784K), 0.1256420 secs]
[GC 3456553K(3824784K), 0.0479950 secs]
[GC 3230632K->2961618K(4650880K), 0.1335920 secs]
[GC 3217746K->3002148K(4650880K), 0.1135830 secs]
[GC 3258264K->3035946K(4650880K), 0.1085080 secs]
[GC 3292074K->3019310K(4650880K), 0.1287320 secs]
[GC 3275417K->3070305K(4650880K), 0.1151810 secs]
[GC 3326433K->3081592K(4650880K), 0.1203770 secs]
[GC 3337720K->3101682K(4650880K), 0.1175640 secs]
[GC 3357219K->3124162K(4650880K), 0.1160670 secs]
[GC 3380290K->3146239K(4650880K), 0.1132020 secs]
[GC 3402367K->3164885K(4650880K), 0.1174100 secs]
[GC 3421013K->3199581K(4650880K), 0.1204440 secs]
[GC 3455709K->3186349K(4650880K), 0.1198470 secs]
[GC 3442477K->3216771K(4650880K), 0.1171720 secs]
[GC 3472873K->3226080K(4650880K), 0.1046220 secs]
[GC 3482205K->3265785K(4650880K), 0.1051890 secs]
[GC 3520381K->3269007K(4650880K), 0.1176050 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.4G, free=1.1G, total=4.4G, max=4.7G, used/total=75.75% used/max=71.80%
cpu process-load=1.00%, system-load=10.00%, system-loadaverage=263.00%
[GC 3525135K->3303392K(4650880K), 0.1089240 secs]
[GC 3559520K->3325088K(4650880K), 0.1044840 secs]
[GC 3581216K->3330079K(4650880K), 0.1105650 secs]
[GC 3586207K->3355793K(4650880K), 0.1913220 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.4G, free=1.0G, total=4.4G, max=4.7G, used/total=76.97% used/max=72.96%
cpu process-load=1.00%, system-load=13.00%, system-loadaverage=228.00%
[GC 3611921K->3406049K(4650880K), 0.1102860 secs]
[GC 3662177K->3390431K(4650880K), 0.1198130 secs]
[GC 3646559K->3444759K(4650880K), 0.1097770 secs]
[GC 3700887K->3466691K(4650880K), 0.1109180 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.5G, free=932.0M, total=4.4G, max=4.7G, used/total=79.48% used/max=75.34%
cpu process-load=1.00%, system-load=13.00%, system-loadaverage=240.00%
[GC 3722260K->3456403K(4650880K), 0.1073710 secs]
[GC 3712531K->3495360K(4650880K), 0.1009480 secs]
[GC 3751488K->3529184K(4650880K), 0.1091720 secs]
[GC 3785312K->3513007K(4650880K), 0.1091920 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.5G, free=951.9M, total=4.4G, max=4.7G, used/total=79.04% used/max=74.92%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=264.00%
[GC 3769135K->3569642K(4650880K), 0.1179130 secs]
[GC 3825770K->3590119K(4650880K), 0.1167900 secs]
[GC 3846247K->3580139K(4650880K), 0.1175720 secs]
[GC 3836267K->3601735K(4650880K), 0.1105380 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.5G, free=922.0M, total=4.4G, max=4.7G, used/total=79.70% used/max=75.54%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=279.00%
[GC 3857863K->3638852K(4650880K), 0.1129010 secs]
[GC 3894980K->3658463K(4650880K), 0.1183330 secs]
[GC 3914591K->3692832K(4650880K), 0.1168100 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.8G, free=691.7M, total=4.4G, max=4.7G, used/total=84.77% used/max=80.35%
cpu process-load=1.00%, system-load=15.00%, system-loadaverage=372.00%
[GC 3947430K->3681666K(4650880K), 0.1107590 secs]
[GC 3937786K->3700229K(4650880K), 0.1087230 secs]
[GC 3956357K->3718826K(4650880K), 0.1005170 secs]
[GC 3974954K->3758029K(4650880K), 0.0997510 secs]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.HealthMonitor] {com.hazelcast.util.HealthMonitor} [127.0.0.1]:5703 [FenixFrameworkGroup] 
memory used=3.8G, free=690.9M, total=4.4G, max=4.7G, used/total=84.79% used/max=80.37%
cpu process-load=1.00%, system-load=14.00%, system-loadaverage=393.00%
[GC 4014157K->3780447K(4650880K), 0.1056100 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 46 ms.
