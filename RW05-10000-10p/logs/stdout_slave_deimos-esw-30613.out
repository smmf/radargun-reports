/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-30613 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-30613
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0962910 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 1. Sleeping for 5500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 1
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@56e43ef
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=1, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5702, using socket ServerSocket[addr=/0.0.0.0,localport=5702], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5702 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5702 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5702 [FenixFrameworkGroup] Address[127.0.0.1]:5702 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5702 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 52079 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 58699 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:54075
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:54075
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:42138
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:42138
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:51116
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:51116
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:53832
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:53832
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:55009
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:55009
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:57242
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:57242
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 is accepting socket connection from /127.0.0.1:34781
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5702 [FenixFrameworkGroup] 5702 accepted socket connection from /127.0.0.1:34781
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5702 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702 this
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5702 [FenixFrameworkGroup] Address[127.0.0.1]:5702 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 1
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=1, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 1
[GC 259695K->11344K(2944064K), 0.0431820 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|1] [deimos-esw-3193, deimos-esw-49443]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-49443, physical addresses are [127.0.0.1:52001]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-49443] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|2] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-49443] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|3] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174]
 INFO  [Incoming-4,deimos-esw-49443] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|4] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-49443] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|5] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562]
 INFO  [Incoming-4,deimos-esw-49443] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|6] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562, deimos-esw-21063]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 1, serverOidBase: 1000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 1: org.radargun.cachewrappers.FFWrapper@6f02243e
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 2
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6f02243e, nodeIndex=1, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 267408K->22114K(2944064K), 0.0617880 secs]
[GC 278178K->30207K(2944064K), 0.0493780 secs]
[GC 286271K->44897K(2944064K), 0.0490390 secs]
[GC 300961K->71543K(2944064K), 0.0567840 secs]
[GC 327607K->70116K(2944064K), 0.0579710 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 326180K->100531K(2944064K), 0.0670410 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 5850. Elapsed time: 20.953 secs. Remaining: 39.047 secs. Total: 1 mins 0 secs
[GC 356595K->110787K(2944064K), 0.1652940 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 14800. Elapsed time: 41.342 secs. Remaining: 18.658 secs. Total: 1 mins 0 secs
[GC 366851K->156477K(2944064K), 0.0779890 secs]
[GC 412541K->148492K(2944064K), 0.0750340 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 55 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 175 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,577,672 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 366391K->129074K(2944064K), 0.6376710 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,813,791 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@6f02243e, nodeIndex=1, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 385202K->194495K(2944192K), 0.0344180 secs]
[GC 450623K->146967K(2944192K), 0.0379390 secs]
[GC 403095K->161685K(2944192K), 0.0431760 secs]
[GC 417813K->172684K(2944192K), 0.0470700 secs]
[GC 428812K->187197K(2944192K), 0.0531560 secs]
[GC 443325K->202278K(2944192K), 0.0583890 secs]
[GC 458406K->217472K(2944192K), 0.0653890 secs]
[GC 473600K->232761K(2944192K), 0.0683410 secs]
[GC 488889K->210660K(2944192K), 0.1142430 secs]
[GC 466788K->259152K(2944192K), 0.1331510 secs]
[GC 515280K->277616K(2944192K), 0.0995600 secs]
[GC 533744K->284208K(2944192K), 0.0941850 secs]
[GC 540286K->273286K(2944192K), 0.1066770 secs]
[GC 529414K->308958K(2944192K), 0.0843980 secs]
[GC 565086K->323525K(2944192K), 0.0870820 secs]
[GC 579653K->376795K(2944192K), 0.0911860 secs]
[GC 632876K->361793K(2944192K), 0.0945140 secs]
[GC 617921K->418778K(2944192K), 0.0827230 secs]
[GC 674906K->399346K(2944192K), 0.0822350 secs]
[GC 655474K->456920K(2944192K), 0.0776770 secs]
[GC 713048K->435938K(2944192K), 0.0812490 secs]
[GC 692066K->482488K(2944192K), 0.0819310 secs]
[GC 737631K->509719K(2944192K), 0.0811200 secs]
[GC 765808K->494185K(2944192K), 0.0802140 secs]
[GC 750313K->550139K(2944192K), 0.0835110 secs]
[GC 806256K->551152K(2944192K), 0.0825750 secs]
[GC 807032K->555013K(2944192K), 0.0845190 secs]
[GC 811141K->604126K(2944192K), 0.0782490 secs]
[GC 860254K->589719K(2944192K), 0.0818780 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 845847K->632870K(2944192K), 0.0866150 secs]
[GC 888998K->631125K(2944192K), 0.0868730 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 887253K->632172K(2944192K), 0.1066900 secs]
[GC 888300K->649071K(2944192K), 0.0843580 secs]
[GC 905199K->677718K(2944192K), 0.0642840 secs]
[GC 933846K->697289K(2944192K), 0.0708400 secs]
[GC 953417K->687019K(2944192K), 0.0902200 secs]
[GC 943147K->701265K(2944192K), 0.0713750 secs]
[GC 957370K->729669K(2944192K), 0.0844060 secs]
[GC 985777K->755795K(2944192K), 0.0825950 secs]
[GC 1011923K->769388K(2944192K), 0.0957780 secs]
[GC 1025516K->755106K(2944192K), 0.1002470 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1010618K->764569K(2944192K), 0.0868230 secs]
[GC 1020697K->817520K(2944192K), 0.0860330 secs]
[GC 1073644K->835524K(2944192K), 0.0790990 secs]
[GC 1091451K->851070K(2944192K), 0.0834440 secs]
[GC 1107198K->873805K(2944192K), 0.0809500 secs]
[GC 1129928K->890719K(2944192K), 0.0790760 secs]
[GC 1146117K->925257K(2944192K), 0.0803750 secs]
[GC 1181385K->911279K(2944192K), 0.0821310 secs]
[GC 1167369K->955115K(2944192K), 0.0822780 secs]
[GC 1211243K->979142K(2944192K), 0.0873230 secs]
[GC 1235270K->990007K(2944192K), 0.0791810 secs]
[GC 1246135K->1021074K(2944192K), 0.0788940 secs]
[GC 1277160K->1004113K(2944192K), 0.0786070 secs]
[GC 1260241K->1064699K(2944192K), 0.0883690 secs]
[GC 1320807K->1040508K(2944192K), 0.0807240 secs]
[GC 1296370K->1100496K(2944192K), 0.0859140 secs]
[GC 1356624K->1077544K(2944192K), 0.0833710 secs]
[GC 1333672K->1124414K(2944192K), 0.0823460 secs]
[GC 1380542K->1098942K(2944192K), 0.0775780 secs]
[GC 1355070K->1148473K(2944192K), 0.0592330 secs]
[GC 1404601K->1108440K(2944192K), 0.0724240 secs]
[GC 1364568K->1117903K(2944192K), 0.1092230 secs]
[GC 1374031K->1166527K(2944192K), 0.0605230 secs]
[GC 1422655K->1128395K(2944192K), 0.0659190 secs]
[GC 1384523K->1139848K(2944192K), 0.0912860 secs]
[GC 1395976K->1174096K(2944192K), 0.0675100 secs]
[GC 1430224K->1181141K(2944192K), 0.0687340 secs]
[GC 1437269K->1183140K(2944192K), 0.0809720 secs]
[GC 1439268K->1177420K(2944192K), 0.1582540 secs]
[GC 1433548K->1203413K(2944192K), 0.1255970 secs]
[GC 1459541K->1212318K(2944192K), 0.0805560 secs]
[GC 1468446K->1202783K(2944192K), 0.0993580 secs]
[GC 1458911K->1219522K(2944192K), 0.0926480 secs]
[GC 1475650K->1238568K(2944192K), 0.0821650 secs]
[GC 1494696K->1262145K(2944192K), 0.0815120 secs]
[GC 1518273K->1236945K(2944192K), 0.1321120 secs]
[GC 1493073K->1268723K(2944192K), 0.0868400 secs]
[GC 1524851K->1269320K(2944192K), 0.0822090 secs]
[GC 1525448K->1262167K(2944192K), 0.1021350 secs]
[GC 1518295K->1288533K(2944192K), 0.1335610 secs]
[GC 1544661K->1296551K(2944192K), 0.1434180 secs]
[GC 1552679K->1304010K(2944192K), 0.0827550 secs]
[GC 1560138K->1294729K(2944192K), 0.1512520 secs]
[GC 1550857K->1318754K(2944192K), 0.0790590 secs]
[GC 1574882K->1310437K(2944192K), 0.1358800 secs]
[GC 1566565K->1333867K(2944192K), 0.0971690 secs]
[GC 1589995K->1341181K(2944192K), 0.0794700 secs]
[GC 1597309K->1355855K(2944192K), 0.1256520 secs]
[GC 1611983K->1355487K(2944192K), 0.1490340 secs]
[GC 1611615K->1366111K(2944192K), 0.1005450 secs]
[GC 1622239K->1391422K(2944192K), 0.1464910 secs]
[GC 1647537K->1408282K(2944192K), 0.1436470 secs]
[GC 1408642K(2944192K), 0.0426630 secs]
[GC 1664410K->1438578K(2944192K), 0.1045220 secs]
[GC 1607273K(2944192K), 0.0698660 secs]
[GC 1456150K->1213482K(2944192K), 0.0937730 secs]
[GC 1469589K->1199368K(2944192K), 0.0981750 secs]
[GC 1455450K->1208367K(2944192K), 0.0806820 secs]
[GC 1464468K->1276563K(2944192K), 0.0811820 secs]
[GC 1532691K->1261136K(2944192K), 0.0847070 secs]
[GC 1516477K->1317804K(2944192K), 0.0833390 secs]
[GC 1573932K->1294936K(2944192K), 0.0852470 secs]
[GC 1551038K->1352035K(2944192K), 0.0822110 secs]
[GC 1608136K->1329768K(2944192K), 0.0814270 secs]
[GC 1585859K->1390248K(2944192K), 0.0849920 secs]
[GC 1645106K->1368196K(2944192K), 0.0890900 secs]
[GC 1624324K->1429118K(2944192K), 0.0844040 secs]
[GC 1685246K->1407576K(2944192K), 0.0880030 secs]
[GC 1663704K->1469658K(2944192K), 0.0955000 secs]
[GC 1725786K->1447638K(2944192K), 0.0870650 secs]
[GC 1703766K->1441789K(2944192K), 0.0833290 secs]
[GC 1697917K->1491419K(2944192K), 0.0633090 secs]
[GC 1747547K->1455864K(2944192K), 0.0683110 secs]
[GC 1711992K->1465925K(2944192K), 0.0875670 secs]
[GC 1721933K->1502930K(2944192K), 0.0624520 secs]
[GC 1759058K->1525711K(2944192K), 0.0710930 secs]
[GC 1781839K->1508901K(2944192K), 0.0885390 secs]
[GC 1765029K->1518475K(2944192K), 0.0706080 secs]
[GC 1774603K->1532854K(2944192K), 0.0717820 secs]
[GC 1788982K->1553723K(2944192K), 0.0904370 secs]
[GC 1809851K->1529973K(2944192K), 0.0843810 secs]
[GC 1786101K->1562503K(2944192K), 0.0866270 secs]
[GC 1818631K->1577622K(2944192K), 0.0893860 secs]
[GC 1833750K->1599873K(2944192K), 0.0988370 secs]
[GC 1854581K->1616432K(2944192K), 0.1167560 secs]
[GC 1872524K->1615823K(2944192K), 0.1022510 secs]
[GC 1871951K->1624064K(2944192K), 0.1179830 secs]
[GC 1880180K->1633903K(2944192K), 0.0859000 secs]
[GC 1889976K->1683951K(2944192K), 0.0890210 secs]
[GC 1940079K->1702344K(2944192K), 0.1032620 secs]
[GC 1958446K->1704856K(2944192K), 0.0866390 secs]
[GC 1960984K->1724356K(2944192K), 0.0877520 secs]
[GC 1980484K->1740579K(2944192K), 0.0890590 secs]
[GC 1996705K->1761209K(2944192K), 0.0896850 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2017337K->1797205K(2944192K), 0.0870970 secs]
[GC 2053333K->1816332K(2944192K), 0.0897230 secs]
[GC 2072460K->1832872K(2944192K), 0.0880930 secs]
[GC 2089000K->1836883K(2944192K), 0.0808730 secs]
[GC 2093011K->1836526K(2944192K), 0.0888520 secs]
[GC 2092630K->1854268K(2944192K), 0.0916400 secs]
[GC 2110150K->1907960K(2944192K), 0.0750080 secs]
[GC 2164088K->1925514K(2944192K), 0.0939320 secs]
[GC 2181642K->1931215K(2944192K), 0.1094030 secs]
[GC 2186069K->1940241K(2944192K), 0.0965500 secs]
[GC 2195646K->1968141K(2944192K), 0.0909530 secs]
[GC 2223163K->1999959K(2944192K), 0.0892310 secs]
[GC 2255380K->2001193K(2944192K), 0.0875030 secs]
[GC 2257267K->2020272K(2944192K), 0.0882830 secs]
[GC 2276400K->2038396K(2944192K), 0.0856540 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2294524K->2075055K(2944192K), 0.0883650 secs]
[GC 2331183K->2111080K(2944192K), 0.0883010 secs]
[GC 2367208K->2094122K(2944192K), 0.0918400 secs]
[GC 2350250K->2154541K(2944192K), 0.0959190 secs]
[GC 2410669K->2131926K(2944192K), 0.0897680 secs]
[GC 2388054K->2192682K(2944192K), 0.0898120 secs]
[GC 2448810K->2169294K(2944192K), 0.0911950 secs]
[GC 2425422K->2164644K(2944192K), 0.0882930 secs]
[GC 2420772K->2216823K(2944192K), 0.0929340 secs]
[GC 2472951K->2190162K(2944192K), 0.0724720 secs]
[GC 2446290K->2238731K(2944192K), 0.0967610 secs]
[GC 2494573K->2227109K(2944192K), 0.0838120 secs]
[GC 2483221K->2275919K(2944192K), 0.1065010 secs]
[GC 2532047K->2294363K(2944192K), 0.1185400 secs]
[GC 2550491K->2305571K(2944192K), 0.1123050 secs]
[GC 2561699K->2321556K(2944192K), 0.1070910 secs]
[GC 2577608K->2358813K(2944192K), 0.1057770 secs]
[GC 2614921K->2359343K(2944192K), 0.1031460 secs]
[GC 2615440K->2395429K(2944192K), 0.1007070 secs]
[GC 2651557K->2397444K(2944192K), 0.0986270 secs]
[GC 2653571K->2416754K(2944192K), 0.0981600 secs]
[GC 2672882K->2454920K(2944192K), 0.0969560 secs]
[GC 2711048K->2470663K(2944192K), 0.0923400 secs]
[GC 2470767K(2944192K), 0.0378290 secs]
[GC 2725318K->2508858K(2944192K), 0.1070620 secs]
[GC 2666486K(2944192K), 0.0540870 secs]
[GC 2436516K->2168463K(3811792K), 0.1339860 secs]
[GC 2424591K->2227048K(3811792K), 0.1265490 secs]
[GC 2483176K->2216611K(3811792K), 0.1331150 secs]
[GC 2472049K->2237847K(3811792K), 0.1066360 secs]
[GC 2492419K->2278087K(3811792K), 0.1077520 secs]
[GC 2534038K->2280114K(3811792K), 0.1040220 secs]
[GC 2536240K->2301739K(3811792K), 0.0945290 secs]
[GC 2557867K->2339851K(3811792K), 0.0948250 secs]
[GC 2595853K->2341012K(3811792K), 0.1029560 secs]
[GC 2595333K->2356412K(3811792K), 0.0982340 secs]
[GC 2612540K->2373346K(3811792K), 0.0904340 secs]
[GC 2629474K->2395641K(3811792K), 0.0921390 secs]
[GC 2651270K->2428201K(3811792K), 0.0948530 secs]
[GC 2684329K->2430531K(3811792K), 0.0946760 secs]
[GC 2686659K->2465823K(3811792K), 0.0913550 secs]
[GC 2721951K->2464392K(3811792K), 0.0872050 secs]
[GC 2720520K->2467543K(3811792K), 0.0847110 secs]
[GC 2723671K->2520618K(3811792K), 0.0687510 secs]
[GC 2776746K->2504357K(3811792K), 0.0914880 secs]
[GC 2760485K->2528358K(3811792K), 0.0712900 secs]
[GC 2782824K->2514972K(3811792K), 0.0810060 secs]
[GC 2771100K->2574849K(3811792K), 0.1053640 secs]
[GC 2829262K->2550208K(3811792K), 0.1069100 secs]
[GC 2806297K->2603020K(3811792K), 0.0953040 secs]
[GC 2859148K->2583766K(3811792K), 0.1028670 secs]
[GC 2839894K->2592945K(3811792K), 0.0934150 secs]
[GC 2849073K->2643232K(3811792K), 0.0897410 secs]
[GC 2899360K->2664822K(3811792K), 0.0920860 secs]
[GC 2920950K->2666743K(3811792K), 0.0910350 secs]
[GC 2922856K->2668100K(3811792K), 0.0893880 secs]
[GC 2922697K->2715818K(3811792K), 0.0901050 secs]
[GC 2971946K->2753488K(3811792K), 0.0860800 secs]
[GC 3009602K->2737325K(3811792K), 0.0926380 secs]
[GC 2993453K->2793472K(3811792K), 0.0911900 secs]
[GC 3049600K->2773404K(3811792K), 0.0947740 secs]
[GC 3029532K->2833106K(3811792K), 0.0877510 secs]
[GC 3088547K->2811273K(3811792K), 0.0932950 secs]
[GC 3067401K->2839541K(3811792K), 0.0817070 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3095669K->2868078K(3811792K), 0.0767650 secs]
[GC 3124206K->2879639K(3811792K), 0.1068000 secs]
[GC 3135145K->2897064K(3811792K), 0.0898510 secs]
[GC 3151732K->2916404K(3811792K), 0.0734190 secs]
[GC 3172532K->2913805K(3811792K), 0.0702220 secs]
[GC 3169933K->2932256K(3811792K), 0.0785080 secs]
[GC 3187053K->2936950K(3811792K), 0.0819700 secs]
[GC 3193078K->2955031K(3811792K), 0.0770830 secs]
[GC 3211097K->2967289K(3811792K), 0.0799610 secs]
[GC 3223393K->2942869K(3811792K), 0.0651430 secs]
[GC 3198997K->2983155K(3811792K), 0.0664640 secs]
[GC 3238674K->2994631K(3811792K), 0.0723070 secs]
[GC 3250705K->2999739K(3811792K), 0.0767330 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2956247. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 3255867K->3002288K(3811792K), 0.0759060 secs]
[GC 3258390K->3022927K(3811792K), 0.0760880 secs]
[GC 3276371K->3005241K(3811792K), 0.0662310 secs]
[GC 3260168K->3032604K(3811792K), 0.0629690 secs]
[GC 3288710K->3042354K(3811792K), 0.0627700 secs]
[GC 3298482K->3052641K(3811792K), 0.0770130 secs]
[GC 3308358K->3072399K(3811792K), 0.0776950 secs]
[GC 3328527K->3061790K(3811792K), 0.0724080 secs]
[GC 3317404K->3098089K(3811792K), 0.0748530 secs]
[GC 3354207K->3111746K(3811792K), 0.0860910 secs]
[GC 3367874K->3109244K(3811792K), 0.0886100 secs]
[GC 3365372K->3118470K(3811792K), 0.0736420 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6198944. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 3374598K->3111879K(3811792K), 0.0606550 secs]
[GC 3364417K->3136907K(3811792K), 0.0700010 secs]
[GC 3393035K->3159462K(3811792K), 0.0852810 secs]
[GC 3415590K->3165359K(3811792K), 0.0788220 secs]
[GC 3421487K->3143180K(3811792K), 0.0674130 secs]
[GC 3399308K->3154868K(3811792K), 0.0609330 secs]
[GC 3410543K->3168772K(3811792K), 0.0674550 secs]
[GC 3424900K->3202804K(3811792K), 0.0749820 secs]
[GC 3458843K->3196092K(3811792K), 0.0735210 secs]
[GC 3452220K->3241046K(3811792K), 0.0832480 secs]
[GC 3497140K->3242985K(3811792K), 0.0781820 secs]
[GC 3243946K(3811792K), 0.0189670 secs]
[GC 3499090K->3271261K(3811792K), 0.0725700 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8710000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 3525790K->3279941K(3811792K), 0.0747830 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 44 mins 17 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:1, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3393093K(3811792K), 0.0330710 secs]
[GC 3197991K->2926635K(4650880K), 0.0629220 secs]
[GC 3182763K->2944093K(4650880K), 0.0751030 secs]
[GC 3200221K->2977849K(4650880K), 0.0877800 secs]
[GC 3233977K->3009707K(4650880K), 0.1235220 secs]
[GC 3264941K->3013357K(4650880K), 0.1121410 secs]
[GC 3269453K->3032239K(4650880K), 0.1055550 secs]
[GC 3288312K->3050873K(4650880K), 0.0982860 secs]
[GC 3306999K->3088979K(4650880K), 0.0966330 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5702 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3345107K->3108980K(4650880K), 0.0990750 secs]
[GC 3365108K->3133329K(4650880K), 0.0994210 secs]
[GC 3389457K->3156600K(4650880K), 0.1011670 secs]
[GC 3412728K->3154481K(4650880K), 0.1000480 secs]
[GC 3408647K->3157577K(4650880K), 0.1019150 secs]
[GC 3413686K->3176398K(4650880K), 0.1038400 secs]
[GC 3432526K->3248975K(4650880K), 0.0998620 secs]
[GC 3505103K->3233997K(4650880K), 0.0998370 secs]
[GC 3490125K->3290026K(4650880K), 0.0949530 secs]
[GC 3546154K->3278555K(4650880K), 0.1008450 secs]
[GC 3534683K->3317308K(4650880K), 0.1040250 secs]
[GC 3573436K->3335952K(4650880K), 0.0981040 secs]
[GC 3592080K->3360207K(4650880K), 0.1021620 secs]
[GC 3614542K->3362233K(4650880K), 0.0965030 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5702 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5702 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5702 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 57 ms.
