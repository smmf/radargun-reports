/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-14503 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-14503
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.1637140 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@7a583307
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:52079
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:52079
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 40393 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:51483
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:51483
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:33137
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:33137
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:41685
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:41685
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:54032
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:54032
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:60952
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:60952
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:36417
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36417
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:49936
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:49936
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 2
[GC 259695K->11350K(2944064K), 0.0430850 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|2] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-60932, physical addresses are [127.0.0.1:52002]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-3,deimos-esw-60932] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|3] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-3,deimos-esw-60932] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|4] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696]
 INFO  [Incoming-3,deimos-esw-60932] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|5] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-3,deimos-esw-60932] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|6] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562, deimos-esw-21063]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 2, serverOidBase: 2000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@4e2d4656
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@4e2d4656, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 267414K->22710K(2944064K), 0.0622610 secs]
[GC 278774K->30248K(2944064K), 0.0475960 secs]
[GC 286308K->45207K(2944064K), 0.0514150 secs]
[GC 301271K->72735K(2944064K), 0.0592370 secs]
[GC 328799K->82000K(2944064K), 0.0623200 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 338064K->101179K(2944064K), 0.0680620 secs]
[GC 357243K->128179K(2944064K), 0.1690830 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 8400. Elapsed time: 20.374 secs. Remaining: 39.626 secs. Total: 1 mins 0 secs
[GC 384243K->158247K(2944064K), 0.0795220 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 17450. Elapsed time: 40.389 secs. Remaining: 19.611 secs. Total: 1 mins 0 secs
[GC 414311K->150322K(2944064K), 0.0772340 secs]
[GC 406386K->189102K(2944064K), 0.0705760 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 3 mins 3 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 183 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,657,187 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 286876K->143644K(2944064K), 0.6614670 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,798,559 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@4e2d4656, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 399772K->224756K(2944192K), 0.0336660 secs]
[GC 480884K->165461K(2944192K), 0.0392080 secs]
[GC 421589K->178389K(2944192K), 0.0500640 secs]
[GC 434517K->182528K(2944192K), 0.0677570 secs]
[GC 438656K->195087K(2944192K), 0.0816750 secs]
[GC 451215K->208489K(2944192K), 0.1152190 secs]
[GC 464617K->221864K(2944192K), 0.0976250 secs]
[GC 477992K->235419K(2944192K), 0.1222510 secs]
[GC 491547K->248496K(2944192K), 0.1654670 secs]
[GC 502801K->269211K(2944192K), 0.1451020 secs]
[GC 525339K->293474K(2944192K), 0.1456850 secs]
[GC 549602K->299498K(2944192K), 0.1180150 secs]
[GC 554173K->322890K(2944192K), 0.0939100 secs]
[GC 579018K->309747K(2944192K), 0.1101210 secs]
[GC 565817K->321904K(2944192K), 0.0858690 secs]
[GC 578032K->392298K(2944192K), 0.0865910 secs]
[GC 648426K->377585K(2944192K), 0.0914630 secs]
[GC 633713K->426764K(2944192K), 0.0896350 secs]
[GC 682887K->433814K(2944192K), 0.0829920 secs]
[GC 689892K->435635K(2944192K), 0.0827660 secs]
[GC 691763K->469428K(2944192K), 0.0791030 secs]
[GC 725540K->472922K(2944192K), 0.0876340 secs]
[GC 729050K->506208K(2944192K), 0.0856120 secs]
[GC 762336K->512894K(2944192K), 0.0844990 secs]
[GC 769022K->529153K(2944192K), 0.0795880 secs]
[GC 784177K->549688K(2944192K), 0.0804710 secs]
[GC 805816K->585730K(2944192K), 0.0762310 secs]
[GC 841857K->604513K(2944192K), 0.0785960 secs]
[GC 860409K->638993K(2944192K), 0.0863980 secs]
[GC 895121K->624959K(2944192K), 0.0898230 secs]
[GC 879136K->681871K(2944192K), 0.0915650 secs]
[GC 937999K->665371K(2944192K), 0.0831330 secs]
[GC 921499K->657971K(2944192K), 0.0776760 secs]
[GC 914099K->701113K(2944192K), 0.0608270 secs]
[GC 957241K->675203K(2944192K), 0.0673330 secs]
[GC 931331K->694778K(2944192K), 0.0818700 secs]
[GC 950036K->723628K(2944192K), 0.0652310 secs]
[GC 979756K->757794K(2944192K), 0.0857060 secs]
[GC 1013922K->731289K(2944192K), 0.1307590 secs]
[GC 987417K->790352K(2944192K), 0.0911780 secs]
[GC 1046480K->788038K(2944192K), 0.0922740 secs]
[GC 1044166K->823211K(2944192K), 0.0778360 secs]
[GC 1078512K->831789K(2944192K), 0.0926250 secs]
[GC 1087917K->837849K(2944192K), 0.0817930 secs]
[GC 1093977K->872257K(2944192K), 0.0932630 secs]
[GC 1128382K->887861K(2944192K), 0.0820770 secs]
[GC 1143989K->908259K(2944192K), 0.0862280 secs]
[GC 1164387K->930886K(2944192K), 0.0873890 secs]
[GC 1185164K->930356K(2944192K), 0.0878880 secs]
[GC 1186484K->966703K(2944192K), 0.0844890 secs]
[GC 1222831K->967667K(2944192K), 0.0842190 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1223681K->1018219K(2944192K), 0.0854810 secs]
[GC 1274347K->1004073K(2944192K), 0.0836540 secs]
[GC 1260201K->1048193K(2944192K), 0.0829320 secs]
[GC 1303076K->1058665K(2944192K), 0.0795520 secs]
[GC 1314793K->1063568K(2944192K), 0.0789860 secs]
[GC 1319696K->1078944K(2944192K), 0.0788050 secs]
[GC 1335021K->1116361K(2944192K), 0.0803740 secs]
[GC 1372489K->1100836K(2944192K), 0.0813380 secs]
[GC 1356964K->1117799K(2944192K), 0.0762560 secs]
[GC 1373927K->1164081K(2944192K), 0.0593390 secs]
[GC 1420209K->1124964K(2944192K), 0.0696800 secs]
[GC 1381092K->1148408K(2944192K), 0.0903680 secs]
[GC 1404536K->1182660K(2944192K), 0.0596320 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1438788K->1154550K(2944192K), 0.0650360 secs]
[GC 1410678K->1171025K(2944192K), 0.0810410 secs]
[GC 1427153K->1191758K(2944192K), 0.0638200 secs]
[GC 1447886K->1213914K(2944192K), 0.0637410 secs]
[GC 1470042K->1183012K(2944192K), 0.0767990 secs]
[GC 1439140K->1217126K(2944192K), 0.1295460 secs]
[GC 1473254K->1235298K(2944192K), 0.0778920 secs]
[GC 1491426K->1219560K(2944192K), 0.1761270 secs]
[GC 1475688K->1238330K(2944192K), 0.1303820 secs]
[GC 1494458K->1244770K(2944192K), 0.1106740 secs]
[GC 1500898K->1236647K(2944192K), 0.1626770 secs]
[GC 1492775K->1278295K(2944192K), 0.1143010 secs]
[GC 1534423K->1254217K(2944192K), 0.1438070 secs]
[GC 1510345K->1286580K(2944192K), 0.0853090 secs]
[GC 1542708K->1303633K(2944192K), 0.0861630 secs]
[GC 1559761K->1279708K(2944192K), 0.1456710 secs]
[GC 1535836K->1310693K(2944192K), 0.0844110 secs]
[GC 1566821K->1328087K(2944192K), 0.1204100 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1584215K->1304070K(2944192K), 0.0831580 secs]
[GC 1560198K->1335384K(2944192K), 0.1416860 secs]
[GC 1591512K->1334568K(2944192K), 0.1365010 secs]
[GC 1590696K->1326815K(2944192K), 0.1333980 secs]
[GC 1582943K->1335164K(2944192K), 0.0898220 secs]
[GC 1591292K->1358881K(2944192K), 0.1534410 secs]
[GC 1615009K->1350016K(2944192K), 0.1092830 secs]
[GC 1606144K->1381363K(2944192K), 0.1050520 secs]
[GC 1637491K->1381130K(2944192K), 0.1256240 secs]
[GC 1637258K->1413371K(2944192K), 0.0916260 secs]
[GC 1413800K(2944192K), 0.0582180 secs]
[GC 1669499K->1428233K(2944192K), 0.1863490 secs]
[GC 1564692K(2944192K), 0.0601660 secs]
[GC 1436898K->1182761K(2944192K), 0.1587290 secs]
[GC 1438889K->1215376K(2944192K), 0.1193910 secs]
[GC 1471504K->1206644K(2944192K), 0.0983280 secs]
[GC 1462772K->1254271K(2944192K), 0.0987060 secs]
[GC 1510399K->1258814K(2944192K), 0.0958660 secs]
[GC 1514942K->1275651K(2944192K), 0.1035420 secs]
[GC 1531779K->1311318K(2944192K), 0.1043970 secs]
[GC 1567446K->1329839K(2944192K), 0.0966840 secs]
[GC 1585967K->1329339K(2944192K), 0.0944810 secs]
[GC 1585467K->1349434K(2944192K), 0.0915220 secs]
[GC 1605513K->1368661K(2944192K), 0.0845800 secs]
[GC 1624593K->1387011K(2944192K), 0.0866110 secs]
[GC 1643139K->1435765K(2944192K), 0.0876700 secs]
[GC 1691893K->1459576K(2944192K), 0.0991440 secs]
[GC 1715704K->1443831K(2944192K), 0.0920600 secs]
[GC 1699959K->1442112K(2944192K), 0.0849130 secs]
[GC 1698240K->1501862K(2944192K), 0.0652650 secs]
[GC 1757990K->1481112K(2944192K), 0.0784990 secs]
[GC 1737240K->1502818K(2944192K), 0.0657570 secs]
[GC 1758946K->1482167K(2944192K), 0.0833660 secs]
[GC 1738295K->1512025K(2944192K), 0.0627030 secs]
[GC 1768153K->1517239K(2944192K), 0.0670600 secs]
[GC 1773367K->1543060K(2944192K), 0.0707310 secs]
[GC 1799188K->1520821K(2944192K), 0.0871090 secs]
[GC 1776949K->1551885K(2944192K), 0.0690450 secs]
[GC 1808013K->1561281K(2944192K), 0.0821870 secs]
[GC 1817409K->1537682K(2944192K), 0.0872700 secs]
[GC 1793810K->1569705K(2944192K), 0.1010250 secs]
[GC 1825833K->1595004K(2944192K), 0.0954660 secs]
[GC 1851132K->1616495K(2944192K), 0.1063550 secs]
[GC 1872623K->1637455K(2944192K), 0.1092910 secs]
[GC 1892506K->1624265K(2944192K), 0.1238720 secs]
[GC 1880393K->1651955K(2944192K), 0.0924520 secs]
[GC 1908083K->1681734K(2944192K), 0.0920360 secs]
[GC 1937862K->1702164K(2944192K), 0.1180550 secs]
[GC 1958292K->1704563K(2944192K), 0.0928070 secs]
[GC 1960277K->1741097K(2944192K), 0.0918960 secs]
[GC 1997173K->1756711K(2944192K), 0.0852200 secs]
[GC 2012237K->1776408K(2944192K), 0.0857430 secs]
[GC 2032502K->1817476K(2944192K), 0.0848760 secs]
[GC 2073588K->1794508K(2944192K), 0.0873570 secs]
[GC 2050128K->1852151K(2944192K), 0.0875870 secs]
[GC 2108236K->1829509K(2944192K), 0.0845450 secs]
[GC 2085637K->1888652K(2944192K), 0.0843670 secs]
[GC 2144780K->1868438K(2944192K), 0.0812950 secs]
[GC 2124550K->1893415K(2944192K), 0.0729050 secs]
[GC 2149543K->1934270K(2944192K), 0.1003430 secs]
[GC 2190398K->1930523K(2944192K), 0.0923240 secs]
[GC 2186651K->1934538K(2944192K), 0.0993100 secs]
[GC 2189427K->1966155K(2944192K), 0.0845660 secs]
[GC 2222283K->1982879K(2944192K), 0.0884500 secs]
[GC 2239007K->2016022K(2944192K), 0.0863160 secs]
[GC 2272150K->2035521K(2944192K), 0.0843080 secs]
[GC 2291649K->2042613K(2944192K), 0.0937110 secs]
[GC 2298741K->2056185K(2944192K), 0.0902720 secs]
[GC 2312313K->2071292K(2944192K), 0.0843700 secs]
[GC 2327420K->2105980K(2944192K), 0.0983270 secs]
[GC 2362108K->2129085K(2944192K), 0.0991590 secs]
[GC 2385213K->2149045K(2944192K), 0.1010140 secs]
[GC 2403168K->2169906K(2944192K), 0.1135980 secs]
[GC 2426034K->2203887K(2944192K), 0.1165010 secs]
[GC 2460015K->2187532K(2944192K), 0.0957300 secs]
[GC 2443660K->2210491K(2944192K), 0.0823630 secs]
[GC 2466619K->2187554K(2944192K), 0.0944250 secs]
[GC 2443682K->2223187K(2944192K), 0.0765570 secs]
[GC 2479315K->2246077K(2944192K), 0.0880420 secs]
[GC 2501354K->2271288K(2944192K), 0.1174860 secs]
[GC 2527406K->2293638K(2944192K), 0.1248280 secs]
[GC 2549766K->2299302K(2944192K), 0.1255930 secs]
[GC 2553606K->2315714K(2944192K), 0.1024090 secs]
[GC 2571842K->2368060K(2944192K), 0.1159310 secs]
[GC 2623949K->2356809K(2944192K), 0.1059650 secs]
[GC 2612703K->2375267K(2944192K), 0.1011360 secs]
[GC 2630570K->2395780K(2944192K), 0.1837210 secs]
[GC 2651889K->2414284K(2944192K), 0.1124700 secs]
[GC 2670412K->2414910K(2944192K), 0.0945020 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2670997K->2449746K(2944192K), 0.0949100 secs]
[GC 2449958K(2944192K), 0.0397950 secs]
[GC 2705597K->2504870K(2944192K), 0.0989630 secs]
[GC 2644164K(2944192K), 0.0556470 secs]
[GC 2430165K->2162412K(3802428K), 0.0995220 secs]
[GC 2418540K->2221309K(3802428K), 0.0981980 secs]
[GC 2477437K->2205376K(3802428K), 0.1039600 secs]
[GC 2461504K->2265753K(3802428K), 0.1054440 secs]
[GC 2521881K->2253829K(3802428K), 0.0977390 secs]
[GC 2509957K->2309403K(3802428K), 0.1007550 secs]
[GC 2565434K->2280567K(3802428K), 0.0981530 secs]
[GC 2536695K->2300236K(3802428K), 0.0943130 secs]
[GC 2556364K->2351579K(3802428K), 0.0920700 secs]
[GC 2607707K->2353466K(3802428K), 0.0919760 secs]
[GC 2609594K->2369147K(3802428K), 0.0902840 secs]
[GC 2625275K->2422120K(3802428K), 0.0990810 secs]
[GC 2678212K->2405796K(3802428K), 0.0873420 secs]
[GC 2661924K->2460375K(3802428K), 0.0903270 secs]
[GC 2716503K->2438499K(3802428K), 0.0907690 secs]
[GC 2694627K->2500395K(3802428K), 0.0931060 secs]
[GC 2756523K->2480129K(3802428K), 0.0838330 secs]
[GC 2736257K->2504650K(3802428K), 0.0714660 secs]
[GC 2760778K->2482659K(3802428K), 0.0854680 secs]
[GC 2738787K->2518824K(3802428K), 0.0723910 secs]
[GC 2774952K->2540241K(3802428K), 0.0830970 secs]
[GC 2796360K->2539562K(3802428K), 0.1053640 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2795690K->2585424K(3802428K), 0.1053210 secs]
[GC 2841552K->2571861K(3802428K), 0.1172110 secs]
[GC 2827989K->2580878K(3802428K), 0.0923510 secs]
[GC 2836994K->2613060K(3802428K), 0.0967690 secs]
[GC 2869188K->2632138K(3802428K), 0.0943000 secs]
[GC 2888250K->2663118K(3802428K), 0.0884640 secs]
[GC 2919187K->2681360K(3802428K), 0.0911120 secs]
[GC 2937488K->2702376K(3802428K), 0.0921340 secs]
[GC 2958504K->2720597K(3802428K), 0.0902580 secs]
[GC 2976725K->2741239K(3802428K), 0.0995100 secs]
[GC 2997367K->2740766K(3802428K), 0.0908870 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2996894K->2777537K(3802428K), 0.0936290 secs]
[GC 3033665K->2794526K(3802428K), 0.0953930 secs]
[GC 3050654K->2799416K(3802428K), 0.0912620 secs]
[GC 3055544K->2798973K(3802428K), 0.0899380 secs]
[GC 3055101K->2858510K(3802428K), 0.0822380 secs]
[GC 3114638K->2870104K(3802428K), 0.1020500 secs]
[GC 3126183K->2856137K(3802428K), 0.1024910 secs]
[GC 3112265K->2909973K(3802428K), 0.0969170 secs]
[GC 3165200K->2902650K(3802428K), 0.1073820 secs]
[GC 3156817K->2927771K(3802428K), 0.0996460 secs]
[GC 3183883K->2944680K(3802428K), 0.0878680 secs]
[GC 3200808K->2979580K(3802428K), 0.0875370 secs]
[GC 3235671K->2980386K(3802428K), 0.0899310 secs]
[GC 3236514K->3014836K(3802428K), 0.0956660 secs]
[GC 3270964K->3004594K(3802428K), 0.0926990 secs]
[GC 3260677K->3035333K(3802428K), 0.0893440 secs]
[GC 3291461K->3070437K(3802428K), 0.0878700 secs]
[GC 3326565K->3071603K(3802428K), 0.0921920 secs]
[GC 3327702K->3074356K(3802428K), 0.0889780 secs]
[GC 3330484K->3109338K(3802428K), 0.0918010 secs]
[GC 3365466K->3114398K(3802428K), 0.0943480 secs]
[GC 3370526K->3163414K(3802428K), 0.0883710 secs]
[GC 3419542K->3146987K(3802428K), 0.0882400 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3403115K->3207954K(3802428K), 0.0856250 secs]
[GC 3464082K->3222416K(3802428K), 0.1143990 secs]
[GC 3478544K->3224160K(3802428K), 0.0808850 secs]
[GC 3480288K->3245297K(3802428K), 0.0821010 secs]
[GC 3245961K(3802428K), 0.0265850 secs]
[GC 3501425K->3235892K(3802428K), 0.0775960 secs]
[GC 3491973K->3255732K(3802428K), 0.0627070 secs]
[GC 3511860K->3276059K(3802428K), 0.0714510 secs]
[GC 3451756K(3802428K), 0.1380190 secs]
[GC 3506978K->3243026K(3802428K), 0.0886950 secs]
[GC 3232220K->3008596K(4650880K), 0.0886830 secs]
[GC 3264724K->3002039K(4650880K), 0.0955670 secs]
[GC 3258167K->3008974K(4650880K), 0.0837130 secs]
[GC 3264966K->3010772K(4650880K), 0.0726510 secs]
[GC 3266900K->3029190K(4650880K), 0.0869180 secs]
[GC 3285318K->3065363K(4650880K), 0.0904180 secs]
[GC 3321491K->3039945K(4650880K), 0.0955510 secs]
[GC 3296073K->3047672K(4650880K), 0.0649270 secs]
[GC 3302073K->3057600K(4650880K), 0.0712170 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 4545820. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 3313728K->3084318K(4650880K), 0.0802160 secs]
[GC 3340399K->3085747K(4650880K), 0.0813570 secs]
[GC 3341817K->3112080K(4650880K), 0.0817430 secs]
[GC 3368208K->3119846K(4650880K), 0.0923560 secs]
[GC 3375974K->3112905K(4650880K), 0.0848390 secs]
[GC 3369033K->3140687K(4650880K), 0.0716830 secs]
[GC 3395591K->3142073K(4650880K), 0.0817680 secs]
[GC 3398201K->3158946K(4650880K), 0.0783650 secs]
[GC 3415074K->3150461K(4650880K), 0.0677960 secs]
[GC 3406548K->3194979K(4650880K), 0.0873640 secs]
[GC 3451107K->3231175K(4650880K), 0.0992710 secs]
[GC 3487303K->3188450K(4650880K), 0.0790650 secs]
[GC 3444578K->3209502K(4650880K), 0.0653400 secs]
[GC 3465221K->3203950K(4650880K), 0.0804390 secs]
[GC 3460078K->3220716K(4650880K), 0.0691320 secs]
[GC 3473334K->3234366K(4650880K), 0.0789870 secs]
[GC 3488717K->3243841K(4650880K), 0.0697640 secs]
[GC 3499969K->3313811K(4650880K), 0.0870810 secs]
[GC 3569939K->3261594K(4650880K), 0.0725390 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9429674. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 3517722K->3294786K(4650880K), 0.0628380 secs]
[GC 3550914K->3316344K(4650880K), 0.0847720 secs]
[GC 3572130K->3345077K(4650880K), 0.0742890 secs]
[GC 3601010K->3386192K(4650880K), 0.0779360 secs]
[GC 3642320K->3433941K(4650880K), 0.0850490 secs]
[GC 3690069K->3439728K(4650880K), 0.0814370 secs]
[GC 3695856K->3405347K(4650880K), 0.0612250 secs]
[GC 3661475K->3420189K(4650880K), 0.0583900 secs]
[GC 3676317K->3483051K(4650880K), 0.0710600 secs]
[GC 3739166K->3509567K(4650880K), 0.0895060 secs]
[GC 3765695K->3468419K(4650880K), 0.0774520 secs]
[GC 3724547K->3498245K(4650880K), 0.0626330 secs]
[GC 3752710K->3516044K(4650880K), 0.0829470 secs]
[GC 3772172K->3533185K(4650880K), 0.0703750 secs]
[GC 3787055K->3566633K(4650880K), 0.0773360 secs]
[GC 3822715K->3612381K(4650880K), 0.0824530 secs]
[GC 3868503K->3630813K(4650880K), 0.0778620 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 13701086. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 3886535K->3599145K(4650880K), 0.0687850 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 45 mins 31 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 69 ms.
