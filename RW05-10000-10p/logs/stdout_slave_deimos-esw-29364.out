/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-29364 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-29364
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.1634770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Startup staggering, number of slaves to start is 10 This is the slave with index 0, not sleeping
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 0
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@6d4d203d
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5701, using socket ServerSocket[addr=/0.0.0.0,localport=5701], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5701
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5701 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5702. Reason: ConnectException[Connection refused]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5701 [FenixFrameworkGroup] Could not connect to: /127.0.0.1:5703. Reason: ConnectException[Connection refused]
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.cluster.MulticastJoiner} [127.0.0.1]:5701 [FenixFrameworkGroup] 


Members [1] {
	Member [127.0.0.1]:5701 this
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5701 [FenixFrameworkGroup] Address[127.0.0.1]:5701 is STARTED
 INFO  [pool-1-thread-1] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Initializing cluster partition table first arrangement...
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is the first node!
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=0, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 0
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|0] [deimos-esw-3193]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-3193, physical addresses are [127.0.0.1:52000]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:58699
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:58699
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker not present. Data Grid is being initialized for the first time.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 0, serverOidBase: 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Registering new domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 0
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.DomainRoot} Created DomainRoot instance
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Notify other nodes that startup completed
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:40393
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:40393
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:57029
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:57029
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:51940
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:51940
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:49179
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:49179
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:59721
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:59721
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:42251
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:42251
[GC 259695K->20909K(2944064K), 0.0613320 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:37002
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:37002
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 is accepting socket connection from /127.0.0.1:46299
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5701 [FenixFrameworkGroup] 5701 accepted socket connection from /127.0.0.1:46299
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members=1 is not the one expected: 10
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5701 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701 this
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 244
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] Re-partitioning cluster data... Migration queue size: 244
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 0: org.radargun.cachewrappers.FFWrapper@68163524
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.migration] {com.hazelcast.partition.PartitionService} [127.0.0.1]:5701 [FenixFrameworkGroup] All migration tasks has been completed, queues are empty.
 INFO  [Incoming-1,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|1] [deimos-esw-3193, deimos-esw-49443]
 INFO  [Incoming-3,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|2] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822]
 INFO  [Incoming-4,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|3] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174]
 INFO  [Incoming-4,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|4] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696]
 INFO  [Incoming-4,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|5] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562]
 INFO  [Incoming-4,deimos-esw-3193] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-3193|6] [deimos-esw-3193, deimos-esw-49443, deimos-esw-60932, deimos-esw-13822, deimos-esw-46174, deimos-esw-178, deimos-esw-4696, deimos-esw-42503, deimos-esw-32562, deimos-esw-21063]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 6
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@68163524, nodeIndex=0, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 276973K->15506K(2944064K), 0.0414730 secs]
[GC 271570K->24486K(2944064K), 0.0487700 secs]
[GC 280550K->40960K(2944064K), 0.0515800 secs]
[GC 297024K->55329K(2944064K), 0.0568580 secs]
[GC 311393K->71921K(2944064K), 0.0609550 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 327985K->105727K(2944064K), 0.0631070 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9950. Elapsed time: 20.023 secs. Remaining: 39.977 secs. Total: 1 mins 0 secs
[GC 361791K->126966K(2944064K), 0.1148700 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 20650. Elapsed time: 40.025 secs. Remaining: 19.975 secs. Total: 1 mins 0 secs
[GC 383030K->119730K(2944064K), 0.0905130 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 35550. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 33 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 153 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 375794K->129571K(2944064K), 0.0721350 secs]
[GC 385635K->155868K(2944064K), 0.0756470 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,767,186 kb - max:4,906,688 kb- total:2,944,064 kb
 WARN  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Fenix Framework never forgets...
[Full GC 176877K->131483K(2944064K), 0.6599750 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,811,376 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@68163524, nodeIndex=0, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 387611K->204872K(2944192K), 0.0362000 secs]
[GC 461000K->156332K(2944192K), 0.0535030 secs]
[GC 412460K->160789K(2944192K), 0.0600820 secs]
[GC 416917K->174752K(2944192K), 0.0730410 secs]
[GC 430880K->181877K(2944192K), 0.0821130 secs]
[GC 438005K->194700K(2944192K), 0.0961130 secs]
[GC 450828K->207506K(2944192K), 0.1049380 secs]
[GC 463634K->220580K(2944192K), 0.1164100 secs]
[GC 476708K->233493K(2944192K), 0.1308000 secs]
[GC 489616K->254153K(2944192K), 0.1772700 secs]
[GC 510233K->274664K(2944192K), 0.0844190 secs]
[GC 529314K->291526K(2944192K), 0.0951180 secs]
[GC 546856K->300927K(2944192K), 0.1007650 secs]
[GC 555331K->288215K(2944192K), 0.1046370 secs]
[GC 543642K->318933K(2944192K), 0.0897440 secs]
[GC 575061K->355050K(2944192K), 0.0935020 secs]
[GC 611165K->376849K(2944192K), 0.0849300 secs]
[GC 630902K->392582K(2944192K), 0.0913040 secs]
[GC 648710K->411186K(2944192K), 0.0898830 secs]
[GC 667311K->426195K(2944192K), 0.0858190 secs]
[GC 681222K->445925K(2944192K), 0.0826380 secs]
[GC 702053K->465864K(2944192K), 0.0889470 secs]
[GC 721987K->507233K(2944192K), 0.0842010 secs]
[GC 763361K->490186K(2944192K), 0.0799590 secs]
[GC 746309K->545795K(2944192K), 0.0831230 secs]
[GC 800196K->521806K(2944192K), 0.0871220 secs]
[GC 777934K->579351K(2944192K), 0.0796130 secs]
[GC 835479K->559485K(2944192K), 0.0841980 secs]
[GC 815613K->620009K(2944192K), 0.0858940 secs]
[GC 876137K->598861K(2944192K), 0.0868150 secs]
[GC 854989K->658911K(2944192K), 0.0935540 secs]
[GC 913263K->636478K(2944192K), 0.0910390 secs]
[GC 892606K->653865K(2944192K), 0.0837730 secs]
[GC 909993K->694142K(2944192K), 0.0669680 secs]
[GC 950270K->675552K(2944192K), 0.0875780 secs]
[GC 931680K->694321K(2944192K), 0.0644010 secs]
[GC 950449K->696624K(2944192K), 0.0675560 secs]
[GC 951902K->702403K(2944192K), 0.0971600 secs]
[GC 957429K->742454K(2944192K), 0.0791310 secs]
[GC 998530K->760415K(2944192K), 0.1060320 secs]
[GC 1016347K->757202K(2944192K), 0.1132050 secs]
[GC 1012925K->769973K(2944192K), 0.0913780 secs]
[GC 1026101K->817009K(2944192K), 0.0930340 secs]
[GC 1073137K->805559K(2944192K), 0.0968870 secs]
[GC 1061687K->822999K(2944192K), 0.0853140 secs]
[GC 1079127K->842352K(2944192K), 0.0876060 secs]
[GC 1098480K->862584K(2944192K), 0.0874160 secs]
[GC 1118712K->878981K(2944192K), 0.0831060 secs]
[GC 1135090K->894869K(2944192K), 0.0925580 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1150997K->946021K(2944192K), 0.0906670 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1202149K->931138K(2944192K), 0.0896990 secs]
[GC 1187266K->986203K(2944192K), 0.0830790 secs]
[GC 1241360K->967372K(2944192K), 0.0849940 secs]
[GC 1223473K->1022480K(2944192K), 0.0859340 secs]
[GC 1278591K->1002159K(2944192K), 0.0844220 secs]
[GC 1257221K->1061837K(2944192K), 0.0902160 secs]
[GC 1317965K->1043919K(2944192K), 0.0831620 secs]
[GC 1300047K->1099053K(2944192K), 0.0937490 secs]
[GC 1355181K->1079024K(2944192K), 0.1045560 secs]
[GC 1335152K->1141779K(2944192K), 0.0952990 secs]
[GC 1397907K->1117867K(2944192K), 0.0750090 secs]
[GC 1373995K->1144181K(2944192K), 0.0664730 secs]
[GC 1400309K->1120921K(2944192K), 0.0801400 secs]
[GC 1377049K->1152930K(2944192K), 0.0631580 secs]
[GC 1409058K->1175220K(2944192K), 0.0679140 secs]
[GC 1431348K->1161902K(2944192K), 0.0844310 secs]
[GC 1418030K->1177987K(2944192K), 0.0749150 secs]
[GC 1434115K->1164538K(2944192K), 0.0692050 secs]
[GC 1420666K->1179670K(2944192K), 0.0878520 secs]
[GC 1435798K->1199614K(2944192K), 0.1066540 secs]
[GC 1455742K->1216486K(2944192K), 0.1386200 secs]
[GC 1472614K->1229247K(2944192K), 0.0810220 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1485375K->1201030K(2944192K), 0.0855190 secs]
[GC 1457158K->1232221K(2944192K), 0.1503710 secs]
[GC 1488349K->1247736K(2944192K), 0.0835890 secs]
[GC 1503864K->1232067K(2944192K), 0.0905400 secs]
[GC 1488195K->1233609K(2944192K), 0.1530060 secs]
[GC 1489737K->1272055K(2944192K), 0.0850030 secs]
[GC 1528183K->1246561K(2944192K), 0.0819720 secs]
[GC 1502689K->1276630K(2944192K), 0.1538370 secs]
[GC 1532758K->1280091K(2944192K), 0.1549390 secs]
[GC 1536219K->1289366K(2944192K), 0.0906640 secs]
[GC 1545494K->1313940K(2944192K), 0.0814440 secs]
[GC 1570068K->1287071K(2944192K), 0.0865900 secs]
[GC 1543199K->1333812K(2944192K), 0.0870820 secs]
[GC 1589940K->1299175K(2944192K), 0.0840210 secs]
[GC 1555303K->1329684K(2944192K), 0.0859120 secs]
[GC 1585812K->1336540K(2944192K), 0.0903090 secs]
[GC 1592668K->1313840K(2944192K), 0.1441520 secs]
[GC 1569968K->1341671K(2944192K), 0.1591200 secs]
[GC 1597799K->1355110K(2944192K), 0.1654260 secs]
[GC 1611238K->1363031K(2944192K), 0.0890570 secs]
[GC 1619159K->1354377K(2944192K), 0.0907810 secs]
[GC 1610505K->1362084K(2944192K), 0.1228150 secs]
[GC 1618201K->1368958K(2944192K), 0.1537120 secs]
[GC 1369784K(2944192K), 0.0605840 secs]
[GC 1625086K->1420535K(2944192K), 0.1075280 secs]
[GC 1558171K(2944192K), 0.0608610 secs]
[GC 1446638K->1209247K(2944192K), 0.1071420 secs]
[GC 1464059K->1190320K(2944192K), 0.1233230 secs]
[GC 1446448K->1229845K(2944192K), 0.1009810 secs]
[GC 1485973K->1240657K(2944192K), 0.0920540 secs]
[GC 1496161K->1275213K(2944192K), 0.0876760 secs]
[GC 1531304K->1274425K(2944192K), 0.0874280 secs]
[GC 1530553K->1310006K(2944192K), 0.1046660 secs]
[GC 1566134K->1342505K(2944192K), 0.1062010 secs]
[GC 1598627K->1330325K(2944192K), 0.0879730 secs]
[GC 1586433K->1370381K(2944192K), 0.0853390 secs]
[GC 1626509K->1380329K(2944192K), 0.0844640 secs]
[GC 1636457K->1400943K(2944192K), 0.0865560 secs]
[GC 1657071K->1424233K(2944192K), 0.0919260 secs]
[GC 1680361K->1440301K(2944192K), 0.0887590 secs]
[GC 1696429K->1473025K(2944192K), 0.0901120 secs]
[GC 1729153K->1443457K(2944192K), 0.0856500 secs]
[GC 1699585K->1475489K(2944192K), 0.0864170 secs]
[GC 1731617K->1519949K(2944192K), 0.0696790 secs]
[GC 1776077K->1499576K(2944192K), 0.0873990 secs]
[GC 1755704K->1527486K(2944192K), 0.0696520 secs]
[GC 1783614K->1514419K(2944192K), 0.0909870 secs]
[GC 1770547K->1534606K(2944192K), 0.0696360 secs]
[GC 1790734K->1554461K(2944192K), 0.0717700 secs]
[GC 1810589K->1537292K(2944192K), 0.0882560 secs]
[GC 1793420K->1558749K(2944192K), 0.1013010 secs]
[GC 1814877K->1585905K(2944192K), 0.1047040 secs]
[GC 1842033K->1541092K(2944192K), 0.0748120 secs]
[GC 1797220K->1580008K(2944192K), 0.0835460 secs]
[GC 1836136K->1596404K(2944192K), 0.0856380 secs]
[GC 1852532K->1581045K(2944192K), 0.0882300 secs]
[GC 1837173K->1606425K(2944192K), 0.0733380 secs]
[GC 1860840K->1631940K(2944192K), 0.0931470 secs]
[GC 1888068K->1649068K(2944192K), 0.0973250 secs]
[GC 1905196K->1661284K(2944192K), 0.0970230 secs]
[GC 1917412K->1655614K(2944192K), 0.1123290 secs]
[GC 1911696K->1664092K(2944192K), 0.0838640 secs]
[GC 1920220K->1697202K(2944192K), 0.0899510 secs]
[GC 1953330K->1728237K(2944192K), 0.1254060 secs]
[GC 1984365K->1732691K(2944192K), 0.0860800 secs]
[GC 1988819K->1767721K(2944192K), 0.0920670 secs]
[GC 2023828K->1751395K(2944192K), 0.0858480 secs]
[GC 2007523K->1802449K(2944192K), 0.0885870 secs]
[GC 2058577K->1821513K(2944192K), 0.0883220 secs]
[GC 2077227K->1825765K(2944192K), 0.0860090 secs]
[GC 2081893K->1859918K(2944192K), 0.0844720 secs]
[GC 2116046K->1862182K(2944192K), 0.0869160 secs]
[GC 2118310K->1863015K(2944192K), 0.0842430 secs]
[GC 2119143K->1880372K(2944192K), 0.0851270 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 2134888K->1938133K(2944192K), 0.0771630 secs]
[GC 2194261K->1948239K(2944192K), 0.0959390 secs]
[GC 2204367K->1965970K(2944192K), 0.1032820 secs]
[GC 2222098K->2006058K(2944192K), 0.0794550 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2262186K->1989141K(2944192K), 0.0953930 secs]
[GC 2244758K->2018594K(2944192K), 0.0609610 secs]
[GC 2274722K->2018567K(2944192K), 0.0777440 secs]
[GC 2273028K->2003348K(2944192K), 0.0519650 secs]
[GC 2259476K->2047428K(2944192K), 0.0603340 secs]
[GC 2303556K->2043844K(2944192K), 0.0833870 secs]
[GC 2299892K->2055656K(2944192K), 0.0523390 secs]
[GC 2309670K->2076420K(2944192K), 0.0726650 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2354166. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 2332548K->2088948K(2944192K), 0.0664020 secs]
[GC 2344143K->2077977K(2944192K), 0.0623150 secs]
[GC 2334105K->2103859K(2944192K), 0.0615620 secs]
[GC 2356136K->2127491K(2944192K), 0.0921370 secs]
[GC 2383619K->2147352K(2944192K), 0.0601680 secs]
[GC 2403480K->2170437K(2944192K), 0.0628030 secs]
[GC 2426539K->2146969K(2944192K), 0.0572910 secs]
[GC 2403097K->2201734K(2944192K), 0.0577950 secs]
[GC 2457862K->2199233K(2944192K), 0.0755580 secs]
[GC 2455361K->2233732K(2944192K), 0.0717430 secs]
[GC 2489860K->2251321K(2944192K), 0.0656640 secs]
[GC 2507449K->2274176K(2944192K), 0.0653400 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6253170. Elapsed time: 40.001 secs. Remaining: 19.999 secs. Total: 1 mins 0 secs
[GC 2530304K->2315522K(2944192K), 0.0723840 secs]
[GC 2571650K->2362363K(2944192K), 0.0800390 secs]
[GC 2618491K->2366697K(2944192K), 0.0766760 secs]
[GC 2622825K->2348842K(2944192K), 0.0574530 secs]
[GC 2604970K->2379283K(2944192K), 0.0590540 secs]
[GC 2635407K->2383513K(2944192K), 0.0685810 secs]
[GC 2639641K->2398704K(2944192K), 0.0692080 secs]
[GC 2654832K->2428742K(2944192K), 0.0729360 secs]
[GC 2684870K->2420236K(2944192K), 0.0830220 secs]
[GC 2421791K(2944192K), 0.0197150 secs]
[GC 2676356K->2430160K(2944192K), 0.0512270 secs]
[GC 2684858K->2439273K(2944192K), 0.0652280 secs]
[GC 2571714K(2944192K), 0.0544530 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7338756. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 2487860K->2240185K(2944192K), 0.0538800 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 36 mins 32 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:0, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2241427K->2006124K(3565164K), 0.0690380 secs]
[GC 2262252K->1997491K(3565164K), 0.0941880 secs]
[GC 2253516K->2034497K(3565164K), 0.0735990 secs]
[GC 2290472K->2089872K(3565164K), 0.1139600 secs]
[GC 2346000K->2094736K(3565164K), 0.1199210 secs]
[GC 2350864K->2133242K(3565164K), 0.1318780 secs]
[GC 2389370K->2129189K(3565164K), 0.1148790 secs]
[GC 2385260K->2171519K(3565164K), 0.1147280 secs]
[GC 2427647K->2194214K(3565164K), 0.1133660 secs]
[GC 2450342K->2218022K(3565164K), 0.1130310 secs]
[GC 2473776K->2235615K(3565164K), 0.1169310 secs]
[GC 2491743K->2239774K(3565164K), 0.1166530 secs]
[GC 2495902K->2258486K(3565164K), 0.1006600 secs]
[GC 2512893K->2294162K(3565164K), 0.1074750 secs]
[GC 2550290K->2318061K(3565164K), 0.0995430 secs]
[GC 2574189K->2345202K(3565164K), 0.1055250 secs]
[GC 2601330K->2368205K(3565164K), 0.1024840 secs]
[GC 2622652K->2391509K(3565164K), 0.1323880 secs]
[GC 2647637K->2395258K(3565164K), 0.1117190 secs]
[GC 2650776K->2438793K(3565164K), 0.1139670 secs]
[GC 2694921K->2462272K(3565164K), 0.1150180 secs]
[GC 2718400K->2466691K(3565164K), 0.1029820 secs]
[GC 2722819K->2487169K(3565164K), 0.1011170 secs]
[GC 2743256K->2503653K(3565164K), 0.1008270 secs]
[GC 2759781K->2558404K(3565164K), 0.1020760 secs]
[GC 2813573K->2541178K(3565164K), 0.1013010 secs]
[GC 2797306K->2597871K(3565164K), 0.0970450 secs]
[GC 2853970K->2577793K(3565164K), 0.1013250 secs]
[GC 2833921K->2638092K(3565164K), 0.1067490 secs]
[GC 2894220K->2623189K(3565164K), 0.1053390 secs]
[GC 2879317K->2644155K(3565164K), 0.0946080 secs]
[GC 2900283K->2644282K(3565164K), 0.0953980 secs]
[GC 2900392K->2696858K(3565164K), 0.0918950 secs]
[GC 2952986K->2726660K(3565164K), 0.1249020 secs]
[GC 2982748K->2745632K(3565164K), 0.1149020 secs]
[GC 3001760K->2739421K(3565164K), 0.1238300 secs]
[GC 2995549K->2777384K(3565164K), 0.1049490 secs]
[GC 3033512K->2779110K(3565164K), 0.1016020 secs]
[GC 3035213K->2795567K(3565164K), 0.0990950 secs]
[GC 3050024K->2831094K(3565164K), 0.1238560 secs]
[GC 3087222K->2852457K(3565164K), 0.1057210 secs]
[GC 3108585K->2858954K(3565164K), 0.1022600 secs]
[GC 3115064K->2910310K(3565164K), 0.1061510 secs]
[GC 3166438K->2894025K(3565164K), 0.1017900 secs]
[GC 3150153K->2951483K(3565164K), 0.0989420 secs]
[GC 3207611K->2932376K(3565164K), 0.1026260 secs]
[GC 3188504K->2992069K(3565164K), 0.1010760 secs]
[GC 3248197K->2974124K(3565164K), 0.1037970 secs]
[GC 3230252K->3032916K(3565164K), 0.0943990 secs]
[GC 3289044K->3019317K(3565164K), 0.1041210 secs]
[GC 3019845K(3565164K), 0.0406750 secs]
[GC 3275445K->3068382K(3565164K), 0.1054910 secs]
[GC 3198915K(3565164K), 0.0478300 secs]
[GC 3014665K->2789688K(4650880K), 0.1191340 secs]
[GC 3045816K->2773416K(4650880K), 0.1181470 secs]
[GC 3029544K->2818599K(4650880K), 0.1121240 secs]
[GC 3073991K->2812633K(4650880K), 0.1080480 secs]
[GC 3068761K->2851993K(4650880K), 0.1005560 secs]
[GC 3108121K->2890122K(4650880K), 0.1197120 secs]
[GC 3146250K->2875749K(4650880K), 0.1056690 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5701 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3131617K->2901794K(4650880K), 0.1271330 secs]
[GC 3157922K->2946603K(4650880K), 0.1120900 secs]
[GC 3202731K->2937708K(4650880K), 0.1096170 secs]
[GC 3193788K->2971686K(4650880K), 0.1064130 secs]
[GC 3227814K->2991426K(4650880K), 0.1066680 secs]
[GC 3247554K->2997956K(4650880K), 0.1056710 secs]
[GC 3254057K->3032122K(4650880K), 0.1050930 secs]
[GC 3288250K->3070822K(4650880K), 0.1215900 secs]
[GC 3326617K->3058245K(4650880K), 0.1118940 secs]
[GC 3314320K->3119383K(4650880K), 0.1078660 secs]
[GC 3375511K->3098873K(4650880K), 0.1202060 secs]
[GC 3354973K->3148824K(4650880K), 0.1178770 secs]
[GC 3404952K->3179209K(4650880K), 0.1025470 secs]
[GC 3435337K->3163418K(4650880K), 0.1013870 secs]
[GC 3419488K->3219197K(4650880K), 0.0977610 secs]
[GC 3475325K->3204820K(4650880K), 0.1118120 secs]
[GC 3460894K->3259729K(4650880K), 0.1077170 secs]
[GC 3515857K->3238845K(4650880K), 0.1133130 secs]
[GC 3493046K->3290018K(4650880K), 0.1072020 secs]
[GC 3546146K->3281522K(4650880K), 0.1212650 secs]
[GC 3536116K->3323714K(4650880K), 0.1244130 secs]
[GC 3579842K->3325574K(4650880K), 0.1018700 secs]
[GC 3581702K->3361849K(4650880K), 0.1244640 secs]
[GC 3617926K->3365206K(4650880K), 0.1092860 secs]
[GC 3621334K->3386525K(4650880K), 0.1068230 secs]
[GC 3642653K->3424774K(4650880K), 0.1141230 secs]
[GC 3680902K->3441887K(4650880K), 0.1106350 secs]
[GC 3698015K->3463726K(4650880K), 0.1057480 secs]
[GC 3718974K->3464313K(4650880K), 0.1058600 secs]
[GC 3720441K->3485569K(4650880K), 0.1073450 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5701 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5701 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5701 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 43 ms.
