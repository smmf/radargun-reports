/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-31235 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-31235
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0805110 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 4. Sleeping for 7000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 4
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@52b2f956
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5705, using socket ServerSocket[addr=/0.0.0.0,localport=5705], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5705
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 50104 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 47193 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 46296 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5705 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705 this
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 33594 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 41194 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 46832 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 40091 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:40867
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:33351
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:40867
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:33351
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:33723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:33723
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:60879
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-14] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:60879
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 4
[GC 259695K->11344K(2944064K), 0.0372470 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|3] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-46158, physical addresses are [127.0.0.1:52004]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-46158] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|4] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693, deimos-esw-55930]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-46158] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|5] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693, deimos-esw-55930, deimos-esw-36443]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 4, serverOidBase: 4000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 4: org.radargun.cachewrappers.FFWrapper@464b8634
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 2
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@464b8634, nodeIndex=4, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 267408K->22105K(2944064K), 0.0572260 secs]
[GC 278169K->29942K(2944064K), 0.0514030 secs]
[GC 286006K->45074K(2944064K), 0.0507480 secs]
[GC 301138K->72879K(2944064K), 0.0558610 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 328943K->82998K(2944064K), 0.0601210 secs]
[GC 339062K->131631K(2944064K), 0.0657100 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 15750. Elapsed time: 20.241 secs. Remaining: 39.759 secs. Total: 1 mins 0 secs
[GC 387695K->115740K(2944064K), 0.1539090 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 32100. Elapsed time: 40.241 secs. Remaining: 19.759 secs. Total: 1 mins 0 secs
[GC 371804K->142306K(2944064K), 0.0721400 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 30 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 150 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 398370K->157285K(2944064K), 0.0686240 secs]
[GC 413349K->167360K(2944064K), 0.0736040 secs]
[GC 423424K->216010K(2944064K), 0.0863440 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,551,827 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 392236K->173110K(2944064K), 0.8016940 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,770,197 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@464b8634, nodeIndex=4, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 429238K->219378K(2944192K), 0.0336470 secs]
[GC 475506K->199307K(2944192K), 0.0394860 secs]
[GC 455435K->207474K(2944192K), 0.0446830 secs]
[GC 463602K->215981K(2944192K), 0.0501300 secs]
[GC 472109K->231221K(2944192K), 0.0536530 secs]
[GC 487349K->246352K(2944192K), 0.0557710 secs]
[GC 502480K->250313K(2944192K), 0.0613400 secs]
[GC 506441K->264057K(2944192K), 0.0664610 secs]
[GC 518609K->292471K(2944192K), 0.0761210 secs]
[GC 548599K->295176K(2944192K), 0.0981790 secs]
[GC 551304K->307381K(2944192K), 0.1363580 secs]
[GC 563509K->330828K(2944192K), 0.1037630 secs]
[GC 586956K->349582K(2944192K), 0.0965290 secs]
[GC 605710K->399177K(2944192K), 0.0928040 secs]
[GC 655305K->385109K(2944192K), 0.0875180 secs]
[GC 639706K->424790K(2944192K), 0.0775830 secs]
[GC 680918K->450668K(2944192K), 0.0835040 secs]
[GC 705805K->436398K(2944192K), 0.0825670 secs]
[GC 692526K->494262K(2944192K), 0.0823620 secs]
[GC 750214K->473190K(2944192K), 0.0835480 secs]
[GC 729318K->518436K(2944192K), 0.0813600 secs]
[GC 774564K->544358K(2944192K), 0.0814130 secs]
[GC 800486K->568317K(2944192K), 0.0780710 secs]
[GC 824404K->552024K(2944192K), 0.0809520 secs]
[GC 808152K->608337K(2944192K), 0.0780470 secs]
[GC 864178K->588782K(2944192K), 0.0808670 secs]
[GC 844910K->633262K(2944192K), 0.0885920 secs]
[GC 889363K->649621K(2944192K), 0.0897510 secs]
[GC 905749K->667489K(2944192K), 0.0926650 secs]
[GC 923617K->673347K(2944192K), 0.0896900 secs]
[GC 929475K->726153K(2944192K), 0.0888330 secs]
[GC 982281K->712434K(2944192K), 0.0804810 secs]
[GC 968562K->733362K(2944192K), 0.0607480 secs]
[GC 989490K->708067K(2944192K), 0.0771970 secs]
[GC 964195K->755856K(2944192K), 0.0936310 secs]
[GC 1011984K->726440K(2944192K), 0.1188440 secs]
[GC 981768K->745865K(2944192K), 0.1409020 secs]
[GC 1001993K->784779K(2944192K), 0.1006920 secs]
[GC 1039775K->809859K(2944192K), 0.1495630 secs]
[GC 1065987K->800465K(2944192K), 0.0887950 secs]
[GC 1056590K->832462K(2944192K), 0.1010410 secs]
[GC 1088590K->866799K(2944192K), 0.0830000 secs]
[GC 1122927K->850161K(2944192K), 0.0787950 secs]
[GC 1106033K->907938K(2944192K), 0.0843660 secs]
[GC 1164066K->884148K(2944192K), 0.0820410 secs]
[GC 1140241K->914834K(2944192K), 0.0787020 secs]
[GC 1170962K->941227K(2944192K), 0.0804810 secs]
[GC 1197312K->943420K(2944192K), 0.0830060 secs]
[GC 1199548K->1000443K(2944192K), 0.0837530 secs]
[GC 1256524K->982238K(2944192K), 0.0840100 secs]
[GC 1238366K->1037046K(2944192K), 0.0778860 secs]
[GC 1293152K->1017379K(2944192K), 0.0870920 secs]
[GC 1273507K->1077550K(2944192K), 0.0815610 secs]
[GC 1333659K->1056211K(2944192K), 0.0844450 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1312339K->1112912K(2944192K), 0.0843440 secs]
[GC 1369040K->1094861K(2944192K), 0.0800080 secs]
[GC 1350972K->1138958K(2944192K), 0.0825010 secs]
[GC 1395086K->1147210K(2944192K), 0.0822330 secs]
[GC 1403338K->1153473K(2944192K), 0.0848140 secs]
[GC 1409601K->1205789K(2944192K), 0.0888850 secs]
[GC 1461917K->1231247K(2944192K), 0.0922900 secs]
[GC 1487375K->1214160K(2944192K), 0.0892290 secs]
[GC 1470288K->1239629K(2944192K), 0.0713040 secs]
[GC 1495757K->1215725K(2944192K), 0.0923610 secs]
[GC 1471853K->1266798K(2944192K), 0.0702430 secs]
[GC 1522926K->1242813K(2944192K), 0.0881390 secs]
[GC 1498941K->1266969K(2944192K), 0.0626190 secs]
[GC 1523097K->1268804K(2944192K), 0.0729320 secs]
[GC 1524932K->1278248K(2944192K), 0.0884010 secs]
[GC 1534376K->1294490K(2944192K), 0.1160920 secs]
[GC 1550618K->1297042K(2944192K), 0.1486000 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1553170K->1324133K(2944192K), 0.1451520 secs]
[GC 1580261K->1297982K(2944192K), 0.1587790 secs]
[GC 1554110K->1328293K(2944192K), 0.0851590 secs]
[GC 1584421K->1344345K(2944192K), 0.1182560 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1600473K->1319804K(2944192K), 0.0817840 secs]
[GC 1575932K->1351880K(2944192K), 0.1522880 secs]
[GC 1608008K->1351569K(2944192K), 0.1372900 secs]
[GC 1607697K->1360450K(2944192K), 0.0791550 secs]
[GC 1616578K->1368263K(2944192K), 0.1403210 secs]
[GC 1624391K->1375737K(2944192K), 0.1622730 secs]
[GC 1631865K->1367143K(2944192K), 0.1088010 secs]
[GC 1367858K(2944192K), 0.0560120 secs]
[GC 1437426K(2944192K), 0.0488580 secs]
[GC 1392812K->1160194K(2944192K), 0.0757860 secs]
[GC 1416322K->1151100K(2944192K), 0.0759830 secs]
[GC 1407228K->1173510K(2944192K), 0.0698780 secs]
[GC 1429638K->1180536K(2944192K), 0.0700400 secs]
[GC 1436664K->1188158K(2944192K), 0.0694090 secs]
[GC 1444286K->1195028K(2944192K), 0.0741600 secs]
[GC 1451036K->1220577K(2944192K), 0.0706670 secs]
[GC 1476659K->1240884K(2944192K), 0.0833890 secs]
[GC 1497012K->1251474K(2944192K), 0.0959860 secs]
[GC 1507602K->1275568K(2944192K), 0.0959460 secs]
[GC 1531696K->1265389K(2944192K), 0.1019230 secs]
[GC 1521517K->1290877K(2944192K), 0.0827030 secs]
[GC 1547005K->1327051K(2944192K), 0.0848420 secs]
[GC 1583179K->1363785K(2944192K), 0.0859750 secs]
[GC 1619913K->1347091K(2944192K), 0.0866370 secs]
[GC 1603219K->1404536K(2944192K), 0.0837560 secs]
[GC 1660664K->1391747K(2944192K), 0.0837740 secs]
[GC 1647875K->1427272K(2944192K), 0.0832030 secs]
[GC 1683400K->1418050K(2944192K), 0.0832880 secs]
[GC 1674178K->1460143K(2944192K), 0.0835360 secs]
[GC 1716214K->1473458K(2944192K), 0.0849610 secs]
[GC 1729553K->1492327K(2944192K), 0.0881850 secs]
[GC 1748410K->1493521K(2944192K), 0.0852060 secs]
[GC 1749649K->1511550K(2944192K), 0.0861910 secs]
[GC 1767678K->1532724K(2944192K), 0.0873640 secs]
[GC 1788852K->1533174K(2944192K), 0.0821630 secs]
[GC 1789302K->1569859K(2944192K), 0.0706330 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1825987K->1570039K(2944192K), 0.0825180 secs]
[GC 1826167K->1599834K(2944192K), 0.0693440 secs]
[GC 1855962K->1570640K(2944192K), 0.0692260 secs]
[GC 1826768K->1586284K(2944192K), 0.0875870 secs]
[GC 1842361K->1604977K(2944192K), 0.0627390 secs]
[GC 1861105K->1628168K(2944192K), 0.0769170 secs]
[GC 1883408K->1660751K(2944192K), 0.1011580 secs]
[GC 1916367K->1651669K(2944192K), 0.0961590 secs]
[GC 1907797K->1660936K(2944192K), 0.1006460 secs]
[GC 1915771K->1686696K(2944192K), 0.0871450 secs]
[GC 1942824K->1724004K(2944192K), 0.0872930 secs]
[GC 1980124K->1722654K(2944192K), 0.0860010 secs]
[GC 1978782K->1739850K(2944192K), 0.0866270 secs]
[GC 1995978K->1760470K(2944192K), 0.0838840 secs]
[GC 2016598K->1798352K(2944192K), 0.0872860 secs]
[GC 2054467K->1827047K(2944192K), 0.0860160 secs]
[GC 2083175K->1813675K(2944192K), 0.0861770 secs]
[GC 2069803K->1867912K(2944192K), 0.0829580 secs]
[GC 2123997K->1849590K(2944192K), 0.0856200 secs]
[GC 2105666K->1908871K(2944192K), 0.0834240 secs]
[GC 2164999K->1885881K(2944192K), 0.0852130 secs]
[GC 2142009K->1943306K(2944192K), 0.0832790 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 2199434K->1930017K(2944192K), 0.0783270 secs]
[GC 2186145K->1969503K(2944192K), 0.0749290 secs]
[GC 2225631K->1970159K(2944192K), 0.1023670 secs]
[GC 2226287K->1971392K(2944192K), 0.0633710 secs]
[GC 2227520K->1979134K(2944192K), 0.0755180 secs]
[GC 2235262K->2001871K(2944192K), 0.0726050 secs]
[GC 2257999K->2003189K(2944192K), 0.0656730 secs]
[GC 2259299K->2019565K(2944192K), 0.0664720 secs]
[GC 2275693K->2024036K(2944192K), 0.0639960 secs]
[GC 2280164K->2048442K(2944192K), 0.0643570 secs]
[GC 2304570K->2066989K(2944192K), 0.0824420 secs]
[GC 2323103K->2079245K(2944192K), 0.0758350 secs]
[GC 2335373K->2065956K(2944192K), 0.0572950 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3515102. Elapsed time: 20.001 secs. Remaining: 39.999 secs. Total: 1 mins 0 secs
[GC 2322084K->2087448K(2944192K), 0.0538420 secs]
[GC 2343530K->2102266K(2944192K), 0.0686540 secs]
[GC 2358394K->2136500K(2944192K), 0.0776900 secs]
[GC 2392624K->2117447K(2944192K), 0.0763480 secs]
[GC 2373575K->2141426K(2944192K), 0.0557700 secs]
[GC 2396742K->2174331K(2944192K), 0.0763530 secs]
[GC 2430203K->2134466K(2944192K), 0.0652250 secs]
[GC 2390241K->2200306K(2944192K), 0.1146050 secs]
[GC 2456178K->2211820K(2944192K), 0.0835150 secs]
[GC 2467948K->2180471K(2944192K), 0.0545920 secs]
[GC 2436599K->2179494K(2944192K), 0.0487280 secs]
[GC 2435622K->2214418K(2944192K), 0.0546250 secs]
[GC 2470546K->2243449K(2944192K), 0.0798420 secs]
[GC 2496175K->2219200K(2944192K), 0.0663650 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6691763. Elapsed time: 40.001 secs. Remaining: 19.999 secs. Total: 1 mins 0 secs
[GC 2475328K->2218890K(2944192K), 0.0454660 secs]
[GC 2475018K->2289640K(2944192K), 0.0643980 secs]
[GC 2545768K->2309421K(2944192K), 0.0881920 secs]
[GC 2565549K->2314375K(2944192K), 0.0648400 secs]
[GC 2566643K->2307702K(2944192K), 0.0565840 secs]
[GC 2563830K->2307567K(2944192K), 0.0438640 secs]
[GC 2563637K->2335597K(2944192K), 0.0644730 secs]
[GC 2591725K->2350100K(2944192K), 0.0725220 secs]
[GC 2606228K->2363868K(2944192K), 0.0720980 secs]
[GC 2619226K->2387080K(2944192K), 0.0896450 secs]
[GC 2640570K->2391471K(2944192K), 0.0904230 secs]
[GC 2647599K->2426259K(2944192K), 0.0776570 secs]
[GC 2682387K->2413196K(2944192K), 0.0721790 secs]
[GC 2669324K->2414059K(2944192K), 0.0694630 secs]
[GC 2670187K->2427025K(2944192K), 0.0764430 secs]
[GC 2427955K(2944192K), 0.0304020 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 11953029. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 27 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:8, nodeIndex:4, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 2615590K(2944192K), 0.2340100 secs]
[GC 2277745K->2016989K(3636172K), 0.0727390 secs]
[GC 2272155K->2029650K(3636172K), 0.0873960 secs]
[GC 2285778K->2066850K(3636172K), 0.1072150 secs]
[GC 2322948K->2114903K(3636172K), 0.1378980 secs]
[GC 2371031K->2131314K(3636172K), 0.1353370 secs]
[GC 2385572K->2137463K(3636172K), 0.1134290 secs]
[GC 2393591K->2176263K(3636172K), 0.1230240 secs]
[GC 2431544K->2179894K(3636172K), 0.1119570 secs]
[GC 2436022K->2216941K(3636172K), 0.1034580 secs]
[GC 2473069K->2219824K(3636172K), 0.1167690 secs]
[GC 2475952K->2258230K(3636172K), 0.1124730 secs]
[GC 2514358K->2259706K(3636172K), 0.1035250 secs]
[GC 2515834K->2302467K(3636172K), 0.1107450 secs]
[GC 2556948K->2297858K(3636172K), 0.1053920 secs]
[GC 2553986K->2320749K(3636172K), 0.1088290 secs]
[GC 2576877K->2339024K(3636172K), 0.1087670 secs]
[GC 2595152K->2359999K(3636172K), 0.1041190 secs]
[GC 2616127K->2361947K(3636172K), 0.0953780 secs]
[GC 2618075K->2381660K(3636172K), 0.0986250 secs]
[GC 2637788K->2436692K(3636172K), 0.0858320 secs]
[GC 2692820K->2421727K(3636172K), 0.1033680 secs]
[GC 2677855K->2450229K(3636172K), 0.1010110 secs]
[GC 2704631K->2473176K(3636172K), 0.1245600 secs]
[GC 2729268K->2492859K(3636172K), 0.1267500 secs]
[GC 2748987K->2502103K(3636172K), 0.1224950 secs]
[GC 2757992K->2519968K(3636172K), 0.1030620 secs]
[GC 2776096K->2536889K(3636172K), 0.1030160 secs]
[GC 2793017K->2576411K(3636172K), 0.0986760 secs]
[GC 2832273K->2593706K(3636172K), 0.1022890 secs]
[GC 2849834K->2597089K(3636172K), 0.1007740 secs]
[GC 2853217K->2606647K(3636172K), 0.1034230 secs]
[GC 2861523K->2654257K(3636172K), 0.1005700 secs]
[GC 2910363K->2658182K(3636172K), 0.0968700 secs]
[GC 2914310K->2712584K(3636172K), 0.1052230 secs]
[GC 2968228K->2697869K(3636172K), 0.0999970 secs]
[GC 2953997K->2744908K(3636172K), 0.1197240 secs]
[GC 3001036K->2724626K(3636172K), 0.0999650 secs]
[GC 2980754K->2775574K(3636172K), 0.0983010 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3031702K->2779141K(3636172K), 0.1054570 secs]
[GC 3034075K->2801529K(3636172K), 0.0981210 secs]
[GC 3057657K->2803722K(3636172K), 0.0943150 secs]
[GC 3059850K->2841184K(3636172K), 0.1004580 secs]
[GC 3097312K->2880898K(3636172K), 0.1019170 secs]
[GC 3136074K->2898814K(3636172K), 0.0998480 secs]
[GC 3154903K->2936043K(3636172K), 0.0966440 secs]
[GC 3192171K->2918876K(3636172K), 0.1012520 secs]
[GC 3175004K->2976594K(3636172K), 0.1034970 secs]
[GC 3232722K->2983402K(3636172K), 0.1007410 secs]
[GC 3239530K->3006698K(3636172K), 0.1013060 secs]
[GC 3262826K->3025064K(3636172K), 0.1011840 secs]
[GC 3281192K->3059490K(3636172K), 0.0999000 secs]
[GC 3315618K->3044146K(3636172K), 0.0939640 secs]
[GC 3298510K->3094405K(3636172K), 0.0991760 secs]
[GC 3350492K->3102972K(3636172K), 0.1018350 secs]
[GC 3103954K(3636172K), 0.0362090 secs]
[GC 3359100K->3105270K(3636172K), 0.1057590 secs]
[GC 3361382K->3143124K(3636172K), 0.1080450 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3301064K(3636172K), 0.0596650 secs]
[GC 3266156K->3048121K(3636172K), 0.1243280 secs]
[GC 3183220K->2912837K(4650880K), 0.1240350 secs]
[GC 3168965K->2961525K(4650880K), 0.1300050 secs]
[GC 3217653K->2975543K(4650880K), 0.1262460 secs]
[GC 3231671K->2979053K(4650880K), 0.1096410 secs]
[GC 3233897K->2994953K(4650880K), 0.1130600 secs]
[GC 3249773K->3015760K(4650880K), 0.1110740 secs]
[GC 3271888K->3054770K(4650880K), 0.1082070 secs]
[GC 3310898K->3090430K(4650880K), 0.1101780 secs]
[GC 3346558K->3076108K(4650880K), 0.1112820 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5705 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 60 ms.
