/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-31931 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-31931
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0652330 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 2. Sleeping for 6000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 2
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@56e43ef
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5703, using socket ServerSocket[addr=/0.0.0.0,localport=5703], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5703 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTING
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:53703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:53703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5703 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 59887 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:58505
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:58505
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:36000
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36000
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:46329
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:46329
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:59387
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:59387
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:36010
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:36010
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:46805
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:46805
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:54201
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:54201
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:60745
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:60745
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 is accepting socket connection from /127.0.0.1:41814
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5703 [FenixFrameworkGroup] 5703 accepted socket connection from /127.0.0.1:41814
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5703 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703 this
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5703 [FenixFrameworkGroup] Address[127.0.0.1]:5703 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 1
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=2, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 2
[GC 259695K->12537K(2944064K), 0.0422520 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|1] [deimos-esw-45070, deimos-esw-19293]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-19293, physical addresses are [127.0.0.1:52001]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|2] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|3] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409]
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|4] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|5] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476]
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|6] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476, deimos-esw-14407]
 INFO  [Incoming-4,deimos-esw-19293] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-45070|7] [deimos-esw-45070, deimos-esw-19293, deimos-esw-40066, deimos-esw-13047, deimos-esw-13949, deimos-esw-16409, deimos-esw-29516, deimos-esw-6720, deimos-esw-15476, deimos-esw-14407, deimos-esw-26378, deimos-esw-12182]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 1, serverOidBase: 1000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 2: org.radargun.cachewrappers.FFWrapper@40868ba
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 8
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@40868ba, nodeIndex=2, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268601K->22590K(2944064K), 0.0621990 secs]
[GC 278654K->28871K(2944064K), 0.0466320 secs]
[GC 284935K->43998K(2944064K), 0.0504480 secs]
[GC 300062K->61632K(2944064K), 0.0524180 secs]
[GC 317696K->76477K(2944064K), 0.0588770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 332522K->91774K(2944064K), 0.0617820 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9500. Elapsed time: 20.047 secs. Remaining: 39.953 secs. Total: 1 mins 0 secs
[GC 347838K->100894K(2944064K), 0.0818910 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16850. Elapsed time: 40.197 secs. Remaining: 19.803 secs. Total: 1 mins 0 secs
[GC 356958K->114370K(2944064K), 0.0915450 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 24350. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 2 mins 51 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 171 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 370434K->143253K(2944064K), 0.0746460 secs]
[GC 399317K->176054K(2944064K), 0.0760620 secs]
[GC 432118K->191877K(2944064K), 0.0829680 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,705,433 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 238630K->146250K(2944064K), 0.6228100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,796,715 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@40868ba, nodeIndex=2, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 402378K->226419K(2944192K), 0.0320750 secs]
[GC 482547K->167524K(2944192K), 0.0353450 secs]
[GC 423652K->168413K(2944192K), 0.0407270 secs]
[GC 424541K->178003K(2944192K), 0.0437450 secs]
[GC 434131K->189918K(2944192K), 0.0478660 secs]
[GC 446046K->201604K(2944192K), 0.0485090 secs]
[GC 457732K->213460K(2944192K), 0.0569950 secs]
[GC 469588K->225168K(2944192K), 0.0536640 secs]
[GC 481296K->208226K(2944192K), 0.0811080 secs]
[GC 464354K->239373K(2944192K), 0.0614390 secs]
[GC 495501K->243676K(2944192K), 0.0643320 secs]
[GC 499804K->230590K(2944192K), 0.0834060 secs]
[GC 486718K->272090K(2944192K), 0.1670900 secs]
[GC 527288K->269271K(2944192K), 0.0982990 secs]
[GC 525399K->311837K(2944192K), 0.1002780 secs]
[GC 567965K->331281K(2944192K), 0.1373720 secs]
[GC 587409K->307535K(2944192K), 0.1074030 secs]
[GC 563663K->361431K(2944192K), 0.0896490 secs]
[GC 617529K->378177K(2944192K), 0.0896780 secs]
[GC 634288K->375074K(2944192K), 0.0892310 secs]
[GC 630648K->393046K(2944192K), 0.0871190 secs]
[GC 649174K->446458K(2944192K), 0.0780370 secs]
[GC 702586K->418550K(2944192K), 0.0765700 secs]
[GC 673160K->484294K(2944192K), 0.0744800 secs]
[GC 740422K->469522K(2944192K), 0.0787900 secs]
[GC 725650K->498020K(2944192K), 0.0774180 secs]
[GC 754148K->525153K(2944192K), 0.0782690 secs]
[GC 781254K->526421K(2944192K), 0.0761390 secs]
[GC 782549K->580015K(2944192K), 0.0735970 secs]
[GC 836143K->562910K(2944192K), 0.0757660 secs]
[GC 819031K->606909K(2944192K), 0.0795740 secs]
[GC 863037K->633602K(2944192K), 0.0816820 secs]
[GC 889730K->619839K(2944192K), 0.0855660 secs]
[GC 875967K->620775K(2944192K), 0.0834620 secs]
[GC 876903K->664923K(2944192K), 0.0603360 secs]
[GC 921051K->642833K(2944192K), 0.0851820 secs]
[GC 898961K->674418K(2944192K), 0.0577050 secs]
[GC 930546K->656997K(2944192K), 0.0609950 secs]
[GC 913125K->659237K(2944192K), 0.0862110 secs]
[GC 915365K->686372K(2944192K), 0.0602860 secs]
[GC 942500K->704629K(2944192K), 0.0635880 secs]
[GC 960757K->708723K(2944192K), 0.0830420 secs]
[GC 964846K->739326K(2944192K), 0.0804020 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 995336K->762128K(2944192K), 0.0910710 secs]
[GC 1018256K->746359K(2944192K), 0.0978060 secs]
[GC 1002487K->778773K(2944192K), 0.0778110 secs]
[GC 1034901K->809726K(2944192K), 0.0825150 secs]
[GC 1065854K->812972K(2944192K), 0.0805840 secs]
[GC 1069089K->827255K(2944192K), 0.0785110 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1083356K->877374K(2944192K), 0.0888010 secs]
[GC 1133502K->861982K(2944192K), 0.0808420 secs]
[GC 1118072K->902125K(2944192K), 0.0803260 secs]
[GC 1157066K->914476K(2944192K), 0.0868850 secs]
[GC 1170604K->935632K(2944192K), 0.0885220 secs]
[GC 1191760K->957813K(2944192K), 0.0799300 secs]
[GC 1213941K->958943K(2944192K), 0.0854820 secs]
[GC 1215017K->992579K(2944192K), 0.0875650 secs]
[GC 1247628K->1011106K(2944192K), 0.0870540 secs]
[GC 1267223K->1029417K(2944192K), 0.0880250 secs]
[GC 1285545K->1065401K(2944192K), 0.0881070 secs]
[GC 1321529K->1052759K(2944192K), 0.0989140 secs]
[GC 1308887K->1055284K(2944192K), 0.0925360 secs]
[GC 1311412K->1096483K(2944192K), 0.0762180 secs]
[GC 1352611K->1071087K(2944192K), 0.0868660 secs]
[GC 1327215K->1103366K(2944192K), 0.0683260 secs]
[GC 1359494K->1076638K(2944192K), 0.0794560 secs]
[GC 1332766K->1084807K(2944192K), 0.0950530 secs]
[GC 1340935K->1113474K(2944192K), 0.0869840 secs]
[GC 1369602K->1098413K(2944192K), 0.1010750 secs]
[GC 1354541K->1129635K(2944192K), 0.0789280 secs]
[GC 1385763K->1148267K(2944192K), 0.1284490 secs]
[GC 1404395K->1126923K(2944192K), 0.1124680 secs]
[GC 1383051K->1137818K(2944192K), 0.1156290 secs]
[GC 1393946K->1157474K(2944192K), 0.1226430 secs]
[GC 1413602K->1147982K(2944192K), 0.0713100 secs]
[GC 1404110K->1154309K(2944192K), 0.0826750 secs]
[GC 1410437K->1162009K(2944192K), 0.0771970 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1418137K->1153681K(2944192K), 0.0861040 secs]
[GC 1409809K->1159121K(2944192K), 0.1234810 secs]
[GC 1415249K->1197591K(2944192K), 0.0823230 secs]
[GC 1453719K->1170652K(2944192K), 0.1328280 secs]
[GC 1426780K->1199191K(2944192K), 0.0767730 secs]
[GC 1455319K->1197702K(2944192K), 0.0799840 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1453830K->1207185K(2944192K), 0.0802690 secs]
[GC 1463313K->1213030K(2944192K), 0.1613740 secs]
[GC 1469158K->1220598K(2944192K), 0.1647280 secs]
[GC 1476726K->1243909K(2944192K), 0.0786220 secs]
[GC 1500037K->1216514K(2944192K), 0.1566480 secs]
[GC 1472642K->1246236K(2944192K), 0.1427950 secs]
[GC 1502364K->1251626K(2944192K), 0.0885460 secs]
[GC 1507754K->1253828K(2944192K), 0.1111110 secs]
[GC 1509956K->1260084K(2944192K), 0.1563160 secs]
[GC 1516212K->1266222K(2944192K), 0.0810490 secs]
[GC 1522350K->1256565K(2944192K), 0.0839180 secs]
[GC 1512693K->1279391K(2944192K), 0.1254430 secs]
[GC 1535519K->1269227K(2944192K), 0.0765410 secs]
[GC 1525355K->1291361K(2944192K), 0.1623380 secs]
[GC 1547489K->1298007K(2944192K), 0.0779800 secs]
[GC 1554135K->1303630K(2944192K), 0.0768860 secs]
[GC 1559758K->1310937K(2944192K), 0.0745440 secs]
[GC 1567065K->1331656K(2944192K), 0.0747860 secs]
[GC 1587784K->1298171K(2944192K), 0.0963930 secs]
[GC 1554299K->1349241K(2944192K), 0.1150660 secs]
[GC 1605369K->1314341K(2944192K), 0.1562010 secs]
[GC 1570469K->1362559K(2944192K), 0.1552260 secs]
[GC 1618687K->1326466K(2944192K), 0.1431900 secs]
[GC 1582594K->1374147K(2944192K), 0.1123310 secs]
[GC 1630275K->1338187K(2944192K), 0.0764590 secs]
[GC 1594315K->1369951K(2944192K), 0.0769140 secs]
[GC 1626079K->1367567K(2944192K), 0.0720060 secs]
[GC 1623695K->1376155K(2944192K), 0.0740540 secs]
[GC 1632283K->1380808K(2944192K), 0.1157300 secs]
[GC 1381957K(2944192K), 0.0422240 secs]
[GC 1447871K(2944192K), 0.0488230 secs]
[GC 1413198K->1179329K(2944192K), 0.0737050 secs]
[GC 1435275K->1206973K(2944192K), 0.0921750 secs]
[GC 1462868K->1222727K(2944192K), 0.0901580 secs]
[GC 1478855K->1238838K(2944192K), 0.0888100 secs]
[GC 1494966K->1226606K(2944192K), 0.0906470 secs]
[GC 1482734K->1255149K(2944192K), 0.0817440 secs]
[GC 1510187K->1272509K(2944192K), 0.0813220 secs]
[GC 1528637K->1289892K(2944192K), 0.0770490 secs]
[GC 1546020K->1337500K(2944192K), 0.0784230 secs]
[GC 1593628K->1323417K(2944192K), 0.0788950 secs]
[GC 1579545K->1367251K(2944192K), 0.0813680 secs]
[GC 1623379K->1360834K(2944192K), 0.0769660 secs]
[GC 1616962K->1394843K(2944192K), 0.0809450 secs]
[GC 1650971K->1395592K(2944192K), 0.0820790 secs]
[GC 1651720K->1415786K(2944192K), 0.0755750 secs]
[GC 1671914K->1453279K(2944192K), 0.0805570 secs]
[GC 1707996K->1437954K(2944192K), 0.0805750 secs]
[GC 1694082K->1455143K(2944192K), 0.0752790 secs]
[GC 1711271K->1503824K(2944192K), 0.0558790 secs]
[GC 1759952K->1462130K(2944192K), 0.0588580 secs]
[GC 1718258K->1468089K(2944192K), 0.0735420 secs]
[GC 1724217K->1516592K(2944192K), 0.0563240 secs]
[GC 1772720K->1478074K(2944192K), 0.0560130 secs]
[GC 1734202K->1520441K(2944192K), 0.0581220 secs]
[GC 1776569K->1495984K(2944192K), 0.0755850 secs]
[GC 1752112K->1527399K(2944192K), 0.0514510 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1783527K->1500922K(2944192K), 0.0508520 secs]
[GC 1757050K->1542531K(2944192K), 0.0593670 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1798610K->1568979K(2944192K), 0.0726020 secs]
[GC 1825107K->1559385K(2944192K), 0.0787990 secs]
[GC 1815513K->1601325K(2944192K), 0.0931390 secs]
[GC 1857453K->1593900K(2944192K), 0.0889550 secs]
[GC 1850028K->1620154K(2944192K), 0.0933550 secs]
[GC 1876069K->1612241K(2944192K), 0.0893120 secs]
[GC 1868365K->1661679K(2944192K), 0.0947740 secs]
[GC 1917807K->1677735K(2944192K), 0.0930480 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1933863K->1695549K(2944192K), 0.0872340 secs]
[GC 1951677K->1732928K(2944192K), 0.0866520 secs]
[GC 1988931K->1716076K(2944192K), 0.0816320 secs]
[GC 1972151K->1757529K(2944192K), 0.0819160 secs]
[GC 2013657K->1782892K(2944192K), 0.0808870 secs]
[GC 2039020K->1773013K(2944192K), 0.0828220 secs]
[GC 2029141K->1826717K(2944192K), 0.0852420 secs]
[GC 2082844K->1806490K(2944192K), 0.0846910 secs]
[GC 2062618K->1818805K(2944192K), 0.0814330 secs]
[GC 2074933K->1829917K(2944192K), 0.0632020 secs]
[GC 2086045K->1851598K(2944192K), 0.0670400 secs]
[GC 2107726K->1831195K(2944192K), 0.0801830 secs]
[GC 2087323K->1865369K(2944192K), 0.0636490 secs]
[GC 2121497K->1869568K(2944192K), 0.0647180 secs]
[GC 2125696K->1851790K(2944192K), 0.0793730 secs]
[GC 2107918K->1866305K(2944192K), 0.0551690 secs]
[GC 2122430K->1894855K(2944192K), 0.0690940 secs]
[GC 2150979K->1927101K(2944192K), 0.0886900 secs]
[GC 2183177K->1938709K(2944192K), 0.1033800 secs]
[GC 2194162K->1932060K(2944192K), 0.1085370 secs]
[GC 2188188K->1957756K(2944192K), 0.0859550 secs]
[GC 2212866K->1989750K(2944192K), 0.0986420 secs]
[GC 2245878K->1989969K(2944192K), 0.0866490 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2246097K->2007960K(2944192K), 0.0984830 secs]
[GC 2264088K->2029835K(2944192K), 0.0900090 secs]
[GC 2285963K->2045807K(2944192K), 0.0953680 secs]
[GC 2301935K->2078556K(2944192K), 0.0940280 secs]
[GC 2334684K->2084740K(2944192K), 0.0953080 secs]
[GC 2340868K->2098871K(2944192K), 0.0922060 secs]
[GC 2353776K->2136784K(2944192K), 0.1208030 secs]
[GC 2392912K->2120988K(2944192K), 0.0841050 secs]
[GC 2377116K->2176976K(2944192K), 0.0691600 secs]
[GC 2433104K->2155588K(2944192K), 0.0826450 secs]
[GC 2411716K->2184885K(2944192K), 0.0826490 secs]
[GC 2441007K->2224417K(2944192K), 0.1086210 secs]
[GC 2480545K->2238180K(2944192K), 0.1093820 secs]
[GC 2492868K->2230802K(2944192K), 0.1123450 secs]
[GC 2486930K->2245357K(2944192K), 0.1052830 secs]
[GC 2501440K->2297389K(2944192K), 0.1029450 secs]
[GC 2553517K->2298721K(2944192K), 0.1088320 secs]
[GC 2554849K->2339831K(2944192K), 0.1097970 secs]
[GC 2594168K->2358982K(2944192K), 0.1141670 secs]
[GC 2615110K->2380577K(2944192K), 0.1031700 secs]
[GC 2636705K->2403505K(2944192K), 0.1030610 secs]
[GC 2659633K->2418411K(2944192K), 0.1002940 secs]
[GC 2673621K->2421653K(2944192K), 0.0966680 secs]
[GC 2677781K->2438712K(2944192K), 0.0951520 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2694840K->2455191K(2944192K), 0.0959360 secs]
[GC 2455198K(2944192K), 0.0288570 secs]
[GC 2649600K(2944192K), 0.2182190 secs]
[GC 2379741K->2123345K(3780520K), 0.0980940 secs]
[GC 2379473K->2181897K(3780520K), 0.0734430 secs]
[GC 2436436K->2160280K(3780520K), 0.0995270 secs]
[GC 2416408K->2203473K(3780520K), 0.1022870 secs]
[GC 2459601K->2224581K(3780520K), 0.0814280 secs]
[GC 2480709K->2238345K(3780520K), 0.1109820 secs]
[GC 2494436K->2232339K(3780520K), 0.1090580 secs]
[GC 2488467K->2259894K(3780520K), 0.0963880 secs]
[GC 2515959K->2272286K(3780520K), 0.0983460 secs]
[GC 2528414K->2308008K(3780520K), 0.0948850 secs]
[GC 2564095K->2309182K(3780520K), 0.0962500 secs]
[GC 2565253K->2358494K(3780520K), 0.0956770 secs]
[GC 2614622K->2344677K(3780520K), 0.0899530 secs]
[GC 2599653K->2405168K(3780520K), 0.0972510 secs]
[GC 2661296K->2382124K(3780520K), 0.1002010 secs]
[GC 2638197K->2437779K(3780520K), 0.0951660 secs]
[GC 2693907K->2413381K(3780520K), 0.0945490 secs]
[GC 2669509K->2459121K(3780520K), 0.0909260 secs]
[GC 2715249K->2437778K(3780520K), 0.0910480 secs]
[GC 2693906K->2492836K(3780520K), 0.0685470 secs]
[GC 2748964K->2472157K(3780520K), 0.0831880 secs]
[GC 2728285K->2489912K(3780520K), 0.0669650 secs]
[GC 2746040K->2504863K(3780520K), 0.0716110 secs]
[GC 2760945K->2517808K(3780520K), 0.0972890 secs]
[GC 2773893K->2556356K(3780520K), 0.0909150 secs]
[GC 2812470K->2526813K(3780520K), 0.0942690 secs]
[GC 2782941K->2561051K(3780520K), 0.1147790 secs]
[GC 2817179K->2577740K(3780520K), 0.0942640 secs]
[GC 2833850K->2578642K(3780520K), 0.0933940 secs]
[GC 2834770K->2610890K(3780520K), 0.0947680 secs]
[GC 2867018K->2662037K(3780520K), 0.0930990 secs]
[GC 2918165K->2646633K(3780520K), 0.0965580 secs]
[GC 2902761K->2701131K(3780520K), 0.0932080 secs]
[GC 2957259K->2682072K(3780520K), 0.0939320 secs]
[GC 2938142K->2741644K(3780520K), 0.0925610 secs]
[GC 2997772K->2728022K(3780520K), 0.0917900 secs]
[GC 2984150K->2779747K(3780520K), 0.0947080 secs]
[GC 3035875K->2756831K(3780520K), 0.0918630 secs]
[GC 3012959K->2802653K(3780520K), 0.0907430 secs]
[GC 3058781K->2776765K(3780520K), 0.0900360 secs]
[GC 3032893K->2830590K(3780520K), 0.0746010 secs]
[GC 3086718K->2810856K(3780520K), 0.0871220 secs]
[GC 3066984K->2830255K(3780520K), 0.0690870 secs]
[GC 3086383K->2808881K(3780520K), 0.0779140 secs]
[GC 3065009K->2829584K(3780520K), 0.0896350 secs]
[GC 3085712K->2849256K(3780520K), 0.0700930 secs]
[GC 3105384K->2832026K(3780520K), 0.0722510 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 3088154K->2868363K(3780520K), 0.0750530 secs]
[GC 3124491K->2875621K(3780520K), 0.0941100 secs]
[GC 3131749K->2889715K(3780520K), 0.0938730 secs]
[GC 3145843K->2923647K(3780520K), 0.0783880 secs]
[GC 3178892K->2923856K(3780520K), 0.0810570 secs]
[GC 3179984K->2945470K(3780520K), 0.0786780 secs]
[GC 3201555K->2941368K(3780520K), 0.0781320 secs]
[GC 3197455K->2955565K(3780520K), 0.0555100 secs]
[GC 3211693K->3041270K(3780520K), 0.1017320 secs]
[GC 3296952K->3012881K(3780520K), 0.0725030 secs]
[GC 3269009K->3027870K(3780520K), 0.0675760 secs]
[GC 3283998K->3055576K(3780520K), 0.0772640 secs]
[GC 3311704K->3043429K(3780520K), 0.0789360 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 3040000. Elapsed time: 20.149 secs. Remaining: 39.851 secs. Total: 1 mins 0 secs
[GC 3299557K->3069520K(3780520K), 0.0600280 secs]
[GC 3325648K->3057080K(3780520K), 0.0662020 secs]
[GC 3313208K->3122106K(3780520K), 0.0803680 secs]
[GC 3378234K->3108409K(3780520K), 0.0826010 secs]
[GC 3363903K->3112417K(3780520K), 0.0675310 secs]
[GC 3368545K->3109098K(3780520K), 0.0623980 secs]
[GC 3365225K->3164991K(3780520K), 0.0729630 secs]
[GC 3421119K->3182589K(3780520K), 0.0757490 secs]
[GC 3438717K->3194798K(3780520K), 0.0812170 secs]
[GC 3450926K->3244581K(3780520K), 0.0808340 secs]
[GC 3245257K(3780520K), 0.0174010 secs]
[GC 3500709K->3245968K(3780520K), 0.0797020 secs]
[GC 3502073K->3230687K(3780520K), 0.0632680 secs]
[GC 3486815K->3315815K(3780520K), 0.0771280 secs]
[GC 3461844K(3780520K), 0.0607420 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9136213. Elapsed time: 40.149 secs. Remaining: 19.851 secs. Total: 1 mins 0 secs
[GC 3452706K->3182150K(3780520K), 0.0902270 secs]
[GC 3185061K->2926541K(4650880K), 0.0703030 secs]
[GC 3182669K->2963025K(4650880K), 0.0675890 secs]
[GC 3219153K->2968547K(4650880K), 0.0828190 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5703 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3224675K->3005205K(4650880K), 0.0645620 secs]
[GC 3260570K->3009624K(4650880K), 0.0723660 secs]
[GC 3265714K->3044304K(4650880K), 0.0848110 secs]
[GC 3300432K->3043854K(4650880K), 0.0823320 secs]
[GC 3299487K->3039663K(4650880K), 0.0645000 secs]
[GC 3295791K->3068200K(4650880K), 0.0557670 secs]
[GC 3324328K->3109900K(4650880K), 0.0720950 secs]
[GC 3366028K->3124407K(4650880K), 0.0959490 secs]
[GC 3380535K->3146817K(4650880K), 0.0719330 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 13210000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 54 mins 26 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:2, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3402945K->3164878K(4650880K), 0.0571310 secs]
[GC 3421006K->3135201K(4650880K), 0.0703820 secs]
[GC 3391329K->3168661K(4650880K), 0.0726090 secs]
[GC 3424766K->3201810K(4650880K), 0.0832670 secs]
[GC 3457938K->3228686K(4650880K), 0.1099540 secs]
[GC 3484814K->3266610K(4650880K), 0.1001650 secs]
[GC 3522738K->3252254K(4650880K), 0.1004640 secs]
[GC 3508382K->3281967K(4650880K), 0.1039870 secs]
[GC 3538095K->3307269K(4650880K), 0.1039870 secs]
[GC 3563396K->3328243K(4650880K), 0.0967130 secs]
[GC 3584237K->3349560K(4650880K), 0.1019810 secs]
[GC 3605688K->3370829K(4650880K), 0.1011590 secs]
[GC 3626957K->3375411K(4650880K), 0.1008310 secs]
[GC 3631151K->3410073K(4650880K), 0.1047610 secs]
[GC 3666201K->3415227K(4650880K), 0.0967680 secs]
 WARN  [Thread-0] {org.radargun.ShutDownHook} Slave process: unexpected shutdown!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5703 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5703 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5703 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 57 ms.
