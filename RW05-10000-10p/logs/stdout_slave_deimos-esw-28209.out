/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-28209 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-28209
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0961650 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@7e69a380
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49682 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 33774 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 48730 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 32927 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 33351 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 36726 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:53995
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:53995
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:41194
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 50789 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:41194
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:55241
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:55241
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:47112
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:47112
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 5
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
[GC 259695K->10373K(2944064K), 0.0335190 secs]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|3] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-16693, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-16693] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|4] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693, deimos-esw-55930]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-16693] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-17944|5] [deimos-esw-17944, deimos-esw-44775, deimos-esw-43446, deimos-esw-1561, deimos-esw-46158, deimos-esw-16693, deimos-esw-55930, deimos-esw-36443]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 5, serverOidBase: 5000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@32693b5
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@32693b5, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 266437K->23025K(2944064K), 0.0591120 secs]
[GC 279089K->30862K(2944064K), 0.0499130 secs]
[GC 286926K->44713K(2944064K), 0.0468780 secs]
[GC 300777K->64668K(2944064K), 0.0559250 secs]
[GC 320710K->82008K(2944064K), 0.0601220 secs]
[GC 338072K->89542K(2944064K), 0.0693380 secs]
[GC 345606K->131324K(2944064K), 0.1530420 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 387388K->143098K(2944064K), 0.0785660 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 7950. Elapsed time: 20.076 secs. Remaining: 39.924 secs. Total: 1 mins 0 secs
[GC 399162K->161455K(2944064K), 0.0727980 secs]
[GC 417519K->152303K(2944064K), 0.0783440 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 31250. Elapsed time: 40.077 secs. Remaining: 19.923 secs. Total: 1 mins 0 secs
[GC 408340K->205457K(2944064K), 0.0599210 secs]
[GC 461521K->210035K(2944064K), 0.0850520 secs]
[GC 466099K->208730K(2944064K), 0.0670330 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 3 mins 12 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 192 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,549,999 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 394064K->184163K(2944064K), 0.6614800 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,758,791 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@32693b5, nodeIndex=5, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 440291K->252310K(2944192K), 0.0320000 secs]
[GC 508438K->202717K(2944192K), 0.0370260 secs]
[GC 458845K->217195K(2944192K), 0.0401980 secs]
[GC 473323K->227567K(2944192K), 0.0448900 secs]
[GC 483695K->241613K(2944192K), 0.0489950 secs]
[GC 497741K->257231K(2944192K), 0.0574170 secs]
[GC 513359K->261715K(2944192K), 0.0613660 secs]
[GC 517843K->274892K(2944192K), 0.0662200 secs]
[GC 530977K->303146K(2944192K), 0.0707370 secs]
[GC 559274K->323344K(2944192K), 0.1044130 secs]
[GC 578867K->345981K(2944192K), 0.1026040 secs]
[GC 602109K->344098K(2944192K), 0.0940770 secs]
[GC 600202K->379355K(2944192K), 0.0958560 secs]
[GC 634000K->376163K(2944192K), 0.0851470 secs]
[GC 632291K->411770K(2944192K), 0.0898070 secs]
[GC 667898K->429975K(2944192K), 0.0814750 secs]
[GC 686103K->447632K(2944192K), 0.0913310 secs]
[GC 701709K->451589K(2944192K), 0.0907450 secs]
[GC 707717K->503338K(2944192K), 0.0872650 secs]
[GC 759466K->488754K(2944192K), 0.0855690 secs]
[GC 744882K->545263K(2944192K), 0.0887540 secs]
[GC 800860K->521213K(2944192K), 0.0805560 secs]
[GC 777341K->583122K(2944192K), 0.0904300 secs]
[GC 839250K->562611K(2944192K), 0.0817090 secs]
[GC 818739K->618799K(2944192K), 0.0882460 secs]
[GC 874927K->585766K(2944192K), 0.0838100 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 841894K->656124K(2944192K), 0.0916780 secs]
[GC 912252K->663815K(2944192K), 0.0966310 secs]
[GC 919943K->699968K(2944192K), 0.0930680 secs]
[GC 956096K->670034K(2944192K), 0.0901240 secs]
[GC 926162K->708541K(2944192K), 0.0889720 secs]
[GC 964669K->705414K(2944192K), 0.0762440 secs]
[GC 961542K->741790K(2944192K), 0.0622660 secs]
[GC 997918K->721821K(2944192K), 0.0797400 secs]
[GC 977949K->766978K(2944192K), 0.0620090 secs]
[GC 1023106K->729068K(2944192K), 0.0707630 secs]
[GC 984632K->756704K(2944192K), 0.0888320 secs]
[GC 1012832K->796933K(2944192K), 0.0714670 secs]
[GC 1052493K->817015K(2944192K), 0.0950390 secs]
[GC 1073143K->833728K(2944192K), 0.1011360 secs]
[GC 1088674K->818441K(2944192K), 0.0987750 secs]
[GC 1074569K->847570K(2944192K), 0.0821160 secs]
[GC 1103663K->845276K(2944192K), 0.0816400 secs]
[GC 1101404K->896236K(2944192K), 0.0839180 secs]
[GC 1152364K->904612K(2944192K), 0.0844630 secs]
[GC 1159157K->935727K(2944192K), 0.0898500 secs]
[GC 1191855K->937470K(2944192K), 0.0796120 secs]
[GC 1193598K->957666K(2944192K), 0.0786460 secs]
[GC 1213794K->976188K(2944192K), 0.0880840 secs]
[GC 1232316K->994055K(2944192K), 0.0801640 secs]
[GC 1250183K->1014196K(2944192K), 0.0831720 secs]
[GC 1269491K->1032478K(2944192K), 0.0809420 secs]
[GC 1288606K->1069980K(2944192K), 0.0836840 secs]
[GC 1326108K->1052540K(2944192K), 0.0825100 secs]
[GC 1308668K->1103628K(2944192K), 0.0878730 secs]
[GC 1359756K->1111740K(2944192K), 0.0865400 secs]
[GC 1367015K->1146699K(2944192K), 0.0787630 secs]
[GC 1402827K->1149297K(2944192K), 0.0845270 secs]
[GC 1405390K->1182300K(2944192K), 0.0843570 secs]
[GC 1438428K->1201959K(2944192K), 0.0917790 secs]
[GC 1458087K->1207289K(2944192K), 0.0909030 secs]
[GC 1463417K->1208273K(2944192K), 0.0862140 secs]
[GC 1464401K->1246396K(2944192K), 0.0655000 secs]
[GC 1502524K->1227676K(2944192K), 0.0834090 secs]
[GC 1483804K->1258009K(2944192K), 0.0656780 secs]
[GC 1514137K->1278795K(2944192K), 0.0704820 secs]
[GC 1534923K->1267694K(2944192K), 0.0872190 secs]
[GC 1523822K->1282208K(2944192K), 0.0948790 secs]
[GC 1538336K->1297388K(2944192K), 0.1241900 secs]
[GC 1553516K->1272017K(2944192K), 0.1449560 secs]
[GC 1528145K->1322046K(2944192K), 0.1141490 secs]
[GC 1578174K->1291085K(2944192K), 0.0831580 secs]
[GC 1547213K->1339729K(2944192K), 0.1185470 secs]
[GC 1595857K->1307757K(2944192K), 0.1385300 secs]
[GC 1563885K->1355385K(2944192K), 0.0825170 secs]
[GC 1611513K->1322868K(2944192K), 0.1634810 secs]
[GC 1578996K->1354921K(2944192K), 0.0812120 secs]
[GC 1611049K->1339497K(2944192K), 0.1485790 secs]
[GC 1595625K->1388190K(2944192K), 0.1548780 secs]
[GC 1644318K->1354365K(2944192K), 0.1687810 secs]
[GC 1610493K->1405017K(2944192K), 0.1647350 secs]
[GC 1661145K->1370441K(2944192K), 0.0855050 secs]
[GC 1370787K(2944192K), 0.0610750 secs]
[GC 1427923K(2944192K), 0.0472930 secs]
[GC 1387036K->1180469K(2944192K), 0.0784950 secs]
[GC 1436597K->1142787K(2944192K), 0.0756090 secs]
[GC 1398915K->1189458K(2944192K), 0.0732650 secs]
[GC 1445586K->1176065K(2944192K), 0.0792740 secs]
[GC 1432193K->1222578K(2944192K), 0.0947260 secs]
[GC 1478706K->1229618K(2944192K), 0.0881040 secs]
[GC 1485746K->1220686K(2944192K), 0.0937980 secs]
[GC 1476814K->1235118K(2944192K), 0.0844030 secs]
[GC 1491246K->1267889K(2944192K), 0.1363290 secs]
[GC 1522166K->1268733K(2944192K), 0.0848370 secs]
[GC 1524278K->1319153K(2944192K), 0.0913920 secs]
[GC 1575281K->1363522K(2944192K), 0.0853760 secs]
[GC 1619650K->1337859K(2944192K), 0.0841850 secs]
[GC 1593987K->1399550K(2944192K), 0.0843190 secs]
[GC 1655632K->1374964K(2944192K), 0.0893010 secs]
[GC 1631092K->1434422K(2944192K), 0.0859560 secs]
[GC 1690539K->1412765K(2944192K), 0.0857350 secs]
[GC 1668893K->1471574K(2944192K), 0.0832910 secs]
[GC 1727702K->1451118K(2944192K), 0.0829150 secs]
[GC 1707245K->1512709K(2944192K), 0.0863950 secs]
[GC 1767678K->1490880K(2944192K), 0.0864040 secs]
[GC 1747008K->1516577K(2944192K), 0.0802080 secs]
[GC 1772705K->1549536K(2944192K), 0.0674870 secs]
[GC 1805664K->1528817K(2944192K), 0.0793420 secs]
[GC 1784945K->1553599K(2944192K), 0.0649190 secs]
[GC 1809727K->1529621K(2944192K), 0.0788230 secs]
[GC 1785749K->1574032K(2944192K), 0.0610660 secs]
[GC 1830116K->1572463K(2944192K), 0.0701490 secs]
[GC 1828591K->1613937K(2944192K), 0.0928670 secs]
[GC 1870065K->1633252K(2944192K), 0.0996980 secs]
[GC 1887410K->1612444K(2944192K), 0.1093990 secs]
[GC 1868074K->1641820K(2944192K), 0.0893380 secs]
[GC 1897948K->1642528K(2944192K), 0.0842310 secs]
[GC 1897762K->1673534K(2944192K), 0.0831360 secs]
[GC 1929662K->1676071K(2944192K), 0.0835820 secs]
[GC 1932162K->1710479K(2944192K), 0.0838580 secs]
[GC 1966607K->1747103K(2944192K), 0.0832690 secs]
[GC 2003231K->1767587K(2944192K), 0.0874750 secs]
[GC 2023715K->1801922K(2944192K), 0.0843290 secs]
[GC 2058050K->1792375K(2944192K), 0.0894640 secs]
[GC 2048503K->1843999K(2944192K), 0.0906370 secs]
[GC 2100127K->1823516K(2944192K), 0.0854980 secs]
[GC 2079644K->1877734K(2944192K), 0.0837480 secs]
[GC 2133828K->1855987K(2944192K), 0.0842450 secs]
[GC 2112115K->1901383K(2944192K), 0.0842530 secs]
[GC 2157511K->1945175K(2944192K), 0.0852760 secs]
[GC 2201303K->1923583K(2944192K), 0.0870190 secs]
[GC 2179711K->1972792K(2944192K), 0.0879110 secs]
[GC 2228869K->1960087K(2944192K), 0.0847070 secs]
[GC 2214539K->1994288K(2944192K), 0.0850110 secs]
[GC 2250416K->1980399K(2944192K), 0.0834190 secs]
[GC 2236527K->2049357K(2944192K), 0.0829300 secs]
[GC 2305485K->2043617K(2944192K), 0.0864140 secs]
[GC 2299745K->2082657K(2944192K), 0.0883510 secs]
[GC 2337156K->2070588K(2944192K), 0.0911290 secs]
[GC 2325499K->2090494K(2944192K), 0.0851930 secs]
[GC 2345455K->2109743K(2944192K), 0.0837120 secs]
[GC 2364729K->2144300K(2944192K), 0.1018400 secs]
[GC 2400428K->2165299K(2944192K), 0.0895630 secs]
[GC 2420953K->2169558K(2944192K), 0.0895370 secs]
[GC 2425658K->2188331K(2944192K), 0.0895400 secs]
[GC 2444123K->2245299K(2944192K), 0.0927410 secs]
[GC 2501427K->2229716K(2944192K), 0.0907990 secs]
[GC 2485844K->2288583K(2944192K), 0.0956200 secs]
[GC 2544711K->2276211K(2944192K), 0.0991790 secs]
[GC 2532339K->2315206K(2944192K), 0.0995390 secs]
[GC 2571332K->2339441K(2944192K), 0.0957530 secs]
[GC 2595569K->2363011K(2944192K), 0.1023100 secs]
[GC 2619139K->2379994K(2944192K), 0.0962270 secs]
[GC 2636122K->2382348K(2944192K), 0.1001060 secs]
[GC 2638476K->2421723K(2944192K), 0.0896710 secs]
[GC 2676758K->2405754K(2944192K), 0.0965960 secs]
[GC 2660959K->2439471K(2944192K), 0.0949270 secs]
[GC 2695599K->2458467K(2944192K), 0.0955500 secs]
[GC 2458498K(2944192K), 0.0421960 secs]
[GC 2712761K->2478828K(2944192K), 0.0921280 secs]
[GC 2608771K(2944192K), 0.0618280 secs]
[GC 2396002K->2138842K(3799856K), 0.1014650 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2394970K->2157054K(3799856K), 0.1003830 secs]
[GC 2413125K->2223844K(3799856K), 0.1013590 secs]
[GC 2478535K->2209720K(3799856K), 0.0979560 secs]
[GC 2465828K->2268023K(3799856K), 0.0922600 secs]
[GC 2524151K->2244610K(3799856K), 0.0892170 secs]
[GC 2500738K->2257077K(3799856K), 0.0888060 secs]
[GC 2513205K->2296466K(3799856K), 0.0765950 secs]
[GC 2552594K->2284697K(3799856K), 0.0853870 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2540825K->2288705K(3799856K), 0.0671130 secs]
[GC 2544833K->2314566K(3799856K), 0.0682130 secs]
[GC 2570694K->2308293K(3799856K), 0.0925370 secs]
[GC 2564421K->2329376K(3799856K), 0.0723370 secs]
[GC 2585504K->2320117K(3799856K), 0.0758900 secs]
[GC 2574594K->2362251K(3799856K), 0.0946150 secs]
[GC 2616630K->2380920K(3799856K), 0.1078700 secs]
[GC 2635723K->2389397K(3799856K), 0.1068980 secs]
[GC 2645525K->2378408K(3799856K), 0.1054800 secs]
[GC 2634015K->2408972K(3799856K), 0.0991070 secs]
[GC 2665076K->2406330K(3799856K), 0.0865580 secs]
[GC 2662433K->2439722K(3799856K), 0.0862060 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 2695850K->2473117K(3799856K), 0.0927210 secs]
[GC 2729245K->2481393K(3799856K), 0.0964830 secs]
[GC 2735722K->2497296K(3799856K), 0.0881150 secs]
[GC 2753424K->2515704K(3799856K), 0.0871960 secs]
[GC 2771832K->2521154K(3799856K), 0.0914550 secs]
[GC 2775470K->2586301K(3799856K), 0.0900090 secs]
[GC 2842429K->2571626K(3799856K), 0.0936400 secs]
[GC 2827754K->2618714K(3799856K), 0.0950250 secs]
[GC 2873323K->2638677K(3799856K), 0.0873990 secs]
[GC 2894805K->2626398K(3799856K), 0.0910840 secs]
[GC 2882526K->2671541K(3799856K), 0.0929670 secs]
[GC 2927669K->2681547K(3799856K), 0.0892110 secs]
[GC 2936686K->2686028K(3799856K), 0.0890220 secs]
[GC 2942156K->2685218K(3799856K), 0.0861490 secs]
[GC 2941346K->2744425K(3799856K), 0.0741770 secs]
[GC 3000553K->2751120K(3799856K), 0.0886220 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 3007248K->2751546K(3799856K), 0.0871310 secs]
[GC 3007674K->2756277K(3799856K), 0.0704920 secs]
[GC 3012348K->2786129K(3799856K), 0.0979930 secs]
[GC 3042257K->2764563K(3799856K), 0.0700450 secs]
[GC 3020633K->2777838K(3799856K), 0.0539980 secs]
[GC 3033966K->2800206K(3799856K), 0.0574840 secs]
[GC 3056334K->2807810K(3799856K), 0.0760300 secs]
[GC 3063938K->2793087K(3799856K), 0.0635230 secs]
[GC 3049215K->2823938K(3799856K), 0.0589440 secs]
[GC 3078198K->2813779K(3799856K), 0.0740000 secs]
[GC 3069907K->2839501K(3799856K), 0.0627220 secs]
[GC 3095629K->2849686K(3799856K), 0.0703850 secs]
[GC 3105814K->2862911K(3799856K), 0.0711890 secs]
[GC 3119039K->2863131K(3799856K), 0.0640820 secs]
[GC 3118858K->2869300K(3799856K), 0.0602360 secs]
[GC 3125428K->2894876K(3799856K), 0.0689700 secs]
[GC 3151004K->2900792K(3799856K), 0.0809600 secs]
[GC 3156909K->2903370K(3799856K), 0.0694240 secs]
[GC 3157311K->2926099K(3799856K), 0.0584480 secs]
[GC 3182227K->2918934K(3799856K), 0.0666740 secs]
[GC 3175062K->2926628K(3799856K), 0.0518720 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 3182205K->2940884K(3799856K), 0.0623950 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 4996371. Elapsed time: 20.059 secs. Remaining: 39.941 secs. Total: 1 mins 0 secs
[GC 3194415K->2960559K(3799856K), 0.0664380 secs]
[GC 3216681K->3000492K(3799856K), 0.0781460 secs]
[GC 3256051K->2980840K(3799856K), 0.0861370 secs]
[GC 3236968K->3002896K(3799856K), 0.0599220 secs]
[GC 3257990K->2987757K(3799856K), 0.0592950 secs]
[GC 3243885K->3008841K(3799856K), 0.0557990 secs]
[GC 3264931K->3017854K(3799856K), 0.0671710 secs]
[GC 3273982K->3024992K(3799856K), 0.0594030 secs]
[GC 3280758K->3049009K(3799856K), 0.0764200 secs]
[GC 3305137K->3051208K(3799856K), 0.0756240 secs]
[GC 3307336K->3061990K(3799856K), 0.0585770 secs]
[GC 3318118K->3062447K(3799856K), 0.0641200 secs]
[GC 3318575K->3101445K(3799856K), 0.0682920 secs]
[GC 3357552K->3091788K(3799856K), 0.0764840 secs]
[GC 3347916K->3095019K(3799856K), 0.0612930 secs]
[GC 3351147K->3120323K(3799856K), 0.0595560 secs]
[GC 3376451K->3108910K(3799856K), 0.0709510 secs]
[GC 3365038K->3129494K(3799856K), 0.0509020 secs]
[GC 3385622K->3145576K(3799856K), 0.0553850 secs]
[GC 3401704K->3163467K(3799856K), 0.0739120 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 12219535. Elapsed time: 40.059 secs. Remaining: 19.941 secs. Total: 1 mins 0 secs
[GC 3419539K->3158087K(3799856K), 0.0758740 secs]
[GC 3411496K->3178496K(3799856K), 0.0610890 secs]
[GC 3434624K->3167245K(3799856K), 0.0698320 secs]
[GC 3422965K->3196669K(3799856K), 0.0621400 secs]
[GC 3449692K->3189159K(3799856K), 0.0773690 secs]
[GC 3444393K->3220202K(3799856K), 0.0560340 secs]
[GC 3476330K->3234797K(3799856K), 0.0754880 secs]
[GC 3234862K(3799856K), 0.0170800 secs]
[GC 3490925K->3239456K(3799856K), 0.0569700 secs]
[GC 3495584K->3272499K(3799856K), 0.0684080 secs]
[GC 3528627K->3283590K(3799856K), 0.1004780 secs]
[GC 3428427K(3799856K), 0.0661750 secs]
[GC 3512400K->3251401K(3799856K), 0.0554590 secs]
[GC 3208703K->2974564K(4650880K), 0.0598990 secs]
[GC 3230517K->2994192K(4650880K), 0.0658750 secs]
[GC 3250065K->2976064K(4650880K), 0.0811050 secs]
[GC 3232192K->3003015K(4650880K), 0.0573530 secs]
[GC 3259143K->3023533K(4650880K), 0.0682790 secs]
[GC 3279661K->3016285K(4650880K), 0.0802600 secs]
[GC 3272413K->3037301K(4650880K), 0.0594530 secs]
[GC 3293429K->3047762K(4650880K), 0.0661560 secs]
[GC 3303890K->3049281K(4650880K), 0.0674300 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 16250000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 33 mins 39 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:8, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 63 ms.
