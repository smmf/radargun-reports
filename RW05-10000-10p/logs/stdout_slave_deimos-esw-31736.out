/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-31736 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-31736
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.1118690 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 8 slaves. This is the slave with index 7. Sleeping for 8500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 7
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@496d6956
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=7, confAttributes={name=hzl3-repl-sync.xml, decorate=hazelcast3}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5709, using socket ServerSocket[addr=/0.0.0.0,localport=5709], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5709 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5709
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5709 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5709 [FenixFrameworkGroup] Address[127.0.0.1]:5709 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 58884 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 54328 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 36613 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5709 [FenixFrameworkGroup] hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5702, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5709 [FenixFrameworkGroup] 

Members [8] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709 this
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 36468 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5706, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 59521 accepted socket connection from /127.0.0.1:5706
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 56607 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 47640 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5709 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 55654 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:43258
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:43258
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5709 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:50040
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5709 [FenixFrameworkGroup] 5709 accepted socket connection from /127.0.0.1:50040
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5709 [FenixFrameworkGroup] Address[127.0.0.1]:5709 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 7
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=hzl3-repl-sync.xml, isLocal=false, nodeIndex=7, confAttributes={name=hzl3-repl-sync.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Creating cache with the following configuration: hzl3-repl-sync.xml
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5716, using socket ServerSocket[addr=/0.0.0.0,localport=5716], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5716 [dev] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5716
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5716 [dev] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5716 [dev] Address[127.0.0.1]:5716 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5716 [dev] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 46098 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 39667 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_2_dev.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 58457 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 WARN  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5716 [dev] hz._hzInstance_2_dev.IO.thread-in-0 Closing socket to endpoint Address[127.0.0.1]:5703, Cause:java.io.EOFException: Remote socket closed!
 WARN  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.ReadHandler} [127.0.0.1]:5716 [dev] hz._hzInstance_2_dev.IO.thread-in-2 Closing socket to endpoint Address[127.0.0.1]:5701, Cause:java.io.EOFException: Remote socket closed!
 INFO  [hz._hzInstance_2_dev.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5716 [dev] 

Members [8] {
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
	Member [127.0.0.1]:5713
	Member [127.0.0.1]:5714
	Member [127.0.0.1]:5715
	Member [127.0.0.1]:5716 this
}

 INFO  [hz._hzInstance_2_dev.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 60540 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:49493
 INFO  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 35197 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5713, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5714, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.cached.thread-10] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 51608 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:49493
 INFO  [hz._hzInstance_2_dev.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 44524 accepted socket connection from /127.0.0.1:5713
 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5716 [dev] Connecting to /127.0.0.1:5715, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:48754
 INFO  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 56505 accepted socket connection from /127.0.0.1:5714
 INFO  [hz._hzInstance_2_dev.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 52629 accepted socket connection from /127.0.0.1:5715
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:48754
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:47378
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:47378
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:44592
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:44592
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:45534
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:45534
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5716 [dev] Accepting socket connection from /127.0.0.1:34564
 INFO  [hz._hzInstance_2_dev.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5716 [dev] 5716 accepted socket connection from /127.0.0.1:34564
[GC 259695K->11866K(2944064K), 0.0401410 secs]
 WARN  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Config seed port is 5701 and cluster size is 8. Some of the ports seem occupied!
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5716 [dev] Address[127.0.0.1]:5716 is STARTED
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.Hazelcast3Wrapper} Hazelcast configuration:Config{groupConfig=GroupConfig [name=dev, password=********], properties={hazelcast.logging.type=log4j}, networkConfig=NetworkConfig {publicAddress='null', port=5701, portCount=100, portAutoIncrement=true, join=JoinConfig{multicastConfig=MulticastConfig [enabled=true, multicastGroup=224.0.2.128, multicastPort=54327, multicastTimeToLive=32, multicastTimeoutSeconds=2, trustedInterfaces=[]], tcpIpConfig=TcpIpConfig [enabled=true, connectionTimeoutSeconds=5, members=[127.0.0.1], requiredMember=null], awsConfig=AwsConfig{enabled=false, region='us-east-1', securityGroupName='null', tagKey='null', tagValue='null', hostHeader='ec2.amazonaws.com', connectionTimeoutSeconds=5}}, interfaces=InterfacesConfig{enabled=false, interfaces=[]}, sslConfig=null, socketInterceptorConfig=null, symmetricEncryptionConfig=null}, mapConfigs={default=MapConfig{name='default', inMemoryFormat=BINARY', backupCount=5, asyncBackupCount=0, timeToLiveSeconds=0, maxIdleSeconds=0, evictionPolicy='NONE', evictionPercentage=0, maxSizeConfig=MaxSizeConfig{maxSizePolicy='PER_PARTITION', size=2147483647}, readBackupData=true, nearCacheConfig=null, mapStoreConfig=null, mergePolicyConfig='hz.ADD_NEW_ENTRY', wanReplicationRef=null, listenerConfigs=[], mapIndexConfigs=[], storageType=null}}, topicConfigs={}, queueConfigs={}, multiMapConfigs={}, executorConfigs={default=ExecutorConfig{name='default', poolSize=8, queueCapacity=2147483647}}, semaphoreConfigs={}, wanReplicationConfigs={}, listenerConfigs=[], partitionGroupConfig=PartitionGroupConfig{enabled=false, groupType=PER_MEMBER, memberGroupConfigs=[]}, managementCenterConfig=ManagementCenterConfig{enabled=false, url='null', updateInterval=5}, securityConfig=SecurityConfig{enabled=false, memberCredentialsConfig=CredentialsFactoryConfig{className='null', implementation=null, properties={}}, memberLoginModuleConfigs=[], clientLoginModuleConfigs=[], clientPolicyConfig=PermissionPolicyConfig{className='null', implementation=null, properties={}}, clientPermissionConfigs=[]}}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 7, serverOidBase: 7000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 8
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 7: org.radargun.cachewrappers.FFWrapper@75624cae
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=hzl3-repl-sync.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 3796e02c-bc83-4b93-9975-6c89f1cb3a91
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> f9f8047b-4872-4f17-9ef8-8127be52317a
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> b306ae41-be84-4802-ab31-e8814297effc
 WARN  [hz._hzInstance_2_dev.cached.thread-3] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 1cac2673-b3d8-47cf-87e1-843c3187e7ca
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 056e07c5-a7e6-4d73-ac65-c883e50b3be0
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 1
 WARN  [hz._hzInstance_2_dev.cached.thread-12] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> 8665f17b-4671-403a-99ff-821e7f118d44
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> bf7680c2-182f-4771-8327-f8d8843e29fc
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> cf283a4d-8446-4a10-9d13-b8508c86ac7a
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 7
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 7
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> de2c5c52-46f7-40a3-a972-a243297dc032
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> a0a8f343-81fe-41de-9b64-3e956b79d694
 WARN  [hz._hzInstance_2_dev.cached.thread-5] {com.hazelcast.transaction.TransactionManagerService} [127.0.0.1]:5716 [dev] No tx backup log is found, tx -> fc10b417-17c9-4321-981c-13cb5f7c2a6a
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@75624cae, nodeIndex=7, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 267930K->11623K(2944064K), 0.0335650 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 267687K->13679K(2944064K), 0.0322680 secs]
[GC 269743K->14986K(2944064K), 0.0318410 secs]
[GC 271050K->15207K(2944064K), 0.0364830 secs]
[GC 271271K->16997K(2944064K), 0.0337980 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 10450. Elapsed time: 20.136 secs. Remaining: 39.864 secs. Total: 1 mins 0 secs
[GC 273061K->18816K(2944064K), 0.0379860 secs]
[GC 274880K->23340K(2944064K), 0.0352240 secs]
[GC 279404K->25671K(2944064K), 0.0377630 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 19650. Elapsed time: 40.333 secs. Remaining: 19.667 secs. Total: 1 mins 0 secs
[GC 281735K->28012K(2944064K), 0.0378360 secs]
[GC 284076K->30466K(2944064K), 0.0399340 secs]
[GC 286530K->33069K(2944064K), 0.0378870 secs]
[GC 289133K->35569K(2944064K), 0.0413660 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 27500. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 12 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 72 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 291633K->38187K(2944064K), 0.0385690 secs]
[GC 294251K->40742K(2944064K), 0.0394370 secs]
[GC 296806K->47974K(2944064K), 0.0597390 secs]
[GC 304038K->43208K(2944064K), 0.0409750 secs]
[GC 299272K->39780K(2944064K), 0.0402860 secs]
[GC 295844K->45162K(2944064K), 0.0423550 secs]
[GC 301226K->48701K(2944064K), 0.0380680 secs]
[GC 304765K->51742K(2944064K), 0.0422010 secs]
[GC 307806K->54657K(2944064K), 0.0429650 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,639,836 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 304227K->50505K(2944064K), 0.4031280 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,892,978 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=10000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@75624cae, nodeIndex=7, useTransactions=true, transactionSize=10000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using hazelcast3
[GC 306633K->79592K(2944192K), 0.0309550 secs]
[GC 335720K->58104K(2944192K), 0.0297100 secs]
[GC 314232K->56646K(2944192K), 0.0277890 secs]
[GC 312774K->58732K(2944192K), 0.0278760 secs]
[GC 314860K->61257K(2944192K), 0.0327130 secs]
[GC 317385K->63884K(2944192K), 0.0301600 secs]
[GC 320012K->66445K(2944192K), 0.0345240 secs]
[GC 322573K->68985K(2944192K), 0.0327900 secs]
[GC 325113K->66585K(2944192K), 0.0312670 secs]
[GC 322713K->72195K(2944192K), 0.0347950 secs]
[GC 328323K->76426K(2944192K), 0.0395390 secs]
[GC 332554K->72695K(2944192K), 0.0365710 secs]
[GC 328823K->79475K(2944192K), 0.0339310 secs]
[GC 335603K->84272K(2944192K), 0.0394310 secs]
[GC 340400K->73183K(2944192K), 0.0366160 secs]
[GC 329311K->84237K(2944192K), 0.0422920 secs]
[GC 340365K->88171K(2944192K), 0.0390370 secs]
[GC 344299K->80104K(2944192K), 0.0413490 secs]
[GC 336232K->92889K(2944192K), 0.0370080 secs]
[GC 349017K->82068K(2944192K), 0.0429760 secs]
[GC 338196K->95428K(2944192K), 0.0425230 secs]
[GC 351556K->84720K(2944192K), 0.0376660 secs]
[GC 340848K->98371K(2944192K), 0.0362290 secs]
[GC 354499K->87574K(2944192K), 0.0372390 secs]
[GC 343702K->96590K(2944192K), 0.0417590 secs]
[GC 352718K->95714K(2944192K), 0.0374310 secs]
[GC 351842K->97635K(2944192K), 0.0396970 secs]
[GC 353763K->99160K(2944192K), 0.0359450 secs]
[GC 355288K->100508K(2944192K), 0.0387550 secs]
[GC 356636K->96881K(2944192K), 0.0391270 secs]
[GC 353009K->103418K(2944192K), 0.0396620 secs]
[GC 359546K->99672K(2944192K), 0.0364960 secs]
[GC 355800K->100956K(2944192K), 0.0411740 secs]
[GC 357084K->107509K(2944192K), 0.0417000 secs]
[GC 363637K->108966K(2944192K), 0.0425620 secs]
[GC 365094K->110334K(2944192K), 0.0401060 secs]
[GC 366462K->111866K(2944192K), 0.0393160 secs]
[GC 367994K->113190K(2944192K), 0.0442610 secs]
[GC 369318K->114576K(2944192K), 0.0382150 secs]
[GC 370704K->116112K(2944192K), 0.0500910 secs]
[GC 372240K->117593K(2944192K), 0.0375700 secs]
[GC 373721K->118984K(2944192K), 0.0454970 secs]
[GC 375112K->125532K(2944192K), 0.0400260 secs]
[GC 381660K->116541K(2944192K), 0.0363630 secs]
[GC 372669K->129642K(2944192K), 0.0357570 secs]
[GC 385770K->121450K(2944192K), 0.0535820 secs]
[GC 377578K->132047K(2944192K), 0.0357910 secs]
[GC 388175K->124662K(2944192K), 0.0612220 secs]
[GC 380790K->133713K(2944192K), 0.0410380 secs]
[GC 389841K->141366K(2944192K), 0.0399580 secs]
[GC 397494K->147345K(2944192K), 0.0413510 secs]
[GC 403473K->160123K(2944192K), 0.0411180 secs]
[GC 416251K->141648K(2944192K), 0.0401360 secs]
[GC 397776K->166083K(2944192K), 0.0543400 secs]
[GC 422211K->153795K(2944192K), 0.0418600 secs]
[GC 409923K->176134K(2944192K), 0.0461540 secs]
[GC 432262K->155923K(2944192K), 0.0450570 secs]
[GC 412051K->177056K(2944192K), 0.0460860 secs]
[GC 433184K->186962K(2944192K), 0.0467960 secs]
[GC 443090K->192491K(2944192K), 0.0477280 secs]
[GC 448619K->171603K(2944192K), 0.0485830 secs]
[GC 427731K->192914K(2944192K), 0.0516460 secs]
[GC 449042K->204247K(2944192K), 0.0529700 secs]
[GC 460375K->183291K(2944192K), 0.0553010 secs]
[GC 439419K->192178K(2944192K), 0.0515710 secs]
[GC 448306K->212591K(2944192K), 0.0538250 secs]
[GC 468719K->199393K(2944192K), 0.0571500 secs]
[GC 455521K->210578K(2944192K), 0.0512700 secs]
[GC 466706K->207064K(2944192K), 0.0486550 secs]
[GC 463192K->210852K(2944192K), 0.0501290 secs]
[GC 466980K->202311K(2944192K), 0.0490640 secs]
[GC 458439K->204963K(2944192K), 0.0493730 secs]
[GC 461091K->216337K(2944192K), 0.0508300 secs]
[GC 472465K->207803K(2944192K), 0.0561590 secs]
[GC 463931K->220504K(2944192K), 0.0468690 secs]
[GC 476632K->223530K(2944192K), 0.0509260 secs]
[GC 479658K->236982K(2944192K), 0.0464260 secs]
[GC 493110K->219169K(2944192K), 0.0491290 secs]
[GC 475297K->235952K(2944192K), 0.0487920 secs]
[GC 492080K->233689K(2944192K), 0.0468700 secs]
[GC 489817K->227280K(2944192K), 0.0453150 secs]
[GC 483408K->240747K(2944192K), 0.0477420 secs]
[GC 496875K->233240K(2944192K), 0.0648760 secs]
[GC 489368K->246496K(2944192K), 0.0457780 secs]
[GC 502624K->238888K(2944192K), 0.0461220 secs]
[GC 495016K->252074K(2944192K), 0.0476190 secs]
[GC 508202K->254857K(2944192K), 0.0470780 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 510985K->257813K(2944192K), 0.0476520 secs]
[GC 513941K->262742K(2944192K), 0.0518560 secs]
[GC 518870K->281652K(2944192K), 0.0723560 secs]
[GC 537780K->275461K(2944192K), 0.0531690 secs]
[GC 531589K->278810K(2944192K), 0.0548370 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 410000. Elapsed time: 21.465 secs. Remaining: 38.535 secs. Total: 1 mins 0 secs
[GC 534938K->283987K(2944192K), 0.0599930 secs]
[GC 540115K->288619K(2944192K), 0.0565360 secs]
[GC 544747K->279848K(2944192K), 0.0534470 secs]
[GC 535976K->310406K(2944192K), 0.0555900 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 440000. Elapsed time: 41.572 secs. Remaining: 18.428 secs. Total: 1 mins 0 secs
[GC 566534K->295950K(2944192K), 0.0662780 secs]
[GC 552078K->323179K(2944192K), 0.0666190 secs]
[GC 579307K->290776K(2944192K), 0.0615690 secs]
[GC 546904K->331093K(2944192K), 0.0612320 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1610000. Elapsed time: 1 mins 2 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
[GC 587221K->298859K(2944192K), 0.0514650 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 10 mins 19 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using hazelcast3, clusterSize:8, nodeIndex:7, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=10000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=10000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=10000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 554987K->338939K(2944192K), 0.0551900 secs]
[GC 595067K->302808K(2944192K), 0.0525690 secs]
[GC 558936K->342637K(2944192K), 0.0526740 secs]
[GC 598765K->307929K(2944192K), 0.0516940 secs]
[GC 564057K->328242K(2944192K), 0.0517190 secs]
[GC 584370K->323798K(2944192K), 0.0521150 secs]
[GC 579926K->300537K(2944192K), 0.0483830 secs]
[GC 556665K->302797K(2944192K), 0.0469490 secs]
[GC 558925K->315278K(2944192K), 0.0473990 secs]
[GC 571406K->316975K(2944192K), 0.0502910 secs]
[GC 573103K->307251K(2944192K), 0.0460440 secs]
[GC 563379K->327493K(2944192K), 0.0497250 secs]
[GC 583621K->320527K(2944192K), 0.0483530 secs]
[GC 576655K->321908K(2944192K), 0.0467840 secs]
[GC 578036K->314170K(2944192K), 0.0465180 secs]
[GC 570298K->320601K(2944192K), 0.0444510 secs]
[GC 576729K->320937K(2944192K), 0.0474140 secs]
[GC 577065K->328571K(2944192K), 0.0426180 secs]
[GC 584699K->323986K(2944192K), 0.0409240 secs]
[GC 580114K->332022K(2944192K), 0.0476550 secs]
[GC 588150K->333730K(2944192K), 0.0453860 secs]
[GC 589858K->335499K(2944192K), 0.0511320 secs]
[GC 591627K->330973K(2944192K), 0.0420640 secs]
[GC 587101K->339139K(2944192K), 0.0448780 secs]
[GC 595267K->340851K(2944192K), 0.0491190 secs]
[GC 596979K->336221K(2944192K), 0.0433600 secs]
[GC 592349K->338085K(2944192K), 0.0527960 secs]
[GC 594213K->346405K(2944192K), 0.0464880 secs]
[GC 602533K->348166K(2944192K), 0.0436790 secs]
[GC 604294K->343490K(2944192K), 0.0514640 secs]
[GC 599618K->351750K(2944192K), 0.0452400 secs]
[GC 607878K->353460K(2944192K), 0.0509410 secs]
[GC 609588K->348684K(2944192K), 0.0507220 secs]
[GC 604812K->357057K(2944192K), 0.0438640 secs]
[GC 613185K->365409K(2944192K), 0.0413960 secs]
[GC 621537K->354075K(2944192K), 0.0421860 secs]
[GC 610203K->364716K(2944192K), 0.0539440 secs]
[GC 620844K->363357K(2944192K), 0.0434730 secs]
[GC 619485K->359242K(2944192K), 0.0518470 secs]
[GC 615370K->367950K(2944192K), 0.0431600 secs]
[GC 624078K->369762K(2944192K), 0.0510040 secs]
[GC 625890K->371521K(2944192K), 0.0508860 secs]
[GC 627649K->366692K(2944192K), 0.0913650 secs]
[GC 622820K->375118K(2944192K), 0.0464150 secs]
[GC 631246K->376942K(2944192K), 0.0479450 secs]
[GC 633070K->385374K(2944192K), 0.0495290 secs]
[GC 641502K->373882K(2944192K), 0.0507290 secs]
[GC 630010K->390832K(2944192K), 0.0437120 secs]
[GC 646960K->376282K(2944192K), 0.0455540 secs]
[GC 632410K->394058K(2944192K), 0.0474550 secs]
[GC 650186K->379779K(2944192K), 0.0441840 secs]
[GC 635907K->391690K(2944192K), 0.0435150 secs]
[GC 647818K->383889K(2944192K), 0.0528590 secs]
[GC 640017K->392955K(2944192K), 0.0500450 secs]
[GC 649083K->394981K(2944192K), 0.0478690 secs]
[GC 651109K->396836K(2944192K), 0.0524550 secs]
[GC 652964K->398721K(2944192K), 0.0442090 secs]
[GC 654849K->400402K(2944192K), 0.0516630 secs]
[GC 656530K->402129K(2944192K), 0.0452960 secs]
[GC 658257K->403842K(2944192K), 0.0428130 secs]
[GC 659970K->405632K(2944192K), 0.0436900 secs]
[GC 661760K->407329K(2944192K), 0.0498910 secs]
[GC 663457K->409127K(2944192K), 0.0429060 secs]
[GC 665255K->410840K(2944192K), 0.0416140 secs]
[GC 666968K->405945K(2944192K), 0.0422640 secs]
[GC 662073K->414387K(2944192K), 0.0519880 secs]
[GC 670515K->416127K(2944192K), 0.0489450 secs]
[GC 672255K->417832K(2944192K), 0.0482110 secs]
[GC 673960K->413023K(2944192K), 0.0490740 secs]
[GC 669151K->421389K(2944192K), 0.0425730 secs]
[GC 677517K->423130K(2944192K), 0.0493590 secs]
[GC 679258K->424772K(2944192K), 0.0496230 secs]
[GC 680900K->426569K(2944192K), 0.0477920 secs]
[GC 682697K->428396K(2944192K), 0.0443930 secs]
[GC 684524K->423530K(2944192K), 0.0457080 secs]
[GC 679658K->431960K(2944192K), 0.0425090 secs]
[GC 688088K->440285K(2944192K), 0.0484220 secs]
[GC 696413K->450912K(2944192K), 0.0445260 secs]
[GC 707040K->439641K(2944192K), 0.0476490 secs]
[GC 695769K->461401K(2944192K), 0.0578520 secs]
[GC 717529K->465626K(2944192K), 0.0508110 secs]
[GC 721754K->484963K(2944192K), 0.0540980 secs]
[GC 741091K->466265K(2944192K), 0.0582870 secs]
[GC 722393K->493968K(2944192K), 0.0566130 secs]
[GC 750096K->496172K(2944192K), 0.0555070 secs]
[GC 752300K->502337K(2944192K), 0.0558020 secs]
[GC 758465K->478061K(2944192K), 0.0579390 secs]
[GC 734189K->499467K(2944192K), 0.0500090 secs]
[GC 755595K->508866K(2944192K), 0.0573350 secs]
[GC 764994K->484597K(2944192K), 0.0582990 secs]
[GC 740725K->519707K(2944192K), 0.0578700 secs]
[GC 775835K->488418K(2944192K), 0.0588530 secs]
[GC 744546K->513989K(2944192K), 0.0587260 secs]
[GC 770117K->496192K(2944192K), 0.0566350 secs]
[GC 752320K->486524K(2944192K), 0.0533720 secs]
[GC 742652K->489086K(2944192K), 0.0541310 secs]
[GC 745214K->502865K(2944192K), 0.0597040 secs]
[GC 758993K->504153K(2944192K), 0.0600260 secs]
[GC 760281K->505784K(2944192K), 0.0773890 secs]
[GC 761912K->512234K(2944192K), 0.0564150 secs]
[GC 768362K->503649K(2944192K), 0.0592040 secs]
[GC 759777K->513144K(2944192K), 0.0448180 secs]
[GC 769272K->515035K(2944192K), 0.0514890 secs]
[GC 771163K->524914K(2944192K), 0.0435060 secs]
[GC 781042K->511300K(2944192K), 0.0437330 secs]
[GC 767428K->523947K(2944192K), 0.0912100 secs]
[GC 780075K->522270K(2944192K), 0.0525310 secs]
[GC 778398K->525228K(2944192K), 0.0521220 secs]
[GC 781356K->527590K(2944192K), 0.0550850 secs]
[GC 783718K->529727K(2944192K), 0.0563570 secs]
[GC 785855K->523950K(2944192K), 0.0573450 secs]
[GC 780078K->533951K(2944192K), 0.0521290 secs]
[GC 790079K->536150K(2944192K), 0.0570370 secs]
[GC 792278K->538120K(2944192K), 0.0480560 secs]
[GC 794248K->540247K(2944192K), 0.0437820 secs]
[GC 796375K->542335K(2944192K), 0.0458410 secs]
[GC 798463K->544545K(2944192K), 0.0433960 secs]
[GC 800673K->546602K(2944192K), 0.0450100 secs]
[GC 802730K->548964K(2944192K), 0.0438280 secs]
[GC 805092K->558989K(2944192K), 0.0582990 secs]
[GC 815117K->545243K(2944192K), 0.0446250 secs]
[GC 801371K->565239K(2944192K), 0.0474640 secs]
[GC 821367K->548020K(2944192K), 0.0519510 secs]
[GC 804148K->569103K(2944192K), 0.0531570 secs]
[GC 825231K->552173K(2944192K), 0.0447490 secs]
[GC 808301K->573374K(2944192K), 0.0514150 secs]
[GC 829502K->556441K(2944192K), 0.0461550 secs]
[GC 812569K->579801K(2944192K), 0.0594020 secs]
[GC 835929K->585304K(2944192K), 0.0603990 secs]
[GC 841432K->596195K(2944192K), 0.0649160 secs]
[GC 852323K->617709K(2944192K), 0.0615860 secs]
[GC 873837K->589605K(2944192K), 0.0624070 secs]
[GC 845733K->629132K(2944192K), 0.0608550 secs]
[GC 885260K->601339K(2944192K), 0.0641380 secs]
[GC 857467K->641445K(2944192K), 0.0626620 secs]
[GC 897573K->608425K(2944192K), 0.0611840 secs]
[GC 864553K->634687K(2944192K), 0.0635160 secs]
[GC 890815K->646116K(2944192K), 0.0648790 secs]
[GC 902244K->619624K(2944192K), 0.0632390 secs]
[GC 875752K->659437K(2944192K), 0.0684670 secs]
[GC 915565K->623261K(2944192K), 0.0667130 secs]
[GC 879389K->666997K(2944192K), 0.0690290 secs]
[GC 923125K->633610K(2944192K), 0.0663130 secs]
[GC 889738K->645804K(2944192K), 0.0651840 secs]
[GC 901932K->669038K(2944192K), 0.0656090 secs]
[GC 925166K->647828K(2944192K), 0.0721130 secs]
[GC 903956K->690967K(2944192K), 0.0735030 secs]
[GC 947095K->662160K(2944192K), 0.0764210 secs]
[GC 918288K->702855K(2944192K), 0.0759600 secs]
[GC 958983K->692597K(2944192K), 0.0787080 secs]
[GC 948725K->716828K(2944192K), 0.0684240 secs]
[GC 972956K->686028K(2944192K), 0.0659540 secs]
[GC 942156K->729194K(2944192K), 0.0681250 secs]
[GC 985322K->690378K(2944192K), 0.0663530 secs]
[GC 946506K->720892K(2944192K), 0.0705740 secs]
[GC 977020K->703020K(2944192K), 0.0673220 secs]
[GC 955916K->748375K(2944192K), 0.0663730 secs]
[GC 1004503K->711921K(2944192K), 0.0756590 secs]
[GC 968049K->762593K(2944192K), 0.0781280 secs]
[GC 1018721K->732079K(2944192K), 0.0767630 secs]
[GC 988207K->785723K(2944192K), 0.0747560 secs]
[GC 1041851K->761828K(2944192K), 0.0896220 secs]
[GC 1017956K->803742K(2944192K), 0.0892350 secs]
[GC 1059870K->801470K(2944192K), 0.0846060 secs]
[GC 1057598K->842911K(2944192K), 0.0806330 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5709 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5709 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5709 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 62 ms.
[GC 1099039K->869537K(2944192K), 0.0915280 secs]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5713] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5711] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5710] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5711] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5715] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5714] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_2_dev.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5716 [dev] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5716 [dev] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5716 [dev] Hazelcast Shutdown is completed in 466 ms.
