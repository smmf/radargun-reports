/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-14301 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-14301
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0992140 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@2ca44b35
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 36727 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 54834 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 39592 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 39449 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 36012 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 51802 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-12] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 34591 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 45135 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5712, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 60000 accepted socket connection from /127.0.0.1:5712
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 37033 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 56014 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:51841
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:51841
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:53704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-6] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:53704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:48991
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:48991
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:41484
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:36982
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:36982
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:41484
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 is accepting socket connection from /127.0.0.1:33144
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:33144
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 4
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
[GC 259695K->12022K(2944064K), 0.0406180 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-9173|2] [deimos-esw-9173, deimos-esw-26046, deimos-esw-8763, deimos-esw-28665, deimos-esw-26249]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-26249, physical addresses are [127.0.0.1:52004]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-26249] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-9173|3] [deimos-esw-9173, deimos-esw-26046, deimos-esw-8763, deimos-esw-28665, deimos-esw-26249, deimos-esw-15159]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-26249] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-9173|4] [deimos-esw-9173, deimos-esw-26046, deimos-esw-8763, deimos-esw-28665, deimos-esw-26249, deimos-esw-15159, deimos-esw-44871]
 INFO  [Incoming-4,deimos-esw-26249] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-9173|5] [deimos-esw-9173, deimos-esw-26046, deimos-esw-8763, deimos-esw-28665, deimos-esw-26249, deimos-esw-15159, deimos-esw-44871, deimos-esw-60986, deimos-esw-35120]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-26249] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-9173|6] [deimos-esw-9173, deimos-esw-26046, deimos-esw-8763, deimos-esw-28665, deimos-esw-26249, deimos-esw-15159, deimos-esw-44871, deimos-esw-60986, deimos-esw-35120, deimos-esw-64729, deimos-esw-3980, deimos-esw-24965]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 4, serverOidBase: 4000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@857e3fa
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 2
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@857e3fa, nodeIndex=5, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268086K->21189K(2944064K), 0.0557680 secs]
[GC 277253K->18302K(2944064K), 0.0373440 secs]
[GC 274366K->19932K(2944064K), 0.0369900 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 275996K->22120K(2944064K), 0.0371870 secs]
[GC 278184K->24823K(2944064K), 0.0381850 secs]
[GC 280887K->29640K(2944064K), 0.0431390 secs]
[GC 285704K->35765K(2944064K), 0.0413370 secs]
[GC 291829K->42109K(2944064K), 0.0439590 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 26450. Elapsed time: 20.007 secs. Remaining: 39.993 secs. Total: 1 mins 0 secs
[GC 298173K->49988K(2944064K), 0.0452580 secs]
[GC 306052K->58325K(2944064K), 0.0632210 secs]
[GC 314389K->58302K(2944064K), 0.0465880 secs]
[GC 314366K->64632K(2944064K), 0.0500000 secs]
[GC 320696K->72065K(2944064K), 0.0553120 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 65350. Elapsed time: 40.022 secs. Remaining: 19.978 secs. Total: 1 mins 0 secs
[GC 328129K->72040K(2944064K), 0.0526330 secs]
[GC 328104K->85251K(2944064K), 0.0649270 secs]
[GC 341315K->95300K(2944064K), 0.0631610 secs]
[GC 351364K->87083K(2944064K), 0.0516000 secs]
[GC 343147K->85758K(2944064K), 0.0492680 secs]
[GC 341822K->81993K(2944064K), 0.0498870 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 105850. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 17 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 77 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 338057K->72538K(2944064K), 0.0462580 secs]
[GC 328602K->77346K(2944064K), 0.0480730 secs]
[GC 333410K->79249K(2944064K), 0.0451480 secs]
[GC 335313K->80492K(2944064K), 0.0479700 secs]
[GC 336556K->82047K(2944064K), 0.0443240 secs]
[GC 338111K->84226K(2944064K), 0.0446130 secs]
[GC 340290K->86966K(2944064K), 0.0466570 secs]
[GC 343030K->87342K(2944064K), 0.0437360 secs]
[GC 343406K->95931K(2944064K), 0.0435790 secs]
[GC 351995K->86014K(2944064K), 0.0514660 secs]
[GC 342078K->98112K(2944064K), 0.0476610 secs]
[GC 354176K->107415K(2944064K), 0.0501090 secs]
[GC 363479K->114344K(2944064K), 0.0500060 secs]
[GC 370408K->120118K(2944064K), 0.0477800 secs]
[GC 376182K->102905K(2944064K), 0.0490260 secs]
[GC 358969K->123246K(2944064K), 0.0527700 secs]
[GC 379310K->134073K(2944064K), 0.0563020 secs]
[GC 390137K->159651K(2944064K), 0.0605270 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,569,650 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 374413K->130372K(2944064K), 0.6626070 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,812,659 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=1000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@857e3fa, nodeIndex=5, useTransactions=true, transactionSize=1000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 386500K->195500K(2944192K), 0.0310620 secs]
[GC 451628K->147140K(2944192K), 0.0270740 secs]
[GC 403268K->138327K(2944192K), 0.0309260 secs]
[GC 394455K->141139K(2944192K), 0.0341410 secs]
[GC 397267K->143914K(2944192K), 0.0314760 secs]
[GC 400042K->146856K(2944192K), 0.0353930 secs]
[GC 402984K->149887K(2944192K), 0.0355850 secs]
[GC 406015K->153022K(2944192K), 0.0448150 secs]
[GC 409150K->156202K(2944192K), 0.0454930 secs]
[GC 412330K->155554K(2944192K), 0.0369450 secs]
[GC 411682K->158754K(2944192K), 0.0543370 secs]
[GC 414882K->161731K(2944192K), 0.0532390 secs]
[GC 417859K->164694K(2944192K), 0.0553600 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 420822K->167728K(2944192K), 0.0551540 secs]
[GC 423856K->187974K(2944192K), 0.0516770 secs]
[GC 444102K->199057K(2944192K), 0.0648720 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 455185K->202691K(2944192K), 0.0461400 secs]
[GC 458819K->219089K(2944192K), 0.0479780 secs]
[GC 475217K->235299K(2944192K), 0.0520840 secs]
[GC 491399K->247191K(2944192K), 0.0550220 secs]
[GC 503319K->226068K(2944192K), 0.0463690 secs]
[GC 482196K->240788K(2944192K), 0.0435810 secs]
[GC 496802K->254635K(2944192K), 0.0569720 secs]
[GC 510763K->267410K(2944192K), 0.0482710 secs]
[GC 523538K->266294K(2944192K), 0.0520130 secs]
[GC 522422K->264514K(2944192K), 0.0475800 secs]
[GC 520642K->272795K(2944192K), 0.0676270 secs]
[GC 528923K->255020K(2944192K), 0.0408620 secs]
[GC 511148K->277336K(2944192K), 0.0496340 secs]
[GC 533464K->279994K(2944192K), 0.0440740 secs]
[GC 536094K->283470K(2944192K), 0.0405900 secs]
[GC 539598K->294709K(2944192K), 0.0522530 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 9422924. Elapsed time: 20.051 secs. Remaining: 39.949 secs. Total: 1 mins 0 secs
[GC 550837K->302190K(2944192K), 0.0536060 secs]
[GC 558318K->294133K(2944192K), 0.0465350 secs]
[GC 550261K->297284K(2944192K), 0.0520950 secs]
[GC 553412K->313564K(2944192K), 0.0432050 secs]
[GC 569692K->310569K(2944192K), 0.0465880 secs]
[GC 566697K->314775K(2944192K), 0.0482050 secs]
[GC 570903K->314087K(2944192K), 0.0440150 secs]
[GC 570215K->324114K(2944192K), 0.0559940 secs]
[GC 580242K->327396K(2944192K), 0.0438000 secs]
[GC 583524K->343243K(2944192K), 0.0440520 secs]
[GC 599371K->336879K(2944192K), 0.0446220 secs]
[GC 593007K->338044K(2944192K), 0.0416690 secs]
[GC 594172K->349523K(2944192K), 0.0477000 secs]
[GC 605651K->342337K(2944192K), 0.0422640 secs]
[GC 598465K->341469K(2944192K), 0.0463740 secs]
[GC 597597K->353818K(2944192K), 0.0527710 secs]
[GC 609910K->358922K(2944192K), 0.0510290 secs]
[GC 615050K->346215K(2944192K), 0.0426000 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 18703000. Elapsed time: 40.108 secs. Remaining: 19.892 secs. Total: 1 mins 0 secs
[GC 602343K->366976K(2944192K), 0.0481300 secs]
[GC 623104K->384433K(2944192K), 0.0468220 secs]
[GC 640561K->364360K(2944192K), 0.0402390 secs]
[GC 620488K->354184K(2944192K), 0.0397710 secs]
[GC 610129K->360452K(2944192K), 0.0490560 secs]
[GC 616580K->382057K(2944192K), 0.0525900 secs]
[GC 637845K->378022K(2944192K), 0.0489160 secs]
[GC 634150K->373087K(2944192K), 0.0455130 secs]
[GC 629215K->379007K(2944192K), 0.0532530 secs]
[GC 635135K->385368K(2944192K), 0.0459490 secs]
[GC 641496K->381826K(2944192K), 0.0497300 secs]
[GC 637954K->405601K(2944192K), 0.0541280 secs]
[GC 661729K->399894K(2944192K), 0.0461090 secs]
[GC 656022K->400808K(2944192K), 0.0495670 secs]
[GC 656936K->403470K(2944192K), 0.0478800 secs]
[GC 659598K->399609K(2944192K), 0.0466220 secs]
[GC 655722K->392620K(2944192K), 0.0417430 secs]
[GC 648748K->408490K(2944192K), 0.0510500 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 27457000. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 56 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=1 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 664618K->400269K(2944192K), 0.0492970 secs]
[GC 656391K->383232K(2944192K), 0.0458280 secs]
[GC 639360K->422065K(2944192K), 0.0476910 secs]
[GC 678193K->409130K(2944192K), 0.0551290 secs]
[GC 665258K->437300K(2944192K), 0.0581740 secs]
[GC 693428K->461609K(2944192K), 0.0620880 secs]
[GC 717737K->433261K(2944192K), 0.0711750 secs]
[GC 689354K->467744K(2944192K), 0.0677660 secs]
[GC 723872K->464203K(2944192K), 0.0680170 secs]
[GC 720331K->492326K(2944192K), 0.0663860 secs]
[GC 748454K->467073K(2944192K), 0.0730960 secs]
[GC 723031K->514042K(2944192K), 0.0716800 secs]
[GC 770170K->479967K(2944192K), 0.0729270 secs]
[GC 736095K->530644K(2944192K), 0.0732050 secs]
[GC 786772K->496406K(2944192K), 0.0722750 secs]
[GC 752534K->531095K(2944192K), 0.0736540 secs]
[GC 787223K->547942K(2944192K), 0.0684980 secs]
[GC 804070K->523530K(2944192K), 0.0719840 secs]
[GC 779658K->535261K(2944192K), 0.0622080 secs]
[GC 791389K->534584K(2944192K), 0.0541580 secs]
[GC 790712K->535836K(2944192K), 0.0557980 secs]
[GC 791964K->537284K(2944192K), 0.0631990 secs]
[GC 793412K->538830K(2944192K), 0.0658170 secs]
[GC 794958K->524777K(2944192K), 0.0641710 secs]
[GC 780905K->534838K(2944192K), 0.0726270 secs]
[GC 790966K->528343K(2944192K), 0.0638760 secs]
[GC 784471K->542456K(2944192K), 0.0621770 secs]
[GC 798584K->551257K(2944192K), 0.0679430 secs]
[GC 807385K->540063K(2944192K), 0.0574710 secs]
[GC 796191K->521556K(2944192K), 0.0565810 secs]
[GC 777684K->527439K(2944192K), 0.0536970 secs]
[GC 783567K->530116K(2944192K), 0.0494640 secs]
[GC 786244K->529794K(2944192K), 0.0473930 secs]
[GC 785922K->524425K(2944192K), 0.0407900 secs]
[GC 780553K->528501K(2944192K), 0.0418660 secs]
[GC 784629K->533670K(2944192K), 0.0383850 secs]
[GC 789798K->534908K(2944192K), 0.0404690 secs]
[GC 791036K->536121K(2944192K), 0.0438870 secs]
[GC 792249K->537295K(2944192K), 0.0385890 secs]
[GC 793423K->533937K(2944192K), 0.0444730 secs]
[GC 790065K->539418K(2944192K), 0.0392640 secs]
[GC 795546K->540589K(2944192K), 0.0366150 secs]
[GC 796717K->537391K(2944192K), 0.0448060 secs]
[GC 793519K->543099K(2944192K), 0.0393320 secs]
[GC 799227K->539881K(2944192K), 0.0399300 secs]
[GC 796009K->540975K(2944192K), 0.0378970 secs]
[GC 797103K->542022K(2944192K), 0.0390290 secs]
[GC 798150K->543272K(2944192K), 0.0393470 secs]
[GC 799400K->549125K(2944192K), 0.0404600 secs]
[GC 805253K->550518K(2944192K), 0.0390490 secs]
[GC 806646K->560810K(2944192K), 0.0432620 secs]
[GC 816938K->566139K(2944192K), 0.0454470 secs]
[GC 822267K->581504K(2944192K), 0.0489490 secs]
[GC 837478K->593246K(2944192K), 0.0528080 secs]
[GC 849346K->609229K(2944192K), 0.0603620 secs]
[GC 865357K->624224K(2944192K), 0.0612090 secs]
[GC 880352K->604833K(2944192K), 0.0611100 secs]
[GC 860961K->643024K(2944192K), 0.0672090 secs]
[GC 899152K->666100K(2944192K), 0.0789570 secs]
[GC 922228K->635966K(2944192K), 0.0802010 secs]
[GC 892094K->675364K(2944192K), 0.0830840 secs]
[GC 931492K->652165K(2944192K), 0.0708830 secs]
[GC 908293K->700676K(2944192K), 0.0730080 secs]
[GC 956804K->668386K(2944192K), 0.0743410 secs]
[GC 924472K->720014K(2944192K), 0.0801750 secs]
[GC 976142K->695876K(2944192K), 0.0863680 secs]
[GC 951982K->737198K(2944192K), 0.0767860 secs]
[GC 993326K->706591K(2944192K), 0.0706190 secs]
[GC 962719K->756500K(2944192K), 0.0721440 secs]
[GC 1012628K->727276K(2944192K), 0.0737400 secs]
[GC 983404K->781139K(2944192K), 0.0772120 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1037267K->751321K(2944192K), 0.0782900 secs]
[GC 1007449K->803935K(2944192K), 0.0718830 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5706 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1060005K->772377K(2944192K), 0.0766520 secs]
[GC 1028505K->824670K(2944192K), 0.0773470 secs]
[GC 1080798K->792435K(2944192K), 0.0738800 secs]
[GC 1048563K->844876K(2944192K), 0.0755690 secs]
[GC 1101004K->812626K(2944192K), 0.0738160 secs]
[GC 1068754K->850816K(2944192K), 0.0775610 secs]
[GC 1106944K->871040K(2944192K), 0.0750250 secs]
[GC 1127168K->848730K(2944192K), 0.0758440 secs]
[GC 1104808K->897543K(2944192K), 0.0810720 secs]
[GC 1153614K->879297K(2944192K), 0.0867330 secs]
[GC 1135425K->925053K(2944192K), 0.0765810 secs]
[GC 1181181K->896488K(2944192K), 0.0789290 secs]
[GC 1152616K->953690K(2944192K), 0.0781910 secs]
[GC 1209818K->922190K(2944192K), 0.0789760 secs]
[GC 1178318K->978355K(2944192K), 0.0769360 secs]
[GC 1234408K->949576K(2944192K), 0.0772410 secs]
[GC 1205704K->1002608K(2944192K), 0.0766590 secs]
[GC 1258691K->973602K(2944192K), 0.0775830 secs]
[GC 1229728K->1028789K(2944192K), 0.0791500 secs]
[GC 1284892K->1002014K(2944192K), 0.0790370 secs]
[GC 1258142K->1007262K(2944192K), 0.0929410 secs]
[GC 1263390K->1067077K(2944192K), 0.0812840 secs]
[GC 1323205K->1047717K(2944192K), 0.0774210 secs]
[GC 1303845K->1105249K(2944192K), 0.0836560 secs]
[GC 1361377K->1081236K(2944192K), 0.0817770 secs]
[GC 1337364K->1141191K(2944192K), 0.0849120 secs]
[GC 1397296K->1113884K(2944192K), 0.0776510 secs]
[GC 1370012K->1171818K(2944192K), 0.0860740 secs]
[GC 1427935K->1147764K(2944192K), 0.0856120 secs]
[GC 1403871K->1203489K(2944192K), 0.0917160 secs]
[GC 1459617K->1220027K(2944192K), 0.1014500 secs]
[GC 1476144K->1207298K(2944192K), 0.1172410 secs]
[GC 1463426K->1217008K(2944192K), 0.0944040 secs]
[GC 1473136K->1251118K(2944192K), 0.0905690 secs]
[GC 1507246K->1267184K(2944192K), 0.0848940 secs]
[GC 1523312K->1312419K(2944192K), 0.0715900 secs]
[GC 1568545K->1332750K(2944192K), 0.0895140 secs]
[GC 1588878K->1351000K(2944192K), 0.0935630 secs]
[GC 1607032K->1369035K(2944192K), 0.0891260 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 54 ms.
