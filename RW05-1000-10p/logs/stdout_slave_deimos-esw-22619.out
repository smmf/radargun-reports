/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-22619 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-22619
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0775900 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 12 slaves. This is the slave with index 4. Sleeping for 7000 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 4
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@3fbefe6e
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5705, using socket ServerSocket[addr=/0.0.0.0,localport=5705], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Community Edition 3.0-RC1 (20130627) starting at Address[127.0.0.1]:5705
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5705 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 53218 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 53131 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 49225 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5705 [FenixFrameworkGroup] 

Members [12] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705 this
	Member [127.0.0.1]:5706
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
	Member [127.0.0.1]:5711
	Member [127.0.0.1]:5712
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:49374
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-13] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:49374
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:43230
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:43230
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:57762
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:57762
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:45733
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 49685 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:45733
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5711, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 41650 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5705 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:56845
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:56845
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 50810 accepted socket connection from /127.0.0.1:5711
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-4] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 45284 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-11] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 45196 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:54429
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 is accepting socket connection from /127.0.0.1:43087
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:54429
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5705 [FenixFrameworkGroup] 5705 accepted socket connection from /127.0.0.1:43087
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5705 [FenixFrameworkGroup] Address[127.0.0.1]:5705 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 3
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=4, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 4
[GC 259695K->12244K(2944064K), 0.0411580 secs]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57502|2] [deimos-esw-57502, deimos-esw-147, deimos-esw-11955, deimos-esw-58664]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-58664, physical addresses are [127.0.0.1:52003]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-58664] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57502|3] [deimos-esw-57502, deimos-esw-147, deimos-esw-11955, deimos-esw-58664, deimos-esw-60366, deimos-esw-48750]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-58664] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57502|4] [deimos-esw-57502, deimos-esw-147, deimos-esw-11955, deimos-esw-58664, deimos-esw-60366, deimos-esw-48750, deimos-esw-54339, deimos-esw-5135, deimos-esw-53687]
 INFO  [Incoming-4,deimos-esw-58664] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57502|5] [deimos-esw-57502, deimos-esw-147, deimos-esw-11955, deimos-esw-58664, deimos-esw-60366, deimos-esw-48750, deimos-esw-54339, deimos-esw-5135, deimos-esw-53687, deimos-esw-55651]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [Incoming-4,deimos-esw-58664] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-57502|6] [deimos-esw-57502, deimos-esw-147, deimos-esw-11955, deimos-esw-58664, deimos-esw-60366, deimos-esw-48750, deimos-esw-54339, deimos-esw-5135, deimos-esw-53687, deimos-esw-55651, deimos-esw-34697, deimos-esw-34065]
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 3, serverOidBase: 3000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 12
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 4: org.radargun.cachewrappers.FFWrapper@676c00a9
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 2
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 11
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=100, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@676c00a9, nodeIndex=4, useTransactions=true, transactionSize=50, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 268308K->20431K(2944064K), 0.0523600 secs]
[GC 276495K->18455K(2944064K), 0.0359830 secs]
[GC 274519K->17640K(2944064K), 0.0366400 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 273704K->22193K(2944064K), 0.0370340 secs]
[GC 278257K->30142K(2944064K), 0.0372310 secs]
[GC 286206K->32743K(2944064K), 0.0418800 secs]
[GC 288807K->39128K(2944064K), 0.0441130 secs]
[GC 295192K->47687K(2944064K), 0.0441940 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 25500. Elapsed time: 20.015 secs. Remaining: 39.985 secs. Total: 1 mins 0 secs
[GC 303751K->56183K(2944064K), 0.0459040 secs]
[GC 312247K->66053K(2944064K), 0.0491250 secs]
[GC 322117K->66809K(2944064K), 0.0473290 secs]
[GC 322873K->72491K(2944064K), 0.0465970 secs]
[GC 328555K->80766K(2944064K), 0.0506490 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 68150. Elapsed time: 40.050 secs. Remaining: 19.950 secs. Total: 1 mins 0 secs
[GC 336803K->80413K(2944064K), 0.0526370 secs]
[GC 336477K->94813K(2944064K), 0.0611120 secs]
[GC 350877K->106465K(2944064K), 0.0564980 secs]
[GC 362529K->81139K(2944064K), 0.0509150 secs]
[GC 337203K->83491K(2944064K), 0.0473200 secs]
[GC 339555K->84687K(2944064K), 0.0465680 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 124350. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 15 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 75 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=100, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=100, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=50, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 340751K->94825K(2944064K), 0.0492690 secs]
[GC 350889K->87049K(2944064K), 0.0483480 secs]
[GC 343113K->75270K(2944064K), 0.0489800 secs]
[GC 331334K->90650K(2944064K), 0.0483670 secs]
[GC 346714K->88748K(2944064K), 0.0490580 secs]
[GC 344812K->89797K(2944064K), 0.0478800 secs]
[GC 345854K->80865K(2944064K), 0.0487650 secs]
[GC 336929K->87664K(2944064K), 0.0496940 secs]
[GC 343728K->89771K(2944064K), 0.0499070 secs]
[GC 345835K->103433K(2944064K), 0.0495370 secs]
[GC 359497K->88026K(2944064K), 0.0538400 secs]
[GC 344090K->106940K(2944064K), 0.0507290 secs]
[GC 363004K->117394K(2944064K), 0.0510430 secs]
[GC 373458K->124131K(2944064K), 0.0521140 secs]
[GC 380195K->113725K(2944064K), 0.0499380 secs]
[GC 369789K->128070K(2944064K), 0.0576890 secs]
[GC 384121K->137349K(2944064K), 0.0515490 secs]
[GC 393413K->133156K(2944064K), 0.0552710 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 2,612,061 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 332002K->126075K(2944064K), 0.6491770 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 2,816,879 kb - max:4,906,688 kb- total:2,944,192 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=1000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@676c00a9, nodeIndex=4, useTransactions=true, transactionSize=1000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 382203K->186877K(2944192K), 0.0306090 secs]
[GC 443005K->141800K(2944192K), 0.0314380 secs]
[GC 397928K->136348K(2944192K), 0.0270850 secs]
[GC 392476K->138929K(2944192K), 0.0299650 secs]
[GC 395057K->140487K(2944192K), 0.0314750 secs]
[GC 396615K->144046K(2944192K), 0.0324980 secs]
[GC 400174K->148307K(2944192K), 0.0336640 secs]
[GC 404435K->148384K(2944192K), 0.0329650 secs]
[GC 404512K->151480K(2944192K), 0.0357460 secs]
[GC 407608K->154558K(2944192K), 0.0390470 secs]
[GC 410686K->157813K(2944192K), 0.0362100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 413932K->178726K(2944192K), 0.0464690 secs]
[GC 434813K->200296K(2944192K), 0.0457980 secs]
[GC 456424K->225693K(2944192K), 0.0562610 secs]
[GC 481804K->239705K(2944192K), 0.0684980 secs]
[GC 495833K->232379K(2944192K), 0.0443320 secs]
[GC 488203K->242559K(2944192K), 0.0485800 secs]
[GC 498687K->251041K(2944192K), 0.0710430 secs]
[GC 507169K->248585K(2944192K), 0.0444760 secs]
[GC 504674K->244236K(2944192K), 0.0453750 secs]
[GC 500327K->266653K(2944192K), 0.0575210 secs]
[GC 522761K->234481K(2944192K), 0.0406580 secs]
[GC 490609K->264950K(2944192K), 0.0429750 secs]
[GC 521078K->279399K(2944192K), 0.0524730 secs]
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 2306453. Elapsed time: 20.000 secs. Remaining: 40.000 secs. Total: 1 mins 0 secs
[GC 535527K->257765K(2944192K), 0.0436840 secs]
[GC 513893K->269255K(2944192K), 0.0483370 secs]
[GC 525382K->297446K(2944192K), 0.0584090 secs]
[GC 553469K->261743K(2944192K), 0.0419620 secs]
[GC 517871K->279867K(2944192K), 0.0443030 secs]
[GC 535995K->301531K(2944192K), 0.0510110 secs]
[GC 557659K->317164K(2944192K), 0.0459620 secs]
[GC 573292K->323758K(2944192K), 0.0600710 secs]
[GC 579886K->287518K(2944192K), 0.0418130 secs]
[GC 543646K->304590K(2944192K), 0.0467310 secs]
[GC 560600K->332833K(2944192K), 0.0560610 secs]
[GC 588961K->298416K(2944192K), 0.0379010 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 4921793. Elapsed time: 40.000 secs. Remaining: 20.000 secs. Total: 1 mins 0 secs
[GC 554544K->313668K(2944192K), 0.0478300 secs]
[GC 569796K->321899K(2944192K), 0.0541330 secs]
[GC 578027K->329608K(2944192K), 0.0425350 secs]
[GC 585736K->336448K(2944192K), 0.0448100 secs]
[GC 592576K->354301K(2944192K), 0.0567020 secs]
[GC 610429K->331427K(2944192K), 0.0478270 secs]
[GC 587385K->355810K(2944192K), 0.0502940 secs]
[GC 611899K->375994K(2944192K), 0.0677340 secs]
[GC 631932K->327800K(2944192K), 0.0493570 secs]
[GC 583928K->359821K(2944192K), 0.0500500 secs]
[GC 615949K->386562K(2944192K), 0.0656840 secs]
[GC 642527K->379659K(2944192K), 0.0507280 secs]
[GC 635787K->398264K(2944192K), 0.0644000 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 6736586. Elapsed time: 1 mins 0 secs. Remaining: 0.000 secs. Total: 1 mins 0 secs
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 1 mins 46 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:12, nodeIndex:4, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=5 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 654392K->374329K(2944192K), 0.0434560 secs]
[GC 630457K->365720K(2944192K), 0.0411940 secs]
[GC 621848K->344139K(2944192K), 0.0440930 secs]
[GC 600267K->381005K(2944192K), 0.0482480 secs]
[GC 637133K->370034K(2944192K), 0.0498250 secs]
[GC 626134K->400628K(2944192K), 0.0533000 secs]
[GC 656756K->403294K(2944192K), 0.0630340 secs]
[GC 659422K->420414K(2944192K), 0.0673180 secs]
[GC 676542K->425110K(2944192K), 0.0659220 secs]
[GC 681238K->438561K(2944192K), 0.0683410 secs]
[GC 694689K->449895K(2944192K), 0.0683160 secs]
[GC 706023K->459199K(2944192K), 0.0674910 secs]
[GC 715327K->486518K(2944192K), 0.0706310 secs]
[GC 742646K->460622K(2944192K), 0.0675020 secs]
[GC 716750K->495060K(2944192K), 0.0691990 secs]
[GC 751188K->512658K(2944192K), 0.0690560 secs]
[GC 768786K->487747K(2944192K), 0.0645530 secs]
[GC 743875K->523177K(2944192K), 0.0708730 secs]
[GC 779305K->523369K(2944192K), 0.0669530 secs]
[GC 779497K->534799K(2944192K), 0.0702780 secs]
[GC 790927K->544377K(2944192K), 0.0652220 secs]
[GC 800339K->555392K(2944192K), 0.0757880 secs]
[GC 811520K->529627K(2944192K), 0.0693620 secs]
[GC 785755K->534041K(2944192K), 0.0583730 secs]
[GC 790169K->541147K(2944192K), 0.0489310 secs]
[GC 797275K->568969K(2944192K), 0.0484820 secs]
[GC 825097K->540544K(2944192K), 0.0498710 secs]
[GC 796672K->576190K(2944192K), 0.0529910 secs]
[GC 832318K->540694K(2944192K), 0.0543830 secs]
[GC 796822K->579621K(2944192K), 0.0515080 secs]
[GC 835749K->543217K(2944192K), 0.0562600 secs]
[GC 799345K->549898K(2944192K), 0.0606580 secs]
[GC 806026K->577237K(2944192K), 0.0521750 secs]
[GC 833365K->558079K(2944192K), 0.0608120 secs]
[GC 814207K->542816K(2944192K), 0.0569480 secs]
[GC 798944K->549290K(2944192K), 0.0574820 secs]
[GC 805418K->555539K(2944192K), 0.0604580 secs]
[GC 811667K->550762K(2944192K), 0.0375150 secs]
[GC 806890K->546485K(2944192K), 0.0404430 secs]
[GC 802613K->548289K(2944192K), 0.0421160 secs]
[GC 804417K->549666K(2944192K), 0.0408680 secs]
[GC 805794K->555841K(2944192K), 0.0361930 secs]
[GC 811969K->552433K(2944192K), 0.0395250 secs]
[GC 808561K->553601K(2944192K), 0.0366980 secs]
[GC 809729K->564352K(2944192K), 0.0371820 secs]
[GC 820480K->556217K(2944192K), 0.0375030 secs]
[GC 812345K->569318K(2944192K), 0.0427550 secs]
[GC 825446K->581525K(2944192K), 0.0441160 secs]
[GC 837653K->593772K(2944192K), 0.0505610 secs]
[GC 849893K->606161K(2944192K), 0.0514620 secs]
[GC 862289K->618443K(2944192K), 0.0558950 secs]
[GC 874571K->635529K(2944192K), 0.0561130 secs]
[GC 891657K->652326K(2944192K), 0.0578720 secs]
[GC 908454K->628441K(2944192K), 0.0664830 secs]
[GC 884569K->680544K(2944192K), 0.0741740 secs]
[GC 936672K->643259K(2944192K), 0.0679570 secs]
[GC 899387K->699889K(2944192K), 0.0688620 secs]
[GC 956017K->662683K(2944192K), 0.0656450 secs]
[GC 918762K->709330K(2944192K), 0.0668020 secs]
[GC 965311K->677481K(2944192K), 0.0659820 secs]
[GC 933609K->712711K(2944192K), 0.0663970 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 968778K->713459K(2944192K), 0.0668160 secs]
[GC 969587K->722521K(2944192K), 0.0628330 secs]
[GC 978649K->729940K(2944192K), 0.0647150 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 986068K->720986K(2944192K), 0.0640100 secs]
[GC 977114K->750069K(2944192K), 0.0495780 secs]
[GC 1006197K->729377K(2944192K), 0.0590580 secs]
[GC 985505K->756729K(2944192K), 0.0521730 secs]
[GC 1012857K->720556K(2944192K), 0.0501160 secs]
[GC 976684K->759275K(2944192K), 0.0535580 secs]
 WARN  [hz._hzInstance_1_FenixFrameworkGroup.event] {com.hazelcast.spi.EventService} [127.0.0.1]:5705 [FenixFrameworkGroup] Caution: Off-load event processing to your own thread-pool, don't use event thread!
[GC 1015383K->723570K(2944192K), 0.0559670 secs]
[GC 979698K->780761K(2944192K), 0.0657100 secs]
[GC 1036865K->748795K(2944192K), 0.0686600 secs]
[GC 1004923K->794703K(2944192K), 0.0689940 secs]
[GC 1050823K->763570K(2944192K), 0.0583500 secs]
[GC 1019694K->788101K(2944192K), 0.0786350 secs]
[GC 1044229K->815782K(2944192K), 0.0731850 secs]
[GC 1071720K->790904K(2944192K), 0.0707030 secs]
[GC 1047032K->818918K(2944192K), 0.0778030 secs]
[GC 1075046K->821807K(2944192K), 0.0743800 secs]
[GC 1077935K->844709K(2944192K), 0.0664950 secs]
[GC 1100837K->872509K(2944192K), 0.0683660 secs]
[GC 1128637K->847350K(2944192K), 0.0719470 secs]
[GC 1103478K->898780K(2944192K), 0.0708070 secs]
[GC 1154908K->867714K(2944192K), 0.0727500 secs]
[GC 1123842K->918992K(2944192K), 0.0710640 secs]
[GC 1175120K->887388K(2944192K), 0.0734660 secs]
[GC 1143516K->921739K(2944192K), 0.0811030 secs]
[GC 1177867K->915548K(2944192K), 0.0683430 secs]
[GC 1171676K->941827K(2944192K), 0.0709430 secs]
[GC 1197955K->969322K(2944192K), 0.0677110 secs]
[GC 1225450K->985537K(2944192K), 0.0665700 secs]
[GC 1241665K->964067K(2944192K), 0.0710190 secs]
[GC 1220132K->1018838K(2944192K), 0.0734190 secs]
[GC 1274966K->991513K(2944192K), 0.0840750 secs]
[GC 1247638K->1034316K(2944192K), 0.0817200 secs]
[GC 1290444K->1040239K(2944192K), 0.0818470 secs]
[GC 1296367K->1030843K(2944192K), 0.0910110 secs]
[GC 1286926K->1053017K(2944192K), 0.0757830 secs]
[GC 1309145K->1081718K(2944192K), 0.0736420 secs]
[GC 1337833K->1095842K(2944192K), 0.0803040 secs]
[GC 1351970K->1127417K(2944192K), 0.0847170 secs]
[GC 1383545K->1109974K(2944192K), 0.0848180 secs]
[GC 1366102K->1155371K(2944192K), 0.0881770 secs]
[GC 1411499K->1178551K(2944192K), 0.0912980 secs]
[GC 1434465K->1181319K(2944192K), 0.0941940 secs]
[GC 1437447K->1203438K(2944192K), 0.0923960 secs]
[GC 1459566K->1225516K(2944192K), 0.0899680 secs]
[GC 1481644K->1243122K(2944192K), 0.0891570 secs]
[GC 1499133K->1241656K(2944192K), 0.0851220 secs]
[GC 1497784K->1278144K(2944192K), 0.0911450 secs]
[GC 1534272K->1292782K(2944192K), 0.0857780 secs]
[GC 1548910K->1309348K(2944192K), 0.0849630 secs]
[GC 1565476K->1326359K(2944192K), 0.0794820 secs]
[GC 1582487K->1356639K(2944192K), 0.0838810 secs]
[GC 1612767K->1341307K(2944192K), 0.1050350 secs]
[GC 1597435K->1384210K(2944192K), 0.0790930 secs]
[GC 1640338K->1392724K(2944192K), 0.0781570 secs]
[GC 1648852K->1425265K(2944192K), 0.0777070 secs]
[GC 1425971K(2944192K), 0.0443310 secs]
[GC 1681335K->1434031K(2944192K), 0.0830850 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5706] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-1] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5711] lost. Reason: Explicit close
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-0] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-in-2] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5712] lost. Reason: java.io.EOFException[Remote socket closed!]
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5705 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Explicit close
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5705 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5705 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 54 ms.
