/usr/java/jdk1.7.0_21/bin/java -server -Xmx1024M -Xms1024M -Dresolve.dns=false -Djgroups.timer.num_threads=4 -verbose:gc -Xmx5000M -Xms3000M -server -XX:+UseConcMarkSweepGC -XX:+AggressiveOpts -verbose:gc -XX:ParallelGCThreads=4 -XX:NewRatio=5 -XX:SurvivorRatio=2 -Dhazelcast.operation.thread.count=4 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=deimos-esw-363 -Dbind.address= -Djgroups.bind_addr= -classpath /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/activation-1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-beanutils-1.8.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-digester-2.0.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-logging-1.1.1.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/commons-math-1.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jcommon-1.0.15.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/jfreechart-1.0.12.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/log4j-1.2.14.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/mail-1.4.2.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar:/home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/conf org.radargun.Slave -master 127.0.0.1:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:deimos-esw-363
 INFO  [main] {org.radargun.Slave} Attempting to connect to master 127.0.0.1:2103
 INFO  [main] {org.radargun.Slave} Successfully established connection with master at: 127.0.0.1:2103
Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.config.AnnotatedHelper} Loading JARS from /home/smf/github/radargun/target/distribution/RadarGun-1.1.0-SNAPSHOT/lib/radargun-framework-1.1.0-SNAPSHOT.jar
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Received destroy cache wrapper request from master...
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} No cache wrapper deployed on this slave, nothing to do.
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} Before executing clear, memory looks like this: Memory - free: 2,928,638 kb - max:4,906,688 kb- total:2,944,000 kb
[Full GC 15361K->3631K(2944000K), 0.0779150 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.DestroyWrapperStage} After executing cleanup, memory looks like this: Memory - free: 2,935,311 kb - max:4,906,688 kb- total:2,944,064 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: DestroyWrapper {enforceMemoryThrashHold=true, exitBenchmarkOnSlaveFailure=false, heapDumpDir=null, memoryThreshold=95, runOnAllSlaves=true, slaves=null, useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage}  Startup staggering, starting 10 slaves. This is the slave with index 5. Sleeping for 7500 millis.
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Ack master's StartCluster stage. Local address is: /127.0.0.1. This slave's index is: 5
 INFO  [pool-1-thread-1] {org.radargun.utils.ClassLoadHelper} Creating newInstance org.radargun.cachewrappers.FFWrapper with classloader java.net.URLClassLoader@14320874
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml, decorate=infinispan52}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Found fenix framework config options in 'rg-fenix-framework-config-options.properties'.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Setting extra config properties for Fenix Framework.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} Will initialize Fenix Framework with RadarGunDataGridConfig
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [BEGIN]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Trying auto-initialization with configuration by convention
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading default config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} CurrentBackEndName = jvstm-datagrid
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Resource 'fenix-framework-jvstm-datagrid.properties' not found
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after reading backend config file:{}
 DEBUG [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Fenix Framework properties after enforcing system properties:{}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Skipping configuration by convention.
 TRACE [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Static initializer block for FenixFramework class [END]
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initializing Fenix Framework with config.class=pt.ist.fenixframework.backend.jvstm.datagrid.radargun.RadarGunDataGridConfig
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} initializeGroupCommunication()
 INFO  [pool-1-thread-1] {com.hazelcast.config.ClasspathXmlConfig} Configuring Hazelcast from 'hazelcast-ff.xml'.
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Interfaces is disabled, trying to pick one address from TCP-IP config addresses: [127.0.0.1]
 INFO  [pool-1-thread-1] {com.hazelcast.instance.DefaultAddressPicker} Picked Address[127.0.0.1]:5706, using socket ServerSocket[addr=/0.0.0.0,localport=5706], bind any local is true
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Community Edition 3.0.2 (20130906) starting at Address[127.0.0.1]:5706
 INFO  [pool-1-thread-1] {com.hazelcast.system} [127.0.0.1]:5706 [FenixFrameworkGroup] Copyright (C) 2008-2013 Hazelcast.com
 INFO  [pool-1-thread-1] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Creating MulticastJoiner
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTING
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5703
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5702
 INFO  [pool-1-thread-1] {com.hazelcast.cluster.TcpIpJoiner} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to possible member: Address[127.0.0.1]:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5703, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5701, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5702, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 53790 accepted socket connection from /127.0.0.1:5703
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 33917 accepted socket connection from /127.0.0.1:5701
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 54569 accepted socket connection from /127.0.0.1:5702
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-3] {com.hazelcast.cluster.ClusterService} [127.0.0.1]:5706 [FenixFrameworkGroup] 

Members [10] {
	Member [127.0.0.1]:5701
	Member [127.0.0.1]:5702
	Member [127.0.0.1]:5704
	Member [127.0.0.1]:5705
	Member [127.0.0.1]:5706 this
	Member [127.0.0.1]:5703
	Member [127.0.0.1]:5707
	Member [127.0.0.1]:5708
	Member [127.0.0.1]:5709
	Member [127.0.0.1]:5710
}

 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:50795
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:50795
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5704, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:46619
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 42675 accepted socket connection from /127.0.0.1:5704
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:46619
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5705, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5708, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5707, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:57397
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5710, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-9] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49982 accepted socket connection from /127.0.0.1:5707
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.SocketConnector} [127.0.0.1]:5706 [FenixFrameworkGroup] Connecting to /127.0.0.1:5709, timeout: 0, bind-any: true
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-8] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 49889 accepted socket connection from /127.0.0.1:5709
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-1] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 38588 accepted socket connection from /127.0.0.1:5708
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-2] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 50029 accepted socket connection from /127.0.0.1:5705
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:57397
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.cached.thread-7] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 52581 accepted socket connection from /127.0.0.1:5710
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:51434
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:51434
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.SocketAcceptor} [127.0.0.1]:5706 [FenixFrameworkGroup] Accepting socket connection from /127.0.0.1:41927
 INFO  [hz._hzInstance_1_FenixFrameworkGroup.IO.thread-Acceptor] {com.hazelcast.nio.TcpIpConnectionManager} [127.0.0.1]:5706 [FenixFrameworkGroup] 5706 accepted socket connection from /127.0.0.1:41927
 INFO  [pool-1-thread-1] {com.hazelcast.core.LifecycleService} [127.0.0.1]:5706 [FenixFrameworkGroup] Address[127.0.0.1]:5706 is STARTED
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Got (long) serverId: 5
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.JvstmClusterBackEnd} This is NOT the first node.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.cluster.ClusterUtils} Waiting for startup from first node
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeRepository()
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.radargun.DataGridDecorator} config=ispn52-repl-sync-rc.xml, isLocal=false, nodeIndex=5, confAttributes={name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Cannot find any site for slave index 5
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000078: Starting JGroups Channel
[GC 259695K->17483K(2944064K), 0.0515680 secs]
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket DatagramSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket DatagramSocket was set to 20MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the send buffer of socket MulticastSocket was set to 640KB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
 WARN  [pool-1-thread-1] {org.jgroups.protocols.UDP} [JGRP00014] the receive buffer of socket MulticastSocket was set to 25MB, but the OS only allocated 229.38KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-42853|4] [deimos-esw-42853, deimos-esw-11429, deimos-esw-30057, deimos-esw-24099, deimos-esw-49044, deimos-esw-18096]
 INFO  [pool-1-thread-1] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000079: Cache local address is deimos-esw-18096, physical addresses are [127.0.0.1:52005]
 INFO  [pool-1-thread-1] {org.infinispan.factories.GlobalComponentRegistry} ISPN000128: Infinispan version: Infinispan 'Delirium' 5.2.6.Final
 INFO  [Incoming-4,deimos-esw-18096] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-42853|5] [deimos-esw-42853, deimos-esw-11429, deimos-esw-30057, deimos-esw-24099, deimos-esw-49044, deimos-esw-18096, deimos-esw-50613, deimos-esw-7836]
 INFO  [pool-1-thread-1] {org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup} ISPN000107: Retrieving transaction manager Transaction: unknown
 INFO  [Incoming-4,deimos-esw-18096] {org.infinispan.remoting.transport.jgroups.JGroupsTransport} ISPN000094: Received new cluster view: [deimos-esw-42853|6] [deimos-esw-42853, deimos-esw-11429, deimos-esw-30057, deimos-esw-24099, deimos-esw-49044, deimos-esw-18096, deimos-esw-50613, deimos-esw-7836, deimos-esw-45827, deimos-esw-46441]
 INFO  [pool-1-thread-1] {org.infinispan.jmx.CacheJmxRegistration} ISPN000031: MBeans were successfully registered to the platform MBean server.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using transaction manager: Transaction: unknown
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} No RELAY2 protocol in XS wrapper
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} JGroups version: JGroups 3.2.7.Final
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.InfinispanXSWrapper} Using config attributes: {name=ispn52-repl-sync-rc.xml}
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.datagrid.DataGridRepository} Initialization marker is present. Data Grid already existed.
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} initializeDomainClassInfos
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} serverId: 5, serverOidBase: 5000000000000
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNodeArray' with id 'c'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNodeArray' with id 'a'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.DomainRoot' with id '0'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.ListNode' with id '6'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.TransactionStatisticsEntry' with id '5'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.linkedlist.LinkedList' with id '9'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.AbstractNode' with id 'f'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainLeafNode' with id '1'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTreeArray' with id '2'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNode' with id '8'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainBPlusTree' with id 'e'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.InnerNodeArray' with id 'b'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.backend.jvstm.pstm.FenixFrameworkData' with id 'd'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.DomainInnerNode' with id '3'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.LeafNode' with id '4'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.pstm.DomainClassInfo} Existing domain class 'pt.ist.fenixframework.adt.bplustree.BPlusTree' with id '7'
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} setupJVSTM
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} Setting the last committed TX number to 2
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} createDomainRootIfNeeded
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.backend.jvstm.JVSTMBackEnd} ensureFenixFrameworkDataExists
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.hibernatesearch.HibernateSearchConfig} Resource 'fenix-framework-hibernate-search.properties' not found. Hibernate Search disabled
 INFO  [pool-1-thread-1] {pt.ist.fenixframework.FenixFramework} Initialization of Fenix Framework is now complete.
 INFO  [pool-1-thread-1] {org.radargun.cachewrappers.FFWrapper} FF STARTED=true
 INFO  [pool-1-thread-1] {org.radargun.stages.helpers.StartHelper} Number of members is the one expected: 10
 INFO  [pool-1-thread-1] {org.radargun.stages.StartClusterStage} Successfully started cache wrapper on slave 5: org.radargun.cachewrappers.FFWrapper@5b0a7910
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StartCluster {config=ispn52-repl-sync-rc.xml, delayAfterFirstSlaveStarts=5.000 secs, delayBetweenStartingSlaves=0.500 secs, exitBenchmarkOnSlaveFailure=true, expectNumSlaves=null, mayFailOn=null, reachable=null, runOnAllSlaves=false, slaves=null, staggerSlaveStartup=true, useSmartClassLoading=true, validateCluster=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=null, useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 3
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test failed, 1 tries so far. Sleeping for 2 seconds and trying again.
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Number of caches that replicated here is 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Replication test successfully passed. partialReplication? false, replicationCount = 9
 INFO  [pool-1-thread-1] {org.radargun.stages.ClusterValidationStage} Confirm phase successful.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClusterValidation {exitBenchmarkOnSlaveFailure=false, partialReplication=false, replicationTimeSleep=2000, replicationTryCount=60, runOnAllSlaves=false, slaves=[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} Starting StressTestWarmupStage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=100000, numRequests=10000, numEntries=1000, entrySize=1000, writePercentage=20, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@5b0a7910, nodeIndex=5, useTransactions=true, transactionSize=1000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 273547K->20340K(2944064K), 0.0494270 secs]
[GC 276404K->22618K(2944064K), 0.0428710 secs]
[GC 278643K->38757K(2944064K), 0.0480360 secs]
[GC 294803K->57973K(2944064K), 0.0537780 secs]
[GC 314011K->89274K(2944064K), 0.0590420 secs]
[GC 345338K->109554K(2944064K), 0.0640200 secs]
[GC 365618K->115994K(2944064K), 0.1190890 secs]
[GC 371913K->118913K(2944064K), 0.0942290 secs]
[GC 374977K->161413K(2944064K), 0.0740930 secs]
[GC 417470K->174069K(2944064K), 0.0730760 secs]
[GC 430133K->189284K(2944064K), 0.0727050 secs]
[GC 445348K->205360K(2944064K), 0.0744530 secs]
[GC 461424K->222159K(2944064K), 0.0752310 secs]
[GC 478189K->221337K(2944064K), 0.0733590 secs]
[GC 477401K->253192K(2944064K), 0.0811480 secs]
[GC 509245K->268968K(2944064K), 0.0836360 secs]
[GC 525032K->284027K(2944064K), 0.0837370 secs]
[GC 540091K->300174K(2944064K), 0.0845390 secs]
[GC 556165K->315738K(2944064K), 0.0795530 secs]
[GC 571761K->349464K(2944064K), 0.0790830 secs]
[GC 605528K->335918K(2944064K), 0.0875240 secs]
[GC 591925K->367377K(2944064K), 0.0687660 secs]
[GC 623441K->352295K(2944064K), 0.0967800 secs]
[GC 608331K->398605K(2944064K), 0.0848950 secs]
[GC 654508K->429793K(2944064K), 0.0796880 secs]
[GC 685850K->410854K(2944064K), 0.0830200 secs]
[GC 666918K->465035K(2944064K), 0.0834350 secs]
[GC 721099K->438974K(2944064K), 0.0833500 secs]
[GC 695038K->496608K(2944064K), 0.0806600 secs]
[GC 752672K->470798K(2944064K), 0.0812400 secs]
[GC 726862K->525910K(2944064K), 0.0797900 secs]
[GC 781974K->502052K(2944064K), 0.0835120 secs]
[GC 758116K->544877K(2944064K), 0.0835520 secs]
[GC 800941K->520591K(2944064K), 0.0826060 secs]
[GC 776655K->578964K(2944064K), 0.0691910 secs]
[GC 835028K->552080K(2944064K), 0.0833330 secs]
[GC 807788K->578478K(2944064K), 0.0703930 secs]
[GC 834542K->613026K(2944064K), 0.0901460 secs]
[GC 868743K->593870K(2944064K), 0.0948890 secs]
[GC 849922K->632766K(2944064K), 0.0812450 secs]
[GC 888695K->625492K(2944064K), 0.1006410 secs]
[GC 881513K->636294K(2944064K), 0.0902500 secs]
[GC 892358K->650012K(2944064K), 0.0852340 secs]
[GC 905945K->681029K(2944064K), 0.0844450 secs]
[GC 937093K->696759K(2944064K), 0.0786500 secs]
[GC 952537K->712802K(2944064K), 0.0783390 secs]
[GC 968866K->743713K(2944064K), 0.0812240 secs]
[GC 999777K->726575K(2944064K), 0.0790290 secs]
[GC 982639K->760123K(2944064K), 0.0674520 secs]
[GC 1016187K->784581K(2944064K), 0.0847330 secs]
[GC 1040442K->786033K(2944064K), 0.0872060 secs]
[GC 1042097K->784796K(2944064K), 0.0828360 secs]
[GC 1040714K->820721K(2944064K), 0.0858010 secs]
[GC 1076785K->805161K(2944064K), 0.0944460 secs]
[GC 1061225K->847791K(2944064K), 0.0810980 secs]
[GC 1103842K->844257K(2944064K), 0.0820090 secs]
[GC 1100321K->874844K(2944064K), 0.0861890 secs]
[GC 1130884K->906772K(2944064K), 0.0849470 secs]
[GC 1162836K->890078K(2944064K), 0.0796030 secs]
[GC 1146142K->931631K(2944064K), 0.0862780 secs]
[GC 1187695K->956148K(2944064K), 0.0850530 secs]
[GC 1212212K->939354K(2944064K), 0.0841870 secs]
[GC 1195418K->995509K(2944064K), 0.0857750 secs]
[GC 1251540K->970484K(2944064K), 0.0871960 secs]
[GC 1226379K->1024909K(2944064K), 0.0898620 secs]
[GC 1280917K->1001204K(2944064K), 0.0875050 secs]
[GC 1257268K->1060948K(2944064K), 0.0901760 secs]
[GC 1317001K->1038697K(2944064K), 0.0943550 secs]
[GC 1294760K->1093451K(2944064K), 0.0970090 secs]
[GC 1349515K->1110768K(2944064K), 0.0994210 secs]
[GC 1366832K->1116769K(2944064K), 0.0949900 secs]
[GC 1372833K->1135532K(2944064K), 0.0949000 secs]
[GC 1391551K->1153172K(2944064K), 0.0922610 secs]
[GC 1409236K->1132291K(2944064K), 0.0933240 secs]
[GC 1388355K->1181431K(2944064K), 0.0848100 secs]
[GC 1437495K->1196006K(2944064K), 0.0830130 secs]
[GC 1452070K->1211424K(2944064K), 0.0841350 secs]
[GC 1467464K->1228512K(2944064K), 0.0874350 secs]
[GC 1484576K->1245491K(2944064K), 0.0867360 secs]
[GC 1501555K->1262694K(2944064K), 0.0865470 secs]
[GC 1518732K->1281006K(2944064K), 0.0821440 secs]
[GC 1537070K->1294355K(2944064K), 0.0841890 secs]
[GC 1550419K->1308037K(2944064K), 0.0836390 secs]
[GC 1564101K->1342429K(2944064K), 0.0900100 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-2] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.001 secs. Remaining: 59.999 secs. Total: 1 mins 0 secs
[GC 1598446K->1333302K(2944064K), 0.0814710 secs]
[GC 1589366K->1368516K(2944064K), 0.0870230 secs]
[GC 1624580K->1378443K(2944064K), 0.0926820 secs]
[GC 1378617K(2944064K), 0.0284450 secs]
[GC 1634507K->1397614K(2944064K), 0.0667580 secs]
[GC 1548447K(2944064K), 0.0477660 secs]
[GC 1610654K->1345994K(2944064K), 0.0857640 secs]
[GC 1602001K->1373172K(2944064K), 0.0776320 secs]
[GC 1629236K->1355378K(2944064K), 0.0591320 secs]
 INFO  [Stressor-1] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 193000. Elapsed time: 20.630 secs. Remaining: 39.370 secs. Total: 1 mins 0 secs
[GC 1610817K->1371752K(2944064K), 0.0744500 secs]
[GC 1627803K->1383262K(2944064K), 0.0704630 secs]
[GC 1639294K->1391157K(2944064K), 0.0679830 secs]
[GC 1647221K->1436481K(2944064K), 0.0697260 secs]
[GC 1692351K->1464209K(2944064K), 0.0983190 secs]
[GC 1720221K->1443487K(2944064K), 0.0541910 secs]
[GC 1699551K->1441881K(2944064K), 0.0632310 secs]
[GC 1697937K->1453743K(2944064K), 0.0548120 secs]
[GC 1709507K->1452155K(2944064K), 0.0586200 secs]
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 480000. Elapsed time: 40.640 secs. Remaining: 19.360 secs. Total: 1 mins 0 secs
[GC 1707949K->1495413K(2944064K), 0.0625950 secs]
[GC 1750944K->1495795K(2944064K), 0.0766610 secs]
[GC 1751859K->1487541K(2944064K), 0.0541120 secs]
[GC 1743477K->1524825K(2944064K), 0.0618220 secs]
[GC 1780840K->1504718K(2944064K), 0.0697870 secs]
[GC 1760422K->1504096K(2944064K), 0.0669030 secs]
[GC 1760160K->1536920K(2944064K), 0.0733050 secs]
[GC 1792983K->1552774K(2944064K), 0.0791580 secs]
[GC 1808234K->1556544K(2944064K), 0.0638690 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 10 mins 39 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestWarmupStage} The warmup took: 639 seconds.
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTestWarmup {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000, opsCountStatusLog=100000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=null, writePercentage=20, writeTxPercentage=20 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 1812608K->1546110K(2944064K), 0.0550190 secs]
[GC 1802174K->1583829K(2944064K), 0.0622200 secs]
[GC 1839634K->1612315K(2944064K), 0.0815570 secs]
[GC 1868379K->1582942K(2944064K), 0.0867890 secs]
[GC 1839006K->1634969K(2944064K), 0.0852160 secs]
[GC 1891010K->1654030K(2944064K), 0.0902540 secs]
[GC 1910045K->1671644K(2944064K), 0.0833560 secs]
[GC 1927708K->1689274K(2944064K), 0.0764340 secs]
[GC 1945338K->1706693K(2944064K), 0.0860050 secs]
[GC 1962757K->1724972K(2944064K), 0.0833520 secs]
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} Before executing clear, memory looks like this: Memory - free: 1,130,973 kb - max:4,906,688 kb- total:2,944,064 kb
[Full GC 1813090K->1683426K(2944064K), 4.6383630 secs]
 INFO  [pool-1-thread-1] {org.radargun.stages.ClearClusterStage} After executing cleanup, memory looks like this: Memory - free: 1,542,022 kb - max:4,906,688 kb- total:3,226,768 kb
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: ClearClusterStage {ClearCluster {exitBenchmarkOnSlaveFailure=false, runOnAllSlaves=false, slaves=[ 0 ], useSmartClassLoading=true }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
 INFO  [pool-1-thread-1] {org.radargun.Slave} Executing stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=100 }
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} Starting StressTestStage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=100 }
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Using key generator org.radargun.stressors.StringKeyGenerator, param null
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Executing: StressTestStressor{opsCountStatusLog=500000, numRequests=10000000, numEntries=1000, entrySize=1000, writePercentage=10, numThreads=4, cacheWrapper=org.radargun.cachewrappers.FFWrapper@5b0a7910, nodeIndex=5, useTransactions=true, transactionSize=1000, commitTransactions=true, durationMillis=60000}
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Cache wrapper info is: FFWrapper using infinispan52
[GC 1964130K->1758900K(3226768K), 0.0338890 secs]
[GC 2039604K->1726274K(3226768K), 0.0468470 secs]
[GC 2006978K->1740325K(3226768K), 0.0571090 secs]
[GC 2021029K->1769847K(3226768K), 0.0647540 secs]
[GC 2050551K->1803383K(3226768K), 0.0703010 secs]
[GC 2084087K->1825907K(3226768K), 0.1075620 secs]
[GC 2106611K->1840724K(3226768K), 0.0832450 secs]
[GC 2121428K->1876281K(3226768K), 0.0918360 secs]
[GC 2156985K->1856655K(3226768K), 0.0899590 secs]
[GC 2137359K->1899530K(3226768K), 0.0887570 secs]
[GC 2180234K->1909025K(3226768K), 0.0923320 secs]
[GC 2189729K->1947477K(3226768K), 0.0893110 secs]
[GC 2228168K->1929139K(3226768K), 0.0922630 secs]
[GC 2209843K->1974480K(3226768K), 0.0928960 secs]
[GC 2255184K->2005752K(3226768K), 0.0983670 secs]
[GC 2286456K->2028363K(3226768K), 0.1077210 secs]
[GC 2308948K->2035585K(3226768K), 0.1079550 secs]
[GC 2316289K->2057738K(3226768K), 0.1057290 secs]
[GC 2338212K->2057348K(3226768K), 0.1082040 secs]
[GC 2337902K->2100485K(3226768K), 0.1043310 secs]
[GC 2381107K->2119455K(3226768K), 0.1040670 secs]
[GC 2400159K->2116612K(3226768K), 0.1049720 secs]
[GC 2397316K->2113126K(3226768K), 0.0974130 secs]
[GC 2393773K->2150672K(3226768K), 0.0960010 secs]
[GC 2431376K->2187377K(3226768K), 0.0965970 secs]
[GC 2468081K->2184195K(3226768K), 0.0906070 secs]
[GC 2464899K->2200840K(3226768K), 0.0918160 secs]
[GC 2481544K->2197797K(3226768K), 0.0865250 secs]
[GC 2478501K->2264137K(3226768K), 0.0688090 secs]
[GC 2544841K->2236918K(3226768K), 0.0963850 secs]
[GC 2517622K->2299240K(3226768K), 0.0835140 secs]
[GC 2579927K->2269487K(3226768K), 0.0850160 secs]
[GC 2550191K->2323066K(3226768K), 0.0822460 secs]
[GC 2603770K->2305293K(3226768K), 0.0830900 secs]
[GC 2585997K->2308126K(3226768K), 0.1069730 secs]
[GC 2588804K->2358979K(3226768K), 0.0855450 secs]
[GC 2639683K->2375052K(3226768K), 0.0839780 secs]
[GC 2655756K->2391292K(3226768K), 0.0849200 secs]
[GC 2671996K->2406933K(3226768K), 0.0879720 secs]
[GC 2687612K->2444684K(3226768K), 0.0852940 secs]
[GC 2725388K->2425634K(3226768K), 0.0859190 secs]
[GC 2706338K->2468649K(3226768K), 0.0858120 secs]
[GC 2749353K->2473532K(3226768K), 0.0867000 secs]
[GC 2754236K->2510944K(3226768K), 0.0899170 secs]
[GC 2791648K->2493329K(3226768K), 0.0908200 secs]
[GC 2774033K->2556408K(3226768K), 0.0964670 secs]
[GC 2837080K->2529584K(3226768K), 0.0901800 secs]
[GC 2810235K->2592837K(3226768K), 0.0851570 secs]
[GC 2873541K->2567690K(3226768K), 0.0916680 secs]
[GC 2848394K->2628809K(3226768K), 0.0841320 secs]
[GC 2909513K->2608581K(3226768K), 0.0887320 secs]
[GC 2889285K->2666458K(3226768K), 0.0863060 secs]
[GC 2947162K->2641990K(3226768K), 0.0846960 secs]
[GC 2922694K->2701450K(3226768K), 0.0898350 secs]
[GC 2982154K->2678331K(3226768K), 0.0865670 secs]
[GC 2959035K->2736715K(3226768K), 0.0850440 secs]
[GC 2737302K(3226768K), 0.0466960 secs]
[GC 3017419K->2714000K(3226768K), 0.0875200 secs]
[GC 2784372K(3226768K), 0.0376880 secs]
[GC 2903286K->2681669K(4625804K), 0.0941970 secs]
[GC 2962373K->2659489K(4625804K), 0.0945450 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Started 4 stressor threads.
 INFO  [Stressor-0] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 1. Elapsed time: 0.000 secs. Remaining: 1 mins 0 secs. Total: 1 mins 0 secs
[GC 2940164K->2721364K(4625804K), 0.0938780 secs]
[GC 3002068K->2699221K(4625804K), 0.0963120 secs]
[GC 2979925K->2732775K(4625804K), 0.1009480 secs]
[GC 3013479K->2770164K(4625804K), 0.0735180 secs]
[GC 3050868K->2752104K(4625804K), 0.0903140 secs]
[GC 3032576K->2767515K(4625804K), 0.0909890 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 47000. Elapsed time: 20.195 secs. Remaining: 39.805 secs. Total: 1 mins 0 secs
[GC 3048219K->2786998K(4625804K), 0.0843660 secs]
[GC 3067686K->2801080K(4625804K), 0.0836730 secs]
[GC 3081784K->2807466K(4625804K), 0.0866600 secs]
[GC 3088170K->2822091K(4625804K), 0.0861350 secs]
[GC 3102795K->2840634K(4625804K), 0.0835110 secs]
[GC 3121338K->2850641K(4625804K), 0.0869360 secs]
 INFO  [Stressor-3] {org.radargun.stressors.StressTestStressor} Number of ops executed so far: 106000. Elapsed time: 40.272 secs. Remaining: 19.728 secs. Total: 1 mins 0 secs
[GC 3130965K->2862890K(4625804K), 0.0872470 secs]
[GC 3143594K->2874960K(4625804K), 0.0842680 secs]
[GC 3155661K->2889827K(4625804K), 0.0900410 secs]
[GC 3170531K->2927747K(4625804K), 0.0983400 secs]
[GC 3208451K->2931439K(4625804K), 0.0707170 secs]
[GC 3212143K->2934507K(4625804K), 0.0848840 secs]
 INFO  [pool-1-thread-1] {org.radargun.stressors.StressTestStressor} Finished generating report. Test duration is: 8 mins 33 secs
 INFO  [pool-1-thread-1] {org.radargun.stages.StressTestStage} size info: FFWrapper using infinispan52, clusterSize:10, nodeIndex:5, cacheSize: -1
 INFO  [pool-1-thread-1] {org.radargun.Slave} Finished stage: StressTest {bulkSize=1, cacheSpecificKeyGenerator=false, commitTransactions=true, duration=1 mins 0 secs, entrySize=1000, exitBenchmarkOnSlaveFailure=false, fixedKeys=true, generateHistogramRange=false, keyGeneratorClass=org.radargun.stressors.StringKeyGenerator, keyGeneratorParam=null, loadAllKeys=false, numEntries=1000, numOfThreads=4, numRequests=10000000, numThreads=4, numberOfAttributes=1000, numberOfRequests=10000000, opsCountStatusLog=500000, poolKeys=true, preferAsyncOperations=false, removePercentage=0, replaceInvalidPercentage=40, runOnAllSlaves=false, sharedKeys=false, sizeOfAnAttribute=1000, slaves=null, transactionSize=1000, useAtomics=false, useHistogramStatistics=false, useSimpleStatistics=true, useSmartClassLoading=true, useTransactions=true, writePercentage=10, writeTxPercentage=100 }
 INFO  [main] {org.radargun.Slave} Ack successfully sent to the master
[GC 3215165K->2952196K(4625804K), 0.0825960 secs]
[GC 3232900K->2943236K(4625804K), 0.0862740 secs]
 INFO  [main] {org.radargun.Slave} Master shutdown!
 INFO  [Thread-0] {org.radargun.ShutDownHook} Slave process is being shutdown
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5708] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5702] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5701] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5703] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5704] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5705] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5707] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5709] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.nio.TcpIpConnection} [127.0.0.1]:5706 [FenixFrameworkGroup] Connection [Address[127.0.0.1]:5710] lost. Reason: Socket explicitly closed
 INFO  [hz.ShutdownThread] {com.hazelcast.initializer} [127.0.0.1]:5706 [FenixFrameworkGroup] Destroying node initializer.
 INFO  [hz.ShutdownThread] {com.hazelcast.instance.Node} [127.0.0.1]:5706 [FenixFrameworkGroup] Hazelcast Shutdown is completed in 49 ms.
